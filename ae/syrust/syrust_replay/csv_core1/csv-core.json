{"dependencies":{"<QuoteStyle as core::clone::Clone>::clone":["QuoteStyle"],"<QuoteStyle as core::default::Default>::default":["QuoteStyle"],"<QuoteStyle as core::fmt::Debug>::fmt":["QuoteStyle","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<Terminator as core::clone::Clone>::clone":["Terminator"],"<Terminator as core::default::Default>::default":["Terminator"],"<Terminator as core::fmt::Debug>::fmt":["Terminator","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<reader::Dfa as core::clone::Clone>::clone":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"<reader::Dfa as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::Dfa","reader::DfaClasses","reader::DfaState"],"<reader::DfaClasses as core::clone::Clone>::clone":["reader::DfaClasses"],"<reader::DfaClasses as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::DfaClasses"],"<reader::DfaState as core::clone::Clone>::clone":["reader::DfaState"],"<reader::DfaState as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::DfaState"],"<reader::DfaState as core::cmp::Ord>::cmp":["core::cmp::Ordering","reader::DfaState"],"<reader::DfaState as core::cmp::PartialEq>::eq":["reader::DfaState"],"<reader::DfaState as core::cmp::PartialOrd>::partial_cmp":["core::marker::Sized","core::option::Option","reader::DfaState"],"<reader::DfaState as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::DfaState"],"<reader::NfaInputAction as core::clone::Clone>::clone":["reader::NfaInputAction"],"<reader::NfaInputAction as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::NfaInputAction"],"<reader::NfaInputAction as core::cmp::PartialEq>::eq":["reader::NfaInputAction"],"<reader::NfaInputAction as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::NfaInputAction"],"<reader::NfaState as core::clone::Clone>::clone":["reader::NfaState"],"<reader::NfaState as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::NfaState"],"<reader::NfaState as core::cmp::PartialEq>::eq":["reader::NfaState"],"<reader::NfaState as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::NfaState"],"<reader::ReadFieldNoCopyResult as core::clone::Clone>::clone":["reader::ReadFieldNoCopyResult"],"<reader::ReadFieldNoCopyResult as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::ReadFieldNoCopyResult"],"<reader::ReadFieldNoCopyResult as core::cmp::PartialEq>::eq":["reader::ReadFieldNoCopyResult"],"<reader::ReadFieldNoCopyResult as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::ReadFieldNoCopyResult"],"<reader::ReadFieldResult as core::clone::Clone>::clone":["reader::ReadFieldResult"],"<reader::ReadFieldResult as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::ReadFieldResult"],"<reader::ReadFieldResult as core::cmp::PartialEq>::eq":["reader::ReadFieldResult"],"<reader::ReadFieldResult as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::ReadFieldResult"],"<reader::ReadRecordNoCopyResult as core::clone::Clone>::clone":["reader::ReadRecordNoCopyResult"],"<reader::ReadRecordNoCopyResult as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::ReadRecordNoCopyResult"],"<reader::ReadRecordNoCopyResult as core::cmp::PartialEq>::eq":["reader::ReadRecordNoCopyResult"],"<reader::ReadRecordNoCopyResult as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::ReadRecordNoCopyResult"],"<reader::ReadRecordResult as core::clone::Clone>::clone":["reader::ReadRecordResult"],"<reader::ReadRecordResult as core::cmp::Eq>::assert_receiver_is_total_eq":["reader::ReadRecordResult"],"<reader::ReadRecordResult as core::cmp::PartialEq>::eq":["reader::ReadRecordResult"],"<reader::ReadRecordResult as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","reader::ReadRecordResult"],"<reader::Reader as core::clone::Clone>::clone":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"<reader::Reader as core::default::Default>::default":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"<reader::Reader as core::fmt::Debug>::fmt":["Terminator","core::fmt::Formatter","core::marker::Sized","core::option::Option","core::result::Result","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"<reader::ReaderBuilder as core::default::Default>::default":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"<reader::ReaderBuilder as core::fmt::Debug>::fmt":["Terminator","core::fmt::Formatter","core::marker::Sized","core::option::Option","core::result::Result","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"<writer::WriteResult as core::clone::Clone>::clone":["writer::WriteResult"],"<writer::WriteResult as core::cmp::Eq>::assert_receiver_is_total_eq":["writer::WriteResult"],"<writer::WriteResult as core::cmp::PartialEq>::eq":["writer::WriteResult"],"<writer::WriteResult as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","writer::WriteResult"],"<writer::Writer as core::clone::Clone>::clone":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"<writer::Writer as core::default::Default>::default":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"<writer::Writer as core::fmt::Debug>::fmt":["QuoteStyle","Terminator","core::fmt::Formatter","core::marker::Sized","core::result::Result","writer::Writer","writer::WriterState"],"<writer::WriterBuilder as core::default::Default>::default":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"<writer::WriterBuilder as core::fmt::Debug>::fmt":["QuoteStyle","Terminator","core::fmt::Formatter","core::marker::Sized","core::result::Result","writer::Writer","writer::WriterBuilder","writer::WriterState"],"<writer::WriterState as core::clone::Clone>::clone":["writer::WriterState"],"<writer::WriterState as core::default::Default>::default":["writer::WriterState"],"<writer::WriterState as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::Sized","core::result::Result","writer::WriterState"],"QuoteStyle":["QuoteStyle"],"Terminator":["Terminator"],"Terminator::equals":["Terminator"],"Terminator::is_crlf":["Terminator"],"reader::Dfa":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::finish":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::get_output":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::new":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::new_read_field_result":["reader::Dfa","reader::DfaClasses","reader::DfaState","reader::ReadFieldResult"],"reader::Dfa::new_read_record_result":["reader::Dfa","reader::DfaClasses","reader::DfaState","reader::ReadRecordResult"],"reader::Dfa::new_state":["reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState"],"reader::Dfa::new_state_final_end":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::new_state_final_record":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::Dfa::set":["reader::Dfa","reader::DfaClasses","reader::DfaState"],"reader::DfaClasses":["reader::DfaClasses"],"reader::DfaClasses::add":["reader::DfaClasses"],"reader::DfaClasses::new":["reader::DfaClasses"],"reader::DfaClasses::num_classes":["reader::DfaClasses"],"reader::DfaClasses::scan_and_copy":["reader::DfaClasses"],"reader::DfaState":["reader::DfaState"],"reader::DfaState::is_start":["reader::DfaState"],"reader::DfaState::start":["reader::DfaState"],"reader::NfaInputAction":["reader::NfaInputAction"],"reader::NfaState":["reader::NfaState"],"reader::NfaState::is_field_final":["reader::NfaState"],"reader::NfaState::is_record_final":["reader::NfaState"],"reader::ReadFieldNoCopyResult":["reader::ReadFieldNoCopyResult"],"reader::ReadFieldResult":["reader::ReadFieldResult"],"reader::ReadFieldResult::from_nfa":["reader::NfaState","reader::ReadFieldResult"],"reader::ReadRecordNoCopyResult":["reader::ReadRecordNoCopyResult"],"reader::ReadRecordResult":["reader::ReadRecordResult"],"reader::ReadRecordResult::from_nfa":["reader::NfaState","reader::ReadRecordResult"],"reader::ReadRecordResult::is_record":["reader::ReadRecordResult"],"reader::Reader":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::build_dfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::line":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::new":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::read_field":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadFieldResult","reader::Reader"],"reader::Reader::read_field_dfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadFieldResult","reader::Reader"],"reader::Reader::read_field_nfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadFieldResult","reader::Reader"],"reader::Reader::read_record":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadRecordResult","reader::Reader"],"reader::Reader::read_record_dfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadRecordResult","reader::Reader"],"reader::Reader::read_record_nfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::ReadRecordResult","reader::Reader"],"reader::Reader::reset":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::set_line":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::strip_utf8_bom":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::transition_final_dfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::transition_final_nfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader"],"reader::Reader::transition_nfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::Reader"],"reader::ReaderBuilder":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::ascii":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::build":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::comment":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::delimiter":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::double_quote":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::escape":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::new":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::nfa":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::quote":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::quoting":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"reader::ReaderBuilder::terminator":["Terminator","core::marker::Sized","core::option::Option","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaState","reader::Reader","reader::ReaderBuilder"],"writer::WriteResult":["writer::WriteResult"],"writer::Writer":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::delimiter":["QuoteStyle","Terminator","writer::WriteResult","writer::Writer","writer::WriterState"],"writer::Writer::field":["QuoteStyle","Terminator","writer::WriteResult","writer::Writer","writer::WriterState"],"writer::Writer::finish":["QuoteStyle","Terminator","writer::WriteResult","writer::Writer","writer::WriterState"],"writer::Writer::get_delimiter":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::get_double_quote":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::get_escape":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::get_quote":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::get_quote_style":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::get_terminator":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::is_special_byte":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::needs_quotes":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::new":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::should_quote":["QuoteStyle","Terminator","writer::Writer","writer::WriterState"],"writer::Writer::terminator":["QuoteStyle","Terminator","writer::WriteResult","writer::Writer","writer::WriterState"],"writer::Writer::write":["QuoteStyle","Terminator","writer::WriteResult","writer::Writer","writer::WriterState"],"writer::WriterBuilder":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::build":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::delimiter":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::double_quote":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::escape":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::new":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::quote":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::quote_style":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterBuilder::terminator":["QuoteStyle","Terminator","writer::Writer","writer::WriterBuilder","writer::WriterState"],"writer::WriterState":["writer::WriterState"],"writer::is_non_numeric":[],"writer::moving":["core::marker::Sized"],"writer::quote":["writer::WriteResult"],"writer::write_optimistic":["writer::WriteResult"],"writer::write_pessimistic":["writer::WriteResult"]},"glob_path_import":{},"self_to_fn":{"QuoteStyle":["Clone","Copy","Debug","impl Default for QuoteStyle {\n    fn default() -> QuoteStyle {\n        QuoteStyle::Necessary\n    }\n}"],"Terminator":["Clone","Copy","Debug","impl Default for Terminator {\n    fn default() -> Terminator {\n        Terminator::CRLF\n    }\n}","impl Terminator {\n    /// Checks whether the terminator is set to CRLF.\n    fn is_crlf(&self) -> bool {\n        match *self {\n            Terminator::CRLF => true,\n            Terminator::Any(_) => false,\n            _ => unreachable!(),\n        }\n    }\n\n    fn equals(&self, other: u8) -> bool {\n        match *self {\n            Terminator::CRLF => other == b'\\r' || other == b'\\n',\n            Terminator::Any(b) => other == b,\n            _ => unreachable!(),\n        }\n    }\n}"],"reader::Dfa":["impl Clone for Dfa {\n    fn clone(&self) -> Dfa {\n        let mut dfa = Dfa::new();\n        dfa.trans.copy_from_slice(&self.trans);\n        dfa\n    }\n}","impl Dfa {\n    fn new() -> Dfa {\n        Dfa {\n            trans: [DfaState(0); TRANS_SIZE],\n            has_output: [false; TRANS_SIZE],\n            classes: DfaClasses::new(),\n            in_field: DfaState(0),\n            in_quoted: DfaState(0),\n            final_field: DfaState(0),\n            final_record: DfaState(0),\n        }\n    }\n\n    fn new_state(&self, nfa_state: NfaState) -> DfaState {\n        let nclasses = self.classes.num_classes() as u8;\n        let idx = (nfa_state as u8).checked_mul(nclasses).unwrap();\n        DfaState(idx)\n    }\n\n    fn new_state_final_end(&self) -> DfaState {\n        self.new_state(NfaState::StartRecord)\n    }\n\n    fn new_state_final_record(&self) -> DfaState {\n        self.new_state(NfaState::EndRecord)\n    }\n\n    fn get_output(&self, state: DfaState, c: u8) -> (DfaState, bool) {\n        let cls = self.classes.classes[c as usize];\n        let idx = state.0 as usize + cls as usize;\n        (self.trans[idx], self.has_output[idx])\n    }\n\n    fn set(&mut self, from: DfaState, c: u8, to: DfaState, output: bool) {\n        let cls = self.classes.classes[c as usize];\n        let idx = from.0 as usize + cls as usize;\n        self.trans[idx] = to;\n        self.has_output[idx] = output;\n    }\n\n    fn finish(&mut self) {\n        self.in_field = self.new_state(NfaState::InField);\n        self.in_quoted = self.new_state(NfaState::InQuotedField);\n        self.final_field = self.new_state(NfaState::EndFieldDelim);\n        self.final_record = self.new_state(NfaState::EndRecord);\n    }\n\n    fn new_read_field_result(\n        &self,\n        state: DfaState,\n        is_final_trans: bool,\n        inpdone: bool,\n        outdone: bool,\n    ) -> ReadFieldResult {\n        if state >= self.final_record {\n            ReadFieldResult::Field { record_end: true }\n        } else if state == self.final_field {\n            ReadFieldResult::Field { record_end: false }\n        } else if is_final_trans && state.is_start() {\n            ReadFieldResult::End\n        } else {\n            debug_assert!(state < self.final_field);\n            if !inpdone && outdone {\n                ReadFieldResult::OutputFull\n            } else {\n                ReadFieldResult::InputEmpty\n            }\n        }\n    }\n\n    fn new_read_record_result(\n        &self,\n        state: DfaState,\n        is_final_trans: bool,\n        inpdone: bool,\n        outdone: bool,\n        endsdone: bool,\n    ) -> ReadRecordResult {\n        if state >= self.final_record {\n            ReadRecordResult::Record\n        } else if is_final_trans && state.is_start() {\n            ReadRecordResult::End\n        } else {\n            debug_assert!(state < self.final_record);\n            if !inpdone && outdone {\n                ReadRecordResult::OutputFull\n            } else if !inpdone && endsdone {\n                ReadRecordResult::OutputEndsFull\n            } else {\n                ReadRecordResult::InputEmpty\n            }\n        }\n    }\n}","impl fmt::Debug for Dfa {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(f, \"Dfa(N/A)\")\n    }\n}"],"reader::DfaClasses":["impl Clone for DfaClasses {\n    fn clone(&self) -> DfaClasses {\n        let mut x = DfaClasses::new();\n        x.classes.copy_from_slice(&self.classes);\n        x\n    }\n}","impl DfaClasses {\n    fn new() -> DfaClasses {\n        DfaClasses { classes: [0; CLASS_SIZE], next_class: 1 }\n    }\n\n    fn add(&mut self, b: u8) {\n        if self.next_class > CLASS_SIZE {\n            panic!(\"added too many classes\")\n        }\n        self.classes[b as usize] = self.next_class as u8;\n        self.next_class = self.next_class + 1;\n    }\n\n    fn num_classes(&self) -> usize {\n        self.next_class as usize\n    }\n\n    /// Scan and copy the input bytes to the output buffer quickly.\n    ///\n    /// This assumes that the current state of the DFA is either `InField` or\n    /// `InQuotedField`. In this case, all bytes corresponding to the first\n    /// equivalence class (i.e., not a delimiter/quote/escape/etc.) are\n    /// guaranteed to never result in a state transition out of the current\n    /// state. This function takes advantage of that copies every byte from\n    /// `input` in the first equivalence class to `output`. Once a byte is seen\n    /// outside the first equivalence class, we quit and should fall back to\n    /// the main DFA loop.\n    #[inline(always)]\n    fn scan_and_copy(\n        &self,\n        input: &[u8],\n        nin: &mut usize,\n        output: &mut [u8],\n        nout: &mut usize,\n    ) {\n        while *nin < input.len()\n            && *nout < output.len()\n            && self.classes[input[*nin] as usize] == 0\n        {\n            output[*nout] = input[*nin];\n            *nin += 1;\n            *nout += 1;\n        }\n    }\n}","impl fmt::Debug for DfaClasses {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(\n            f,\n            \"DfaClasses {{ classes: N/A, next_class: {:?} }}\",\n            self.next_class\n        )\n    }\n}"],"reader::DfaState":["Clone","Copy","Debug","Eq","Ord","PartialEq","PartialOrd","impl DfaState {\n    fn start() -> DfaState {\n        DfaState(0)\n    }\n\n    fn is_start(&self) -> bool {\n        self.0 == 0\n    }\n}"],"reader::NfaInputAction":["Clone","Debug","Eq","PartialEq"],"reader::NfaState":["Clone","Copy","Debug","Eq","PartialEq","impl NfaState {\n    /// Returns true if this state indicates that a field has been parsed.\n    fn is_field_final(&self) -> bool {\n        match *self {\n            NfaState::End\n            | NfaState::EndRecord\n            | NfaState::CRLF\n            | NfaState::EndFieldDelim => true,\n            _ => false,\n        }\n    }\n\n    /// Returns true if this state indicates that a record has been parsed.\n    fn is_record_final(&self) -> bool {\n        match *self {\n            NfaState::End | NfaState::EndRecord | NfaState::CRLF => true,\n            _ => false,\n        }\n    }\n}"],"reader::ReadFieldNoCopyResult":["Clone","Debug","Eq","PartialEq"],"reader::ReadFieldResult":["Clone","Debug","Eq","PartialEq","impl ReadFieldResult {\n    fn from_nfa(\n        state: NfaState,\n        inpdone: bool,\n        outdone: bool,\n    ) -> ReadFieldResult {\n        match state {\n            NfaState::End => ReadFieldResult::End,\n            NfaState::EndRecord | NfaState::CRLF => {\n                ReadFieldResult::Field { record_end: true }\n            }\n            NfaState::EndFieldDelim => {\n                ReadFieldResult::Field { record_end: false }\n            }\n            _ => {\n                assert!(!state.is_field_final());\n                if !inpdone && outdone {\n                    ReadFieldResult::OutputFull\n                } else {\n                    ReadFieldResult::InputEmpty\n                }\n            }\n        }\n    }\n}"],"reader::ReadRecordNoCopyResult":["Clone","Debug","Eq","PartialEq"],"reader::ReadRecordResult":["Clone","Debug","Eq","PartialEq","impl ReadRecordResult {\n    fn is_record(&self) -> bool {\n        *self == ReadRecordResult::Record\n    }\n\n    fn from_nfa(\n        state: NfaState,\n        inpdone: bool,\n        outdone: bool,\n        endsdone: bool,\n    ) -> ReadRecordResult {\n        match state {\n            NfaState::End => ReadRecordResult::End,\n            NfaState::EndRecord | NfaState::CRLF => ReadRecordResult::Record,\n            _ => {\n                assert!(!state.is_record_final());\n                if !inpdone && outdone {\n                    ReadRecordResult::OutputFull\n                } else if !inpdone && endsdone {\n                    ReadRecordResult::OutputEndsFull\n                } else {\n                    ReadRecordResult::InputEmpty\n                }\n            }\n        }\n    }\n}"],"reader::Reader":["Clone","Debug","impl Default for Reader {\n    fn default() -> Reader {\n        Reader {\n            dfa: Dfa::new(),\n            dfa_state: DfaState::start(),\n            nfa_state: NfaState::StartRecord,\n            delimiter: b',',\n            term: Terminator::default(),\n            quote: b'\"',\n            escape: None,\n            double_quote: true,\n            comment: None,\n            quoting: true,\n            use_nfa: false,\n            line: 1,\n            has_read: false,\n            output_pos: 0,\n        }\n    }\n}","impl Reader {\n    /// Create a new CSV reader with a default parser configuration.\n    pub fn new() -> Reader {\n        ReaderBuilder::new().build()\n    }\n\n    /// Reset the parser such that it behaves as if it had never been used.\n    ///\n    /// This may be useful when reading CSV data in a random access pattern.\n    pub fn reset(&mut self) {\n        self.dfa_state = self.dfa.new_state(NfaState::StartRecord);\n        self.nfa_state = NfaState::StartRecord;\n        self.line = 1;\n        self.has_read = false;\n    }\n\n    /// Return the current line number as measured by the number of occurrences\n    /// of `\\n`.\n    ///\n    /// Line numbers starts at `1` and are reset when `reset` is called.\n    pub fn line(&self) -> u64 {\n        self.line\n    }\n\n    /// Set the line number.\n    ///\n    /// This is useful after a call to `reset` where the caller knows the\n    /// line number from some additional context.\n    pub fn set_line(&mut self, line: u64) {\n        self.line = line;\n    }\n\n    /// Parse a single CSV field in `input` and copy field data to `output`.\n    ///\n    /// This routine requires a caller provided buffer of CSV data as the\n    /// `input` and a caller provided buffer, `output`, in which to store field\n    /// data extracted from `input`. The field data copied to `output` will\n    /// have its quotes unescaped.\n    ///\n    /// Calling this routine parses at most a single field and returns\n    /// three values indicating the state of the parser. The first value, a\n    /// `ReadFieldResult`, tells the caller what to do next. For example, if\n    /// the entire input was read or if the output buffer was filled before\n    /// a full field had been read, then `ReadFieldResult::InputEmpty` or\n    /// `ReadFieldResult::OutputFull` is returned, respectively. See the\n    /// documentation for `ReadFieldResult` for more details.\n    ///\n    /// The other two values returned correspond to the number of bytes\n    /// read from `input` and written to `output`, respectively.\n    ///\n    /// # Termination\n    ///\n    /// This reader interprets an empty `input` buffer as an indication that\n    /// there is no CSV data left to read. Namely, when the caller has\n    /// exhausted all CSV data, the caller should continue to call `read` with\n    /// an empty input buffer until `ReadFieldResult::End` is returned.\n    ///\n    /// # Errors\n    ///\n    /// This CSV reader can never return an error. Instead, it prefers *a*\n    /// parse over *no* parse.\n    pub fn read_field(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize) {\n        let (input, bom_nin) = self.strip_utf8_bom(input);\n        let (res, nin, nout) = if self.use_nfa {\n            self.read_field_nfa(input, output)\n        } else {\n            self.read_field_dfa(input, output)\n        };\n        self.has_read = true;\n        (res, nin + bom_nin, nout)\n    }\n\n    /// Parse a single CSV record in `input` and copy each field contiguously\n    /// to `output`, with the end position of each field written to `ends`.\n    ///\n    /// **NOTE**: This method is more cumbersome to use than `read_field`, but\n    /// it can be faster since it amortizes more work.\n    ///\n    /// This routine requires a caller provided buffer of CSV data as the\n    /// `input` and two caller provided buffers to store the unescaped field\n    /// data (`output`) and the end position of each field in the record\n    /// (`fields`).\n    ///\n    /// Calling this routine parses at most a single record and returns four\n    /// values indicating the state of the parser. The first value, a\n    /// `ReadRecordResult`, tells the caller what to do next. For example, if\n    /// the entire input was read or if the output buffer was filled before a\n    /// full field had been read, then `ReadRecordResult::InputEmpty` or\n    /// `ReadRecordResult::OutputFull` is returned, respectively. Similarly, if\n    /// the `ends` buffer is full, then `ReadRecordResult::OutputEndsFull` is\n    /// returned. See the documentation for `ReadRecordResult` for more\n    /// details.\n    ///\n    /// The other three values correspond to the number of bytes read from\n    /// `input`, the number of bytes written to `output` and the number of\n    /// end positions written to `ends`, respectively.\n    ///\n    /// The end positions written to `ends` are constructed as if there was\n    /// a single contiguous buffer in memory containing the entire row, even\n    /// if `ReadRecordResult::OutputFull` was returned in the middle of reading\n    /// a row.\n    ///\n    /// # Termination\n    ///\n    /// This reader interprets an empty `input` buffer as an indication that\n    /// there is no CSV data left to read. Namely, when the caller has\n    /// exhausted all CSV data, the caller should continue to call `read` with\n    /// an empty input buffer until `ReadRecordResult::End` is returned.\n    ///\n    /// # Errors\n    ///\n    /// This CSV reader can never return an error. Instead, it prefers *a*\n    /// parse over *no* parse.\n    pub fn read_record(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize) {\n        let (input, bom_nin) = self.strip_utf8_bom(input);\n        let (res, nin, nout, nend) = if self.use_nfa {\n            self.read_record_nfa(input, output, ends)\n        } else {\n            self.read_record_dfa(input, output, ends)\n        };\n        self.has_read = true;\n        (res, nin + bom_nin, nout, nend)\n    }\n\n    /// Strip off a possible UTF-8 BOM at the start of a file. Quick note that\n    /// this method will fail to strip off the BOM if only part of the BOM is\n    /// buffered. Hopefully that won't happen very often.\n    fn strip_utf8_bom<'a>(&self, input: &'a [u8]) -> (&'a [u8], usize) {\n        let (input, nin) = if {\n            !self.has_read\n                && input.len() >= 3\n                && &input[0..3] == b\"\\xef\\xbb\\xbf\"\n        } {\n            (&input[3..], 3)\n        } else {\n            (input, 0)\n        };\n        (input, nin)\n    }\n\n    #[inline(always)]\n    fn read_record_dfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize) {\n        if input.is_empty() {\n            let s = self.transition_final_dfa(self.dfa_state);\n            let res =\n                self.dfa.new_read_record_result(s, true, false, false, false);\n            // This part is a little tricky. When reading the final record,\n            // the last result the caller will get is an InputEmpty, and while\n            // they'll have everything they need in `output`, they'll be\n            // missing the final end position of the final field in `ends`.\n            // We insert that here, but we must take care to handle the case\n            // where `ends` doesn't have enough space. If it doesn't have\n            // enough space, then we also can't transition to the next state.\n            return match res {\n                ReadRecordResult::Record => {\n                    if ends.is_empty() {\n                        return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n                    }\n                    self.dfa_state = s;\n                    ends[0] = self.output_pos;\n                    self.output_pos = 0;\n                    (res, 0, 0, 1)\n                }\n                _ => {\n                    self.dfa_state = s;\n                    (res, 0, 0, 0)\n                }\n            };\n        }\n        if output.is_empty() {\n            return (ReadRecordResult::OutputFull, 0, 0, 0);\n        }\n        if ends.is_empty() {\n            return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n        }\n        let (mut nin, mut nout, mut nend) = (0, 0, 0);\n        let mut state = self.dfa_state;\n        while nin < input.len() && nout < output.len() && nend < ends.len() {\n            let (s, has_out) = self.dfa.get_output(state, input[nin]);\n            self.line += (input[nin] == b'\\n') as u64;\n            state = s;\n            if has_out {\n                output[nout] = input[nin];\n                nout += 1;\n            }\n            nin += 1;\n            if state >= self.dfa.final_field {\n                ends[nend] = self.output_pos + nout;\n                nend += 1;\n                if state > self.dfa.final_field {\n                    break;\n                }\n            }\n            if state == self.dfa.in_field || state == self.dfa.in_quoted {\n                self.dfa\n                    .classes\n                    .scan_and_copy(input, &mut nin, output, &mut nout);\n            }\n        }\n        let res = self.dfa.new_read_record_result(\n            state,\n            false,\n            nin >= input.len(),\n            nout >= output.len(),\n            nend >= ends.len(),\n        );\n        self.dfa_state = state;\n        if res.is_record() {\n            self.output_pos = 0;\n        } else {\n            self.output_pos += nout;\n        }\n        (res, nin, nout, nend)\n    }\n\n    #[inline(always)]\n    fn read_field_dfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize) {\n        if input.is_empty() {\n            self.dfa_state = self.transition_final_dfa(self.dfa_state);\n            let res = self.dfa.new_read_field_result(\n                self.dfa_state,\n                true,\n                false,\n                false,\n            );\n            return (res, 0, 0);\n        }\n        if output.is_empty() {\n            return (ReadFieldResult::OutputFull, 0, 0);\n        }\n        let (mut nin, mut nout) = (0, 0);\n        let mut state = self.dfa_state;\n        while nin < input.len() && nout < output.len() {\n            let b = input[nin];\n            self.line += (b == b'\\n') as u64;\n            let (s, has_out) = self.dfa.get_output(state, b);\n            state = s;\n            if has_out {\n                output[nout] = b;\n                nout += 1;\n            }\n            nin += 1;\n            if state >= self.dfa.final_field {\n                break;\n            }\n        }\n        let res = self.dfa.new_read_field_result(\n            state,\n            false,\n            nin >= input.len(),\n            nout >= output.len(),\n        );\n        self.dfa_state = state;\n        (res, nin, nout)\n    }\n\n    /// Perform the final state transition, i.e., when the caller indicates\n    /// that the input has been exhausted.\n    fn transition_final_dfa(&self, state: DfaState) -> DfaState {\n        // If we''ve already emitted a record or think we're ready to start\n        // parsing a new record, then we should sink into the final state\n        // and never move from there. (pro-tip: the start state doubles as\n        // the final state!)\n        if state >= self.dfa.final_record || state.is_start() {\n            self.dfa.new_state_final_end()\n        } else {\n            self.dfa.new_state_final_record()\n        }\n    }\n\n    /// Write the transition tables for the DFA based on this parser's\n    /// configuration.\n    fn build_dfa(&mut self) {\n        // A naive DFA transition table has\n        // `cells = (# number of states) * (# size of alphabet)`. While we\n        // could get away with that, the table would have `10 * 256 = 2560`\n        // entries. Even worse, in order to avoid a multiplication instruction\n        // when computing the next transition, we store the starting index of\n        // each state's row, which would not be representible in a single byte.\n        // So we'd need a `u16`, which doubles our transition table size to\n        // ~5KB. This is a lot to put on the stack, even though it probably\n        // fits in the L1 cache of most modern CPUs.\n        //\n        // To avoid this, we note that while our \"true\" alphabet\n        // has 256 distinct possibilities, the DFA itself is only\n        // discriminatory on a very small subset of that alphabet. For\n        // example, assuming neither `a` nor `b` are set as special\n        // quote/comment/escape/delimiter/terminator bytes, they are otherwise\n        // indistinguishable to the DFA, so it would be OK to treat them as\n        // if they were equivalent. That is, they are in the same equivalence\n        // class.\n        //\n        // As it turns out, using this logic, we can shrink our effective\n        // alphabet down to 7 equivalence classes:\n        //\n        //   1. The field delimiter.\n        //   2. The record terminator.\n        //   3. If the record terminator is CRLF, then CR and LF are\n        //      distinct equivalence classes.\n        //   4. The quote byte.\n        //   5. The escape byte.\n        //   6. The comment byte.\n        //   7. Everything else.\n        //\n        // We add those equivalence classes here. If more configuration knobs\n        // are added to the parser with more discriminating bytes, then this\n        // logic will need to be adjusted further.\n        //\n        // Even though this requires an extra bit of indirection when computing\n        // the next transition, microbenchmarks say that it doesn't make much\n        // of a difference. Perhaps because everything fits into the L1 cache.\n        self.dfa.classes.add(self.delimiter);\n        if self.quoting {\n            self.dfa.classes.add(self.quote);\n            if let Some(escape) = self.escape {\n                self.dfa.classes.add(escape);\n            }\n        }\n        if let Some(comment) = self.comment {\n            self.dfa.classes.add(comment);\n        }\n        match self.term {\n            Terminator::Any(b) => self.dfa.classes.add(b),\n            Terminator::CRLF => {\n                self.dfa.classes.add(b'\\r');\n                self.dfa.classes.add(b'\\n');\n            }\n            _ => unreachable!(),\n        }\n        // Build the DFA transition table by computing the DFA state for all\n        // possible combinations of state and input byte.\n        for &state in NFA_STATES {\n            for c in (0..256).map(|c| c as u8) {\n                let mut nfa_result = (state, NfaInputAction::Epsilon);\n                // Consume NFA states until we hit a non-epsilon transition.\n                while nfa_result.0 != NfaState::End\n                    && nfa_result.1 == NfaInputAction::Epsilon\n                {\n                    nfa_result = self.transition_nfa(nfa_result.0, c);\n                }\n                let from = self.dfa.new_state(state);\n                let to = self.dfa.new_state(nfa_result.0);\n                self.dfa.set(\n                    from,\n                    c,\n                    to,\n                    nfa_result.1 == NfaInputAction::CopyToOutput,\n                );\n            }\n        }\n        self.dfa_state = self.dfa.new_state(NfaState::StartRecord);\n        self.dfa.finish();\n    }\n\n    // The NFA implementation follows. The transition_final_nfa and\n    // transition_nfa methods are required for the DFA to operate. The\n    // rest are included for completeness (and debugging). Note that this\n    // NFA implementation is included in most of the CSV parser tests below.\n\n    #[inline(always)]\n    fn read_record_nfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize) {\n        if input.is_empty() {\n            let s = self.transition_final_nfa(self.nfa_state);\n            let res = ReadRecordResult::from_nfa(s, false, false, false);\n            return match res {\n                ReadRecordResult::Record => {\n                    if ends.is_empty() {\n                        return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n                    }\n                    self.nfa_state = s;\n                    ends[0] = self.output_pos;\n                    self.output_pos = 0;\n                    (res, 0, 0, 1)\n                }\n                _ => {\n                    self.nfa_state = s;\n                    (res, 0, 0, 0)\n                }\n            };\n        }\n        if output.is_empty() {\n            return (ReadRecordResult::OutputFull, 0, 0, 0);\n        }\n        if ends.is_empty() {\n            return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n        }\n        let (mut nin, mut nout, mut nend) = (0, self.output_pos, 0);\n        let mut state = self.nfa_state;\n        while nin < input.len() && nout < output.len() && nend < ends.len() {\n            let (s, io) = self.transition_nfa(state, input[nin]);\n            match io {\n                NfaInputAction::CopyToOutput => {\n                    output[nout] = input[nin];\n                    nout += 1;\n                    nin += 1;\n                }\n                NfaInputAction::Discard => {\n                    nin += 1;\n                }\n                NfaInputAction::Epsilon => {}\n            }\n            state = s;\n            if state.is_field_final() {\n                ends[nend] = nout;\n                nend += 1;\n                if state != NfaState::EndFieldDelim {\n                    break;\n                }\n            }\n        }\n        let res = ReadRecordResult::from_nfa(\n            state,\n            nin >= input.len(),\n            nout >= output.len(),\n            nend >= ends.len(),\n        );\n        self.nfa_state = state;\n        self.output_pos = if res.is_record() { 0 } else { nout };\n        (res, nin, nout, nend)\n    }\n\n    #[inline(always)]\n    fn read_field_nfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize) {\n        if input.is_empty() {\n            self.nfa_state = self.transition_final_nfa(self.nfa_state);\n            let res = ReadFieldResult::from_nfa(self.nfa_state, false, false);\n            return (res, 0, 0);\n        }\n        if output.is_empty() {\n            // If the output buffer is empty, then we can never make progress,\n            // so just quit now.\n            return (ReadFieldResult::OutputFull, 0, 0);\n        }\n        let (mut nin, mut nout) = (0, 0);\n        let mut state = self.nfa_state;\n        while nin < input.len() && nout < output.len() {\n            let (s, io) = self.transition_nfa(state, input[nin]);\n            match io {\n                NfaInputAction::CopyToOutput => {\n                    output[nout] = input[nin];\n                    nout += 1;\n                    nin += 1;\n                }\n                NfaInputAction::Discard => {\n                    nin += 1;\n                }\n                NfaInputAction::Epsilon => (),\n            }\n            state = s;\n            if state.is_field_final() {\n                break;\n            }\n        }\n        let res = ReadFieldResult::from_nfa(\n            state,\n            nin >= input.len(),\n            nout >= output.len(),\n        );\n        self.nfa_state = state;\n        (res, nin, nout)\n    }\n\n    /// Compute the final NFA transition after all caller-provided input has\n    /// been exhausted.\n    #[inline(always)]\n    fn transition_final_nfa(&self, state: NfaState) -> NfaState {\n        use self::NfaState::*;\n        match state {\n            End | StartRecord | EndRecord | InComment | CRLF => End,\n            StartField | EndFieldDelim | EndFieldTerm | InField\n            | InQuotedField | InEscapedQuote | InDoubleEscapedQuote\n            | InRecordTerm => EndRecord,\n        }\n    }\n\n    /// Compute the next NFA state given the current NFA state and the current\n    /// input byte.\n    ///\n    /// This returns the next NFA state along with an NfaInputAction that\n    /// indicates what should be done with the input byte (nothing for an epsilon\n    /// transition, copied to a caller provided output buffer, or discarded).\n    #[inline(always)]\n    fn transition_nfa(\n        &self,\n        state: NfaState,\n        c: u8,\n    ) -> (NfaState, NfaInputAction) {\n        use self::NfaState::*;\n        match state {\n            End => (End, NfaInputAction::Epsilon),\n            StartRecord => {\n                if self.term.equals(c) {\n                    (StartRecord, NfaInputAction::Discard)\n                } else if self.comment == Some(c) {\n                    (InComment, NfaInputAction::Discard)\n                } else {\n                    (StartField, NfaInputAction::Epsilon)\n                }\n            }\n            EndRecord => (StartRecord, NfaInputAction::Epsilon),\n            StartField => {\n                if self.quoting && self.quote == c {\n                    (InQuotedField, NfaInputAction::Discard)\n                } else if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            EndFieldDelim => (StartField, NfaInputAction::Epsilon),\n            EndFieldTerm => (InRecordTerm, NfaInputAction::Epsilon),\n            InField => {\n                if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InQuotedField => {\n                if self.quoting && self.quote == c {\n                    (InDoubleEscapedQuote, NfaInputAction::Discard)\n                } else if self.quoting && self.escape == Some(c) {\n                    (InEscapedQuote, NfaInputAction::Discard)\n                } else {\n                    (InQuotedField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InEscapedQuote => (InQuotedField, NfaInputAction::CopyToOutput),\n            InDoubleEscapedQuote => {\n                if self.quoting && self.double_quote && self.quote == c {\n                    (InQuotedField, NfaInputAction::CopyToOutput)\n                } else if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InComment => {\n                if b'\\n' == c {\n                    (StartRecord, NfaInputAction::Discard)\n                } else {\n                    (InComment, NfaInputAction::Discard)\n                }\n            }\n            InRecordTerm => {\n                if self.term.is_crlf() && b'\\r' == c {\n                    (CRLF, NfaInputAction::Discard)\n                } else {\n                    (EndRecord, NfaInputAction::Discard)\n                }\n            }\n            CRLF => {\n                if b'\\n' == c {\n                    (StartRecord, NfaInputAction::Discard)\n                } else {\n                    (StartRecord, NfaInputAction::Epsilon)\n                }\n            }\n        }\n    }\n}"],"reader::ReaderBuilder":["Debug","Default","impl ReaderBuilder {\n    /// Create a new builder.\n    pub fn new() -> ReaderBuilder {\n        ReaderBuilder::default()\n    }\n\n    /// Build a CSV parser from this configuration.\n    pub fn build(&self) -> Reader {\n        let mut rdr = self.rdr.clone();\n        rdr.build_dfa();\n        rdr\n    }\n\n    /// The field delimiter to use when parsing CSV.\n    ///\n    /// The default is `b','`.\n    pub fn delimiter(&mut self, delimiter: u8) -> &mut ReaderBuilder {\n        self.rdr.delimiter = delimiter;\n        self\n    }\n\n    /// The record terminator to use when parsing CSV.\n    ///\n    /// A record terminator can be any single byte. The default is a special\n    /// value, `Terminator::CRLF`, which treats any occurrence of `\\r`, `\\n`\n    /// or `\\r\\n` as a single record terminator.\n    pub fn terminator(&mut self, term: Terminator) -> &mut ReaderBuilder {\n        self.rdr.term = term;\n        self\n    }\n\n    /// The quote character to use when parsing CSV.\n    ///\n    /// The default is `b'\"'`.\n    pub fn quote(&mut self, quote: u8) -> &mut ReaderBuilder {\n        self.rdr.quote = quote;\n        self\n    }\n\n    /// The escape character to use when parsing CSV.\n    ///\n    /// In some variants of CSV, quotes are escaped using a special escape\n    /// character like `\\` (instead of escaping quotes by doubling them).\n    ///\n    /// By default, recognizing these idiosyncratic escapes is disabled.\n    pub fn escape(&mut self, escape: Option<u8>) -> &mut ReaderBuilder {\n        self.rdr.escape = escape;\n        self\n    }\n\n    /// Enable double quote escapes.\n    ///\n    /// This is enabled by default, but it may be disabled. When disabled,\n    /// doubled quotes are not interpreted as escapes.\n    pub fn double_quote(&mut self, yes: bool) -> &mut ReaderBuilder {\n        self.rdr.double_quote = yes;\n        self\n    }\n\n    /// Enable or disable quoting.\n    ///\n    /// This is enabled by default, but it may be disabled. When disabled,\n    /// quotes are not treated specially.\n    pub fn quoting(&mut self, yes: bool) -> &mut ReaderBuilder {\n        self.rdr.quoting = yes;\n        self\n    }\n\n    /// The comment character to use when parsing CSV.\n    ///\n    /// If the start of a record begins with the byte given here, then that\n    /// line is ignored by the CSV parser.\n    ///\n    /// This is disabled by default.\n    pub fn comment(&mut self, comment: Option<u8>) -> &mut ReaderBuilder {\n        self.rdr.comment = comment;\n        self\n    }\n\n    /// A convenience method for specifying a configuration to read ASCII\n    /// delimited text.\n    ///\n    /// This sets the delimiter and record terminator to the ASCII unit\n    /// separator (`\\x1F`) and record separator (`\\x1E`), respectively.\n    pub fn ascii(&mut self) -> &mut ReaderBuilder {\n        self.delimiter(b'\\x1F').terminator(Terminator::Any(b'\\x1E'))\n    }\n\n    /// Enable or disable the NFA for parsing CSV.\n    ///\n    /// This is intended to be a debug option useful for debugging. The NFA\n    /// is always slower than the DFA.\n    #[doc(hidden)]\n    pub fn nfa(&mut self, yes: bool) -> &mut ReaderBuilder {\n        self.rdr.use_nfa = yes;\n        self\n    }\n}"],"writer::WriteResult":["Clone","Debug","Eq","PartialEq"],"writer::Writer":["impl Clone for Writer {\n    fn clone(&self) -> Writer {\n        let mut requires_quotes = [false; 256];\n        for i in 0..256 {\n            requires_quotes[i] = self.requires_quotes[i];\n        }\n        Writer {\n            state: self.state.clone(),\n            requires_quotes: requires_quotes,\n            delimiter: self.delimiter,\n            term: self.term,\n            style: self.style,\n            quote: self.quote,\n            escape: self.escape,\n            double_quote: self.double_quote,\n        }\n    }\n}","impl Default for Writer {\n    fn default() -> Writer {\n        WriterBuilder::new().build()\n    }\n}","impl Writer {\n    /// Creates a new CSV writer with the default configuration.\n    pub fn new() -> Writer {\n        Writer::default()\n    }\n\n    /// Finish writing CSV data to `output`.\n    ///\n    /// This must be called when one is done writing CSV data to `output`.\n    /// In particular, it will write closing quotes if necessary.\n    pub fn finish(&mut self, mut output: &mut [u8]) -> (WriteResult, usize) {\n        let mut nout = 0;\n        if self.state.record_bytes == 0 && self.state.in_field {\n            assert!(!self.state.quoting);\n            let (res, o) = self.write(&[self.quote, self.quote], output);\n            if o == 0 {\n                return (res, 0);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n        }\n        if !self.state.quoting {\n            return (WriteResult::InputEmpty, nout);\n        }\n        let (res, o) = self.write(&[self.quote], output);\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes = 0;\n        self.state.in_field = false;\n        self.state.quoting = false;\n        (res, nout)\n    }\n\n    /// Write a single CSV field from `input` to `output` while employing this\n    /// writer's quoting style.\n    ///\n    /// This returns the result of writing field data, in addition to the\n    /// number of bytes consumed from `input` and the number of bytes\n    /// written to `output`.\n    ///\n    /// The result of writing field data is either `WriteResult::InputEmpty`\n    /// or `WriteResult::OutputFull`. The former occurs when all bytes in\n    /// `input` were copied to `output`, while the latter occurs when `output`\n    /// is too small to fit everything from `input`. The maximum number of\n    /// bytes that can be written to `output` is `2 + (2 * input.len())`\n    /// because of quoting. (The worst case is a field consisting entirely\n    /// of quotes.)\n    ///\n    /// Multiple successive calls to `field` will write more data to the same\n    /// field. Subsequent fields can be written by calling either `delimiter`\n    /// or `terminator` first.\n    ///\n    /// If this writer's quoting style is `QuoteStyle::Necessary`, then `input`\n    /// should contain the *entire* field. Otherwise, whether the field needs\n    /// to be quoted or not cannot be determined.\n    pub fn field(\n        &mut self,\n        input: &[u8],\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize, usize) {\n        let (mut nin, mut nout) = (0, 0);\n\n        if !self.state.in_field {\n            self.state.quoting = self.should_quote(input);\n            if self.state.quoting {\n                let (res, o) = self.write(&[self.quote], output);\n                if o == 0 {\n                    return (res, 0, 0);\n                }\n                output = &mut moving(output)[o..];\n                nout += o;\n                self.state.record_bytes += o as u64;\n            }\n            self.state.in_field = true;\n        }\n        let (res, i, o) = if self.state.quoting {\n            quote(input, output, self.quote, self.escape, self.double_quote)\n        } else {\n            write_optimistic(input, output)\n        };\n        nin += i;\n        nout += o;\n        self.state.record_bytes += o as u64;\n        (res, nin, nout)\n    }\n\n    /// Write the configured field delimiter to `output`.\n    ///\n    /// If the output buffer does not have enough room to fit\n    /// a field delimiter, then nothing is written to `output`\n    /// and `WriteResult::OutputFull` is returned. Otherwise,\n    /// `WriteResult::InputEmpty` is returned along with the number of bytes\n    /// written to `output` (which is `1` in case of an unquoted\n    /// field, or `2` in case of an end quote and a field separator).\n    pub fn delimiter(\n        &mut self,\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize) {\n        let mut nout = 0;\n        if self.state.quoting {\n            let (res, o) = self.write(&[self.quote], output);\n            if o == 0 {\n                return (res, o);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n            self.state.quoting = false;\n        }\n        let (res, o) = self.write(&[self.delimiter], output);\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes += o as u64;\n        self.state.in_field = false;\n        (res, nout)\n    }\n\n    /// Write the configured record terminator to `output`.\n    ///\n    /// If the output buffer does not have enough room to fit a record\n    /// terminator, then no part of the terminator is written and\n    /// `WriteResult::OutputFull` is returned. Otherwise,\n    /// `WriteResult::InputEmpty` is returned along with the number of bytes\n    /// written to `output` (which is always `1` or `2`).\n    pub fn terminator(\n        &mut self,\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize) {\n        let mut nout = 0;\n        if self.state.record_bytes == 0 {\n            assert!(!self.state.quoting);\n            let (res, o) = self.write(&[self.quote, self.quote], output);\n            if o == 0 {\n                return (res, 0);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n        }\n        if self.state.quoting {\n            let (res, o) = self.write(&[self.quote], output);\n            if o == 0 {\n                return (res, o);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n            self.state.quoting = false;\n        }\n        let (res, o) = match self.term {\n            Terminator::CRLF => write_pessimistic(&[b'\\r', b'\\n'], output),\n            Terminator::Any(b) => write_pessimistic(&[b], output),\n            _ => unreachable!(),\n        };\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes = 0;\n        self.state.in_field = false;\n        (res, nout)\n    }\n\n    /// Returns true if and only if the given input field *requires* quotes to\n    /// preserve the integrity of `input` while taking into account the current\n    /// configuration of this writer (except for the configured quoting style).\n    #[inline]\n    fn needs_quotes(&self, mut input: &[u8]) -> bool {\n        let mut needs = false;\n        while !needs && input.len() >= 8 {\n            needs = self.requires_quotes[input[0] as usize]\n                || self.requires_quotes[input[1] as usize]\n                || self.requires_quotes[input[2] as usize]\n                || self.requires_quotes[input[3] as usize]\n                || self.requires_quotes[input[4] as usize]\n                || self.requires_quotes[input[5] as usize]\n                || self.requires_quotes[input[6] as usize]\n                || self.requires_quotes[input[7] as usize];\n            input = &input[8..];\n        }\n        needs || input.iter().any(|&b| self.is_special_byte(b))\n    }\n\n    /// Returns true if and only if the given byte corresponds to a special\n    /// byte in this CSV writer's configuration.\n    ///\n    /// Note that this does **not** take into account this writer's quoting\n    /// style.\n    #[inline]\n    pub fn is_special_byte(&self, b: u8) -> bool {\n        self.requires_quotes[b as usize]\n    }\n\n    /// Returns true if and only if we should put the given field data\n    /// in quotes. This takes the quoting style into account.\n    #[inline]\n    pub fn should_quote(&self, input: &[u8]) -> bool {\n        match self.style {\n            QuoteStyle::Always => true,\n            QuoteStyle::Never => false,\n            QuoteStyle::NonNumeric => is_non_numeric(input),\n            QuoteStyle::Necessary => self.needs_quotes(input),\n            _ => unreachable!(),\n        }\n    }\n\n    /// Return the delimiter used for this writer.\n    #[inline]\n    pub fn get_delimiter(&self) -> u8 {\n        self.delimiter\n    }\n\n    /// Return the terminator used for this writer.\n    #[inline]\n    pub fn get_terminator(&self) -> Terminator {\n        self.term\n    }\n\n    /// Return the quoting style used for this writer.\n    #[inline]\n    pub fn get_quote_style(&self) -> QuoteStyle {\n        self.style\n    }\n\n    /// Return the quote character used for this writer.\n    #[inline]\n    pub fn get_quote(&self) -> u8 {\n        self.quote\n    }\n\n    /// Return the escape character used for this writer.\n    #[inline]\n    pub fn get_escape(&self) -> u8 {\n        self.escape\n    }\n\n    /// Return whether this writer doubles quotes or not. When the writer\n    /// does not double quotes, it will escape them using the escape character.\n    #[inline]\n    pub fn get_double_quote(&self) -> bool {\n        self.double_quote\n    }\n\n    fn write(&self, data: &[u8], output: &mut [u8]) -> (WriteResult, usize) {\n        if data.len() > output.len() {\n            (WriteResult::OutputFull, 0)\n        } else {\n            output[..data.len()].copy_from_slice(data);\n            (WriteResult::InputEmpty, data.len())\n        }\n    }\n}","impl fmt::Debug for Writer {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"Writer\")\n            .field(\"state\", &self.state)\n            .field(\"delimiter\", &self.delimiter)\n            .field(\"term\", &self.term)\n            .field(\"style\", &self.style)\n            .field(\"quote\", &self.quote)\n            .field(\"escape\", &self.escape)\n            .field(\"double_quote\", &self.double_quote)\n            .finish()\n    }\n}"],"writer::WriterBuilder":["Debug","impl Default for WriterBuilder {\n    fn default() -> WriterBuilder {\n        WriterBuilder::new()\n    }\n}","impl WriterBuilder {\n    /// Create a new builder for configuring a CSV writer.\n    pub fn new() -> WriterBuilder {\n        let wtr = Writer {\n            state: WriterState::default(),\n            requires_quotes: [false; 256],\n            delimiter: b',',\n            term: Terminator::Any(b'\\n'),\n            style: QuoteStyle::default(),\n            quote: b'\"',\n            escape: b'\\\\',\n            double_quote: true,\n        };\n        WriterBuilder { wtr: wtr }\n    }\n\n    /// Builder a CSV writer from this configuration.\n    pub fn build(&self) -> Writer {\n        use crate::Terminator::*;\n\n        let mut wtr = self.wtr.clone();\n        wtr.requires_quotes[self.wtr.delimiter as usize] = true;\n        wtr.requires_quotes[self.wtr.quote as usize] = true;\n        if !self.wtr.double_quote {\n            // We only need to quote the escape character if the escape\n            // character is used for escaping quotes.\n            wtr.requires_quotes[self.wtr.escape as usize] = true;\n        }\n        match self.wtr.term {\n            CRLF | Any(b'\\n') | Any(b'\\r') => {\n                // This is a bit hokey. By default, the record terminator\n                // is '\\n', but we still need to quote '\\r' (even if our\n                // terminator is only `\\n`) because the reader interprets '\\r'\n                // as a record terminator by default.\n                wtr.requires_quotes[b'\\r' as usize] = true;\n                wtr.requires_quotes[b'\\n' as usize] = true;\n            }\n            Any(b) => {\n                wtr.requires_quotes[b as usize] = true;\n            }\n            _ => unreachable!(),\n        }\n        wtr\n    }\n\n    /// The field delimiter to use when writing CSV.\n    ///\n    /// The default is `b','`.\n    pub fn delimiter(&mut self, delimiter: u8) -> &mut WriterBuilder {\n        self.wtr.delimiter = delimiter;\n        self\n    }\n\n    /// The record terminator to use when writing CSV.\n    ///\n    /// A record terminator can be any single byte. The default is `\\n`.\n    ///\n    /// Note that RFC 4180 specifies that record terminators should be `\\r\\n`.\n    /// To use `\\r\\n`, use the special `Terminator::CRLF` value.\n    pub fn terminator(&mut self, term: Terminator) -> &mut WriterBuilder {\n        self.wtr.term = term;\n        self\n    }\n\n    /// The quoting style to use when writing CSV.\n    ///\n    /// By default, this is set to `QuoteStyle::Necessary`, which will only\n    /// use quotes when they are necessary to preserve the integrity of data.\n    ///\n    /// Note that unless the quote style is set to `Never`, an empty field is\n    /// quoted if it is the only field in a record.\n    pub fn quote_style(&mut self, style: QuoteStyle) -> &mut WriterBuilder {\n        self.wtr.style = style;\n        self\n    }\n\n    /// The quote character to use when writing CSV.\n    ///\n    /// The default value is `b'\"'`.\n    pub fn quote(&mut self, quote: u8) -> &mut WriterBuilder {\n        self.wtr.quote = quote;\n        self\n    }\n\n    /// The escape character to use when writing CSV.\n    ///\n    /// This is only used when `double_quote` is set to `false`.\n    ///\n    /// The default value is `b'\\\\'`.\n    pub fn escape(&mut self, escape: u8) -> &mut WriterBuilder {\n        self.wtr.escape = escape;\n        self\n    }\n\n    /// The quoting escape mechanism to use when writing CSV.\n    ///\n    /// When enabled (which is the default), quotes are escaped by doubling\n    /// them. e.g., `\"` escapes to `\"\"`.\n    ///\n    /// When disabled, quotes are escaped with the escape character (which\n    /// is `\\\\` by default).\n    pub fn double_quote(&mut self, yes: bool) -> &mut WriterBuilder {\n        self.wtr.double_quote = yes;\n        self\n    }\n}"],"writer::WriterState":["Clone","Debug","impl Default for WriterState {\n    fn default() -> WriterState {\n        WriterState { in_field: false, quoting: false, record_bytes: 0 }\n    }\n}"]},"single_path_import":{"reader::ReadFieldNoCopyResult":"ReadFieldNoCopyResult","reader::ReadFieldResult":"ReadFieldResult","reader::ReadRecordNoCopyResult":"ReadRecordNoCopyResult","reader::ReadRecordResult":"ReadRecordResult","reader::Reader":"Reader","reader::ReaderBuilder":"ReaderBuilder","writer::WriteResult":"WriteResult","writer::Writer":"Writer","writer::WriterBuilder":"WriterBuilder","writer::is_non_numeric":"is_non_numeric","writer::quote":"quote"},"srcs":{"<QuoteStyle as core::default::Default>::default":["fn default() -> QuoteStyle{\n        QuoteStyle::Necessary\n    }","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"<Terminator as core::default::Default>::default":["fn default() -> Terminator{\n        Terminator::CRLF\n    }","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"<reader::Dfa as core::clone::Clone>::clone":["fn clone(&self) -> Dfa{\n        let mut dfa = Dfa::new();\n        dfa.trans.copy_from_slice(&self.trans);\n        dfa\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"<reader::Dfa as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        write!(f, \"Dfa(N/A)\")\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"<reader::DfaClasses as core::clone::Clone>::clone":["fn clone(&self) -> DfaClasses{\n        let mut x = DfaClasses::new();\n        x.classes.copy_from_slice(&self.classes);\n        x\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"<reader::DfaClasses as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        write!(\n            f,\n            \"DfaClasses {{ classes: N/A, next_class: {:?} }}\",\n            self.next_class\n        )\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"<reader::Reader as core::default::Default>::default":["fn default() -> Reader{\n        Reader {\n            dfa: Dfa::new(),\n            dfa_state: DfaState::start(),\n            nfa_state: NfaState::StartRecord,\n            delimiter: b',',\n            term: Terminator::default(),\n            quote: b'\"',\n            escape: None,\n            double_quote: true,\n            comment: None,\n            quoting: true,\n            use_nfa: false,\n            line: 1,\n            has_read: false,\n            output_pos: 0,\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"<writer::Writer as core::clone::Clone>::clone":["fn clone(&self) -> Writer{\n        let mut requires_quotes = [false; 256];\n        for i in 0..256 {\n            requires_quotes[i] = self.requires_quotes[i];\n        }\n        Writer {\n            state: self.state.clone(),\n            requires_quotes: requires_quotes,\n            delimiter: self.delimiter,\n            term: self.term,\n            style: self.style,\n            quote: self.quote,\n            escape: self.escape,\n            double_quote: self.double_quote,\n        }\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"<writer::Writer as core::default::Default>::default":["fn default() -> Writer{\n        WriterBuilder::new().build()\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"<writer::Writer as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        f.debug_struct(\"Writer\")\n            .field(\"state\", &self.state)\n            .field(\"delimiter\", &self.delimiter)\n            .field(\"term\", &self.term)\n            .field(\"style\", &self.style)\n            .field(\"quote\", &self.quote)\n            .field(\"escape\", &self.escape)\n            .field(\"double_quote\", &self.double_quote)\n            .finish()\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"<writer::WriterBuilder as core::default::Default>::default":["fn default() -> WriterBuilder{\n        WriterBuilder::new()\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"<writer::WriterState as core::default::Default>::default":["fn default() -> WriterState{\n        WriterState { in_field: false, quoting: false, record_bytes: 0 }\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"QuoteStyle":["/// The quoting style to use when writing CSV data.\npub enum QuoteStyle {\n    /// This puts quotes around every field. Always.\n    Always,\n    /// This puts quotes around fields only when necessary.\n    ///\n    /// They are necessary when fields contain a quote, delimiter or record\n    /// terminator. Quotes are also necessary when writing an empty record\n    /// (which is indistinguishable from a record with one empty field).\n    ///\n    /// This is the default.\n    Necessary,\n    /// This puts quotes around all fields that are non-numeric. Namely, when\n    /// writing a field that does not parse as a valid float or integer, then\n    /// quotes will be used even if they aren't strictly necessary.\n    NonNumeric,\n    /// This *never* writes quotes, even if it would produce invalid CSV data.\n    Never,\n    /// Hints that destructuring should not be exhaustive.\n    ///\n    /// This enum may grow additional variants, so this makes sure clients\n    /// don't count on exhaustive matching. (Otherwise, adding a new variant\n    /// could break existing code.)\n    #[doc(hidden)]\n    __Nonexhaustive,\n}","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"Terminator":["/// A record terminator.\n///\n/// Use this to specify the record terminator while parsing CSV. The default is\n/// CRLF, which treats `\\r`, `\\n` or `\\r\\n` as a single record terminator.\npub enum Terminator {\n    /// Parses `\\r`, `\\n` or `\\r\\n` as a single record terminator.\n    CRLF,\n    /// Parses the byte given as a record terminator.\n    Any(u8),\n    /// Hints that destructuring should not be exhaustive.\n    ///\n    /// This enum may grow additional variants, so this makes sure clients\n    /// don't count on exhaustive matching. (Otherwise, adding a new variant\n    /// could break existing code.)\n    #[doc(hidden)]\n    __Nonexhaustive,\n}","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"Terminator::equals":["fn equals(&self, other: u8) -> bool{\n        match *self {\n            Terminator::CRLF => other == b'\\r' || other == b'\\n',\n            Terminator::Any(b) => other == b,\n            _ => unreachable!(),\n        }\n    }","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"Terminator::is_crlf":["/// Checks whether the terminator is set to CRLF.\nfn is_crlf(&self) -> bool{\n        match *self {\n            Terminator::CRLF => true,\n            Terminator::Any(_) => false,\n            _ => unreachable!(),\n        }\n    }","Real(LocalPath(\"csv-core/src/lib.rs\"))"],"reader::Dfa":["/// A representation of a DFA.\n///\n/// For the most part, this is a transition table, but various optimizations\n/// have been applied to reduce its memory footprint.\nstruct Dfa {\n    /// The core transition table. Each row corresponds to the transitions for\n    /// each input equivalence class. (Input bytes are mapped to their\n    /// corresponding equivalence class with the `classes` map.)\n    ///\n    /// DFA states are represented as an index corresponding to the start of\n    /// its row in this table.\n    trans: [DfaState; TRANS_SIZE],\n    /// A table with the same layout as `trans`, except its values indicate\n    /// whether a particular `(state, equivalence class)` pair should emit an\n    /// output byte.\n    has_output: [bool; TRANS_SIZE],\n    /// A map from input byte to equivalence class.\n    ///\n    /// This is responsible for reducing the effective alphabet size from\n    /// 256 to `TRANS_CLASSES`.\n    classes: DfaClasses,\n    /// The DFA state corresponding to being inside an unquoted field.\n    in_field: DfaState,\n    /// The DFA state corresponding to being inside an quoted field.\n    in_quoted: DfaState,\n    /// The minimum DFA state that indicates a field has been parsed. All DFA\n    /// states greater than this are also final-field states.\n    final_field: DfaState,\n    /// The minimum DFA state that indicates a record has been parsed. All DFA\n    /// states greater than this are also final-record states.\n    final_record: DfaState,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::finish":["fn finish(&mut self){\n        self.in_field = self.new_state(NfaState::InField);\n        self.in_quoted = self.new_state(NfaState::InQuotedField);\n        self.final_field = self.new_state(NfaState::EndFieldDelim);\n        self.final_record = self.new_state(NfaState::EndRecord);\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::get_output":["fn get_output(&self, state: DfaState, c: u8) -> (DfaState, bool){\n        let cls = self.classes.classes[c as usize];\n        let idx = state.0 as usize + cls as usize;\n        (self.trans[idx], self.has_output[idx])\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new":["fn new() -> Dfa{\n        Dfa {\n            trans: [DfaState(0); TRANS_SIZE],\n            has_output: [false; TRANS_SIZE],\n            classes: DfaClasses::new(),\n            in_field: DfaState(0),\n            in_quoted: DfaState(0),\n            final_field: DfaState(0),\n            final_record: DfaState(0),\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new_read_field_result":["fn new_read_field_result(\n        &self,\n        state: DfaState,\n        is_final_trans: bool,\n        inpdone: bool,\n        outdone: bool,\n    ) -> ReadFieldResult{\n        if state >= self.final_record {\n            ReadFieldResult::Field { record_end: true }\n        } else if state == self.final_field {\n            ReadFieldResult::Field { record_end: false }\n        } else if is_final_trans && state.is_start() {\n            ReadFieldResult::End\n        } else {\n            debug_assert!(state < self.final_field);\n            if !inpdone && outdone {\n                ReadFieldResult::OutputFull\n            } else {\n                ReadFieldResult::InputEmpty\n            }\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new_read_record_result":["fn new_read_record_result(\n        &self,\n        state: DfaState,\n        is_final_trans: bool,\n        inpdone: bool,\n        outdone: bool,\n        endsdone: bool,\n    ) -> ReadRecordResult{\n        if state >= self.final_record {\n            ReadRecordResult::Record\n        } else if is_final_trans && state.is_start() {\n            ReadRecordResult::End\n        } else {\n            debug_assert!(state < self.final_record);\n            if !inpdone && outdone {\n                ReadRecordResult::OutputFull\n            } else if !inpdone && endsdone {\n                ReadRecordResult::OutputEndsFull\n            } else {\n                ReadRecordResult::InputEmpty\n            }\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new_state":["fn new_state(&self, nfa_state: NfaState) -> DfaState{\n        let nclasses = self.classes.num_classes() as u8;\n        let idx = (nfa_state as u8).checked_mul(nclasses).unwrap();\n        DfaState(idx)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new_state_final_end":["fn new_state_final_end(&self) -> DfaState{\n        self.new_state(NfaState::StartRecord)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::new_state_final_record":["fn new_state_final_record(&self) -> DfaState{\n        self.new_state(NfaState::EndRecord)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Dfa::set":["fn set(&mut self, from: DfaState, c: u8, to: DfaState, output: bool){\n        let cls = self.classes.classes[c as usize];\n        let idx = from.0 as usize + cls as usize;\n        self.trans[idx] = to;\n        self.has_output[idx] = output;\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaClasses":["/// A map from input byte to equivalence class.\nstruct DfaClasses {\n    classes: [u8; CLASS_SIZE],\n    next_class: usize,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaClasses::add":["fn add(&mut self, b: u8){\n        if self.next_class > CLASS_SIZE {\n            panic!(\"added too many classes\")\n        }\n        self.classes[b as usize] = self.next_class as u8;\n        self.next_class = self.next_class + 1;\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaClasses::new":["fn new() -> DfaClasses{\n        DfaClasses { classes: [0; CLASS_SIZE], next_class: 1 }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaClasses::num_classes":["fn num_classes(&self) -> usize{\n        self.next_class as usize\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaClasses::scan_and_copy":["/// Scan and copy the input bytes to the output buffer quickly.\n///\n/// This assumes that the current state of the DFA is either `InField` or\n/// `InQuotedField`. In this case, all bytes corresponding to the first\n/// equivalence class (i.e., not a delimiter/quote/escape/etc.) are\n/// guaranteed to never result in a state transition out of the current\n/// state. This function takes advantage of that copies every byte from\n/// `input` in the first equivalence class to `output`. Once a byte is seen\n/// outside the first equivalence class, we quit and should fall back to\n/// the main DFA loop.\n#[inline(always)]\nfn scan_and_copy(\n        &self,\n        input: &[u8],\n        nin: &mut usize,\n        output: &mut [u8],\n        nout: &mut usize,\n    ){\n        while *nin < input.len()\n            && *nout < output.len()\n            && self.classes[input[*nin] as usize] == 0\n        {\n            output[*nout] = input[*nin];\n            *nin += 1;\n            *nout += 1;\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaState":["/// A single DFA state.\n///\n/// A DFA state is represented by the starting index of its corresponding row\n/// in the DFA transition table. This representation allows us to elide a\n/// single multiplication instruction when computing the next transition for\n/// a particular input byte.\nstruct DfaState(u8);","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaState::is_start":["fn is_start(&self) -> bool{\n        self.0 == 0\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::DfaState::start":["fn start() -> DfaState{\n        DfaState(0)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::NfaInputAction":["/// What should be done with input bytes during an NFA transition\nenum NfaInputAction {\n    // Do not consume an input byte\n    Epsilon,\n    // Copy input byte to a caller-provided output buffer\n    CopyToOutput,\n    // Consume but do not copy input byte (for example, seeing a field\n    // delimiter will consume an input byte but should not copy it to the\n    // output buffer.\n    Discard,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::NfaState":["/// An NFA state is a state that can be visited in the NFA parser.\n///\n/// Given the simplicity of the machine, a subset of NFA states double as DFA\n/// states. NFA states that only have incoming epsilon transitions are\n/// optimized out when converting the machine to a DFA.\nenum NfaState {\n    // These states aren't used in the DFA, so we\n    // assign them meaningless numbers.\n    EndFieldTerm = 200,\n    InRecordTerm = 201,\n    End = 202,\n\n    // All states below are DFA states.\n    StartRecord = 0,\n    StartField = 1,\n    InField = 2,\n    InQuotedField = 3,\n    InEscapedQuote = 4,\n    InDoubleEscapedQuote = 5,\n    InComment = 6,\n    // All states below are \"final field\" states.\n    // Namely, they indicate that a field has been parsed.\n    EndFieldDelim = 7,\n    // All states below are \"final record\" states.\n    // Namely, they indicate that a record has been parsed.\n    EndRecord = 8,\n    CRLF = 9,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::NfaState::is_field_final":["/// Returns true if this state indicates that a field has been parsed.\nfn is_field_final(&self) -> bool{\n        match *self {\n            NfaState::End\n            | NfaState::EndRecord\n            | NfaState::CRLF\n            | NfaState::EndFieldDelim => true,\n            _ => false,\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::NfaState::is_record_final":["/// Returns true if this state indicates that a record has been parsed.\nfn is_record_final(&self) -> bool{\n        match *self {\n            NfaState::End | NfaState::EndRecord | NfaState::CRLF => true,\n            _ => false,\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadFieldNoCopyResult":["/// The result of parsing at most one field from CSV data while ignoring the\n/// output.\npub enum ReadFieldNoCopyResult {\n    /// The caller provided input was exhausted before the end of a field or\n    /// record was found.\n    InputEmpty,\n    /// The end of a field was found.\n    ///\n    /// Note that when `record_end` is true, then the end of this field also\n    /// corresponds to the end of a record.\n    Field {\n        /// Whether this was the last field in a record or not.\n        record_end: bool,\n    },\n    /// All CSV data has been read.\n    ///\n    /// This state can only be returned when an empty input buffer is provided\n    /// by the caller.\n    End,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadFieldResult":["/// The result of parsing at most one field from CSV data.\npub enum ReadFieldResult {\n    /// The caller provided input was exhausted before the end of a field or\n    /// record was found.\n    InputEmpty,\n    /// The caller provided output buffer was filled before an entire field\n    /// could be written to it.\n    OutputFull,\n    /// The end of a field was found.\n    ///\n    /// Note that when `record_end` is true, then the end of this field also\n    /// corresponds to the end of a record.\n    Field {\n        /// Whether this was the last field in a record or not.\n        record_end: bool,\n    },\n    /// All CSV data has been read.\n    ///\n    /// This state can only be returned when an empty input buffer is provided\n    /// by the caller.\n    End,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadFieldResult::from_nfa":["fn from_nfa(\n        state: NfaState,\n        inpdone: bool,\n        outdone: bool,\n    ) -> ReadFieldResult{\n        match state {\n            NfaState::End => ReadFieldResult::End,\n            NfaState::EndRecord | NfaState::CRLF => {\n                ReadFieldResult::Field { record_end: true }\n            }\n            NfaState::EndFieldDelim => {\n                ReadFieldResult::Field { record_end: false }\n            }\n            _ => {\n                assert!(!state.is_field_final());\n                if !inpdone && outdone {\n                    ReadFieldResult::OutputFull\n                } else {\n                    ReadFieldResult::InputEmpty\n                }\n            }\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadRecordNoCopyResult":["/// The result of parsing at most one record from CSV data while ignoring\n/// output.\npub enum ReadRecordNoCopyResult {\n    /// The caller provided input was exhausted before the end of a record was\n    /// found.\n    InputEmpty,\n    /// The end of a record was found.\n    Record,\n    /// All CSV data has been read.\n    ///\n    /// This state can only be returned when an empty input buffer is provided\n    /// by the caller.\n    End,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadRecordResult":["/// The result of parsing at most one record from CSV data.\npub enum ReadRecordResult {\n    /// The caller provided input was exhausted before the end of a record was\n    /// found.\n    InputEmpty,\n    /// The caller provided output buffer was filled before an entire field\n    /// could be written to it.\n    OutputFull,\n    /// The caller provided output buffer of field end poisitions was filled\n    /// before the next field could be parsed.\n    OutputEndsFull,\n    /// The end of a record was found.\n    Record,\n    /// All CSV data has been read.\n    ///\n    /// This state can only be returned when an empty input buffer is provided\n    /// by the caller.\n    End,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadRecordResult::from_nfa":["fn from_nfa(\n        state: NfaState,\n        inpdone: bool,\n        outdone: bool,\n        endsdone: bool,\n    ) -> ReadRecordResult{\n        match state {\n            NfaState::End => ReadRecordResult::End,\n            NfaState::EndRecord | NfaState::CRLF => ReadRecordResult::Record,\n            _ => {\n                assert!(!state.is_record_final());\n                if !inpdone && outdone {\n                    ReadRecordResult::OutputFull\n                } else if !inpdone && endsdone {\n                    ReadRecordResult::OutputEndsFull\n                } else {\n                    ReadRecordResult::InputEmpty\n                }\n            }\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReadRecordResult::is_record":["fn is_record(&self) -> bool{\n        *self == ReadRecordResult::Record\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader":["/// A pull based CSV reader.\n///\n/// This reader parses CSV data using a finite state machine. Callers can\n/// extract parsed data incrementally using one of the `read` methods.\n///\n/// Note that this CSV reader is somewhat encoding agnostic. The source data\n/// needs to be at least ASCII compatible. There is no support for specifying\n/// the full gamut of Unicode delimiters/terminators/quotes/escapes. Instead,\n/// any byte can be used, although callers probably want to stick to the ASCII\n/// subset (`<= 0x7F`).\n///\n/// # Usage\n///\n/// A reader has two different ways to read CSV data, each with their own\n/// trade offs.\n///\n/// * `read_field` - Copies a single CSV field into an output buffer while\n///   unescaping quotes. This is simple to use and doesn't require storing an\n///   entire record contiguously in memory, but it is slower.\n/// * `read_record` - Copies an entire CSV record into an output buffer while\n///   unescaping quotes. The ending positions of each field are copied into\n///   an additional buffer. This is harder to use and requires larger output\n///   buffers, but it is faster than `read_field` since it amortizes more\n///   costs.\n///\n/// # RFC 4180\n///\n/// [RFC 4180](https://tools.ietf.org/html/rfc4180)\n/// is the closest thing to a specification for CSV data. Unfortunately,\n/// CSV data that is seen in the wild can vary significantly. Often, the CSV\n/// data is outright invalid. Instead of fixing the producers of bad CSV data,\n/// we have seen fit to make consumers much more flexible in what they accept.\n/// This reader continues that tradition, and therefore, isn't technically\n/// compliant with RFC 4180. In particular, this reader will never return an\n/// error and will always find *a* parse.\n///\n/// Here are some detailed differences from RFC 4180:\n///\n/// * CRLF, LF and CR are each treated as a single record terminator by\n///   default.\n/// * Records are permitted to be of varying length.\n/// * Empty lines (that do not include other whitespace) are ignored.\npub struct Reader {\n    /// A table-based DFA for parsing CSV.\n    dfa: Dfa,\n    /// The current DFA state, if the DFA is used.\n    dfa_state: DfaState,\n    /// The current NFA state, if the NFA is used.\n    nfa_state: NfaState,\n    /// The delimiter that separates fields.\n    delimiter: u8,\n    /// The terminator that separates records.\n    term: Terminator,\n    /// The quotation byte.\n    quote: u8,\n    /// Whether to recognize escaped quotes.\n    escape: Option<u8>,\n    /// Whether to recognized doubled quotes.\n    double_quote: bool,\n    /// If enabled, lines beginning with this byte are ignored.\n    comment: Option<u8>,\n    /// If enabled (the default), then quotes are respected. When disabled,\n    /// quotes are not treated specially.\n    quoting: bool,\n    /// Whether to use the NFA for parsing.\n    ///\n    /// Generally this is for debugging. There's otherwise no good reason\n    /// to avoid the DFA.\n    use_nfa: bool,\n    /// The current line number.\n    line: u64,\n    /// Whether this parser has ever read anything.\n    has_read: bool,\n    /// The current position in the output buffer when reading a record.\n    output_pos: usize,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::build_dfa":["/// Write the transition tables for the DFA based on this parser's\n/// configuration.\nfn build_dfa(&mut self){\n        // A naive DFA transition table has\n        // `cells = (# number of states) * (# size of alphabet)`. While we\n        // could get away with that, the table would have `10 * 256 = 2560`\n        // entries. Even worse, in order to avoid a multiplication instruction\n        // when computing the next transition, we store the starting index of\n        // each state's row, which would not be representible in a single byte.\n        // So we'd need a `u16`, which doubles our transition table size to\n        // ~5KB. This is a lot to put on the stack, even though it probably\n        // fits in the L1 cache of most modern CPUs.\n        //\n        // To avoid this, we note that while our \"true\" alphabet\n        // has 256 distinct possibilities, the DFA itself is only\n        // discriminatory on a very small subset of that alphabet. For\n        // example, assuming neither `a` nor `b` are set as special\n        // quote/comment/escape/delimiter/terminator bytes, they are otherwise\n        // indistinguishable to the DFA, so it would be OK to treat them as\n        // if they were equivalent. That is, they are in the same equivalence\n        // class.\n        //\n        // As it turns out, using this logic, we can shrink our effective\n        // alphabet down to 7 equivalence classes:\n        //\n        //   1. The field delimiter.\n        //   2. The record terminator.\n        //   3. If the record terminator is CRLF, then CR and LF are\n        //      distinct equivalence classes.\n        //   4. The quote byte.\n        //   5. The escape byte.\n        //   6. The comment byte.\n        //   7. Everything else.\n        //\n        // We add those equivalence classes here. If more configuration knobs\n        // are added to the parser with more discriminating bytes, then this\n        // logic will need to be adjusted further.\n        //\n        // Even though this requires an extra bit of indirection when computing\n        // the next transition, microbenchmarks say that it doesn't make much\n        // of a difference. Perhaps because everything fits into the L1 cache.\n        self.dfa.classes.add(self.delimiter);\n        if self.quoting {\n            self.dfa.classes.add(self.quote);\n            if let Some(escape) = self.escape {\n                self.dfa.classes.add(escape);\n            }\n        }\n        if let Some(comment) = self.comment {\n            self.dfa.classes.add(comment);\n        }\n        match self.term {\n            Terminator::Any(b) => self.dfa.classes.add(b),\n            Terminator::CRLF => {\n                self.dfa.classes.add(b'\\r');\n                self.dfa.classes.add(b'\\n');\n            }\n            _ => unreachable!(),\n        }\n        // Build the DFA transition table by computing the DFA state for all\n        // possible combinations of state and input byte.\n        for &state in NFA_STATES {\n            for c in (0..256).map(|c| c as u8) {\n                let mut nfa_result = (state, NfaInputAction::Epsilon);\n                // Consume NFA states until we hit a non-epsilon transition.\n                while nfa_result.0 != NfaState::End\n                    && nfa_result.1 == NfaInputAction::Epsilon\n                {\n                    nfa_result = self.transition_nfa(nfa_result.0, c);\n                }\n                let from = self.dfa.new_state(state);\n                let to = self.dfa.new_state(nfa_result.0);\n                self.dfa.set(\n                    from,\n                    c,\n                    to,\n                    nfa_result.1 == NfaInputAction::CopyToOutput,\n                );\n            }\n        }\n        self.dfa_state = self.dfa.new_state(NfaState::StartRecord);\n        self.dfa.finish();\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::line":["/// Return the current line number as measured by the number of occurrences\n/// of `\\n`.\n///\n/// Line numbers starts at `1` and are reset when `reset` is called.\npub fn line(&self) -> u64{\n        self.line\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::new":["/// Create a new CSV reader with a default parser configuration.\npub fn new() -> Reader{\n        ReaderBuilder::new().build()\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_field":["/// Parse a single CSV field in `input` and copy field data to `output`.\n///\n/// This routine requires a caller provided buffer of CSV data as the\n/// `input` and a caller provided buffer, `output`, in which to store field\n/// data extracted from `input`. The field data copied to `output` will\n/// have its quotes unescaped.\n///\n/// Calling this routine parses at most a single field and returns\n/// three values indicating the state of the parser. The first value, a\n/// `ReadFieldResult`, tells the caller what to do next. For example, if\n/// the entire input was read or if the output buffer was filled before\n/// a full field had been read, then `ReadFieldResult::InputEmpty` or\n/// `ReadFieldResult::OutputFull` is returned, respectively. See the\n/// documentation for `ReadFieldResult` for more details.\n///\n/// The other two values returned correspond to the number of bytes\n/// read from `input` and written to `output`, respectively.\n///\n/// # Termination\n///\n/// This reader interprets an empty `input` buffer as an indication that\n/// there is no CSV data left to read. Namely, when the caller has\n/// exhausted all CSV data, the caller should continue to call `read` with\n/// an empty input buffer until `ReadFieldResult::End` is returned.\n///\n/// # Errors\n///\n/// This CSV reader can never return an error. Instead, it prefers *a*\n/// parse over *no* parse.\npub fn read_field(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize){\n        let (input, bom_nin) = self.strip_utf8_bom(input);\n        let (res, nin, nout) = if self.use_nfa {\n            self.read_field_nfa(input, output)\n        } else {\n            self.read_field_dfa(input, output)\n        };\n        self.has_read = true;\n        (res, nin + bom_nin, nout)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_field_dfa":["#[inline(always)]\nfn read_field_dfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize){\n        if input.is_empty() {\n            self.dfa_state = self.transition_final_dfa(self.dfa_state);\n            let res = self.dfa.new_read_field_result(\n                self.dfa_state,\n                true,\n                false,\n                false,\n            );\n            return (res, 0, 0);\n        }\n        if output.is_empty() {\n            return (ReadFieldResult::OutputFull, 0, 0);\n        }\n        let (mut nin, mut nout) = (0, 0);\n        let mut state = self.dfa_state;\n        while nin < input.len() && nout < output.len() {\n            let b = input[nin];\n            self.line += (b == b'\\n') as u64;\n            let (s, has_out) = self.dfa.get_output(state, b);\n            state = s;\n            if has_out {\n                output[nout] = b;\n                nout += 1;\n            }\n            nin += 1;\n            if state >= self.dfa.final_field {\n                break;\n            }\n        }\n        let res = self.dfa.new_read_field_result(\n            state,\n            false,\n            nin >= input.len(),\n            nout >= output.len(),\n        );\n        self.dfa_state = state;\n        (res, nin, nout)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_field_nfa":["#[inline(always)]\nfn read_field_nfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n    ) -> (ReadFieldResult, usize, usize){\n        if input.is_empty() {\n            self.nfa_state = self.transition_final_nfa(self.nfa_state);\n            let res = ReadFieldResult::from_nfa(self.nfa_state, false, false);\n            return (res, 0, 0);\n        }\n        if output.is_empty() {\n            // If the output buffer is empty, then we can never make progress,\n            // so just quit now.\n            return (ReadFieldResult::OutputFull, 0, 0);\n        }\n        let (mut nin, mut nout) = (0, 0);\n        let mut state = self.nfa_state;\n        while nin < input.len() && nout < output.len() {\n            let (s, io) = self.transition_nfa(state, input[nin]);\n            match io {\n                NfaInputAction::CopyToOutput => {\n                    output[nout] = input[nin];\n                    nout += 1;\n                    nin += 1;\n                }\n                NfaInputAction::Discard => {\n                    nin += 1;\n                }\n                NfaInputAction::Epsilon => (),\n            }\n            state = s;\n            if state.is_field_final() {\n                break;\n            }\n        }\n        let res = ReadFieldResult::from_nfa(\n            state,\n            nin >= input.len(),\n            nout >= output.len(),\n        );\n        self.nfa_state = state;\n        (res, nin, nout)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_record":["/// Parse a single CSV record in `input` and copy each field contiguously\n/// to `output`, with the end position of each field written to `ends`.\n///\n/// **NOTE**: This method is more cumbersome to use than `read_field`, but\n/// it can be faster since it amortizes more work.\n///\n/// This routine requires a caller provided buffer of CSV data as the\n/// `input` and two caller provided buffers to store the unescaped field\n/// data (`output`) and the end position of each field in the record\n/// (`fields`).\n///\n/// Calling this routine parses at most a single record and returns four\n/// values indicating the state of the parser. The first value, a\n/// `ReadRecordResult`, tells the caller what to do next. For example, if\n/// the entire input was read or if the output buffer was filled before a\n/// full field had been read, then `ReadRecordResult::InputEmpty` or\n/// `ReadRecordResult::OutputFull` is returned, respectively. Similarly, if\n/// the `ends` buffer is full, then `ReadRecordResult::OutputEndsFull` is\n/// returned. See the documentation for `ReadRecordResult` for more\n/// details.\n///\n/// The other three values correspond to the number of bytes read from\n/// `input`, the number of bytes written to `output` and the number of\n/// end positions written to `ends`, respectively.\n///\n/// The end positions written to `ends` are constructed as if there was\n/// a single contiguous buffer in memory containing the entire row, even\n/// if `ReadRecordResult::OutputFull` was returned in the middle of reading\n/// a row.\n///\n/// # Termination\n///\n/// This reader interprets an empty `input` buffer as an indication that\n/// there is no CSV data left to read. Namely, when the caller has\n/// exhausted all CSV data, the caller should continue to call `read` with\n/// an empty input buffer until `ReadRecordResult::End` is returned.\n///\n/// # Errors\n///\n/// This CSV reader can never return an error. Instead, it prefers *a*\n/// parse over *no* parse.\npub fn read_record(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize){\n        let (input, bom_nin) = self.strip_utf8_bom(input);\n        let (res, nin, nout, nend) = if self.use_nfa {\n            self.read_record_nfa(input, output, ends)\n        } else {\n            self.read_record_dfa(input, output, ends)\n        };\n        self.has_read = true;\n        (res, nin + bom_nin, nout, nend)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_record_dfa":["#[inline(always)]\nfn read_record_dfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize){\n        if input.is_empty() {\n            let s = self.transition_final_dfa(self.dfa_state);\n            let res =\n                self.dfa.new_read_record_result(s, true, false, false, false);\n            // This part is a little tricky. When reading the final record,\n            // the last result the caller will get is an InputEmpty, and while\n            // they'll have everything they need in `output`, they'll be\n            // missing the final end position of the final field in `ends`.\n            // We insert that here, but we must take care to handle the case\n            // where `ends` doesn't have enough space. If it doesn't have\n            // enough space, then we also can't transition to the next state.\n            return match res {\n                ReadRecordResult::Record => {\n                    if ends.is_empty() {\n                        return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n                    }\n                    self.dfa_state = s;\n                    ends[0] = self.output_pos;\n                    self.output_pos = 0;\n                    (res, 0, 0, 1)\n                }\n                _ => {\n                    self.dfa_state = s;\n                    (res, 0, 0, 0)\n                }\n            };\n        }\n        if output.is_empty() {\n            return (ReadRecordResult::OutputFull, 0, 0, 0);\n        }\n        if ends.is_empty() {\n            return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n        }\n        let (mut nin, mut nout, mut nend) = (0, 0, 0);\n        let mut state = self.dfa_state;\n        while nin < input.len() && nout < output.len() && nend < ends.len() {\n            let (s, has_out) = self.dfa.get_output(state, input[nin]);\n            self.line += (input[nin] == b'\\n') as u64;\n            state = s;\n            if has_out {\n                output[nout] = input[nin];\n                nout += 1;\n            }\n            nin += 1;\n            if state >= self.dfa.final_field {\n                ends[nend] = self.output_pos + nout;\n                nend += 1;\n                if state > self.dfa.final_field {\n                    break;\n                }\n            }\n            if state == self.dfa.in_field || state == self.dfa.in_quoted {\n                self.dfa\n                    .classes\n                    .scan_and_copy(input, &mut nin, output, &mut nout);\n            }\n        }\n        let res = self.dfa.new_read_record_result(\n            state,\n            false,\n            nin >= input.len(),\n            nout >= output.len(),\n            nend >= ends.len(),\n        );\n        self.dfa_state = state;\n        if res.is_record() {\n            self.output_pos = 0;\n        } else {\n            self.output_pos += nout;\n        }\n        (res, nin, nout, nend)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::read_record_nfa":["#[inline(always)]\nfn read_record_nfa(\n        &mut self,\n        input: &[u8],\n        output: &mut [u8],\n        ends: &mut [usize],\n    ) -> (ReadRecordResult, usize, usize, usize){\n        if input.is_empty() {\n            let s = self.transition_final_nfa(self.nfa_state);\n            let res = ReadRecordResult::from_nfa(s, false, false, false);\n            return match res {\n                ReadRecordResult::Record => {\n                    if ends.is_empty() {\n                        return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n                    }\n                    self.nfa_state = s;\n                    ends[0] = self.output_pos;\n                    self.output_pos = 0;\n                    (res, 0, 0, 1)\n                }\n                _ => {\n                    self.nfa_state = s;\n                    (res, 0, 0, 0)\n                }\n            };\n        }\n        if output.is_empty() {\n            return (ReadRecordResult::OutputFull, 0, 0, 0);\n        }\n        if ends.is_empty() {\n            return (ReadRecordResult::OutputEndsFull, 0, 0, 0);\n        }\n        let (mut nin, mut nout, mut nend) = (0, self.output_pos, 0);\n        let mut state = self.nfa_state;\n        while nin < input.len() && nout < output.len() && nend < ends.len() {\n            let (s, io) = self.transition_nfa(state, input[nin]);\n            match io {\n                NfaInputAction::CopyToOutput => {\n                    output[nout] = input[nin];\n                    nout += 1;\n                    nin += 1;\n                }\n                NfaInputAction::Discard => {\n                    nin += 1;\n                }\n                NfaInputAction::Epsilon => {}\n            }\n            state = s;\n            if state.is_field_final() {\n                ends[nend] = nout;\n                nend += 1;\n                if state != NfaState::EndFieldDelim {\n                    break;\n                }\n            }\n        }\n        let res = ReadRecordResult::from_nfa(\n            state,\n            nin >= input.len(),\n            nout >= output.len(),\n            nend >= ends.len(),\n        );\n        self.nfa_state = state;\n        self.output_pos = if res.is_record() { 0 } else { nout };\n        (res, nin, nout, nend)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::reset":["/// Reset the parser such that it behaves as if it had never been used.\n///\n/// This may be useful when reading CSV data in a random access pattern.\npub fn reset(&mut self){\n        self.dfa_state = self.dfa.new_state(NfaState::StartRecord);\n        self.nfa_state = NfaState::StartRecord;\n        self.line = 1;\n        self.has_read = false;\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::set_line":["/// Set the line number.\n///\n/// This is useful after a call to `reset` where the caller knows the\n/// line number from some additional context.\npub fn set_line(&mut self, line: u64){\n        self.line = line;\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::strip_utf8_bom":["/// Strip off a possible UTF-8 BOM at the start of a file. Quick note that\n/// this method will fail to strip off the BOM if only part of the BOM is\n/// buffered. Hopefully that won't happen very often.\nfn strip_utf8_bom<'a>(&self, input: &'a [u8]) -> (&'a [u8], usize){\n        let (input, nin) = if {\n            !self.has_read\n                && input.len() >= 3\n                && &input[0..3] == b\"\\xef\\xbb\\xbf\"\n        } {\n            (&input[3..], 3)\n        } else {\n            (input, 0)\n        };\n        (input, nin)\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::transition_final_dfa":["/// Perform the final state transition, i.e., when the caller indicates\n/// that the input has been exhausted.\nfn transition_final_dfa(&self, state: DfaState) -> DfaState{\n        // If we''ve already emitted a record or think we're ready to start\n        // parsing a new record, then we should sink into the final state\n        // and never move from there. (pro-tip: the start state doubles as\n        // the final state!)\n        if state >= self.dfa.final_record || state.is_start() {\n            self.dfa.new_state_final_end()\n        } else {\n            self.dfa.new_state_final_record()\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::transition_final_nfa":["/// Compute the final NFA transition after all caller-provided input has\n/// been exhausted.\n#[inline(always)]\nfn transition_final_nfa(&self, state: NfaState) -> NfaState{\n        use self::NfaState::*;\n        match state {\n            End | StartRecord | EndRecord | InComment | CRLF => End,\n            StartField | EndFieldDelim | EndFieldTerm | InField\n            | InQuotedField | InEscapedQuote | InDoubleEscapedQuote\n            | InRecordTerm => EndRecord,\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::Reader::transition_nfa":["/// Compute the next NFA state given the current NFA state and the current\n/// input byte.\n///\n/// This returns the next NFA state along with an NfaInputAction that\n/// indicates what should be done with the input byte (nothing for an epsilon\n/// transition, copied to a caller provided output buffer, or discarded).\n#[inline(always)]\nfn transition_nfa(\n        &self,\n        state: NfaState,\n        c: u8,\n    ) -> (NfaState, NfaInputAction){\n        use self::NfaState::*;\n        match state {\n            End => (End, NfaInputAction::Epsilon),\n            StartRecord => {\n                if self.term.equals(c) {\n                    (StartRecord, NfaInputAction::Discard)\n                } else if self.comment == Some(c) {\n                    (InComment, NfaInputAction::Discard)\n                } else {\n                    (StartField, NfaInputAction::Epsilon)\n                }\n            }\n            EndRecord => (StartRecord, NfaInputAction::Epsilon),\n            StartField => {\n                if self.quoting && self.quote == c {\n                    (InQuotedField, NfaInputAction::Discard)\n                } else if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            EndFieldDelim => (StartField, NfaInputAction::Epsilon),\n            EndFieldTerm => (InRecordTerm, NfaInputAction::Epsilon),\n            InField => {\n                if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InQuotedField => {\n                if self.quoting && self.quote == c {\n                    (InDoubleEscapedQuote, NfaInputAction::Discard)\n                } else if self.quoting && self.escape == Some(c) {\n                    (InEscapedQuote, NfaInputAction::Discard)\n                } else {\n                    (InQuotedField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InEscapedQuote => (InQuotedField, NfaInputAction::CopyToOutput),\n            InDoubleEscapedQuote => {\n                if self.quoting && self.double_quote && self.quote == c {\n                    (InQuotedField, NfaInputAction::CopyToOutput)\n                } else if self.delimiter == c {\n                    (EndFieldDelim, NfaInputAction::Discard)\n                } else if self.term.equals(c) {\n                    (EndFieldTerm, NfaInputAction::Epsilon)\n                } else {\n                    (InField, NfaInputAction::CopyToOutput)\n                }\n            }\n            InComment => {\n                if b'\\n' == c {\n                    (StartRecord, NfaInputAction::Discard)\n                } else {\n                    (InComment, NfaInputAction::Discard)\n                }\n            }\n            InRecordTerm => {\n                if self.term.is_crlf() && b'\\r' == c {\n                    (CRLF, NfaInputAction::Discard)\n                } else {\n                    (EndRecord, NfaInputAction::Discard)\n                }\n            }\n            CRLF => {\n                if b'\\n' == c {\n                    (StartRecord, NfaInputAction::Discard)\n                } else {\n                    (StartRecord, NfaInputAction::Epsilon)\n                }\n            }\n        }\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder":["/// Builds a CSV reader with various configuration knobs.\n///\n/// This builder can be used to tweak the field delimiter, record terminator\n/// and more for parsing CSV. Once a CSV `Reader` is built, its configuration\n/// cannot be changed.\npub struct ReaderBuilder {\n    rdr: Reader,\n}","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::ascii":["/// A convenience method for specifying a configuration to read ASCII\n/// delimited text.\n///\n/// This sets the delimiter and record terminator to the ASCII unit\n/// separator (`\\x1F`) and record separator (`\\x1E`), respectively.\npub fn ascii(&mut self) -> &mut ReaderBuilder{\n        self.delimiter(b'\\x1F').terminator(Terminator::Any(b'\\x1E'))\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::build":["/// Build a CSV parser from this configuration.\npub fn build(&self) -> Reader{\n        let mut rdr = self.rdr.clone();\n        rdr.build_dfa();\n        rdr\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::comment":["/// The comment character to use when parsing CSV.\n///\n/// If the start of a record begins with the byte given here, then that\n/// line is ignored by the CSV parser.\n///\n/// This is disabled by default.\npub fn comment(&mut self, comment: Option<u8>) -> &mut ReaderBuilder{\n        self.rdr.comment = comment;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::delimiter":["/// The field delimiter to use when parsing CSV.\n///\n/// The default is `b','`.\npub fn delimiter(&mut self, delimiter: u8) -> &mut ReaderBuilder{\n        self.rdr.delimiter = delimiter;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::double_quote":["/// Enable double quote escapes.\n///\n/// This is enabled by default, but it may be disabled. When disabled,\n/// doubled quotes are not interpreted as escapes.\npub fn double_quote(&mut self, yes: bool) -> &mut ReaderBuilder{\n        self.rdr.double_quote = yes;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::escape":["/// The escape character to use when parsing CSV.\n///\n/// In some variants of CSV, quotes are escaped using a special escape\n/// character like `\\` (instead of escaping quotes by doubling them).\n///\n/// By default, recognizing these idiosyncratic escapes is disabled.\npub fn escape(&mut self, escape: Option<u8>) -> &mut ReaderBuilder{\n        self.rdr.escape = escape;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::new":["/// Create a new builder.\npub fn new() -> ReaderBuilder{\n        ReaderBuilder::default()\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::nfa":["/// Enable or disable the NFA for parsing CSV.\n///\n/// This is intended to be a debug option useful for debugging. The NFA\n/// is always slower than the DFA.\n#[doc(hidden)]\npub fn nfa(&mut self, yes: bool) -> &mut ReaderBuilder{\n        self.rdr.use_nfa = yes;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::quote":["/// The quote character to use when parsing CSV.\n///\n/// The default is `b'\"'`.\npub fn quote(&mut self, quote: u8) -> &mut ReaderBuilder{\n        self.rdr.quote = quote;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::quoting":["/// Enable or disable quoting.\n///\n/// This is enabled by default, but it may be disabled. When disabled,\n/// quotes are not treated specially.\npub fn quoting(&mut self, yes: bool) -> &mut ReaderBuilder{\n        self.rdr.quoting = yes;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"reader::ReaderBuilder::terminator":["/// The record terminator to use when parsing CSV.\n///\n/// A record terminator can be any single byte. The default is a special\n/// value, `Terminator::CRLF`, which treats any occurrence of `\\r`, `\\n`\n/// or `\\r\\n` as a single record terminator.\npub fn terminator(&mut self, term: Terminator) -> &mut ReaderBuilder{\n        self.rdr.term = term;\n        self\n    }","Real(LocalPath(\"csv-core/src/reader.rs\"))"],"writer::WriteResult":["/// The result of writing CSV data.\n///\n/// A value of this type is returned from every interaction with `Writer`. It\n/// informs the caller how to proceed, namely, by indicating whether more\n/// input should be given (`InputEmpty`) or if a bigger output buffer is needed\n/// (`OutputFull`).\npub enum WriteResult {\n    /// This result occurs when all of the bytes from the given input have\n    /// been processed.\n    InputEmpty,\n    /// This result occurs when the output buffer was too small to process\n    /// all of the input bytes. Generally, this means the caller must call\n    /// the corresponding method again with the rest of the input and more\n    /// room in the output buffer.\n    OutputFull,\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer":["/// A writer for CSV data.\n///\n/// # RFC 4180\n///\n/// This writer conforms to RFC 4180 with one exception: it doesn't guarantee\n/// that all records written are of the same length. Instead, the onus is on\n/// the caller to ensure that all records written are of the same length.\n///\n/// Note that the default configuration of a `Writer` uses `\\n` for record\n/// terminators instead of `\\r\\n` as specified by RFC 4180. Use the\n/// `terminator` method on `WriterBuilder` to set the terminator to `\\r\\n` if\n/// it's desired.\npub struct Writer {\n    state: WriterState,\n    requires_quotes: [bool; 256],\n    delimiter: u8,\n    term: Terminator,\n    style: QuoteStyle,\n    quote: u8,\n    escape: u8,\n    double_quote: bool,\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::delimiter":["/// Write the configured field delimiter to `output`.\n///\n/// If the output buffer does not have enough room to fit\n/// a field delimiter, then nothing is written to `output`\n/// and `WriteResult::OutputFull` is returned. Otherwise,\n/// `WriteResult::InputEmpty` is returned along with the number of bytes\n/// written to `output` (which is `1` in case of an unquoted\n/// field, or `2` in case of an end quote and a field separator).\npub fn delimiter(\n        &mut self,\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize){\n        let mut nout = 0;\n        if self.state.quoting {\n            let (res, o) = self.write(&[self.quote], output);\n            if o == 0 {\n                return (res, o);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n            self.state.quoting = false;\n        }\n        let (res, o) = self.write(&[self.delimiter], output);\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes += o as u64;\n        self.state.in_field = false;\n        (res, nout)\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::field":["/// Write a single CSV field from `input` to `output` while employing this\n/// writer's quoting style.\n///\n/// This returns the result of writing field data, in addition to the\n/// number of bytes consumed from `input` and the number of bytes\n/// written to `output`.\n///\n/// The result of writing field data is either `WriteResult::InputEmpty`\n/// or `WriteResult::OutputFull`. The former occurs when all bytes in\n/// `input` were copied to `output`, while the latter occurs when `output`\n/// is too small to fit everything from `input`. The maximum number of\n/// bytes that can be written to `output` is `2 + (2 * input.len())`\n/// because of quoting. (The worst case is a field consisting entirely\n/// of quotes.)\n///\n/// Multiple successive calls to `field` will write more data to the same\n/// field. Subsequent fields can be written by calling either `delimiter`\n/// or `terminator` first.\n///\n/// If this writer's quoting style is `QuoteStyle::Necessary`, then `input`\n/// should contain the *entire* field. Otherwise, whether the field needs\n/// to be quoted or not cannot be determined.\npub fn field(\n        &mut self,\n        input: &[u8],\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize, usize){\n        let (mut nin, mut nout) = (0, 0);\n\n        if !self.state.in_field {\n            self.state.quoting = self.should_quote(input);\n            if self.state.quoting {\n                let (res, o) = self.write(&[self.quote], output);\n                if o == 0 {\n                    return (res, 0, 0);\n                }\n                output = &mut moving(output)[o..];\n                nout += o;\n                self.state.record_bytes += o as u64;\n            }\n            self.state.in_field = true;\n        }\n        let (res, i, o) = if self.state.quoting {\n            quote(input, output, self.quote, self.escape, self.double_quote)\n        } else {\n            write_optimistic(input, output)\n        };\n        nin += i;\n        nout += o;\n        self.state.record_bytes += o as u64;\n        (res, nin, nout)\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::finish":["/// Finish writing CSV data to `output`.\n///\n/// This must be called when one is done writing CSV data to `output`.\n/// In particular, it will write closing quotes if necessary.\npub fn finish(&mut self, mut output: &mut [u8]) -> (WriteResult, usize){\n        let mut nout = 0;\n        if self.state.record_bytes == 0 && self.state.in_field {\n            assert!(!self.state.quoting);\n            let (res, o) = self.write(&[self.quote, self.quote], output);\n            if o == 0 {\n                return (res, 0);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n        }\n        if !self.state.quoting {\n            return (WriteResult::InputEmpty, nout);\n        }\n        let (res, o) = self.write(&[self.quote], output);\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes = 0;\n        self.state.in_field = false;\n        self.state.quoting = false;\n        (res, nout)\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_delimiter":["/// Return the delimiter used for this writer.\n#[inline]\npub fn get_delimiter(&self) -> u8{\n        self.delimiter\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_double_quote":["/// Return whether this writer doubles quotes or not. When the writer\n/// does not double quotes, it will escape them using the escape character.\n#[inline]\npub fn get_double_quote(&self) -> bool{\n        self.double_quote\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_escape":["/// Return the escape character used for this writer.\n#[inline]\npub fn get_escape(&self) -> u8{\n        self.escape\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_quote":["/// Return the quote character used for this writer.\n#[inline]\npub fn get_quote(&self) -> u8{\n        self.quote\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_quote_style":["/// Return the quoting style used for this writer.\n#[inline]\npub fn get_quote_style(&self) -> QuoteStyle{\n        self.style\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::get_terminator":["/// Return the terminator used for this writer.\n#[inline]\npub fn get_terminator(&self) -> Terminator{\n        self.term\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::is_special_byte":["/// Returns true if and only if the given byte corresponds to a special\n/// byte in this CSV writer's configuration.\n///\n/// Note that this does **not** take into account this writer's quoting\n/// style.\n#[inline]\npub fn is_special_byte(&self, b: u8) -> bool{\n        self.requires_quotes[b as usize]\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::needs_quotes":["/// Returns true if and only if the given input field *requires* quotes to\n/// preserve the integrity of `input` while taking into account the current\n/// configuration of this writer (except for the configured quoting style).\n#[inline]\nfn needs_quotes(&self, mut input: &[u8]) -> bool{\n        let mut needs = false;\n        while !needs && input.len() >= 8 {\n            needs = self.requires_quotes[input[0] as usize]\n                || self.requires_quotes[input[1] as usize]\n                || self.requires_quotes[input[2] as usize]\n                || self.requires_quotes[input[3] as usize]\n                || self.requires_quotes[input[4] as usize]\n                || self.requires_quotes[input[5] as usize]\n                || self.requires_quotes[input[6] as usize]\n                || self.requires_quotes[input[7] as usize];\n            input = &input[8..];\n        }\n        needs || input.iter().any(|&b| self.is_special_byte(b))\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::new":["/// Creates a new CSV writer with the default configuration.\npub fn new() -> Writer{\n        Writer::default()\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::should_quote":["/// Returns true if and only if we should put the given field data\n/// in quotes. This takes the quoting style into account.\n#[inline]\npub fn should_quote(&self, input: &[u8]) -> bool{\n        match self.style {\n            QuoteStyle::Always => true,\n            QuoteStyle::Never => false,\n            QuoteStyle::NonNumeric => is_non_numeric(input),\n            QuoteStyle::Necessary => self.needs_quotes(input),\n            _ => unreachable!(),\n        }\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::terminator":["/// Write the configured record terminator to `output`.\n///\n/// If the output buffer does not have enough room to fit a record\n/// terminator, then no part of the terminator is written and\n/// `WriteResult::OutputFull` is returned. Otherwise,\n/// `WriteResult::InputEmpty` is returned along with the number of bytes\n/// written to `output` (which is always `1` or `2`).\npub fn terminator(\n        &mut self,\n        mut output: &mut [u8],\n    ) -> (WriteResult, usize){\n        let mut nout = 0;\n        if self.state.record_bytes == 0 {\n            assert!(!self.state.quoting);\n            let (res, o) = self.write(&[self.quote, self.quote], output);\n            if o == 0 {\n                return (res, 0);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n        }\n        if self.state.quoting {\n            let (res, o) = self.write(&[self.quote], output);\n            if o == 0 {\n                return (res, o);\n            }\n            output = &mut moving(output)[o..];\n            nout += o;\n            self.state.record_bytes += o as u64;\n            self.state.quoting = false;\n        }\n        let (res, o) = match self.term {\n            Terminator::CRLF => write_pessimistic(&[b'\\r', b'\\n'], output),\n            Terminator::Any(b) => write_pessimistic(&[b], output),\n            _ => unreachable!(),\n        };\n        if o == 0 {\n            return (res, nout);\n        }\n        nout += o;\n        self.state.record_bytes = 0;\n        self.state.in_field = false;\n        (res, nout)\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::Writer::write":["fn write(&self, data: &[u8], output: &mut [u8]) -> (WriteResult, usize){\n        if data.len() > output.len() {\n            (WriteResult::OutputFull, 0)\n        } else {\n            output[..data.len()].copy_from_slice(data);\n            (WriteResult::InputEmpty, data.len())\n        }\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder":["/// A builder for configuring a CSV writer.\n///\n/// This builder permits specifying the CSV delimiter, terminator, quoting\n/// style and more.\npub struct WriterBuilder {\n    wtr: Writer,\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::build":["/// Builder a CSV writer from this configuration.\npub fn build(&self) -> Writer{\n        use crate::Terminator::*;\n\n        let mut wtr = self.wtr.clone();\n        wtr.requires_quotes[self.wtr.delimiter as usize] = true;\n        wtr.requires_quotes[self.wtr.quote as usize] = true;\n        if !self.wtr.double_quote {\n            // We only need to quote the escape character if the escape\n            // character is used for escaping quotes.\n            wtr.requires_quotes[self.wtr.escape as usize] = true;\n        }\n        match self.wtr.term {\n            CRLF | Any(b'\\n') | Any(b'\\r') => {\n                // This is a bit hokey. By default, the record terminator\n                // is '\\n', but we still need to quote '\\r' (even if our\n                // terminator is only `\\n`) because the reader interprets '\\r'\n                // as a record terminator by default.\n                wtr.requires_quotes[b'\\r' as usize] = true;\n                wtr.requires_quotes[b'\\n' as usize] = true;\n            }\n            Any(b) => {\n                wtr.requires_quotes[b as usize] = true;\n            }\n            _ => unreachable!(),\n        }\n        wtr\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::delimiter":["/// The field delimiter to use when writing CSV.\n///\n/// The default is `b','`.\npub fn delimiter(&mut self, delimiter: u8) -> &mut WriterBuilder{\n        self.wtr.delimiter = delimiter;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::double_quote":["/// The quoting escape mechanism to use when writing CSV.\n///\n/// When enabled (which is the default), quotes are escaped by doubling\n/// them. e.g., `\"` escapes to `\"\"`.\n///\n/// When disabled, quotes are escaped with the escape character (which\n/// is `\\\\` by default).\npub fn double_quote(&mut self, yes: bool) -> &mut WriterBuilder{\n        self.wtr.double_quote = yes;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::escape":["/// The escape character to use when writing CSV.\n///\n/// This is only used when `double_quote` is set to `false`.\n///\n/// The default value is `b'\\\\'`.\npub fn escape(&mut self, escape: u8) -> &mut WriterBuilder{\n        self.wtr.escape = escape;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::new":["/// Create a new builder for configuring a CSV writer.\npub fn new() -> WriterBuilder{\n        let wtr = Writer {\n            state: WriterState::default(),\n            requires_quotes: [false; 256],\n            delimiter: b',',\n            term: Terminator::Any(b'\\n'),\n            style: QuoteStyle::default(),\n            quote: b'\"',\n            escape: b'\\\\',\n            double_quote: true,\n        };\n        WriterBuilder { wtr: wtr }\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::quote":["/// The quote character to use when writing CSV.\n///\n/// The default value is `b'\"'`.\npub fn quote(&mut self, quote: u8) -> &mut WriterBuilder{\n        self.wtr.quote = quote;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::quote_style":["/// The quoting style to use when writing CSV.\n///\n/// By default, this is set to `QuoteStyle::Necessary`, which will only\n/// use quotes when they are necessary to preserve the integrity of data.\n///\n/// Note that unless the quote style is set to `Never`, an empty field is\n/// quoted if it is the only field in a record.\npub fn quote_style(&mut self, style: QuoteStyle) -> &mut WriterBuilder{\n        self.wtr.style = style;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterBuilder::terminator":["/// The record terminator to use when writing CSV.\n///\n/// A record terminator can be any single byte. The default is `\\n`.\n///\n/// Note that RFC 4180 specifies that record terminators should be `\\r\\n`.\n/// To use `\\r\\n`, use the special `Terminator::CRLF` value.\npub fn terminator(&mut self, term: Terminator) -> &mut WriterBuilder{\n        self.wtr.term = term;\n        self\n    }","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::WriterState":["struct WriterState {\n    /// This is set whenever we've begun writing the contents of a field, even\n    /// if the contents are empty. We use it to avoid re-computing whether\n    /// quotes are necessary.\n    in_field: bool,\n    /// This is set whenever we've started writing a field that is enclosed in\n    /// quotes. When the writer is finished, or if a delimiter or terminator\n    /// are written, then a closing quote is inserted when this is true.\n    quoting: bool,\n    /// The number of total bytes written for the current record.\n    ///\n    /// If the writer is finished or a terminator is written when this is `0`,\n    /// then an empty field is added as a pair of adjacent quotes.\n    record_bytes: u64,\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::is_non_numeric":["/// Returns true if and only if the given input is non-numeric.\npub fn is_non_numeric(input: &[u8]) -> bool{\n    let s = match str::from_utf8(input) {\n        Err(_) => return true,\n        Ok(s) => s,\n    };\n    // I suppose this could be faster if we wrote validators of numbers instead\n    // of using the actual parser, but that's probably a lot of work for a bit\n    // of a niche feature.\n    !s.parse::<f64>().is_ok() && !s.parse::<i128>().is_ok()\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::moving":["/// This avoids reborrowing.\n/// See: https://bluss.github.io/rust/fun/2015/10/11/stuff-the-identity-function-does/\nfn moving<T>(x: T) -> T{\n    x\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::quote":["/// Escape quotes `input` and writes the result to `output`.\n///\n/// If `input` does not have a `quote`, then the contents of `input` are\n/// copied verbatim to `output`.\n///\n/// If `output` is not big enough to store the fully quoted contents of\n/// `input`, then `WriteResult::OutputFull` is returned. The `output` buffer\n/// will require a maximum of storage of `2 * input.len()` in the worst case\n/// (where every byte is a quote).\n///\n/// In streaming contexts, `quote` should be called in a loop until\n/// `WriteResult::InputEmpty` is returned. It is possible to write an infinite\n/// loop if your output buffer is less than 2 bytes in length (the minimum\n/// storage space required to store an escaped quote).\n///\n/// In addition to the `WriteResult`, the number of consumed bytes from `input`\n/// and the number of bytes written to `output` are also returned.\n///\n/// `quote` is the quote byte and `escape` is the escape byte. If\n/// `double_quote` is true, then quotes are escaped by doubling them,\n/// otherwise, quotes are escaped with the `escape` byte.\n///\n/// N.B. This function is provided for low level usage. It is called\n/// automatically if you're using a `Writer`.\npub fn quote(\n    mut input: &[u8],\n    mut output: &mut [u8],\n    quote: u8,\n    escape: u8,\n    double_quote: bool,\n) -> (WriteResult, usize, usize){\n    let (mut nin, mut nout) = (0, 0);\n    loop {\n        match memchr(quote, input) {\n            None => {\n                let (res, i, o) = write_optimistic(input, output);\n                nin += i;\n                nout += o;\n                return (res, nin, nout);\n            }\n            Some(next_quote) => {\n                let (res, i, o) =\n                    write_optimistic(&input[..next_quote], output);\n                input = &input[i..];\n                output = &mut moving(output)[o..];\n                nin += i;\n                nout += o;\n                if let WriteResult::OutputFull = res {\n                    return (res, nin, nout);\n                }\n                if double_quote {\n                    let (res, o) = write_pessimistic(&[quote, quote], output);\n                    if let WriteResult::OutputFull = res {\n                        return (res, nin, nout);\n                    }\n                    nout += o;\n                    output = &mut moving(output)[o..];\n                } else {\n                    let (res, o) = write_pessimistic(&[escape, quote], output);\n                    if let WriteResult::OutputFull = res {\n                        return (res, nin, nout);\n                    }\n                    nout += o;\n                    output = &mut moving(output)[o..];\n                }\n                nin += 1;\n                input = &input[1..];\n            }\n        }\n    }\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::write_optimistic":["/// Copy the bytes from `input` to `output`. If `output` is too small to fit\n/// everything from `input`, then copy `output.len()` bytes from `input`.\n/// Otherwise, copy everything from `input` into `output`.\n///\n/// In the first case (`output` is too small), `WriteResult::OutputFull` is\n/// returned, in addition to the number of bytes consumed from `input` and\n/// the number of bytes written to `output`.\n///\n/// In the second case (`input` is no bigger than `output`),\n/// `WriteResult::InputEmpty` is returned, in addition to the number of bytes\n/// consumed from `input` and the number of bytes written to `output`.\nfn write_optimistic(\n    input: &[u8],\n    output: &mut [u8],\n) -> (WriteResult, usize, usize){\n    if input.len() > output.len() {\n        let input = &input[..output.len()];\n        output.copy_from_slice(input);\n        (WriteResult::OutputFull, output.len(), output.len())\n    } else {\n        output[..input.len()].copy_from_slice(input);\n        (WriteResult::InputEmpty, input.len(), input.len())\n    }\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"],"writer::write_pessimistic":["/// Copy the bytes from `input` to `output` only if `input` is no bigger than\n/// `output`. If `input` is bigger than `output`, then return\n/// `WriteResult::OutputFull` and copy nothing into `output`. Otherwise,\n/// return `WriteResult::InputEmpty` and the number of bytes copied into\n/// `output`.\nfn write_pessimistic(input: &[u8], output: &mut [u8]) -> (WriteResult, usize){\n    if input.len() > output.len() {\n        (WriteResult::OutputFull, 0)\n    } else {\n        output[..input.len()].copy_from_slice(input);\n        (WriteResult::InputEmpty, input.len())\n    }\n}","Real(LocalPath(\"csv-core/src/writer.rs\"))"]},"struct_constructor":{"(&'a [u8], usize)":["strip_utf8_bom"],"(reader::DfaState, bool)":["get_output"],"(reader::NfaState, reader::NfaInputAction)":["transition_nfa"],"(reader::ReadFieldResult, usize, usize)":["read_field","read_field_dfa","read_field_nfa"],"(reader::ReadRecordResult, usize, usize, usize)":["read_record","read_record_dfa","read_record_nfa"],"(writer::WriteResult, usize)":["delimiter","finish","terminator","write","write_pessimistic"],"(writer::WriteResult, usize, usize)":["field","quote","write_optimistic"],"QuoteStyle":["clone","default","get_quote_style"],"Terminator":["clone","default","get_terminator"],"bool":["eq","equals","get_double_quote","is_crlf","is_field_final","is_non_numeric","is_record","is_record_final","is_special_byte","is_start","needs_quotes","should_quote"],"core::cmp::Ordering":["cmp"],"core::option::Option":["partial_cmp"],"core::result::Result":["fmt"],"reader::Dfa":["clone","new"],"reader::DfaClasses":["clone","new"],"reader::DfaState":["clone","new_state","new_state_final_end","new_state_final_record","start"],"reader::NfaInputAction":["clone"],"reader::NfaState":["clone"],"reader::ReadFieldNoCopyResult":["clone"],"reader::ReadFieldResult":["clone","from_nfa","new_read_field_result"],"reader::ReadRecordNoCopyResult":["clone"],"reader::ReadRecordResult":["clone","from_nfa","new_read_record_result"],"reader::Reader":["build","clone","default","new"],"reader::ReaderBuilder":["default","new"],"u64":["line"],"u8":["get_delimiter","get_escape","get_quote"],"usize":["num_classes"],"writer::WriteResult":["clone"],"writer::Writer":["build","clone","default","new"],"writer::WriterBuilder":["default","new"],"writer::WriterState":["clone","default"]},"struct_to_trait":{"QuoteStyle":["core::clone::Clone","core::default::Default","core::fmt::Debug","core::marker::Copy"],"Terminator":["core::clone::Clone","core::default::Default","core::fmt::Debug","core::marker::Copy"],"reader::Dfa":["core::clone::Clone","core::fmt::Debug"],"reader::DfaClasses":["core::clone::Clone","core::fmt::Debug"],"reader::DfaState":["core::clone::Clone","core::cmp::Eq","core::cmp::Ord","core::cmp::PartialEq","core::cmp::PartialOrd","core::fmt::Debug","core::marker::Copy","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::NfaInputAction":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::NfaState":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::Copy","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::ReadFieldNoCopyResult":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::ReadFieldResult":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::ReadRecordNoCopyResult":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::ReadRecordResult":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"reader::Reader":["core::clone::Clone","core::default::Default","core::fmt::Debug"],"reader::ReaderBuilder":["core::default::Default","core::fmt::Debug"],"writer::WriteResult":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"writer::Writer":["core::clone::Clone","core::default::Default","core::fmt::Debug"],"writer::WriterBuilder":["core::default::Default","core::fmt::Debug"],"writer::WriterState":["core::clone::Clone","core::default::Default","core::fmt::Debug"]},"targets":{"<QuoteStyle as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/lib.rs\"))","core::default::Default"],"<Terminator as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/lib.rs\"))","core::default::Default"],"<reader::Dfa as core::clone::Clone>::clone":["clone","Real(LocalPath(\"csv-core/src/reader.rs\"))","core::clone::Clone"],"<reader::Dfa as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"csv-core/src/reader.rs\"))","core::fmt::Debug"],"<reader::DfaClasses as core::clone::Clone>::clone":["clone","Real(LocalPath(\"csv-core/src/reader.rs\"))","core::clone::Clone"],"<reader::DfaClasses as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"csv-core/src/reader.rs\"))","core::fmt::Debug"],"<reader::Reader as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/reader.rs\"))","core::default::Default"],"<writer::Writer as core::clone::Clone>::clone":["clone","Real(LocalPath(\"csv-core/src/writer.rs\"))","core::clone::Clone"],"<writer::Writer as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/writer.rs\"))","core::default::Default"],"<writer::Writer as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"csv-core/src/writer.rs\"))","core::fmt::Debug"],"<writer::WriterBuilder as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/writer.rs\"))","core::default::Default"],"<writer::WriterState as core::default::Default>::default":["default","Real(LocalPath(\"csv-core/src/writer.rs\"))","core::default::Default"],"Terminator::equals":["equals","Real(LocalPath(\"csv-core/src/lib.rs\"))",""],"Terminator::is_crlf":["is_crlf","Real(LocalPath(\"csv-core/src/lib.rs\"))",""],"reader::Dfa::finish":["finish","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::get_output":["get_output","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new":["new","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new_read_field_result":["new_read_field_result","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new_read_record_result":["new_read_record_result","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new_state":["new_state","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new_state_final_end":["new_state_final_end","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::new_state_final_record":["new_state_final_record","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Dfa::set":["set","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaClasses::add":["add","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaClasses::new":["new","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaClasses::num_classes":["num_classes","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaClasses::scan_and_copy":["scan_and_copy","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaState::is_start":["is_start","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::DfaState::start":["start","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::NfaState::is_field_final":["is_field_final","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::NfaState::is_record_final":["is_record_final","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReadFieldResult::from_nfa":["from_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReadRecordResult::from_nfa":["from_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReadRecordResult::is_record":["is_record","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::build_dfa":["build_dfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::line":["line","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::new":["new","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_field":["read_field","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_field_dfa":["read_field_dfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_field_nfa":["read_field_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_record":["read_record","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_record_dfa":["read_record_dfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::read_record_nfa":["read_record_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::reset":["reset","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::set_line":["set_line","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::strip_utf8_bom":["strip_utf8_bom","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::transition_final_dfa":["transition_final_dfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::transition_final_nfa":["transition_final_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::Reader::transition_nfa":["transition_nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::ascii":["ascii","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::build":["build","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::comment":["comment","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::delimiter":["delimiter","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::double_quote":["double_quote","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::escape":["escape","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::new":["new","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::nfa":["nfa","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::quote":["quote","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::quoting":["quoting","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"reader::ReaderBuilder::terminator":["terminator","Real(LocalPath(\"csv-core/src/reader.rs\"))",""],"writer::Writer::delimiter":["delimiter","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::field":["field","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::finish":["finish","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_delimiter":["get_delimiter","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_double_quote":["get_double_quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_escape":["get_escape","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_quote":["get_quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_quote_style":["get_quote_style","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::get_terminator":["get_terminator","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::is_special_byte":["is_special_byte","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::needs_quotes":["needs_quotes","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::new":["new","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::should_quote":["should_quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::terminator":["terminator","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::Writer::write":["write","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::build":["build","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::delimiter":["delimiter","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::double_quote":["double_quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::escape":["escape","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::new":["new","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::quote":["quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::quote_style":["quote_style","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::WriterBuilder::terminator":["terminator","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::is_non_numeric":["is_non_numeric","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::moving":["moving","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::quote":["quote","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::write_optimistic":["write_optimistic","Real(LocalPath(\"csv-core/src/writer.rs\"))",""],"writer::write_pessimistic":["write_pessimistic","Real(LocalPath(\"csv-core/src/writer.rs\"))",""]},"trait_to_struct":{"core::clone::Clone":["QuoteStyle","Terminator","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","reader::Reader","writer::WriteResult","writer::Writer","writer::WriterState"],"core::cmp::Eq":["reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","writer::WriteResult"],"core::cmp::Ord":["reader::DfaState"],"core::cmp::PartialEq":["reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","writer::WriteResult"],"core::cmp::PartialOrd":["reader::DfaState"],"core::default::Default":["QuoteStyle","Terminator","reader::Reader","reader::ReaderBuilder","writer::Writer","writer::WriterBuilder","writer::WriterState"],"core::fmt::Debug":["QuoteStyle","Terminator","reader::Dfa","reader::DfaClasses","reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","reader::Reader","reader::ReaderBuilder","writer::WriteResult","writer::Writer","writer::WriterBuilder","writer::WriterState"],"core::marker::Copy":["QuoteStyle","Terminator","reader::DfaState","reader::NfaState"],"core::marker::StructuralEq":["reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","writer::WriteResult"],"core::marker::StructuralPartialEq":["reader::DfaState","reader::NfaInputAction","reader::NfaState","reader::ReadFieldNoCopyResult","reader::ReadFieldResult","reader::ReadRecordNoCopyResult","reader::ReadRecordResult","writer::WriteResult"]},"type_to_def_path":{"QuoteStyle":"QuoteStyle","Terminator":"Terminator","reader::Dfa":"reader::Dfa","reader::DfaClasses":"reader::DfaClasses","reader::DfaState":"reader::DfaState","reader::NfaInputAction":"reader::NfaInputAction","reader::NfaState":"reader::NfaState","reader::ReadFieldNoCopyResult":"reader::ReadFieldNoCopyResult","reader::ReadFieldResult":"reader::ReadFieldResult","reader::ReadRecordNoCopyResult":"reader::ReadRecordNoCopyResult","reader::ReadRecordResult":"reader::ReadRecordResult","reader::Reader":"reader::Reader","reader::ReaderBuilder":"reader::ReaderBuilder","writer::WriteResult":"writer::WriteResult","writer::Writer":"writer::Writer","writer::WriterBuilder":"writer::WriterBuilder","writer::WriterState":"writer::WriterState"}}