{"dependencies":{"<&'a map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<&'a mut map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<&'a set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Iter"],"<&set::HashSet<T, S> as core::ops::BitAnd<&set::HashSet<T, S>>>::bitand":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<&set::HashSet<T, S> as core::ops::BitOr<&set::HashSet<T, S>>>::bitor":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<&set::HashSet<T, S> as core::ops::BitXor<&set::HashSet<T, S>>>::bitxor":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<&set::HashSet<T, S> as core::ops::Sub<&set::HashSet<T, S>>>::sub":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<TryReserveError as core::clone::Clone>::clone":["TryReserveError","core::alloc::Layout"],"<TryReserveError as core::cmp::Eq>::assert_receiver_is_total_eq":["TryReserveError","core::alloc::Layout"],"<TryReserveError as core::cmp::PartialEq>::eq":["TryReserveError","core::alloc::Layout"],"<TryReserveError as core::fmt::Debug>::fmt":["TryReserveError","core::alloc::Layout","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<map::ConsumeAllOnDrop<'_, T> as core::ops::Drop>::drop":["core::iter::Iterator","core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::ConsumeAllOnDrop","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Drain<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","core::result::Result","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Drain<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Drain<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Drain<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::DrainFilter","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::DrainFilter","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<map::DrainFilter<'a, K, V, F> as core::ops::Drop>::drop":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilter","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<map::Entry<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","core::result::Result","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone_from":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::cmp::PartialEq>::eq":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::default::Default>::default":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::iter::Extend<(&'a K, &'a V)>>::extend":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::iter::Extend<(K, V)>>::extend":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::iter::FromIterator<(K, V)>>::from_iter":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<map::HashMap<K, V, S> as core::ops::Index<&Q>>::index":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"<map::IntoIter<K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","core::result::Result","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IntoIter<K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IntoIter<K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IntoIter<K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Iter<'_, K, V> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Iter<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Iter<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Keys<'_, K, V> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Keys<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Keys<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::OccupiedEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","core::result::Result","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"<map::RawEntryBuilder<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"<map::RawEntryBuilderMut<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","map::RawEntryBuilderMut","raw::RawTable"],"<map::RawEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"<map::RawOccupiedEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"<map::RawVacantEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::RawVacantEntryMut","raw::RawTable"],"<map::VacantEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","map::VacantEntry","raw::RawTable"],"<map::Values<'_, K, V> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Values<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Values<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::Values<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::Bucket<T> as core::clone::Clone>::clone":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"<raw::Fallibility as core::clone::Clone>::clone":["raw::Fallibility"],"<raw::ProbeSeq as core::iter::Iterator>::next":["core::marker::Sized","core::option::Option","raw::ProbeSeq"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawDrain<'_, T> as core::ops::Drop>::drop":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIntoIter<T> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIntoIter<T> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIntoIter<T> as core::ops::Drop>::drop":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIter<T> as core::clone::Clone>::clone":["core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIter<T> as core::iter::Iterator>::next":["core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIter<T> as core::iter::Iterator>::size_hint":["core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIterHash<'a, T> as core::iter::Iterator>::next":["core::arch::x86_64::__m128i","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::ProbeSeq","raw::RawIterHash","raw::RawTable","raw::bitmask::BitMask","raw::bitmask::BitMaskIter","raw::sse2::Group"],"<raw::RawIterRange<T> as core::clone::Clone>::clone":["core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIterRange<T> as core::iter::Iterator>::next":["core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawIterRange<T> as core::iter::Iterator>::size_hint":["core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIterRange","raw::bitmask::BitMask"],"<raw::RawTable<T> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"<raw::RawTable<T> as core::clone::Clone>::clone_from":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"<raw::RawTable<T> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"<raw::RawTable<T> as core::ops::Drop>::drop":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"<raw::RawTable<T> as raw::RawTableClone>::clone_from_spec":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","raw::RawTable"],"<raw::bitmask::BitMask as core::clone::Clone>::clone":["raw::bitmask::BitMask"],"<raw::bitmask::BitMask as core::iter::IntoIterator>::into_iter":["raw::bitmask::BitMask","raw::bitmask::BitMaskIter"],"<raw::bitmask::BitMaskIter as core::iter::Iterator>::next":["core::marker::Sized","core::option::Option","raw::bitmask::BitMask","raw::bitmask::BitMaskIter"],"<raw::sse2::Group as core::clone::Clone>::clone":["core::arch::x86_64::__m128i","raw::sse2::Group"],"<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref":["core::marker::Sized","core::ops::FnMut","scopeguard::ScopeGuard"],"<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut":["core::marker::Sized","core::ops::FnMut","scopeguard::ScopeGuard"],"<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop":["core::marker::Sized","core::ops::FnMut","scopeguard::ScopeGuard"],"<set::Difference<'_, T, S> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"<set::Difference<'_, T, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"<set::Difference<'a, T, S> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"<set::Difference<'a, T, S> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"<set::Drain<'_, K> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","core::result::Result","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"<set::Drain<'_, K> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"<set::Drain<'_, K> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"<set::Drain<'_, K> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::option::Option","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::DrainFilter"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::DrainFilter"],"<set::DrainFilter<'a, K, F> as core::ops::Drop>::drop":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::DrainFilter"],"<set::HashSet<T, S> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::clone::Clone>::clone_from":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::cmp::PartialEq>::eq":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::default::Default>::default":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::iter::Extend<T>>::extend":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter":["core::iter::IntoIterator","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"<set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::IntoIter"],"<set::Intersection<'_, T, S> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"<set::Intersection<'_, T, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"<set::IntoIter<K> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","core::result::Result","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"<set::IntoIter<K> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"<set::IntoIter<K> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"<set::IntoIter<K> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"<set::Iter<'_, K> as core::clone::Clone>::clone":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"<set::Iter<'_, K> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"<set::Iter<'a, K> as core::iter::ExactSizeIterator>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"<set::Iter<'a, K> as core::iter::Iterator>::next":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"<set::Iter<'a, K> as core::iter::Iterator>::size_hint":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"<set::SymmetricDifference<'_, T, S> as core::clone::Clone>::clone":["core::iter::Chain","core::marker::Sized","set::SymmetricDifference"],"<set::SymmetricDifference<'_, T, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::iter::Chain","core::marker::Sized","core::result::Result","set::SymmetricDifference"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::next":["core::iter::Chain","core::marker::Sized","core::option::Option","set::SymmetricDifference"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::size_hint":["core::iter::Chain","core::marker::Sized","core::option::Option","set::SymmetricDifference"],"<set::Union<'_, T, S> as core::clone::Clone>::clone":["core::iter::Chain","core::marker::Sized","set::Union"],"<set::Union<'_, T, S> as core::fmt::Debug>::fmt":["core::fmt::Formatter","core::iter::Chain","core::marker::Sized","core::result::Result","set::Union"],"<set::Union<'a, T, S> as core::iter::Iterator>::next":["core::iter::Chain","core::marker::Sized","core::option::Option","set::Union"],"<set::Union<'a, T, S> as core::iter::Iterator>::size_hint":["core::iter::Chain","core::marker::Sized","core::option::Option","set::Union"],"TryReserveError":["TryReserveError","core::alloc::Layout"],"map::ConsumeAllOnDrop":["core::iter::Iterator","core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::ConsumeAllOnDrop","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::Drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::Drain::<'_, K, V>::iter":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","map::Iter","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::DrainFilter":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilter","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::DrainFilterInner":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::DrainFilterInner::<'_, K, V>::next":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::Entry":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::and_modify":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::and_replace_entry_with":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::key":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::or_default":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::or_insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::or_insert_with":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::Entry::<'a, K, V, S>::or_insert_with_key":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::HashMap":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::clear":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::contains_key":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","map::HashMap","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::drain_filter":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilter","map::DrainFilterInner","map::HashMap","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::entry":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::HashMap::<K, V, S>::get":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::get_inner":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::get_inner_mut":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::get_key_value":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::get_key_value_mut":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::get_mut":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::insert":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::is_empty":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::iter_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::keys":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::raw_entry":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::HashMap::<K, V, S>::raw_entry_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","raw::RawTable"],"map::HashMap::<K, V, S>::remove":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::remove_entry":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::reserve":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::retain":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::shrink_to":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::shrink_to_fit":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::try_reserve":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::values":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::values_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"map::HashMap::<K, V, S>::with_capacity_and_hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V, S>::with_hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V>::new":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::HashMap::<K, V>::with_capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::IntoIter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::IntoIter::<K, V>::iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","map::Iter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::Iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::IterMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::IterMut::<'_, K, V>::iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::IterMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::Keys":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::OccupiedEntry":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::get":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::get_mut":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::insert":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::into_mut":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::key":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::remove":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::remove_entry":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::replace_entry":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::replace_entry_with":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::option::Option","core::ptr::NonNull","map::Entry","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::OccupiedEntry::<'a, K, V, S>::replace_key":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","raw::Bucket","raw::RawTable"],"map::RawEntryBuilder":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::RawEntryBuilder::<'a, K, V, S>::from_hash":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::RawEntryBuilder::<'a, K, V, S>::from_key":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::RawEntryBuilder::<'a, K, V, S>::from_key_hashed_nocheck":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::RawEntryBuilder::<'a, K, V, S>::search":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","map::HashMap","map::RawEntryBuilder","raw::RawTable"],"map::RawEntryBuilderMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","raw::RawTable"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_hash":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key_hashed_nocheck":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryBuilderMut::<'a, K, V, S>::search":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::HashMap","map::RawEntryBuilderMut","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut::<'a, K, V, S>::and_modify":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut::<'a, K, V, S>::and_replace_entry_with":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut::<'a, K, V, S>::insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut::<'a, K, V, S>::or_insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawEntryMut::<'a, K, V, S>::or_insert_with":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key_value":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::key_mut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove_entry":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","raw::Bucket","raw::RawTable"],"map::RawOccupiedEntryMut::<'a, K, V, S>::replace_entry_with":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawVacantEntryMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawVacantEntryMut","raw::RawTable"],"map::RawVacantEntryMut::<'a, K, V, S>::insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawVacantEntryMut","raw::RawTable"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_entry":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawOccupiedEntryMut","map::RawVacantEntryMut","raw::Bucket","raw::RawTable"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_hashed_nocheck":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::RawVacantEntryMut","raw::RawTable"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_with_hasher":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","map::RawVacantEntryMut","raw::RawTable"],"map::VacantEntry":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::VacantEntry","raw::RawTable"],"map::VacantEntry::<'a, K, V, S>::insert":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::VacantEntry","raw::RawTable"],"map::VacantEntry::<'a, K, V, S>::insert_entry":["core::hash::BuildHasher","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","map::OccupiedEntry","map::VacantEntry","raw::Bucket","raw::RawTable"],"map::VacantEntry::<'a, K, V, S>::into_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::VacantEntry","raw::RawTable"],"map::VacantEntry::<'a, K, V, S>::key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::VacantEntry","raw::RawTable"],"map::Values":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::ValuesMut":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::IterMut","map::ValuesMut","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance":[],"map::assert_covariance::drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::into_iter_key":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::into_iter_val":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::iter_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::iter_val":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::keys_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::keys_val":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::map_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::assert_covariance::map_val":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable"],"map::assert_covariance::values_key":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::assert_covariance::values_val":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Values","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"map::make_hash":["core::hash::BuildHasher","core::hash::Hash","core::marker::Sized"],"raw::Bucket":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::as_mut":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::as_ptr":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::as_ref":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::copy_from_nonoverlapping":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::drop":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::from_base_index":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::next_n":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::read":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::to_base_index":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Bucket::<T>::write":["core::marker::Sized","core::ptr::NonNull","raw::Bucket"],"raw::Fallibility":["raw::Fallibility"],"raw::Fallibility::alloc_err":["TryReserveError","core::alloc::Layout","raw::Fallibility"],"raw::Fallibility::capacity_overflow":["TryReserveError","core::alloc::Layout","raw::Fallibility"],"raw::ProbeSeq":["raw::ProbeSeq"],"raw::RawDrain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawDrain::<'_, T>::iter":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawIntoIter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawIntoIter::<T>::iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawIter":["core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawIterHash":["core::arch::x86_64::__m128i","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::ProbeSeq","raw::RawIterHash","raw::RawTable","raw::bitmask::BitMask","raw::bitmask::BitMaskIter","raw::sse2::Group"],"raw::RawIterHash::<'a, T>::new":["core::arch::x86_64::__m128i","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::ProbeSeq","raw::RawIterHash","raw::RawTable","raw::bitmask::BitMask","raw::bitmask::BitMaskIter","raw::sse2::Group"],"raw::RawIterRange":["core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawIterRange::<T>::new":["core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIterRange","raw::bitmask::BitMask"],"raw::RawTable":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::bucket":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::bucket_index":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::buckets":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::clear":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::clear_no_drop":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::clone_from_impl":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::ctrl":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::data_end":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"raw::RawTable::<T>::drain_iter_from":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"raw::RawTable::<T>::erase":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::erase_no_drop":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::fallible_with_capacity":["core::marker::Sized","core::result::Result","raw::Fallibility"],"raw::RawTable::<T>::find":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::find_insert_slot":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::free_buckets":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::get":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::get_mut":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::insert":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::insert_entry":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::into_alloc":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::into_iter_from":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"raw::RawTable::<T>::is_empty_singleton":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask"],"raw::RawTable::<T>::iter_hash":["core::arch::x86_64::__m128i","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::ProbeSeq","raw::RawIterHash","raw::RawTable","raw::bitmask::BitMask","raw::bitmask::BitMaskIter","raw::sse2::Group"],"raw::RawTable::<T>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::new":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::new_uninitialized":["core::marker::Sized","core::result::Result","raw::Fallibility"],"raw::RawTable::<T>::num_ctrl_bytes":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::probe_seq":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::ProbeSeq","raw::RawTable"],"raw::RawTable::<T>::rehash_in_place":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::remove":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::remove_entry":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::option::Option","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::replace_bucket_with":["core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","raw::Bucket","raw::RawTable"],"raw::RawTable::<T>::reserve":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::reserve_rehash":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","core::result::Result","raw::Fallibility","raw::RawTable"],"raw::RawTable::<T>::resize":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","core::result::Result","raw::Fallibility","raw::RawTable"],"raw::RawTable::<T>::set_ctrl":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::shrink_to":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","raw::RawTable"],"raw::RawTable::<T>::try_reserve":["core::marker::PhantomData","core::marker::Sized","core::ops::Fn","core::ptr::NonNull","core::result::Result","raw::RawTable"],"raw::RawTable::<T>::with_capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","raw::RawTable"],"raw::RawTableClone::clone_from_spec":["core::marker::Sized","core::ops::FnMut"],"raw::bitmask::BitMask":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::any_bit_set":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::invert":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::leading_zeros":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::lowest_set_bit":["core::marker::Sized","core::option::Option","raw::bitmask::BitMask"],"raw::bitmask::BitMask::lowest_set_bit_nonzero":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::remove_lowest_bit":["raw::bitmask::BitMask"],"raw::bitmask::BitMask::trailing_zeros":["raw::bitmask::BitMask"],"raw::bitmask::BitMaskIter":["raw::bitmask::BitMask","raw::bitmask::BitMaskIter"],"raw::bucket_mask_to_capacity":[],"raw::calculate_layout":["core::marker::Sized","core::option::Option"],"raw::capacity_to_buckets":["core::marker::Sized","core::option::Option"],"raw::h1":[],"raw::h2":[],"raw::is_full":[],"raw::is_special":[],"raw::likely":[],"raw::offset_from":["core::marker::Sized"],"raw::special_is_empty":[],"raw::sse2::Group":["core::arch::x86_64::__m128i","raw::sse2::Group"],"raw::sse2::Group::convert_special_to_empty_and_full_to_deleted":["core::arch::x86_64::__m128i","raw::sse2::Group"],"raw::sse2::Group::load":["core::arch::x86_64::__m128i","raw::sse2::Group"],"raw::sse2::Group::load_aligned":["core::arch::x86_64::__m128i","raw::sse2::Group"],"raw::sse2::Group::match_byte":["core::arch::x86_64::__m128i","raw::bitmask::BitMask","raw::sse2::Group"],"raw::sse2::Group::match_empty":["core::arch::x86_64::__m128i","raw::bitmask::BitMask","raw::sse2::Group"],"raw::sse2::Group::match_empty_or_deleted":["core::arch::x86_64::__m128i","raw::bitmask::BitMask","raw::sse2::Group"],"raw::sse2::Group::match_full":["core::arch::x86_64::__m128i","raw::bitmask::BitMask","raw::sse2::Group"],"raw::sse2::Group::static_empty":[],"raw::sse2::Group::static_empty::AlignedBytes":["core::arch::x86_64::__m128i","raw::sse2::Group","raw::sse2::Group::static_empty::AlignedBytes"],"raw::sse2::Group::store_aligned":["core::arch::x86_64::__m128i","raw::sse2::Group"],"raw::unlikely":[],"scopeguard::ScopeGuard":["core::marker::Sized","core::ops::FnMut","scopeguard::ScopeGuard"],"scopeguard::guard":["core::marker::Sized","core::ops::FnMut","scopeguard::ScopeGuard"],"set::Difference":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"set::Drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"set::DrainFilter":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilterInner","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::DrainFilter"],"set::HashSet":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::clear":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::contains":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::difference":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"set::HashSet::<T, S>::drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","map::HashMap","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Drain","set::HashSet"],"set::HashSet::<T, S>::drain_filter":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::DrainFilterInner","map::HashMap","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::DrainFilter","set::HashSet"],"set::HashSet::<T, S>::get":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::get_or_insert":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::get_or_insert_owned":["TryReserveError","alloc::borrow::ToOwned","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::get_or_insert_with":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ops::FnOnce","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::insert":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::intersection":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"set::HashSet::<T, S>::is_disjoint":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::is_empty":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::is_subset":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::is_superset":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Iter"],"set::HashSet::<T, S>::len":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::remove":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::replace":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::reserve":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::retain":["core::marker::PhantomData","core::marker::Sized","core::ops::FnMut","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::shrink_to":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::shrink_to_fit":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::symmetric_difference":["core::iter::Chain","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet","set::SymmetricDifference"],"set::HashSet::<T, S>::take":["TryReserveError","core::alloc::Layout","core::borrow::Borrow","core::cmp::Eq","core::hash::Hash","core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::try_reserve":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","core::result::Result","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::union":["core::iter::Chain","core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet","set::Union"],"set::HashSet::<T, S>::with_capacity_and_hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T, S>::with_hasher":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T>::new":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::HashSet::<T>::with_capacity":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::Intersection":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"set::IntoIter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"set::Iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"set::SymmetricDifference":["core::iter::Chain","core::marker::Sized","set::SymmetricDifference"],"set::Union":["core::iter::Chain","core::marker::Sized","set::Union"],"set::assert_covariance":[],"set::assert_covariance::difference":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::Difference","set::HashSet","set::Iter"],"set::assert_covariance::drain":["core::marker::PhantomData","core::marker::Sized","core::mem::ManuallyDrop","core::ptr::NonNull","map::Drain","raw::Bucket","raw::RawDrain","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Drain"],"set::assert_covariance::intersection":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","set::HashSet","set::Intersection","set::Iter"],"set::assert_covariance::into_iter":["core::marker::PhantomData","core::marker::Sized","core::option::Option","core::ptr::NonNull","map::IntoIter","raw::Bucket","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::IntoIter"],"set::assert_covariance::iter":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::Iter","map::Keys","raw::Bucket","raw::RawIter","raw::RawIterRange","raw::bitmask::BitMask","set::Iter"],"set::assert_covariance::set":["core::marker::PhantomData","core::marker::Sized","core::ptr::NonNull","map::HashMap","raw::RawTable","set::HashSet"],"set::assert_covariance::symmetric_difference":["core::iter::Chain","core::marker::Sized","set::SymmetricDifference"],"set::assert_covariance::union":["core::iter::Chain","core::marker::Sized","set::Union"]},"glob_path_import":{"map":"hash_map::","set":"hash_set::"},"self_to_fn":{"TryReserveError":["Clone","Debug","Eq","PartialEq"],"map::ConsumeAllOnDrop":["impl<T: Iterator> Drop for ConsumeAllOnDrop<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        self.0.for_each(drop)\n    }\n}"],"map::Drain":["impl<'a, K, V> Iterator for Drain<'a, K, V> {\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.inner.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V> Drain<'_, K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }\n}","impl<K, V> ExactSizeIterator for Drain<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for Drain<'_, K, V> {}","impl<K, V> fmt::Debug for Drain<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}"],"map::DrainFilter":["impl<'a, K, V, F> Drop for DrainFilter<'a, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        while let Some(item) = self.next() {\n            let guard = ConsumeAllOnDrop(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }\n}","impl<K, V, F> FusedIterator for DrainFilter<'_, K, V, F> where F: FnMut(&K, &mut V) -> bool {}","impl<K, V, F> Iterator for DrainFilter<'_, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Self::Item> {\n        self.inner.next(&mut self.f)\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, self.inner.iter.size_hint().1)\n    }\n}"],"map::DrainFilterInner":["impl<K, V> DrainFilterInner<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn next<F>(&mut self, f: &mut F) -> Option<(K, V)>\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        unsafe {\n            while let Some(item) = self.iter.next() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if f(key, value) {\n                    return Some(self.table.remove(item));\n                }\n            }\n        }\n        None\n    }\n}"],"map::Entry":["impl<'a, K, V, S> Entry<'a, K, V, S> {\n    /// Sets the value of the entry, and returns an OccupiedEntry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let entry = map.entry(\"horseyland\").insert(37);\n    ///\n    /// assert_eq!(entry.key(), &\"horseyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert_entry(value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\").or_insert(3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// *map.entry(\"poneyland\").or_insert(10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    /// let s = \"hoho\".to_string();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with(|| s);\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting, if empty, the result of the default function,\n    /// which takes the key as its argument, and returns a mutable reference to the value in the\n    /// entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, usize> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n    ///\n    /// assert_eq!(map[\"poneyland\"], 9);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }\n\n    /// Returns a reference to this entry's key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        match *self {\n            Entry::Occupied(ref entry) => entry.key(),\n            Entry::Vacant(ref entry) => entry.key(),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),\n    {\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// an occupied entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| panic!());\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///     }\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"poneyland\");\n    ///         assert_eq!(v, 42);\n    ///         Some(v + 1)\n    ///     });\n    ///\n    /// match entry {\n    ///     Entry::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| None);\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => assert_eq!(e.key(), &\"poneyland\"),\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.replace_entry_with(f),\n            Entry::Vacant(_) => self,\n        }\n    }\n}","impl<'a, K, V: Default, S> Entry<'a, K, V, S> {\n    /// Ensures a value is in the entry by inserting the default value if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, Option<u32>> = HashMap::new();\n    /// map.entry(\"poneyland\").or_default();\n    ///\n    /// assert_eq!(map[\"poneyland\"], None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }\n}","impl<K: Debug, V: Debug, S> Debug for Entry<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}"],"map::HashMap":["impl<'a, K, V, S> Extend<(&'a K, &'a V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash + Copy,\n    V: Copy,\n    S: BuildHasher,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<T: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: T) {\n        self.extend(iter.into_iter().map(|(&key, &value)| (key, value)));\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, (k, v): (&'a K, &'a V)) {\n        self.insert(*k, *v);\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(K, V)>::extend_reserve(self, additional);\n    }\n}","impl<K, Q: ?Sized, V, S> Index<&Q> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash + Borrow<Q>,\n    Q: Eq + Hash,\n    S: BuildHasher,\n{\n    type Output = V;\n\n    /// Returns a reference to the value corresponding to the supplied key.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the key is not present in the `HashMap`.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn index(&self, key: &Q) -> &V {\n        self.get(key).expect(\"no entry found for key\")\n    }\n}","impl<K, V, S> Debug for HashMap<K, V, S>\nwhere\n    K: Debug,\n    V: Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_map().entries(self.iter()).finish()\n    }\n}","impl<K, V, S> Default for HashMap<K, V, S>\nwhere\n    S: Default,\n{\n    /// Creates an empty `HashMap<K, V, S>`, with the `Default` value for the hasher.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self::with_hasher(Default::default())\n    }\n}","impl<K, V, S> Eq for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    V: Eq,\n    S: BuildHasher,\n{\n}","impl<K, V, S> Extend<(K, V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T) {\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let iter = iter.into_iter();\n        let reserve = if self.is_empty() {\n            iter.size_hint().0\n        } else {\n            (iter.size_hint().0 + 1) / 2\n        };\n        self.reserve(reserve);\n        iter.for_each(move |(k, v)| {\n            self.insert(k, v);\n        });\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, (k, v): (K, V)) {\n        self.insert(k, v);\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let reserve = if self.is_empty() {\n            additional\n        } else {\n            (additional + 1) / 2\n        };\n        self.reserve(reserve);\n    }\n}","impl<K, V, S> FromIterator<(K, V)> for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher + Default,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> Self {\n        let iter = iter.into_iter();\n        let mut map = Self::with_capacity_and_hasher(iter.size_hint().0, S::default());\n        iter.for_each(|(k, v)| {\n            map.insert(k, v);\n        });\n        map\n    }\n}","impl<K, V, S> HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashMap`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new allocation size overflows [`usize`].\n    ///\n    /// [`usize`]: https://doc.rust-lang.org/std/primitive.usize.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// map.reserve(10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize) {\n        let hash_builder = &self.hash_builder;\n        self.table\n            .reserve(additional, |x| make_hash(hash_builder, &x.0));\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashMap<K,V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, isize> = HashMap::new();\n    /// map.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        let hash_builder = &self.hash_builder;\n        self.table\n            .try_reserve(additional, |x| make_hash(hash_builder, &x.0))\n    }\n\n    /// Shrinks the capacity of the map as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to_fit();\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to_fit(&mut self) {\n        let hash_builder = &self.hash_builder;\n        self.table.shrink_to(0, |x| make_hash(hash_builder, &x.0));\n    }\n\n    /// Shrinks the capacity of the map with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// This function does nothing if the current capacity is smaller than the\n    /// supplied minimum capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to(10);\n    /// assert!(map.capacity() >= 10);\n    /// map.shrink_to(0);\n    /// assert!(map.capacity() >= 2);\n    /// map.shrink_to(10);\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        let hash_builder = &self.hash_builder;\n        self.table\n            .shrink_to(min_capacity, |x| make_hash(hash_builder, &x.0));\n    }\n\n    /// Gets the given key's corresponding entry in the map for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut letters = HashMap::new();\n    ///\n    /// for ch in \"a short treatise on fungi\".chars() {\n    ///     let counter = letters.entry(ch).or_insert(0);\n    ///     *counter += 1;\n    /// }\n    ///\n    /// assert_eq!(letters[&'s'], 2);\n    /// assert_eq!(letters[&'t'], 3);\n    /// assert_eq!(letters[&'u'], 1);\n    /// assert_eq!(letters.get(&'y'), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn entry(&mut self, key: K) -> Entry<'_, K, V, S> {\n        let hash = make_hash(&self.hash_builder, &key);\n        if let Some(elem) = self.table.find(hash, |q| q.0.eq(&key)) {\n            Entry::Occupied(OccupiedEntry {\n                hash,\n                key: Some(key),\n                elem,\n                table: self,\n            })\n        } else {\n            Entry::Vacant(VacantEntry {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }\n\n    /// Returns a reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get(&1), Some(&\"a\"));\n    /// assert_eq!(map.get(&2), None);\n    /// ```\n    #[inline]\n    pub fn get<Q: ?Sized>(&self, k: &Q) -> Option<&V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some(&(_, ref v)) => Some(v),\n            None => None,\n        }\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n    /// assert_eq!(map.get_key_value(&2), None);\n    /// ```\n    #[inline]\n    pub fn get_key_value<Q: ?Sized>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some(&(ref key, ref value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    #[inline]\n    fn get_inner<Q: ?Sized>(&self, k: &Q) -> Option<&(K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        let hash = make_hash(&self.hash_builder, k);\n        self.table.get(hash, |x| k.eq(x.0.borrow()))\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key, with a mutable reference to value.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// let (k, v) = map.get_key_value_mut(&1).unwrap();\n    /// assert_eq!(k, &1);\n    /// assert_eq!(v, &mut \"a\");\n    /// *v = \"b\";\n    /// assert_eq!(map.get_key_value_mut(&1), Some((&1, &mut \"b\")));\n    /// assert_eq!(map.get_key_value_mut(&2), None);\n    /// ```\n    #[inline]\n    pub fn get_key_value_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<(&K, &mut V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (ref key, ref mut value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    /// Returns `true` if the map contains a value for the specified key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.contains_key(&1), true);\n    /// assert_eq!(map.contains_key(&2), false);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn contains_key<Q: ?Sized>(&self, k: &Q) -> bool\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.get_inner(k).is_some()\n    }\n\n    /// Returns a mutable reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// if let Some(x) = map.get_mut(&1) {\n    ///     *x = \"b\";\n    /// }\n    /// assert_eq!(map[&1], \"b\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<&mut V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (_, ref mut v)) => Some(v),\n            None => None,\n        }\n    }\n\n    #[inline]\n    fn get_inner_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<&mut (K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        let hash = make_hash(&self.hash_builder, k);\n        self.table.get_mut(hash, |x| k.eq(x.0.borrow()))\n    }\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, [`None`] is returned.\n    ///\n    /// If the map did have this key present, the value is updated, and the old\n    /// value is returned. The key is not updated, though; this matters for\n    /// types that can be `==` without being identical. See the [module-level\n    /// documentation] for more.\n    ///\n    /// [`None`]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None\n    /// [module-level documentation]: index.html#insert-and-complex-keys\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// assert_eq!(map.insert(37, \"a\"), None);\n    /// assert_eq!(map.is_empty(), false);\n    ///\n    /// map.insert(37, \"b\");\n    /// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n    /// assert_eq!(map[&37], \"c\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, k: K, v: V) -> Option<V> {\n        let hash = make_hash(&self.hash_builder, &k);\n        if let Some((_, item)) = self.table.get_mut(hash, |x| k.eq(&x.0)) {\n            Some(mem::replace(item, v))\n        } else {\n            let hash_builder = &self.hash_builder;\n            self.table\n                .insert(hash, (k, v), |x| make_hash(hash_builder, &x.0));\n            None\n        }\n    }\n\n    /// Removes a key from the map, returning the value at the key if the key\n    /// was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove(&1), Some(\"a\"));\n    /// assert_eq!(map.remove(&1), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove<Q: ?Sized>(&mut self, k: &Q) -> Option<V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.remove_entry(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n\n    /// Removes a key from the map, returning the stored key and value if the\n    /// key was previously in the map.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n    /// assert_eq!(map.remove(&1), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry<Q: ?Sized>(&mut self, k: &Q) -> Option<(K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        let hash = make_hash(&self.hash_builder, &k);\n        self.table.remove_entry(hash, |x| k.eq(x.0.borrow()))\n    }\n}","impl<K, V, S> HashMap<K, V, S> {\n    /// Creates a raw entry builder for the HashMap.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched. After this, insertions into a vacant entry\n    /// still require an owned key to be provided.\n    ///\n    /// Raw entries are useful for such exotic situations as:\n    ///\n    /// * Hash memoization\n    /// * Deferring the creation of an owned key until it is known to be required\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Because raw entries provide much more low-level control, it's much easier\n    /// to put the HashMap into an inconsistent state which, while memory-safe,\n    /// will cause the map to produce seemingly random results. Higher-level and\n    /// more foolproof APIs like `entry` should be preferred when possible.\n    ///\n    /// In particular, the hash used to initialized the raw entry must still be\n    /// consistent with the hash of the key that is ultimately stored in the entry.\n    /// This is because implementations of HashMap may need to recompute hashes\n    /// when resizing, at which point only the keys are available.\n    ///\n    /// Raw entries give mutable access to the keys. This must not be used\n    /// to modify how the key would compare or hash, as the map will not re-evaluate\n    /// where the key should go, meaning the keys may become \"lost\" if their\n    /// location does not reflect their state. For instance, if you change a key\n    /// so that the map now contains keys which compare equal, search may start\n    /// acting erratically, with two keys randomly masking each other. Implementations\n    /// are free to assume this doesn't happen (within the limits of memory-safety).\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn raw_entry_mut(&mut self) -> RawEntryBuilderMut<'_, K, V, S> {\n        RawEntryBuilderMut { map: self }\n    }\n\n    /// Creates a raw immutable entry builder for the HashMap.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched.\n    ///\n    /// This is useful for\n    /// * Hash memoization\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Unless you are in such a situation, higher-level and more foolproof APIs like\n    /// `get` should be preferred.\n    ///\n    /// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn raw_entry(&self) -> RawEntryBuilder<'_, K, V, S> {\n        RawEntryBuilder { map: self }\n    }\n}","impl<K, V, S> HashMap<K, V, S> {\n    /// Creates an empty `HashMap` which will use the given hash builder to hash\n    /// keys.\n    ///\n    /// The created map has the default initial capacity.\n    ///\n    /// Warning: `hash_builder` is normally randomly generated, and\n    /// is designed to allow HashMaps to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_hasher(s);\n    /// map.insert(1, 2);\n    /// ```\n    ///\n    /// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub const fn with_hasher(hash_builder: S) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::new(),\n        }\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n    /// to hash the keys.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// Warning: `hash_builder` is normally randomly generated, and\n    /// is designed to allow HashMaps to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_capacity_and_hasher(10, s);\n    /// map.insert(1, 2);\n    /// ```\n    ///\n    /// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity(capacity),\n        }\n    }\n\n    /// Returns a reference to the map's [`BuildHasher`].\n    ///\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);\n    /// let hasher: &DefaultHashBuilder = map.hasher();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn hasher(&self) -> &S {\n        &self.hash_builder\n    }\n\n    /// Returns the number of elements the map can hold without reallocating.\n    ///\n    /// This number is a lower bound; the `HashMap<K, V>` might be able to hold\n    /// more, but is guaranteed to be able to hold at least this many.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// assert!(map.capacity() >= 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn capacity(&self) -> usize {\n        self.table.capacity()\n    }\n\n    /// An iterator visiting all keys in arbitrary order.\n    /// The iterator element type is `&'a K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for key in map.keys() {\n    ///     println!(\"{}\", key);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn keys(&self) -> Keys<'_, K, V> {\n        Keys { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values in arbitrary order.\n    /// The iterator element type is `&'a V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn values(&self) -> Values<'_, K, V> {\n        Values { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values mutably in arbitrary order.\n    /// The iterator element type is `&'a mut V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    ///\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for val in map.values_mut() {\n    ///     *val = *val + 10;\n    /// }\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn values_mut(&mut self) -> ValuesMut<'_, K, V> {\n        ValuesMut {\n            inner: self.iter_mut(),\n        }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order.\n    /// The iterator element type is `(&'a K, &'a V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for (key, val) in map.iter() {\n    ///     println!(\"key: {} val: {}\", key, val);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> Iter<'_, K, V> {\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            Iter {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order,\n    /// with mutable references to the values.\n    /// The iterator element type is `(&'a K, &'a mut V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // Update all values\n    /// for (_, val) in map.iter_mut() {\n    ///     *val *= 2;\n    /// }\n    ///\n    /// for (key, val) in &map {\n    ///     println!(\"key: {} val: {}\", key, val);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter_mut(&mut self) -> IterMut<'_, K, V> {\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            IterMut {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }\n\n    #[cfg(test)]\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn raw_capacity(&self) -> usize {\n        self.table.buckets()\n    }\n\n    /// Returns the number of elements in the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert_eq!(a.len(), 0);\n    /// a.insert(1, \"a\");\n    /// assert_eq!(a.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn len(&self) -> usize {\n        self.table.len()\n    }\n\n    /// Returns `true` if the map contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert!(a.is_empty());\n    /// a.insert(1, \"a\");\n    /// assert!(!a.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Clears the map, returning all key-value pairs as an iterator. Keeps the\n    /// allocated memory for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    ///\n    /// for (k, v) in a.drain().take(1) {\n    ///     assert!(k == 1 || k == 2);\n    ///     assert!(v == \"a\" || v == \"b\");\n    /// }\n    ///\n    /// assert!(a.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> Drain<'_, K, V> {\n        Drain {\n            inner: self.table.drain(),\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all pairs `(k, v)` such that `f(&k,&mut v)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x|(x, x*10)).collect();\n    /// map.retain(|&k, _| k % 2 == 0);\n    /// assert_eq!(map.len(), 4);\n    /// ```\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.table.iter() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if !f(key, value) {\n                    self.table.erase(item);\n                }\n            }\n        }\n    }\n\n    /// Drains elements which are true under the given predicate,\n    /// and returns an iterator over the removed items.\n    ///\n    /// In other words, move all pairs `(k, v)` such that `f(&k,&mut v)` returns `true` out\n    /// into another iterator.\n    ///\n    /// When the returned DrainedFilter is dropped, any remaining elements that satisfy\n    /// the predicate are dropped from the table.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n    /// let drained: HashMap<i32, i32> = map.drain_filter(|k, _v| k % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.keys().cloned().collect::<Vec<_>>();\n    /// let mut odds = map.keys().cloned().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain_filter<F>(&mut self, f: F) -> DrainFilter<'_, K, V, F>\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        DrainFilter {\n            f,\n            inner: DrainFilterInner {\n                iter: unsafe { self.table.iter() },\n                table: &mut self.table,\n            },\n        }\n    }\n\n    /// Clears the map, removing all key-value pairs. Keeps the allocated memory\n    /// for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.clear();\n    /// assert!(a.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        self.table.clear();\n    }\n}","impl<K, V, S> IntoIterator for HashMap<K, V, S> {\n    type Item = (K, V);\n    type IntoIter = IntoIter<K, V>;\n\n    /// Creates a consuming iterator, that is, one that moves each key-value\n    /// pair out of the map in arbitrary order. The map cannot be used after\n    /// calling this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // Not possible with .iter()\n    /// let vec: Vec<(&str, i32)> = map.into_iter().collect();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> IntoIter<K, V> {\n        IntoIter {\n            inner: self.table.into_iter(),\n        }\n    }\n}","impl<K, V, S> PartialEq for HashMap<K, V, S>\nwhere\n    K: Eq + Hash,\n    V: PartialEq,\n    S: BuildHasher,\n{\n    fn eq(&self, other: &Self) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter()\n            .all(|(key, value)| other.get(key).map_or(false, |v| *value == *v))\n    }\n}","impl<K, V> HashMap<K, V, DefaultHashBuilder> {\n    /// Creates an empty `HashMap`.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_and_hasher(capacity, DefaultHashBuilder::default())\n    }\n}","impl<K: Clone, V: Clone, S: Clone> Clone for HashMap<K, V, S> {\n    fn clone(&self) -> Self {\n        HashMap {\n            hash_builder: self.hash_builder.clone(),\n            table: self.table.clone(),\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.table.clone_from(&source.table);\n\n        // Update hash_builder only if we successfully cloned all elements.\n        self.hash_builder.clone_from(&source.hash_builder);\n    }\n}"],"map::IntoIter":["impl<K, V> ExactSizeIterator for IntoIter<K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for IntoIter<K, V> {}","impl<K, V> IntoIter<K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }\n}","impl<K, V> Iterator for IntoIter<K, V> {\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.inner.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K: Debug, V: Debug> fmt::Debug for IntoIter<K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}"],"map::Iter":["impl<'a, K, V> Iterator for Iter<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_ref();\n                Some((&r.0, &r.1))\n            },\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V> Clone for Iter<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}","impl<K, V> ExactSizeIterator for Iter<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for Iter<'_, K, V> {}","impl<K: Debug, V: Debug> fmt::Debug for Iter<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"],"map::IterMut":["impl<'a, K, V> Iterator for IterMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_mut();\n                Some((&r.0, &mut r.1))\n            },\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V> ExactSizeIterator for IterMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for IterMut<'_, K, V> {}","impl<K, V> IterMut<'_, K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}","impl<K, V> fmt::Debug for IterMut<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}","unsafe impl<K: Send, V: Send> Send for IterMut<'_, K, V> {}"],"map::Keys":["impl<'a, K, V> Iterator for Keys<'a, K, V> {\n    type Item = &'a K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V> Clone for Keys<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Keys {\n            inner: self.inner.clone(),\n        }\n    }\n}","impl<K, V> ExactSizeIterator for Keys<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for Keys<'_, K, V> {}","impl<K: Debug, V> fmt::Debug for Keys<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"],"map::OccupiedEntry":["impl<'a, K, V, S> OccupiedEntry<'a, K, V, S> {\n    /// Gets a reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        unsafe { &self.elem.as_ref().0 }\n    }\n\n    /// Take the ownership of the key and value from the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     // We delete the entry from the map.\n    ///     o.remove_entry();\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(self) -> (K, V) {\n        unsafe { self.table.table.remove(self.elem) }\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.get(), &12);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &V {\n        unsafe { &self.elem.as_ref().1 }\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// If you need a reference to the `OccupiedEntry` which may outlive the\n    /// destruction of the `Entry` value, see [`into_mut`].\n    ///\n    /// [`into_mut`]: #method.into_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     *o.get_mut() += 10;\n    ///     assert_eq!(*o.get(), 22);\n    ///\n    ///     // We can use the same Entry multiple times.\n    ///     *o.get_mut() += 2;\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 24);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut(&mut self) -> &mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Converts the OccupiedEntry into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n    ///\n    /// [`get_mut`]: #method.get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     *o.into_mut() += 10;\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 22);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_mut(self) -> &'a mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.insert(15), 12);\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 15);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, mut value: V) -> V {\n        let old_value = self.get_mut();\n        mem::swap(&mut value, old_value);\n        value\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.remove(), 12);\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> V {\n        self.remove_entry().1\n    }\n\n    /// Replaces the entry, returning the old key and value. The new key in the hash map will be\n    /// the key used to create this entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    /// use std::rc::Rc;\n    ///\n    /// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n    /// map.insert(Rc::new(\"Stringthing\".to_string()), 15);\n    ///\n    /// let my_key = Rc::new(\"Stringthing\".to_string());\n    ///\n    /// if let Entry::Occupied(entry) = map.entry(my_key) {\n    ///     // Also replace the key with a handle to our other key.\n    ///     let (old_key, old_value): (Rc<String>, u32) = entry.replace_entry(16);\n    /// }\n    ///\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_entry(self, value: V) -> (K, V) {\n        let entry = unsafe { self.elem.as_mut() };\n\n        let old_key = mem::replace(&mut entry.0, self.key.unwrap());\n        let old_value = mem::replace(&mut entry.1, value);\n\n        (old_key, old_value)\n    }\n\n    /// Replaces the key in the hash map with the key used to create this entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    /// use std::rc::Rc;\n    ///\n    /// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n    /// let mut known_strings: Vec<Rc<String>> = Vec::new();\n    ///\n    /// // Initialise known strings, run program, etc.\n    ///\n    /// reclaim_memory(&mut map, &known_strings);\n    ///\n    /// fn reclaim_memory(map: &mut HashMap<Rc<String>, u32>, known_strings: &[Rc<String>] ) {\n    ///     for s in known_strings {\n    ///         if let Entry::Occupied(entry) = map.entry(s.clone()) {\n    ///             // Replaces the entry's key with our version of it in `known_strings`.\n    ///             entry.replace_key();\n    ///         }\n    ///     }\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_key(self) -> K {\n        let entry = unsafe { self.elem.as_mut() };\n        mem::replace(&mut entry.0, self.key.unwrap())\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// the entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(e) => {\n    ///         e.replace_entry_with(|k, v| {\n    ///             assert_eq!(k, &\"poneyland\");\n    ///             assert_eq!(v, 42);\n    ///             Some(v + 1)\n    ///         })\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// };\n    ///\n    /// match entry {\n    ///     Entry::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(e) => e.replace_entry_with(|_k, _v| None),\n    ///     Entry::Vacant(_) => panic!(),\n    /// };\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///     }\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_entry_with<F>(self, f: F) -> Entry<'a, K, V, S>\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        unsafe {\n            let mut spare_key = None;\n\n            self.table\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    if let Some(new_value) = f(&key, value) {\n                        Some((key, new_value))\n                    } else {\n                        spare_key = Some(key);\n                        None\n                    }\n                });\n\n            if let Some(key) = spare_key {\n                Entry::Vacant(VacantEntry {\n                    hash: self.hash,\n                    key,\n                    table: self.table,\n                })\n            } else {\n                Entry::Occupied(self)\n            }\n        }\n    }\n}","impl<K: Debug, V: Debug, S> Debug for OccupiedEntry<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }\n}","unsafe impl<K, V, S> Send for OccupiedEntry<'_, K, V, S>\nwhere\n    K: Send,\n    V: Send,\n    S: Send,\n{\n}","unsafe impl<K, V, S> Sync for OccupiedEntry<'_, K, V, S>\nwhere\n    K: Sync,\n    V: Sync,\n    S: Sync,\n{\n}"],"map::RawEntryBuilder":["impl<'a, K, V, S> RawEntryBuilder<'a, K, V, S> {\n    /// Access an entry by key.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key<Q: ?Sized>(self, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        S: BuildHasher,\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        let mut hasher = self.map.hash_builder.build_hasher();\n        k.hash(&mut hasher);\n        self.from_key_hashed_nocheck(hasher.finish(), k)\n    }\n\n    /// Access an entry by a key and its hash.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        K: Borrow<Q>,\n        Q: Eq,\n    {\n        self.from_hash(hash, |q| q.borrow().eq(k))\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn search<F>(self, hash: u64, mut is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,\n    {\n        match self.map.table.get(hash, |(k, _)| is_match(k)) {\n            Some(&(ref key, ref value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    /// Access an entry by hash.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,\n    {\n        self.search(hash, is_match)\n    }\n}","impl<K, V, S> Debug for RawEntryBuilder<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }\n}"],"map::RawEntryBuilderMut":["impl<'a, K, V, S> RawEntryBuilderMut<'a, K, V, S> {\n    /// Creates a `RawEntryMut` from the given hash.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> RawEntryMut<'a, K, V, S>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,\n    {\n        self.search(hash, is_match)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn search<F>(self, hash: u64, mut is_match: F) -> RawEntryMut<'a, K, V, S>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,\n    {\n        match self.map.table.find(hash, |(k, _)| is_match(k)) {\n            Some(elem) => RawEntryMut::Occupied(RawOccupiedEntryMut {\n                elem,\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n            None => RawEntryMut::Vacant(RawVacantEntryMut {\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n        }\n    }\n}","impl<'a, K, V, S> RawEntryBuilderMut<'a, K, V, S> {\n    /// Creates a `RawEntryMut` from the given key.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key<Q: ?Sized>(self, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        S: BuildHasher,\n        K: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        let mut hasher = self.map.hash_builder.build_hasher();\n        k.hash(&mut hasher);\n        self.from_key_hashed_nocheck(hasher.finish(), k)\n    }\n\n    /// Creates a `RawEntryMut` from the given key and its hash.\n    #[inline]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        K: Borrow<Q>,\n        Q: Eq,\n    {\n        self.from_hash(hash, |q| q.borrow().eq(k))\n    }\n}","impl<K, V, S> Debug for RawEntryBuilderMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }\n}"],"map::RawEntryMut":["impl<'a, K, V, S> RawEntryMut<'a, K, V, S> {\n    /// Sets the value of the entry, and returns a RawOccupiedEntryMut.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let entry = map.raw_entry_mut().from_key(\"horseyland\").insert(\"horseyland\", 37);\n    ///\n    /// assert_eq!(entry.remove_entry(), (\"horseyland\", 37));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            RawEntryMut::Vacant(entry) => entry.insert_entry(key, value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// *map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 10).1 *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self, default_key: K, default_val: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => entry.insert(default_key, default_val),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert_with(|| {\n    ///     (\"poneyland\", \"hoho\".to_string())\n    /// });\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with<F>(self, default: F) -> (&'a mut K, &'a mut V)\n    where\n        F: FnOnce() -> (K, V),\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => {\n                let (k, v) = default();\n                entry.insert(k, v)\n            }\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 0);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut K, &mut V),\n    {\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                {\n                    let (k, v) = entry.get_key_value_mut();\n                    f(k, v);\n                }\n                RawEntryMut::Occupied(entry)\n            }\n            RawEntryMut::Vacant(entry) => RawEntryMut::Vacant(entry),\n        }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// an occupied entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::RawEntryMut;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| panic!());\n    ///\n    /// match entry {\n    ///     RawEntryMut::Vacant(_) => {},\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"poneyland\");\n    ///         assert_eq!(v, 42);\n    ///         Some(v + 1)\n    ///     });\n    ///\n    /// match entry {\n    ///     RawEntryMut::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     },\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| None);\n    ///\n    /// match entry {\n    ///     RawEntryMut::Vacant(_) => {},\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.replace_entry_with(f),\n            RawEntryMut::Vacant(_) => self,\n        }\n    }\n}","impl<K: Debug, V: Debug, S> Debug for RawEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            RawEntryMut::Vacant(ref v) => f.debug_tuple(\"RawEntry\").field(v).finish(),\n            RawEntryMut::Occupied(ref o) => f.debug_tuple(\"RawEntry\").field(o).finish(),\n        }\n    }\n}"],"map::RawOccupiedEntryMut":["impl<'a, K, V, S> RawOccupiedEntryMut<'a, K, V, S> {\n    /// Gets a reference to the key in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        unsafe { &self.elem.as_ref().0 }\n    }\n\n    /// Gets a mutable reference to the key in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key_mut(&mut self) -> &mut K {\n        unsafe { &mut self.elem.as_mut().0 }\n    }\n\n    /// Converts the entry into a mutable reference to the key in the entry\n    /// with a lifetime bound to the map itself.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key(self) -> &'a mut K {\n        unsafe { &mut self.elem.as_mut().0 }\n    }\n\n    /// Gets a reference to the value in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &V {\n        unsafe { &self.elem.as_ref().1 }\n    }\n\n    /// Converts the OccupiedEntry into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_mut(self) -> &'a mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut(&mut self) -> &mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Gets a reference to the key and value in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_key_value(&mut self) -> (&K, &V) {\n        unsafe {\n            let &(ref key, ref value) = self.elem.as_ref();\n            (key, value)\n        }\n    }\n\n    /// Gets a mutable reference to the key and value in the entry.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_key_value_mut(&mut self) -> (&mut K, &mut V) {\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }\n\n    /// Converts the OccupiedEntry into a mutable reference to the key and value in the entry\n    /// with a lifetime bound to the map itself.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key_value(self) -> (&'a mut K, &'a mut V) {\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, value: V) -> V {\n        mem::replace(self.get_mut(), value)\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_key(&mut self, key: K) -> K {\n        mem::replace(self.key_mut(), key)\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> V {\n        self.remove_entry().1\n    }\n\n    /// Take the ownership of the key and value from the map.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(self) -> (K, V) {\n        unsafe { self.table.remove(self.elem) }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// the entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_entry_with<F>(self, f: F) -> RawEntryMut<'a, K, V, S>\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        unsafe {\n            let still_occupied = self\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    f(&key, value).map(|new_value| (key, new_value))\n                });\n\n            if still_occupied {\n                RawEntryMut::Occupied(self)\n            } else {\n                RawEntryMut::Vacant(RawVacantEntryMut {\n                    table: self.table,\n                    hash_builder: self.hash_builder,\n                })\n            }\n        }\n    }\n}","impl<K: Debug, V: Debug, S> Debug for RawOccupiedEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawOccupiedEntryMut\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }\n}","unsafe impl<K, V, S> Send for RawOccupiedEntryMut<'_, K, V, S>\nwhere\n    K: Send,\n    V: Send,\n    S: Sync,\n{\n}","unsafe impl<K, V, S> Sync for RawOccupiedEntryMut<'_, K, V, S>\nwhere\n    K: Sync,\n    V: Sync,\n    S: Sync,\n{\n}"],"map::RawVacantEntryMut":["impl<'a, K, V, S> RawVacantEntryMut<'a, K, V, S> {\n    /// Sets the value of the entry with the VacantEntry's key,\n    /// and returns a mutable reference to it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let mut hasher = self.hash_builder.build_hasher();\n        key.hash(&mut hasher);\n        self.insert_hashed_nocheck(hasher.finish(), key, value)\n    }\n\n    /// Sets the value of the entry with the VacantEntry's key,\n    /// and returns a mutable reference to it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::shadow_unrelated)]\n    pub fn insert_hashed_nocheck(self, hash: u64, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash_builder = self.hash_builder;\n        self.insert_with_hasher(hash, key, value, |k| make_hash(hash_builder, k))\n    }\n\n    /// Set the value of an entry with a custom hasher function.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_with_hasher<H>(\n        self,\n        hash: u64,\n        key: K,\n        value: V,\n        hasher: H,\n    ) -> (&'a mut K, &'a mut V)\n    where\n        H: Fn(&K) -> u64,\n    {\n        let &mut (ref mut k, ref mut v) = self\n            .table\n            .insert_entry(hash, (key, value), |x| hasher(&x.0));\n        (k, v)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn insert_entry(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash_builder = self.hash_builder;\n        let mut hasher = self.hash_builder.build_hasher();\n        key.hash(&mut hasher);\n\n        let elem = self.table.insert(hasher.finish(), (key, value), |k| {\n            make_hash(hash_builder, &k.0)\n        });\n        RawOccupiedEntryMut {\n            elem,\n            table: self.table,\n            hash_builder: self.hash_builder,\n        }\n    }\n}","impl<K, V, S> Debug for RawVacantEntryMut<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawVacantEntryMut\").finish()\n    }\n}"],"map::VacantEntry":["impl<'a, K, V, S> VacantEntry<'a, K, V, S> {\n    /// Gets a reference to the key that would be used when inserting a value\n    /// through the `VacantEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        &self.key\n    }\n\n    /// Take ownership of the key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n    ///     v.into_key();\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key(self) -> K {\n        self.key\n    }\n\n    /// Sets the value of the entry with the VacantEntry's key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash_builder = &self.table.hash_builder;\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(self.hash, (self.key, value), |x| {\n            make_hash(hash_builder, &x.0)\n        });\n        &mut entry.1\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash_builder = &self.table.hash_builder;\n        let elem = self.table.table.insert(self.hash, (self.key, value), |x| {\n            make_hash(hash_builder, &x.0)\n        });\n        OccupiedEntry {\n            hash: self.hash,\n            key: None,\n            elem,\n            table: self.table,\n        }\n    }\n}","impl<K: Debug, V, S> Debug for VacantEntry<'_, K, V, S> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }\n}"],"map::Values":["impl<'a, K, V> Iterator for Values<'a, K, V> {\n    type Item = &'a V;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a V> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V: Debug> fmt::Debug for Values<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}","impl<K, V> Clone for Values<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Values {\n            inner: self.inner.clone(),\n        }\n    }\n}","impl<K, V> ExactSizeIterator for Values<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for Values<'_, K, V> {}"],"map::ValuesMut":["impl<'a, K, V> Iterator for ValuesMut<'a, K, V> {\n    type Item = &'a mut V;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a mut V> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n}","impl<K, V> ExactSizeIterator for ValuesMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}","impl<K, V> FusedIterator for ValuesMut<'_, K, V> {}","impl<K, V> fmt::Debug for ValuesMut<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.inner.iter()).finish()\n    }\n}"],"raw::Bucket":["impl<T> Bucket<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        let ptr = if mem::size_of::<T>() == 0 {\n            // won't overflow because index must be less than length\n            (index + 1) as *mut T\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {\n        if mem::size_of::<T>() == 0 {\n            self.ptr.as_ptr() as usize - 1\n        } else {\n            offset_from(base.as_ptr(), self.ptr.as_ptr())\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn as_ptr(&self) -> *mut T {\n        if mem::size_of::<T>() == 0 {\n            // Just return an arbitrary ZST pointer which is properly aligned\n            mem::align_of::<T>() as *mut T\n        } else {\n            self.ptr.as_ptr().sub(1)\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if mem::size_of::<T>() == 0 {\n            (self.ptr.as_ptr() as usize + offset) as *mut T\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn drop(&self) {\n        self.as_ptr().drop_in_place();\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn read(&self) -> T {\n        self.as_ptr().read()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn write(&self, val: T) {\n        self.as_ptr().write(val);\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {\n        &*self.as_ptr()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {\n        &mut *self.as_ptr()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn copy_from_nonoverlapping(&self, other: &Self) {\n        self.as_ptr().copy_from_nonoverlapping(other.as_ptr(), 1);\n    }\n}","impl<T> Clone for Bucket<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self { ptr: self.ptr }\n    }\n}","unsafe impl<T> Send for Bucket<T> {}"],"raw::Fallibility":["Clone","Copy","impl Fallibility {\n    /// Error to return on capacity overflow.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn capacity_overflow(self) -> TryReserveError {\n        match self {\n            Fallibility::Fallible => TryReserveError::CapacityOverflow,\n            Fallibility::Infallible => panic!(\"Hash table capacity overflow\"),\n        }\n    }\n\n    /// Error to return on allocation error.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn alloc_err(self, layout: Layout) -> TryReserveError {\n        match self {\n            Fallibility::Fallible => TryReserveError::AllocError { layout },\n            Fallibility::Infallible => handle_alloc_error(layout),\n        }\n    }\n}"],"raw::ProbeSeq":["impl Iterator for ProbeSeq {\n    type Item = usize;\n\n    #[inline]\n    fn next(&mut self) -> Option<usize> {\n        // We should have found an empty bucket by now and ended the probe.\n        debug_assert!(\n            self.stride <= self.bucket_mask,\n            \"Went past end of probe sequence\"\n        );\n\n        let result = self.pos;\n        self.stride += Group::WIDTH;\n        self.pos += self.stride;\n        self.pos &= self.bucket_mask;\n        Some(result)\n    }\n}"],"raw::RawDrain":["impl<T> Drop for RawDrain<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        unsafe {\n            // Drop all remaining elements. Note that this may panic.\n            if mem::needs_drop::<T>() && self.iter.len() != 0 {\n                while let Some(item) = self.iter.next() {\n                    item.drop();\n                }\n            }\n\n            // Reset the contents of the table now that all elements have been\n            // dropped.\n            self.table.clear_no_drop();\n\n            // Move the now empty table back to its original location.\n            self.orig_table\n                .as_ptr()\n                .copy_from_nonoverlapping(&*self.table, 1);\n        }\n    }\n}","impl<T> ExactSizeIterator for RawDrain<'_, T> {}","impl<T> FusedIterator for RawDrain<'_, T> {}","impl<T> Iterator for RawDrain<'_, T> {\n    type Item = T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<T> {\n        unsafe {\n            let item = self.iter.next()?;\n            Some(item.read())\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}","impl<T> RawDrain<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> RawIter<T> {\n        self.iter.clone()\n    }\n}","unsafe impl<T> Send for RawDrain<'_, T> where T: Send {}","unsafe impl<T> Sync for RawDrain<'_, T> where T: Sync {}"],"raw::RawIntoIter":["impl<T> Drop for RawIntoIter<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        unsafe {\n            // Drop all remaining elements\n            if mem::needs_drop::<T>() && self.iter.len() != 0 {\n                while let Some(item) = self.iter.next() {\n                    item.drop();\n                }\n            }\n\n            // Free the table\n            if let Some((ptr, layout)) = self.alloc {\n                dealloc(ptr.as_ptr(), layout);\n            }\n        }\n    }\n}","impl<T> ExactSizeIterator for RawIntoIter<T> {}","impl<T> FusedIterator for RawIntoIter<T> {}","impl<T> Iterator for RawIntoIter<T> {\n    type Item = T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<T> {\n        unsafe { Some(self.iter.next()?.read()) }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}","impl<T> RawIntoIter<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> RawIter<T> {\n        self.iter.clone()\n    }\n}","unsafe impl<T> Send for RawIntoIter<T> where T: Send {}","unsafe impl<T> Sync for RawIntoIter<T> where T: Sync {}"],"raw::RawIter":["impl<T> Clone for RawIter<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self {\n            iter: self.iter.clone(),\n            items: self.items,\n        }\n    }\n}","impl<T> ExactSizeIterator for RawIter<T> {}","impl<T> FusedIterator for RawIter<T> {}","impl<T> Iterator for RawIter<T> {\n    type Item = Bucket<T>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Bucket<T>> {\n        if let Some(b) = self.iter.next() {\n            self.items -= 1;\n            Some(b)\n        } else {\n            // We don't check against items == 0 here to allow the\n            // compiler to optimize away the item count entirely if the\n            // iterator length is never queried.\n            debug_assert_eq!(self.items, 0);\n            None\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.items, Some(self.items))\n    }\n}","impl<T> RawIter<T> {\n    /// Refresh the iterator so that it reflects a removal from the given bucket.\n    ///\n    /// For the iterator to remain valid, this method must be called once\n    /// for each removed bucket before `next` is called again.\n    ///\n    /// This method should be called _before_ the removal is made. It is not necessary to call this\n    /// method if you are removing an item that this iterator yielded in the past.\n    #[cfg(feature = \"raw\")]\n    pub fn reflect_remove(&mut self, b: &Bucket<T>) {\n        self.reflect_toggle_full(b, false);\n    }\n\n    /// Refresh the iterator so that it reflects an insertion into the given bucket.\n    ///\n    /// For the iterator to remain valid, this method must be called once\n    /// for each insert before `next` is called again.\n    ///\n    /// This method does not guarantee that an insertion of a bucket witha greater\n    /// index than the last one yielded will be reflected in the iterator.\n    ///\n    /// This method should be called _after_ the given insert is made.\n    #[cfg(feature = \"raw\")]\n    pub fn reflect_insert(&mut self, b: &Bucket<T>) {\n        self.reflect_toggle_full(b, true);\n    }\n\n    /// Refresh the iterator so that it reflects a change to the state of the given bucket.\n    #[cfg(feature = \"raw\")]\n    fn reflect_toggle_full(&mut self, b: &Bucket<T>, is_insert: bool) {\n        unsafe {\n            if b.as_ptr() > self.iter.data.as_ptr() {\n                // The iterator has already passed the bucket's group.\n                // So the toggle isn't relevant to this iterator.\n                return;\n            }\n\n            if self.iter.next_ctrl < self.iter.end\n                && b.as_ptr() <= self.iter.data.next_n(Group::WIDTH).as_ptr()\n            {\n                // The iterator has not yet reached the bucket's group.\n                // We don't need to reload anything, but we do need to adjust the item count.\n\n                if cfg!(debug_assertions) {\n                    // Double-check that the user isn't lying to us by checking the bucket state.\n                    // To do that, we need to find its control byte. We know that self.iter.data is\n                    // at self.iter.next_ctrl - Group::WIDTH, so we work from there:\n                    let offset = offset_from(self.iter.data.as_ptr(), b.as_ptr());\n                    let ctrl = self.iter.next_ctrl.sub(Group::WIDTH).add(offset);\n                    // This method should be called _before_ a removal, or _after_ an insert,\n                    // so in both cases the ctrl byte should indicate that the bucket is full.\n                    assert!(is_full(*ctrl));\n                }\n\n                if is_insert {\n                    self.items += 1;\n                } else {\n                    self.items -= 1;\n                }\n\n                return;\n            }\n\n            // The iterator is at the bucket group that the toggled bucket is in.\n            // We need to do two things:\n            //\n            //  - Determine if the iterator already yielded the toggled bucket.\n            //    If it did, we're done.\n            //  - Otherwise, update the iterator cached group so that it won't\n            //    yield a to-be-removed bucket, or _will_ yield a to-be-added bucket.\n            //    We'll also need ot update the item count accordingly.\n            if let Some(index) = self.iter.current_group.lowest_set_bit() {\n                let next_bucket = self.iter.data.next_n(index);\n                if b.as_ptr() > next_bucket.as_ptr() {\n                    // The toggled bucket is \"before\" the bucket the iterator would yield next. We\n                    // therefore don't need to do anything --- the iterator has already passed the\n                    // bucket in question.\n                    //\n                    // The item count must already be correct, since a removal or insert \"prior\" to\n                    // the iterator's position wouldn't affect the item count.\n                } else {\n                    // The removed bucket is an upcoming bucket. We need to make sure it does _not_\n                    // get yielded, and also that it's no longer included in the item count.\n                    //\n                    // NOTE: We can't just reload the group here, both since that might reflect\n                    // inserts we've already passed, and because that might inadvertently unset the\n                    // bits for _other_ removals. If we do that, we'd have to also decrement the\n                    // item count for those other bits that we unset. But the presumably subsequent\n                    // call to reflect for those buckets might _also_ decrement the item count.\n                    // Instead, we _just_ flip the bit for the particular bucket the caller asked\n                    // us to reflect.\n                    let our_bit = offset_from(self.iter.data.as_ptr(), b.as_ptr());\n                    let was_full = self.iter.current_group.flip(our_bit);\n                    debug_assert_ne!(was_full, is_insert);\n\n                    if is_insert {\n                        self.items += 1;\n                    } else {\n                        self.items -= 1;\n                    }\n\n                    if cfg!(debug_assertions) {\n                        if b.as_ptr() == next_bucket.as_ptr() {\n                            // The removed bucket should no longer be next\n                            debug_assert_ne!(self.iter.current_group.lowest_set_bit(), Some(index));\n                        } else {\n                            // We should not have changed what bucket comes next.\n                            debug_assert_eq!(self.iter.current_group.lowest_set_bit(), Some(index));\n                        }\n                    }\n                }\n            } else {\n                // We must have already iterated past the removed item.\n            }\n        }\n    }\n}"],"raw::RawIterHash":["impl<'a, T> Iterator for RawIterHash<'a, T> {\n    type Item = Bucket<T>;\n\n    fn next(&mut self) -> Option<Bucket<T>> {\n        unsafe {\n            loop {\n                if let Some(bit) = self.bitmask.next() {\n                    let index = (self.pos + bit) & self.table.bucket_mask;\n                    let bucket = self.table.bucket(index);\n                    return Some(bucket);\n                }\n                if likely(self.group.match_empty().any_bit_set()) {\n                    return None;\n                }\n                self.pos = self.probe_seq.next().unwrap();\n                self.group = Group::load(self.table.ctrl(self.pos));\n                self.bitmask = self.group.match_byte(self.h2_hash).into_iter();\n            }\n        }\n    }\n}","impl<'a, T> RawIterHash<'a, T> {\n    fn new(table: &'a RawTable<T>, hash: u64) -> Self {\n        unsafe {\n            let h2_hash = h2(hash);\n            let mut probe_seq = table.probe_seq(hash);\n            let pos = probe_seq.next().unwrap();\n            let group = Group::load(table.ctrl(pos));\n            let bitmask = group.match_byte(h2_hash).into_iter();\n\n            RawIterHash {\n                table,\n                h2_hash,\n                probe_seq,\n                pos,\n                group,\n                bitmask,\n            }\n        }\n    }\n}"],"raw::RawIterRange":["impl<T> Clone for RawIterRange<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self {\n            data: self.data.clone(),\n            next_ctrl: self.next_ctrl,\n            current_group: self.current_group,\n            end: self.end,\n        }\n    }\n}","impl<T> FusedIterator for RawIterRange<T> {}","impl<T> Iterator for RawIterRange<T> {\n    type Item = Bucket<T>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Bucket<T>> {\n        unsafe {\n            loop {\n                if let Some(index) = self.current_group.lowest_set_bit() {\n                    self.current_group = self.current_group.remove_lowest_bit();\n                    return Some(self.data.next_n(index));\n                }\n\n                if self.next_ctrl >= self.end {\n                    return None;\n                }\n\n                // We might read past self.end up to the next group boundary,\n                // but this is fine because it only occurs on tables smaller\n                // than the group size where the trailing control bytes are all\n                // EMPTY. On larger tables self.end is guaranteed to be aligned\n                // to the group size (since tables are power-of-two sized).\n                self.current_group = Group::load_aligned(self.next_ctrl).match_full();\n                self.data = self.data.next_n(Group::WIDTH);\n                self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        // We don't have an item count, so just guess based on the range size.\n        (\n            0,\n            Some(unsafe { offset_from(self.end, self.next_ctrl) + Group::WIDTH }),\n        )\n    }\n}","impl<T> RawIterRange<T> {\n    /// Returns a `RawIterRange` covering a subset of a table.\n    ///\n    /// The control byte address must be aligned to the group size.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new(ctrl: *const u8, data: Bucket<T>, len: usize) -> Self {\n        debug_assert_ne!(len, 0);\n        debug_assert_eq!(ctrl as usize % Group::WIDTH, 0);\n        let end = ctrl.add(len);\n\n        // Load the first group and advance ctrl to point to the next group\n        let current_group = Group::load_aligned(ctrl).match_full();\n        let next_ctrl = ctrl.add(Group::WIDTH);\n\n        Self {\n            current_group,\n            data,\n            next_ctrl,\n            end,\n        }\n    }\n\n    /// Splits a `RawIterRange` into two halves.\n    ///\n    /// Returns `None` if the remaining range is smaller than or equal to the\n    /// group width.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(feature = \"rayon\")]\n    pub(crate) fn split(mut self) -> (Self, Option<RawIterRange<T>>) {\n        unsafe {\n            if self.end <= self.next_ctrl {\n                // Nothing to split if the group that we are current processing\n                // is the last one.\n                (self, None)\n            } else {\n                // len is the remaining number of elements after the group that\n                // we are currently processing. It must be a multiple of the\n                // group size (small tables are caught by the check above).\n                let len = offset_from(self.end, self.next_ctrl);\n                debug_assert_eq!(len % Group::WIDTH, 0);\n\n                // Split the remaining elements into two halves, but round the\n                // midpoint down in case there is an odd number of groups\n                // remaining. This ensures that:\n                // - The tail is at least 1 group long.\n                // - The split is roughly even considering we still have the\n                //   current group to process.\n                let mid = (len / 2) & !(Group::WIDTH - 1);\n\n                let tail = Self::new(\n                    self.next_ctrl.add(mid),\n                    self.data.next_n(Group::WIDTH).next_n(mid),\n                    len - mid,\n                );\n                debug_assert_eq!(\n                    self.data.next_n(Group::WIDTH).next_n(mid).ptr,\n                    tail.data.ptr\n                );\n                debug_assert_eq!(self.end, tail.end);\n                self.end = self.next_ctrl.add(mid);\n                debug_assert_eq!(self.end.add(Group::WIDTH), tail.next_ctrl);\n                (self, Some(tail))\n            }\n        }\n    }\n}","unsafe impl<T> Send for RawIterRange<T> {}","unsafe impl<T> Sync for RawIterRange<T> {}"],"raw::RawTable":["impl<T: Clone> Clone for RawTable<T> {\n    fn clone(&self) -> Self {\n        if self.is_empty_singleton() {\n            Self::new()\n        } else {\n            unsafe {\n                let mut new_table = ManuallyDrop::new(\n                    // Avoid `Result::ok_or_else` because it bloats LLVM IR.\n                    match Self::new_uninitialized(self.buckets(), Fallibility::Infallible) {\n                        Ok(table) => table,\n                        Err(_) => hint::unreachable_unchecked(),\n                    },\n                );\n\n                new_table.clone_from_spec(self, |new_table| {\n                    // We need to free the memory allocated for the new table.\n                    new_table.free_buckets();\n                });\n\n                // Return the newly created table.\n                ManuallyDrop::into_inner(new_table)\n            }\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        if source.is_empty_singleton() {\n            *self = Self::new();\n        } else {\n            unsafe {\n                // First, drop all our elements without clearing the control bytes.\n                if mem::needs_drop::<T>() && self.len() != 0 {\n                    for item in self.iter() {\n                        item.drop();\n                    }\n                }\n\n                // If necessary, resize our table to match the source.\n                if self.buckets() != source.buckets() {\n                    // Skip our drop by using ptr::write.\n                    if !self.is_empty_singleton() {\n                        self.free_buckets();\n                    }\n                    (self as *mut Self).write(\n                        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                        match Self::new_uninitialized(source.buckets(), Fallibility::Infallible) {\n                            Ok(table) => table,\n                            Err(_) => hint::unreachable_unchecked(),\n                        },\n                    );\n                }\n\n                self.clone_from_spec(source, |self_| {\n                    // We need to leave the table in an empty state.\n                    self_.clear_no_drop()\n                });\n            }\n        }\n    }\n}","impl<T: Clone> RawTable<T> {\n    /// Common code for clone and clone_from. Assumes `self.buckets() == source.buckets()`.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn clone_from_impl(&mut self, source: &Self, mut on_panic: impl FnMut(&mut Self)) {\n        // Copy the control bytes unchanged. We do this in a single pass\n        source\n            .ctrl(0)\n            .copy_to_nonoverlapping(self.ctrl(0), self.num_ctrl_bytes());\n\n        // The cloning of elements may panic, in which case we need\n        // to make sure we drop only the elements that have been\n        // cloned so far.\n        let mut guard = guard((0, &mut *self), |(index, self_)| {\n            if mem::needs_drop::<T>() && self_.len() != 0 {\n                for i in 0..=*index {\n                    if is_full(*self_.ctrl(i)) {\n                        self_.bucket(i).drop();\n                    }\n                }\n            }\n\n            // Depending on whether we were called from clone or clone_from, we\n            // either need to free the memory for the destination table or just\n            // clear the control bytes.\n            on_panic(self_);\n        });\n\n        for from in source.iter() {\n            let index = source.bucket_index(&from);\n            let to = guard.1.bucket(index);\n            to.write(from.as_ref().clone());\n\n            // Update the index in case we need to unwind.\n            guard.0 = index;\n        }\n\n        // Successfully cloned all items, no need to clean up.\n        mem::forget(guard);\n\n        self.items = source.items;\n        self.growth_left = source.growth_left;\n    }\n\n    /// Variant of `clone_from` to use when a hasher is available.\n    #[cfg(feature = \"raw\")]\n    pub fn clone_from_with_hasher(&mut self, source: &Self, hasher: impl Fn(&T) -> u64) {\n        // If we have enough capacity in the table, just clear it and insert\n        // elements one by one. We don't do this if we have the same number of\n        // buckets as the source since we can just copy the contents directly\n        // in that case.\n        if self.buckets() != source.buckets()\n            && bucket_mask_to_capacity(self.bucket_mask) >= source.len()\n        {\n            self.clear();\n\n            let guard_self = guard(&mut *self, |self_| {\n                // Clear the partially copied table if a panic occurs, otherwise\n                // items and growth_left will be out of sync with the contents\n                // of the table.\n                self_.clear();\n            });\n\n            unsafe {\n                for item in source.iter() {\n                    // This may panic.\n                    let item = item.as_ref().clone();\n                    let hash = hasher(&item);\n\n                    // We can use a simpler version of insert() here since:\n                    // - there are no DELETED entries.\n                    // - we know there is enough space in the table.\n                    // - all elements are unique.\n                    let index = guard_self.find_insert_slot(hash);\n                    guard_self.set_ctrl(index, h2(hash));\n                    guard_self.bucket(index).write(item);\n                }\n            }\n\n            // Successfully cloned all items, no need to clean up.\n            mem::forget(guard_self);\n\n            self.items = source.items;\n            self.growth_left -= source.items;\n        } else {\n            self.clone_from(source);\n        }\n    }\n}","impl<T: Clone> RawTableClone for RawTable<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    default_fn! {\n        unsafe fn clone_from_spec(&mut self, source: &Self, on_panic: impl FnMut(&mut Self)) {\n            self.clone_from_impl(source, on_panic);\n        }\n    }\n}","impl<T> Drop for RawTable<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        if !self.is_empty_singleton() {\n            unsafe {\n                if mem::needs_drop::<T>() && self.len() != 0 {\n                    for item in self.iter() {\n                        item.drop();\n                    }\n                }\n                self.free_buckets();\n            }\n        }\n    }\n}","impl<T> IntoIterator for RawTable<T> {\n    type Item = T;\n    type IntoIter = RawIntoIter<T>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> RawIntoIter<T> {\n        unsafe {\n            let iter = self.iter();\n            self.into_iter_from(iter)\n        }\n    }\n}","impl<T> RawTable<T> {\n    /// Creates a new empty hash table without allocating any memory.\n    ///\n    /// In effect this returns a table with exactly 1 bucket. However we can\n    /// leave the data pointer dangling since that bucket is never written to\n    /// due to our load factor forcing us to always have at least 1 free bucket.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub const fn new() -> Self {\n        Self {\n            // Be careful to cast the entire slice to a raw pointer.\n            ctrl: unsafe { NonNull::new_unchecked(Group::static_empty() as *const _ as *mut u8) },\n            bucket_mask: 0,\n            items: 0,\n            growth_left: 0,\n            marker: PhantomData,\n        }\n    }\n\n    /// Allocates a new hash table with the given number of buckets.\n    ///\n    /// The control bytes are left uninitialized.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized(\n        buckets: usize,\n        fallability: Fallibility,\n    ) -> Result<Self, TryReserveError> {\n        debug_assert!(buckets.is_power_of_two());\n\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match calculate_layout::<T>(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallability.capacity_overflow()),\n        };\n        let ptr = match NonNull::new(alloc(layout)) {\n            Some(ptr) => ptr,\n            None => return Err(fallability.alloc_err(layout)),\n        };\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n            marker: PhantomData,\n        })\n    }\n\n    /// Attempts to allocate a new hash table with at least enough capacity\n    /// for inserting the given number of elements without reallocating.\n    fn fallible_with_capacity(\n        capacity: usize,\n        fallability: Fallibility,\n    ) -> Result<Self, TryReserveError> {\n        if capacity == 0 {\n            Ok(Self::new())\n        } else {\n            unsafe {\n                // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n                let buckets = match capacity_to_buckets(capacity) {\n                    Some(buckets) => buckets,\n                    None => return Err(fallability.capacity_overflow()),\n                };\n                let result = Self::new_uninitialized(buckets, fallability)?;\n                result.ctrl(0).write_bytes(EMPTY, result.num_ctrl_bytes());\n\n                Ok(result)\n            }\n        }\n    }\n\n    /// Attempts to allocate a new hash table with at least enough capacity\n    /// for inserting the given number of elements without reallocating.\n    #[cfg(feature = \"raw\")]\n    pub fn try_with_capacity(capacity: usize) -> Result<Self, TryReserveError> {\n        Self::fallible_with_capacity(capacity, Fallibility::Fallible)\n    }\n\n    /// Allocates a new hash table with at least enough capacity for inserting\n    /// the given number of elements without reallocating.\n    pub fn with_capacity(capacity: usize) -> Self {\n        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n        match Self::fallible_with_capacity(capacity, Fallibility::Infallible) {\n            Ok(capacity) => capacity,\n            Err(_) => unsafe { hint::unreachable_unchecked() },\n        }\n    }\n\n    /// Deallocates the table without dropping any entries.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn free_buckets(&mut self) {\n        // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match calculate_layout::<T>(self.buckets()) {\n            Some(lco) => lco,\n            None => hint::unreachable_unchecked(),\n        };\n        dealloc(self.ctrl.as_ptr().sub(ctrl_offset), layout);\n    }\n\n    /// Returns pointer to one past last element of data table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn data_end(&self) -> NonNull<T> {\n        NonNull::new_unchecked(self.ctrl.as_ptr() as *mut T)\n    }\n\n    /// Returns pointer to start of data table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(feature = \"nightly\")]\n    pub unsafe fn data_start(&self) -> *mut T {\n        self.data_end().as_ptr().wrapping_sub(self.buckets())\n    }\n\n    /// Returns the index of a bucket from a `Bucket`.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn bucket_index(&self, bucket: &Bucket<T>) -> usize {\n        bucket.to_base_index(self.data_end())\n    }\n\n    /// Returns a pointer to a control byte.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn ctrl(&self, index: usize) -> *mut u8 {\n        debug_assert!(index < self.num_ctrl_bytes());\n        self.ctrl.as_ptr().add(index)\n    }\n\n    /// Returns a pointer to an element in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn bucket(&self, index: usize) -> Bucket<T> {\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }\n\n    /// Erases an element from the table without dropping it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[deprecated(since = \"0.8.1\", note = \"use erase or remove instead\")]\n    pub unsafe fn erase_no_drop(&mut self, item: &Bucket<T>) {\n        let index = self.bucket_index(item);\n        debug_assert!(is_full(*self.ctrl(index)));\n        let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;\n        let empty_before = Group::load(self.ctrl(index_before)).match_empty();\n        let empty_after = Group::load(self.ctrl(index)).match_empty();\n\n        // If we are inside a continuous block of Group::WIDTH full or deleted\n        // cells then a probe window may have seen a full block when trying to\n        // insert. We therefore need to keep that block non-empty so that\n        // lookups will continue searching to the next probe window.\n        //\n        // Note that in this context `leading_zeros` refers to the bytes at the\n        // end of a group, while `trailing_zeros` refers to the bytes at the\n        // begining of a group.\n        let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {\n            DELETED\n        } else {\n            self.growth_left += 1;\n            EMPTY\n        };\n        self.set_ctrl(index, ctrl);\n        self.items -= 1;\n    }\n\n    /// Erases an element from the table, dropping it in place.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    #[allow(deprecated)]\n    pub unsafe fn erase(&mut self, item: Bucket<T>) {\n        // Erase the element from the table first since drop might panic.\n        self.erase_no_drop(&item);\n        item.drop();\n    }\n\n    /// Finds and erases an element from the table, dropping it in place.\n    /// Returns true if an element was found.\n    #[cfg(feature = \"raw\")]\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn erase_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> bool {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        if let Some(bucket) = self.find(hash, eq) {\n            unsafe { self.erase(bucket) };\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Removes an element from the table, returning it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    #[allow(deprecated)]\n    pub unsafe fn remove(&mut self, item: Bucket<T>) -> T {\n        self.erase_no_drop(&item);\n        item.read()\n    }\n\n    /// Finds and removes an element from the table, returning it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { self.remove(bucket) }),\n            None => None,\n        }\n    }\n\n    /// Returns an iterator for a probe sequence on the table.\n    ///\n    /// This iterator never terminates, but is guaranteed to visit each bucket\n    /// group exactly once. The loop using `probe_seq` must terminate upon\n    /// reaching a group containing an empty bucket.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn probe_seq(&self, hash: u64) -> ProbeSeq {\n        ProbeSeq {\n            bucket_mask: self.bucket_mask,\n            pos: h1(hash) & self.bucket_mask,\n            stride: 0,\n        }\n    }\n\n    /// Sets a control byte, and possibly also the replicated control byte at\n    /// the end of the array.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn set_ctrl(&self, index: usize, ctrl: u8) {\n        // Replicate the first Group::WIDTH control bytes at the end of\n        // the array without using a branch:\n        // - If index >= Group::WIDTH then index == index2.\n        // - Otherwise index2 == self.bucket_mask + 1 + index.\n        //\n        // The very last replicated control byte is never actually read because\n        // we mask the initial index for unaligned loads, but we write it\n        // anyways because it makes the set_ctrl implementation simpler.\n        //\n        // If there are fewer buckets than Group::WIDTH then this code will\n        // replicate the buckets at the end of the trailing group. For example\n        // with 2 buckets and a group size of 4, the control bytes will look\n        // like this:\n        //\n        //     Real    |             Replicated\n        // ---------------------------------------------\n        // | [A] | [B] | [EMPTY] | [EMPTY] | [A] | [B] |\n        // ---------------------------------------------\n        let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;\n\n        *self.ctrl(index) = ctrl;\n        *self.ctrl(index2) = ctrl;\n    }\n\n    /// Searches for an empty or deleted bucket which is suitable for inserting\n    /// a new element.\n    ///\n    /// There must be at least 1 empty bucket in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn find_insert_slot(&self, hash: u64) -> usize {\n        for pos in self.probe_seq(hash) {\n            unsafe {\n                let group = Group::load(self.ctrl(pos));\n                if let Some(bit) = group.match_empty_or_deleted().lowest_set_bit() {\n                    let result = (pos + bit) & self.bucket_mask;\n\n                    // In tables smaller than the group width, trailing control\n                    // bytes outside the range of the table are filled with\n                    // EMPTY entries. These will unfortunately trigger a\n                    // match, but once masked may point to a full bucket that\n                    // is already occupied. We detect this situation here and\n                    // perform a second scan starting at the begining of the\n                    // table. This second scan is guaranteed to find an empty\n                    // slot (due to the load factor) before hitting the trailing\n                    // control bytes (containing EMPTY).\n                    if unlikely(is_full(*self.ctrl(result))) {\n                        debug_assert!(self.bucket_mask < Group::WIDTH);\n                        debug_assert_ne!(pos, 0);\n                        return Group::load_aligned(self.ctrl(0))\n                            .match_empty_or_deleted()\n                            .lowest_set_bit_nonzero();\n                    } else {\n                        return result;\n                    }\n                }\n            }\n        }\n\n        // probe_seq never returns.\n        unreachable!();\n    }\n\n    /// Marks all table buckets as empty without dropping their contents.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear_no_drop(&mut self) {\n        if !self.is_empty_singleton() {\n            unsafe {\n                self.ctrl(0).write_bytes(EMPTY, self.num_ctrl_bytes());\n            }\n        }\n        self.items = 0;\n        self.growth_left = bucket_mask_to_capacity(self.bucket_mask);\n    }\n\n    /// Removes all elements from the table without freeing the backing memory.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        // Ensure that the table is reset even if one of the drops panic\n        let self_ = guard(self, |self_| self_.clear_no_drop());\n\n        if mem::needs_drop::<T>() && self_.len() != 0 {\n            unsafe {\n                for item in self_.iter() {\n                    item.drop();\n                }\n            }\n        }\n    }\n\n    /// Shrinks the table to fit `max(self.len(), min_size)` elements.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64) {\n        // Calculate the minimal number of elements that we need to reserve\n        // space for.\n        let min_size = usize::max(self.items, min_size);\n        if min_size == 0 {\n            *self = Self::new();\n            return;\n        }\n\n        // Calculate the number of buckets that we need for this number of\n        // elements. If the calculation overflows then the requested bucket\n        // count must be larger than what we have right and nothing needs to be\n        // done.\n        let min_buckets = match capacity_to_buckets(min_size) {\n            Some(buckets) => buckets,\n            None => return,\n        };\n\n        // If we have more buckets than we need, shrink the table.\n        if min_buckets < self.buckets() {\n            // Fast path if the table is empty\n            if self.items == 0 {\n                *self = Self::with_capacity(min_size)\n            } else {\n                // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                if self\n                    .resize(min_size, hasher, Fallibility::Infallible)\n                    .is_err()\n                {\n                    unsafe { hint::unreachable_unchecked() }\n                }\n            }\n        }\n    }\n\n    /// Ensures that at least `additional` items can be inserted into the table\n    /// without reallocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {\n        if additional > self.growth_left {\n            // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n            if self\n                .reserve_rehash(additional, hasher, Fallibility::Infallible)\n                .is_err()\n            {\n                unsafe { hint::unreachable_unchecked() }\n            }\n        }\n    }\n\n    /// Tries to ensure that at least `additional` items can be inserted into\n    /// the table without reallocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError> {\n        if additional > self.growth_left {\n            self.reserve_rehash(additional, hasher, Fallibility::Fallible)\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Out-of-line slow path for `reserve` and `try_reserve`.\n    #[cold]\n    #[inline(never)]\n    fn reserve_rehash(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallability: Fallibility,\n    ) -> Result<(), TryReserveError> {\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let new_items = match self.items.checked_add(additional) {\n            Some(new_items) => new_items,\n            None => return Err(fallability.capacity_overflow()),\n        };\n        let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n        if new_items <= full_capacity / 2 {\n            // Rehash in-place without re-allocating if we have plenty of spare\n            // capacity that is locked up due to DELETED entries.\n            self.rehash_in_place(hasher);\n            Ok(())\n        } else {\n            // Otherwise, conservatively resize to at least the next size up\n            // to avoid churning deletes into frequent rehashes.\n            self.resize(\n                usize::max(new_items, full_capacity + 1),\n                hasher,\n                fallability,\n            )\n        }\n    }\n\n    /// Rehashes the contents of the table in place (i.e. without changing the\n    /// allocation).\n    ///\n    /// If `hasher` panics then some the table's contents may be lost.\n    fn rehash_in_place(&mut self, hasher: impl Fn(&T) -> u64) {\n        unsafe {\n            // Bulk convert all full control bytes to DELETED, and all DELETED\n            // control bytes to EMPTY. This effectively frees up all buckets\n            // containing a DELETED entry.\n            for i in (0..self.buckets()).step_by(Group::WIDTH) {\n                let group = Group::load_aligned(self.ctrl(i));\n                let group = group.convert_special_to_empty_and_full_to_deleted();\n                group.store_aligned(self.ctrl(i));\n            }\n\n            // Fix up the trailing control bytes. See the comments in set_ctrl\n            // for the handling of tables smaller than the group width.\n            if self.buckets() < Group::WIDTH {\n                self.ctrl(0)\n                    .copy_to(self.ctrl(Group::WIDTH), self.buckets());\n            } else {\n                self.ctrl(0)\n                    .copy_to(self.ctrl(self.buckets()), Group::WIDTH);\n            }\n\n            // If the hash function panics then properly clean up any elements\n            // that we haven't rehashed yet. We unfortunately can't preserve the\n            // element since we lost their hash and have no way of recovering it\n            // without risking another panic.\n            let mut guard = guard(self, |self_| {\n                if mem::needs_drop::<T>() {\n                    for i in 0..self_.buckets() {\n                        if *self_.ctrl(i) == DELETED {\n                            self_.set_ctrl(i, EMPTY);\n                            self_.bucket(i).drop();\n                            self_.items -= 1;\n                        }\n                    }\n                }\n                self_.growth_left = bucket_mask_to_capacity(self_.bucket_mask) - self_.items;\n            });\n\n            // At this point, DELETED elements are elements that we haven't\n            // rehashed yet. Find them and re-insert them at their ideal\n            // position.\n            'outer: for i in 0..guard.buckets() {\n                if *guard.ctrl(i) != DELETED {\n                    continue;\n                }\n                'inner: loop {\n                    // Hash the current item\n                    let item = guard.bucket(i);\n                    let hash = hasher(item.as_ref());\n\n                    // Search for a suitable place to put it\n                    let new_i = guard.find_insert_slot(hash);\n\n                    // Probing works by scanning through all of the control\n                    // bytes in groups, which may not be aligned to the group\n                    // size. If both the new and old position fall within the\n                    // same unaligned group, then there is no benefit in moving\n                    // it and we can just continue to the next item.\n                    let probe_index = |pos: usize| {\n                        (pos.wrapping_sub(guard.probe_seq(hash).pos) & guard.bucket_mask)\n                            / Group::WIDTH\n                    };\n                    if likely(probe_index(i) == probe_index(new_i)) {\n                        guard.set_ctrl(i, h2(hash));\n                        continue 'outer;\n                    }\n\n                    // We are moving the current item to a new position. Write\n                    // our H2 to the control byte of the new position.\n                    let prev_ctrl = *guard.ctrl(new_i);\n                    guard.set_ctrl(new_i, h2(hash));\n\n                    if prev_ctrl == EMPTY {\n                        // If the target slot is empty, simply move the current\n                        // element into the new slot and clear the old control\n                        // byte.\n                        guard.set_ctrl(i, EMPTY);\n                        guard.bucket(new_i).copy_from_nonoverlapping(&item);\n                        continue 'outer;\n                    } else {\n                        // If the target slot is occupied, swap the two elements\n                        // and then continue processing the element that we just\n                        // swapped into the old slot.\n                        debug_assert_eq!(prev_ctrl, DELETED);\n                        mem::swap(guard.bucket(new_i).as_mut(), item.as_mut());\n                        continue 'inner;\n                    }\n                }\n            }\n\n            guard.growth_left = bucket_mask_to_capacity(guard.bucket_mask) - guard.items;\n            mem::forget(guard);\n        }\n    }\n\n    /// Allocates a new table of a different size and moves the contents of the\n    /// current table into it.\n    fn resize(\n        &mut self,\n        capacity: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallability: Fallibility,\n    ) -> Result<(), TryReserveError> {\n        unsafe {\n            debug_assert!(self.items <= capacity);\n\n            // Allocate and initialize the new table.\n            let mut new_table = Self::fallible_with_capacity(capacity, fallability)?;\n            new_table.growth_left -= self.items;\n            new_table.items = self.items;\n\n            // The hash function may panic, in which case we simply free the new\n            // table without dropping any elements that may have been copied into\n            // it.\n            //\n            // This guard is also used to free the old table on success, see\n            // the comment at the bottom of this function.\n            let mut new_table = guard(ManuallyDrop::new(new_table), |new_table| {\n                if !new_table.is_empty_singleton() {\n                    new_table.free_buckets();\n                }\n            });\n\n            // Copy all elements to the new table.\n            for item in self.iter() {\n                // This may panic.\n                let hash = hasher(item.as_ref());\n\n                // We can use a simpler version of insert() here since:\n                // - there are no DELETED entries.\n                // - we know there is enough space in the table.\n                // - all elements are unique.\n                let index = new_table.find_insert_slot(hash);\n                new_table.set_ctrl(index, h2(hash));\n                new_table.bucket(index).copy_from_nonoverlapping(&item);\n            }\n\n            // We successfully copied all elements without panicking. Now replace\n            // self with the new table. The old table will have its memory freed but\n            // the items will not be dropped (since they have been moved into the\n            // new table).\n            mem::swap(self, &mut new_table);\n\n            Ok(())\n        }\n    }\n\n    /// Inserts a new element into the table, and returns its raw bucket.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T> {\n        unsafe {\n            let mut index = self.find_insert_slot(hash);\n\n            // We can avoid growing the table once we have reached our load\n            // factor if we are replacing a tombstone. This works since the\n            // number of EMPTY slots does not change in this case.\n            let old_ctrl = *self.ctrl(index);\n            if unlikely(self.growth_left == 0 && special_is_empty(old_ctrl)) {\n                self.reserve(1, hasher);\n                index = self.find_insert_slot(hash);\n            }\n\n            let bucket = self.bucket(index);\n            self.growth_left -= special_is_empty(old_ctrl) as usize;\n            self.set_ctrl(index, h2(hash));\n            bucket.write(value);\n            self.items += 1;\n            bucket\n        }\n    }\n\n    /// Inserts a new element into the table, and returns a mutable reference to it.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T {\n        unsafe { self.insert(hash, value, hasher).as_mut() }\n    }\n\n    /// Inserts a new element into the table, without growing the table.\n    ///\n    /// There must be enough space in the table to insert the new element.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(any(feature = \"raw\", feature = \"rustc-internal-api\"))]\n    pub fn insert_no_grow(&mut self, hash: u64, value: T) -> Bucket<T> {\n        unsafe {\n            let index = self.find_insert_slot(hash);\n            let bucket = self.bucket(index);\n\n            // If we are replacing a DELETED entry then we don't need to update\n            // the load counter.\n            let old_ctrl = *self.ctrl(index);\n            self.growth_left -= special_is_empty(old_ctrl) as usize;\n\n            self.set_ctrl(index, h2(hash));\n            bucket.write(value);\n            self.items += 1;\n            bucket\n        }\n    }\n\n    /// Temporary removes a bucket, applying the given function to the removed\n    /// element and optionally put back the returned value in the same bucket.\n    ///\n    /// Returns `true` if the bucket still contains an element\n    ///\n    /// This does not check if the given bucket is actually occupied.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn replace_bucket_with<F>(&mut self, bucket: Bucket<T>, f: F) -> bool\n    where\n        F: FnOnce(T) -> Option<T>,\n    {\n        let index = self.bucket_index(&bucket);\n        let old_ctrl = *self.ctrl(index);\n        debug_assert!(is_full(old_ctrl));\n        let old_growth_left = self.growth_left;\n        let item = self.remove(bucket);\n        if let Some(new_item) = f(item) {\n            self.growth_left = old_growth_left;\n            self.set_ctrl(index, old_ctrl);\n            self.items += 1;\n            self.bucket(index).write(new_item);\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Searches for an element in the table.\n    #[inline]\n    pub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>> {\n        unsafe {\n            for bucket in self.iter_hash(hash) {\n                let elm = bucket.as_ref();\n                if likely(eq(elm)) {\n                    return Some(bucket);\n                }\n            }\n            None\n        }\n    }\n\n    /// Gets a reference to an element in the table.\n    #[inline]\n    pub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }\n\n    /// Gets a mutable reference to an element in the table.\n    #[inline]\n    pub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }\n\n    /// Returns the number of elements the map can hold without reallocating.\n    ///\n    /// This number is a lower bound; the table might be able to hold\n    /// more, but is guaranteed to be able to hold at least this many.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn capacity(&self) -> usize {\n        self.items + self.growth_left\n    }\n\n    /// Returns the number of elements in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn len(&self) -> usize {\n        self.items\n    }\n\n    /// Returns the number of buckets in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn buckets(&self) -> usize {\n        self.bucket_mask + 1\n    }\n\n    /// Returns the number of control bytes in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn num_ctrl_bytes(&self) -> usize {\n        self.bucket_mask + 1 + Group::WIDTH\n    }\n\n    /// Returns whether this table points to the empty singleton with a capacity\n    /// of 0.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn is_empty_singleton(&self) -> bool {\n        self.bucket_mask == 0\n    }\n\n    /// Returns an iterator over every element in the table. It is up to\n    /// the caller to ensure that the `RawTable` outlives the `RawIter`.\n    /// Because we cannot make the `next` method unsafe on the `RawIter`\n    /// struct, we have to make the `iter` method unsafe.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn iter(&self) -> RawIter<T> {\n        let data = Bucket::from_base_index(self.data_end(), 0);\n        RawIter {\n            iter: RawIterRange::new(self.ctrl.as_ptr(), data, self.buckets()),\n            items: self.items,\n        }\n    }\n\n    /// Returns an iterator over occupied buckets that could match a given hash.\n    ///\n    /// In rare cases, the iterator may return a bucket with a different hash.\n    ///\n    /// It is up to the caller to ensure that the `RawTable` outlives the\n    /// `RawIterHash`. Because we cannot make the `next` method unsafe on the\n    /// `RawIterHash` struct, we have to make the `iter_hash` method unsafe.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn iter_hash(&self, hash: u64) -> RawIterHash<'_, T> {\n        RawIterHash::new(self, hash)\n    }\n\n    /// Returns an iterator which removes all elements from the table without\n    /// freeing the memory.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> RawDrain<'_, T> {\n        unsafe {\n            let iter = self.iter();\n            self.drain_iter_from(iter)\n        }\n    }\n\n    /// Returns an iterator which removes all elements from the table without\n    /// freeing the memory.\n    ///\n    /// Iteration starts at the provided iterator's current location.\n    ///\n    /// It is up to the caller to ensure that the iterator is valid for this\n    /// `RawTable` and covers all items that remain in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn drain_iter_from(&mut self, iter: RawIter<T>) -> RawDrain<'_, T> {\n        debug_assert_eq!(iter.len(), self.len());\n        RawDrain {\n            iter,\n            table: ManuallyDrop::new(mem::replace(self, Self::new())),\n            orig_table: NonNull::from(self),\n            marker: PhantomData,\n        }\n    }\n\n    /// Returns an iterator which consumes all elements from the table.\n    ///\n    /// Iteration starts at the provided iterator's current location.\n    ///\n    /// It is up to the caller to ensure that the iterator is valid for this\n    /// `RawTable` and covers all items that remain in the table.\n    pub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T> {\n        debug_assert_eq!(iter.len(), self.len());\n\n        let alloc = self.into_alloc();\n        RawIntoIter {\n            iter,\n            alloc,\n            marker: PhantomData,\n        }\n    }\n\n    /// Converts the table into a raw allocation. The contents of the table\n    /// should be dropped using a `RawIter` before freeing the allocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) fn into_alloc(self) -> Option<(NonNull<u8>, Layout)> {\n        let alloc = if self.is_empty_singleton() {\n            None\n        } else {\n            // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n            let (layout, ctrl_offset) = match calculate_layout::<T>(self.buckets()) {\n                Some(lco) => lco,\n                None => unsafe { hint::unreachable_unchecked() },\n            };\n            Some((\n                unsafe { NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)) },\n                layout,\n            ))\n        };\n        mem::forget(self);\n        alloc\n    }\n}","unsafe impl<T> Send for RawTable<T> where T: Send {}","unsafe impl<T> Sync for RawTable<T> where T: Sync {}"],"raw::bitmask::BitMask":["Clone","Copy","impl BitMask {\n    /// Returns a new `BitMask` with all bits inverted.\n    #[inline]\n    #[must_use]\n    pub fn invert(self) -> Self {\n        BitMask(self.0 ^ BITMASK_MASK)\n    }\n\n    /// Flip the bit in the mask for the entry at the given index.\n    ///\n    /// Returns the bit's previous state.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)]\n    #[cfg(feature = \"raw\")]\n    pub unsafe fn flip(&mut self, index: usize) -> bool {\n        // NOTE: The + BITMASK_STRIDE - 1 is to set the high bit.\n        let mask = 1 << (index * BITMASK_STRIDE + BITMASK_STRIDE - 1);\n        self.0 ^= mask;\n        // The bit was set if the bit is now 0.\n        self.0 & mask == 0\n    }\n\n    /// Returns a new `BitMask` with the lowest bit removed.\n    #[inline]\n    #[must_use]\n    pub fn remove_lowest_bit(self) -> Self {\n        BitMask(self.0 & (self.0 - 1))\n    }\n    /// Returns whether the `BitMask` has at least one set bit.\n    #[inline]\n    pub fn any_bit_set(self) -> bool {\n        self.0 != 0\n    }\n\n    /// Returns the first set bit in the `BitMask`, if there is one.\n    #[inline]\n    pub fn lowest_set_bit(self) -> Option<usize> {\n        if self.0 == 0 {\n            None\n        } else {\n            Some(unsafe { self.lowest_set_bit_nonzero() })\n        }\n    }\n\n    /// Returns the first set bit in the `BitMask`, if there is one. The\n    /// bitmask must not be empty.\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    pub unsafe fn lowest_set_bit_nonzero(self) -> usize {\n        intrinsics::cttz_nonzero(self.0) as usize / BITMASK_STRIDE\n    }\n    #[inline]\n    #[cfg(not(feature = \"nightly\"))]\n    pub unsafe fn lowest_set_bit_nonzero(self) -> usize {\n        self.trailing_zeros()\n    }\n\n    /// Returns the number of trailing zeroes in the `BitMask`.\n    #[inline]\n    pub fn trailing_zeros(self) -> usize {\n        // ARM doesn't have a trailing_zeroes instruction, and instead uses\n        // reverse_bits (RBIT) + leading_zeroes (CLZ). However older ARM\n        // versions (pre-ARMv7) don't have RBIT and need to emulate it\n        // instead. Since we only have 1 bit set in each byte on ARM, we can\n        // use swap_bytes (REV) + leading_zeroes instead.\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            self.0.swap_bytes().leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            self.0.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }\n\n    /// Returns the number of leading zeroes in the `BitMask`.\n    #[inline]\n    pub fn leading_zeros(self) -> usize {\n        self.0.leading_zeros() as usize / BITMASK_STRIDE\n    }\n}","impl IntoIterator for BitMask {\n    type Item = usize;\n    type IntoIter = BitMaskIter;\n\n    #[inline]\n    fn into_iter(self) -> BitMaskIter {\n        BitMaskIter(self)\n    }\n}"],"raw::bitmask::BitMaskIter":["impl Iterator for BitMaskIter {\n    type Item = usize;\n\n    #[inline]\n    fn next(&mut self) -> Option<usize> {\n        let bit = self.0.lowest_set_bit()?;\n        self.0 = self.0.remove_lowest_bit();\n        Some(bit)\n    }\n}"],"raw::sse2::Group":["Clone","Copy","impl Group {\n    /// Number of bytes in the group.\n    pub const WIDTH: usize = mem::size_of::<Self>();\n\n    /// Returns a full group of empty bytes, suitable for use as the initial\n    /// value for an empty hash table.\n    ///\n    /// This is guaranteed to be aligned to the group size.\n    pub const fn static_empty() -> &'static [u8; Group::WIDTH] {\n        #[repr(C)]\n        struct AlignedBytes {\n            _align: [Group; 0],\n            bytes: [u8; Group::WIDTH],\n        };\n        const ALIGNED_BYTES: AlignedBytes = AlignedBytes {\n            _align: [],\n            bytes: [EMPTY; Group::WIDTH],\n        };\n        &ALIGNED_BYTES.bytes\n    }\n\n    /// Loads a group of bytes starting at the given address.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)] // unaligned load\n    pub unsafe fn load(ptr: *const u8) -> Self {\n        Group(x86::_mm_loadu_si128(ptr as *const _))\n    }\n\n    /// Loads a group of bytes starting at the given address, which must be\n    /// aligned to `mem::align_of::<Group>()`.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)]\n    pub unsafe fn load_aligned(ptr: *const u8) -> Self {\n        // FIXME: use align_offset once it stabilizes\n        debug_assert_eq!(ptr as usize & (mem::align_of::<Self>() - 1), 0);\n        Group(x86::_mm_load_si128(ptr as *const _))\n    }\n\n    /// Stores the group of bytes to the given address, which must be\n    /// aligned to `mem::align_of::<Group>()`.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)]\n    pub unsafe fn store_aligned(self, ptr: *mut u8) {\n        // FIXME: use align_offset once it stabilizes\n        debug_assert_eq!(ptr as usize & (mem::align_of::<Self>() - 1), 0);\n        x86::_mm_store_si128(ptr as *mut _, self.0);\n    }\n\n    /// Returns a `BitMask` indicating all bytes in the group which have\n    /// the given value.\n    #[inline]\n    pub fn match_byte(self, byte: u8) -> BitMask {\n        #[allow(\n            clippy::cast_possible_wrap, // byte: u8 as i8\n            // byte: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            let cmp = x86::_mm_cmpeq_epi8(self.0, x86::_mm_set1_epi8(byte as i8));\n            BitMask(x86::_mm_movemask_epi8(cmp) as u16)\n        }\n    }\n\n    /// Returns a `BitMask` indicating all bytes in the group which are\n    /// `EMPTY`.\n    #[inline]\n    pub fn match_empty(self) -> BitMask {\n        self.match_byte(EMPTY)\n    }\n\n    /// Returns a `BitMask` indicating all bytes in the group which are\n    /// `EMPTY` or `DELETED`.\n    #[inline]\n    pub fn match_empty_or_deleted(self) -> BitMask {\n        #[allow(\n            // byte: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            // A byte is EMPTY or DELETED iff the high bit is set\n            BitMask(x86::_mm_movemask_epi8(self.0) as u16)\n        }\n    }\n\n    /// Returns a `BitMask` indicating all bytes in the group which are full.\n    #[inline]\n    pub fn match_full(&self) -> BitMask {\n        self.match_empty_or_deleted().invert()\n    }\n\n    /// Performs the following transformation on all bytes in the group:\n    /// - `EMPTY => EMPTY`\n    /// - `DELETED => EMPTY`\n    /// - `FULL => DELETED`\n    #[inline]\n    pub fn convert_special_to_empty_and_full_to_deleted(self) -> Self {\n        // Map high_bit = 1 (EMPTY or DELETED) to 1111_1111\n        // and high_bit = 0 (FULL) to 1000_0000\n        //\n        // Here's this logic expanded to concrete values:\n        //   let special = 0 > byte = 1111_1111 (true) or 0000_0000 (false)\n        //   1111_1111 | 1000_0000 = 1111_1111\n        //   0000_0000 | 1000_0000 = 1000_0000\n        #[allow(\n            clippy::cast_possible_wrap, // byte: 0x80_u8 as i8\n        )]\n        unsafe {\n            let zero = x86::_mm_setzero_si128();\n            let special = x86::_mm_cmpgt_epi8(zero, self.0);\n            Group(x86::_mm_or_si128(\n                special,\n                x86::_mm_set1_epi8(0x80_u8 as i8),\n            ))\n        }\n    }\n}"],"scopeguard::ScopeGuard":["impl<T, F> Deref for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    type Target = T;\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn deref(&self) -> &T {\n        &self.value\n    }\n}","impl<T, F> DerefMut for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn deref_mut(&mut self) -> &mut T {\n        &mut self.value\n    }\n}","impl<T, F> Drop for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        (self.dropfn)(&mut self.value)\n    }\n}"],"set::Difference":["impl<'a, T, S> Iterator for Difference<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if !self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }\n}","impl<T, S> Clone for Difference<'_, T, S> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Difference {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }\n}","impl<T, S> FusedIterator for Difference<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}","impl<T, S> fmt::Debug for Difference<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"],"set::Drain":["impl<K: fmt::Debug> fmt::Debug for Drain<'_, K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }\n}","impl<K> ExactSizeIterator for Drain<'_, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}","impl<K> FusedIterator for Drain<'_, K> {}","impl<K> Iterator for Drain<'_, K> {\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}"],"set::DrainFilter":["impl<'a, K, F> Drop for DrainFilter<'a, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        while let Some(item) = self.next() {\n            let guard = ConsumeAllOnDrop(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }\n}","impl<K, F> FusedIterator for DrainFilter<'_, K, F> where F: FnMut(&K) -> bool {}","impl<K, F> Iterator for DrainFilter<'_, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Self::Item> {\n        let f = &mut self.f;\n        let (k, _) = self.inner.next(&mut |k, _| f(k))?;\n        Some(k)\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, self.inner.iter.size_hint().1)\n    }\n}"],"set::HashSet":["impl<'a, T, S> Extend<&'a T> for HashSet<T, S>\nwhere\n    T: 'a + Eq + Hash + Copy,\n    S: BuildHasher,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().cloned());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, k: &'a T) {\n        self.map.insert(*k, ());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(T, ())>::extend_reserve(&mut self.map, additional);\n    }\n}","impl<T, S> Default for HashSet<T, S>\nwhere\n    S: Default,\n{\n    /// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            map: HashMap::default(),\n        }\n    }\n}","impl<T, S> Eq for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}","impl<T, S> Extend<T> for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        self.map.extend(iter.into_iter().map(|k| (k, ())));\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, k: T) {\n        self.map.insert(k, ());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(T, ())>::extend_reserve(&mut self.map, additional);\n    }\n}","impl<T, S> FromIterator<T> for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher + Default,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n        let mut set = Self::with_hasher(Default::default());\n        set.extend(iter);\n        set\n    }\n}","impl<T, S> HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashSet`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new allocation size overflows `usize`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.reserve(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize) {\n        self.map.reserve(additional)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashSet<K,V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.map.try_reserve(additional)\n    }\n\n    /// Shrinks the capacity of the set as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to_fit();\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to_fit(&mut self) {\n        self.map.shrink_to_fit()\n    }\n\n    /// Shrinks the capacity of the set with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// Panics if the current capacity is smaller than the supplied\n    /// minimum capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to(10);\n    /// assert!(set.capacity() >= 10);\n    /// set.shrink_to(0);\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.map.shrink_to(min_capacity)\n    }\n\n    /// Visits the values representing the difference,\n    /// i.e., the values that are in `self` but not in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Can be seen as `a - b`.\n    /// for x in a.difference(&b) {\n    ///     println!(\"{}\", x); // Print 1\n    /// }\n    ///\n    /// let diff: HashSet<_> = a.difference(&b).collect();\n    /// assert_eq!(diff, [1].iter().collect());\n    ///\n    /// // Note that difference is not symmetric,\n    /// // and `b - a` means something else:\n    /// let diff: HashSet<_> = b.difference(&a).collect();\n    /// assert_eq!(diff, [4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn difference<'a>(&'a self, other: &'a Self) -> Difference<'a, T, S> {\n        Difference {\n            iter: self.iter(),\n            other,\n        }\n    }\n\n    /// Visits the values representing the symmetric difference,\n    /// i.e., the values that are in `self` or in `other` but not in both.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 1, 4 in arbitrary order.\n    /// for x in a.symmetric_difference(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();\n    /// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();\n    ///\n    /// assert_eq!(diff1, diff2);\n    /// assert_eq!(diff1, [1, 4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn symmetric_difference<'a>(&'a self, other: &'a Self) -> SymmetricDifference<'a, T, S> {\n        SymmetricDifference {\n            iter: self.difference(other).chain(other.difference(self)),\n        }\n    }\n\n    /// Visits the values representing the intersection,\n    /// i.e., the values that are both in `self` and `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 2, 3 in arbitrary order.\n    /// for x in a.intersection(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let intersection: HashSet<_> = a.intersection(&b).collect();\n    /// assert_eq!(intersection, [2, 3].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn intersection<'a>(&'a self, other: &'a Self) -> Intersection<'a, T, S> {\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Intersection {\n            iter: smaller.iter(),\n            other: larger,\n        }\n    }\n\n    /// Visits the values representing the union,\n    /// i.e., all the values in `self` or `other`, without duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n    ///\n    /// // Print 1, 2, 3, 4 in arbitrary order.\n    /// for x in a.union(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let union: HashSet<_> = a.union(&b).collect();\n    /// assert_eq!(union, [1, 2, 3, 4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn union<'a>(&'a self, other: &'a Self) -> Union<'a, T, S> {\n        let (smaller, larger) = if self.len() >= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Union {\n            iter: larger.iter().chain(smaller.difference(larger)),\n        }\n    }\n\n    /// Returns `true` if the set contains a value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.contains(&1), true);\n    /// assert_eq!(set.contains(&4), false);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn contains<Q: ?Sized>(&self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.map.contains_key(value)\n    }\n\n    /// Returns a reference to the value in the set, if any, that is equal to the given value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.get(&2), Some(&2));\n    /// assert_eq!(set.get(&4), None);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get<Q: ?Sized>(&self, value: &Q) -> Option<&T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.get_key_value(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n\n    /// Inserts the given `value` into the set if it is not present, then\n    /// returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.len(), 3);\n    /// assert_eq!(set.get_or_insert(2), &2);\n    /// assert_eq!(set.get_or_insert(100), &100);\n    /// assert_eq!(set.len(), 4); // 100 was inserted\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_or_insert(&mut self, value: T) -> &T {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(&value)\n            .or_insert(value, ())\n            .0\n    }\n\n    /// Inserts an owned copy of the given `value` into the set if it is not\n    /// present, then returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n    ///     .iter().map(|&pet| pet.to_owned()).collect();\n    ///\n    /// assert_eq!(set.len(), 3);\n    /// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n    ///     let value = set.get_or_insert_owned(pet);\n    ///     assert_eq!(value, pet);\n    /// }\n    /// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n    /// ```\n    #[inline]\n    pub fn get_or_insert_owned<Q: ?Sized>(&mut self, value: &Q) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq + ToOwned<Owned = T>,\n    {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(value)\n            .or_insert_with(|| (value.to_owned(), ()))\n            .0\n    }\n\n    /// Inserts a value computed from `f` into the set if the given `value` is\n    /// not present, then returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n    ///     .iter().map(|&pet| pet.to_owned()).collect();\n    ///\n    /// assert_eq!(set.len(), 3);\n    /// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n    ///     let value = set.get_or_insert_with(pet, str::to_owned);\n    ///     assert_eq!(value, pet);\n    /// }\n    /// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_or_insert_with<Q: ?Sized, F>(&mut self, value: &Q, f: F) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n        F: FnOnce(&Q) -> T,\n    {\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(value)\n            .or_insert_with(|| (f(value), ()))\n            .0\n    }\n\n    /// Returns `true` if `self` has no elements in common with `other`.\n    /// This is equivalent to checking for an empty intersection.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut b = HashSet::new();\n    ///\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(4);\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(1);\n    /// assert_eq!(a.is_disjoint(&b), false);\n    /// ```\n    pub fn is_disjoint(&self, other: &Self) -> bool {\n        self.iter().all(|v| !other.contains(v))\n    }\n\n    /// Returns `true` if the set is a subset of another,\n    /// i.e., `other` contains at least all the values in `self`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let sup: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(2);\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(4);\n    /// assert_eq!(set.is_subset(&sup), false);\n    /// ```\n    pub fn is_subset(&self, other: &Self) -> bool {\n        self.len() <= other.len() && self.iter().all(|v| other.contains(v))\n    }\n\n    /// Returns `true` if the set is a superset of another,\n    /// i.e., `self` contains at least all the values in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let sub: HashSet<_> = [1, 2].iter().cloned().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(0);\n    /// set.insert(1);\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.is_superset(&sub), true);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_superset(&self, other: &Self) -> bool {\n        other.is_subset(self)\n    }\n\n    /// Adds a value to the set.\n    ///\n    /// If the set did not have this value present, `true` is returned.\n    ///\n    /// If the set did have this value present, `false` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.insert(2), true);\n    /// assert_eq!(set.insert(2), false);\n    /// assert_eq!(set.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, value: T) -> bool {\n        self.map.insert(value, ()).is_none()\n    }\n\n    /// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n    /// one. Returns the replaced value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    /// set.insert(Vec::<i32>::new());\n    ///\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n    /// set.replace(Vec::with_capacity(10));\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace(&mut self, value: T) -> Option<T> {\n        match self.map.entry(value) {\n            map::Entry::Occupied(occupied) => Some(occupied.replace_key()),\n            map::Entry::Vacant(vacant) => {\n                vacant.insert(());\n                None\n            }\n        }\n    }\n\n    /// Removes a value from the set. Returns whether the value was\n    /// present in the set.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.remove(&2), true);\n    /// assert_eq!(set.remove(&2), false);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove<Q: ?Sized>(&mut self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        self.map.remove(value).is_some()\n    }\n\n    /// Removes and returns the value in the set, if any, that is equal to the given one.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert_eq!(set.take(&2), Some(2));\n    /// assert_eq!(set.take(&2), None);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn take<Q: ?Sized>(&mut self, value: &Q) -> Option<T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.remove_entry(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n}","impl<T, S> HashSet<T, S> {\n    /// Creates a new empty hash set which will use the given hasher to hash\n    /// keys.\n    ///\n    /// The hash set is also created with the default initial capacity.\n    ///\n    /// Warning: `hasher` is normally randomly generated, and\n    /// is designed to allow `HashSet`s to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_hasher(s);\n    /// set.insert(2);\n    /// ```\n    ///\n    /// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub const fn with_hasher(hasher: S) -> Self {\n        Self {\n            map: HashMap::with_hasher(hasher),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity, using\n    /// `hasher` to hash the keys.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// Warning: `hasher` is normally randomly generated, and\n    /// is designed to allow `HashSet`s to be resistant to attacks that\n    /// cause many collisions and very poor performance. Setting it\n    /// manually using this function can expose a DoS attack vector.\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the HashMap to be useful, see its documentation for details.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_capacity_and_hasher(10, s);\n    /// set.insert(1);\n    /// ```\n    ///\n    /// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> Self {\n        Self {\n            map: HashMap::with_capacity_and_hasher(capacity, hasher),\n        }\n    }\n\n    /// Returns the number of elements the set can hold without reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(100);\n    /// assert!(set.capacity() >= 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn capacity(&self) -> usize {\n        self.map.capacity()\n    }\n\n    /// An iterator visiting all elements in arbitrary order.\n    /// The iterator element type is `&'a T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\");\n    /// set.insert(\"b\");\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in set.iter() {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter {\n            iter: self.map.keys(),\n        }\n    }\n\n    /// Returns the number of elements in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.insert(1);\n    /// assert_eq!(v.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn len(&self) -> usize {\n        self.map.len()\n    }\n\n    /// Returns `true` if the set contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert!(v.is_empty());\n    /// v.insert(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_empty(&self) -> bool {\n        self.map.is_empty()\n    }\n\n    /// Clears the set, returning all elements in an iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n    /// assert!(!set.is_empty());\n    ///\n    /// // print 1, 2, 3 in an arbitrary order\n    /// for i in set.drain() {\n    ///     println!(\"{}\", i);\n    /// }\n    ///\n    /// assert!(set.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> Drain<'_, T> {\n        Drain {\n            iter: self.map.drain(),\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let xs = [1,2,3,4,5,6];\n    /// let mut set: HashSet<i32> = xs.iter().cloned().collect();\n    /// set.retain(|&k| k % 2 == 0);\n    /// assert_eq!(set.len(), 3);\n    /// ```\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        self.map.retain(|k, _| f(k));\n    }\n\n    /// Drains elements which are true under the given predicate,\n    /// and returns an iterator over the removed items.\n    ///\n    /// In other words, move all elements `e` such that `f(&e)` returns `true` out\n    /// into another iterator.\n    ///\n    /// When the returned DrainedFilter is dropped, any remaining elements that satisfy\n    /// the predicate are dropped from the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<i32> = (0..8).collect();\n    /// let drained: HashSet<i32> = set.drain_filter(|v| v % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.into_iter().collect::<Vec<_>>();\n    /// let mut odds = set.into_iter().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain_filter<F>(&mut self, f: F) -> DrainFilter<'_, T, F>\n    where\n        F: FnMut(&T) -> bool,\n    {\n        DrainFilter {\n            f,\n            inner: DrainFilterInner {\n                iter: unsafe { self.map.table.iter() },\n                table: &mut self.map.table,\n            },\n        }\n    }\n\n    /// Clears the set, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// v.insert(1);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        self.map.clear()\n    }\n\n    /// Returns a reference to the set's [`BuildHasher`].\n    ///\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_map::DefaultHashBuilder;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let set: HashSet<i32> = HashSet::with_hasher(hasher);\n    /// let hasher: &DefaultHashBuilder = set.hasher();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn hasher(&self) -> &S {\n        self.map.hasher()\n    }\n}","impl<T, S> IntoIterator for HashSet<T, S> {\n    type Item = T;\n    type IntoIter = IntoIter<T>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out\n    /// of the set in arbitrary order. The set cannot be used after calling\n    /// this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\".to_string());\n    /// set.insert(\"b\".to_string());\n    ///\n    /// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n    /// let v: Vec<String> = set.into_iter().collect();\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in &v {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> IntoIter<T> {\n        IntoIter {\n            iter: self.map.into_iter(),\n        }\n    }\n}","impl<T, S> PartialEq for HashSet<T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    fn eq(&self, other: &Self) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|key| other.contains(key))\n    }\n}","impl<T, S> fmt::Debug for HashSet<T, S>\nwhere\n    T: Eq + Hash + fmt::Debug,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_set().entries(self.iter()).finish()\n    }\n}","impl<T: Clone, S: Clone> Clone for HashSet<T, S> {\n    fn clone(&self) -> Self {\n        HashSet {\n            map: self.map.clone(),\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.map.clone_from(&source.map);\n    }\n}","impl<T> HashSet<T, DefaultHashBuilder> {\n    /// Creates an empty `HashSet`.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::new();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new() -> Self {\n        Self {\n            map: HashMap::new(),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self {\n            map: HashMap::with_capacity(capacity),\n        }\n    }\n}"],"set::Intersection":["impl<'a, T, S> Iterator for Intersection<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }\n}","impl<T, S> Clone for Intersection<'_, T, S> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Intersection {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }\n}","impl<T, S> FusedIterator for Intersection<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}","impl<T, S> fmt::Debug for Intersection<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"],"set::IntoIter":["impl<K: fmt::Debug> fmt::Debug for IntoIter<K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }\n}","impl<K> ExactSizeIterator for IntoIter<K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}","impl<K> FusedIterator for IntoIter<K> {}","impl<K> Iterator for IntoIter<K> {\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}"],"set::Iter":["impl<'a, K> ExactSizeIterator for Iter<'a, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}","impl<'a, K> Iterator for Iter<'a, K> {\n    type Item = &'a K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a K> {\n        self.iter.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}","impl<K: fmt::Debug> fmt::Debug for Iter<'_, K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}","impl<K> Clone for Iter<'_, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Iter {\n            iter: self.iter.clone(),\n        }\n    }\n}","impl<K> FusedIterator for Iter<'_, K> {}"],"set::SymmetricDifference":["impl<'a, T, S> Iterator for SymmetricDifference<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}","impl<T, S> Clone for SymmetricDifference<'_, T, S> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        SymmetricDifference {\n            iter: self.iter.clone(),\n        }\n    }\n}","impl<T, S> FusedIterator for SymmetricDifference<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}","impl<T, S> fmt::Debug for SymmetricDifference<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"],"set::Union":["impl<'a, T, S> Iterator for Union<'a, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}","impl<T, S> Clone for Union<'_, T, S> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Union {\n            iter: self.iter.clone(),\n        }\n    }\n}","impl<T, S> FusedIterator for Union<'_, T, S>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n{\n}","impl<T, S> fmt::Debug for Union<'_, T, S>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"]},"single_path_import":{"map::HashMap":"HashMap","set::HashSet":"HashSet"},"srcs":{"<&'a map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["inline\nfn into_iter(self) -> Iter<'a, K, V>{\n        self.iter()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<&'a mut map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["inline\nfn into_iter(self) -> IterMut<'a, K, V>{\n        self.iter_mut()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<&'a set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["inline\nfn into_iter(self) -> Iter<'a, T>{\n        self.iter()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<&set::HashSet<T, S> as core::ops::BitAnd<&set::HashSet<T, S>>>::bitand":["/// Returns the intersection of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();\n///\n/// let set = &a & &b;\n///\n/// let mut i = 0;\n/// let expected = [2, 3];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitand(self, rhs: &HashSet<T, S>) -> HashSet<T, S>{\n        self.intersection(rhs).cloned().collect()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<&set::HashSet<T, S> as core::ops::BitOr<&set::HashSet<T, S>>>::bitor":["/// Returns the union of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a | &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 3, 4, 5];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitor(self, rhs: &HashSet<T, S>) -> HashSet<T, S>{\n        self.union(rhs).cloned().collect()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<&set::HashSet<T, S> as core::ops::BitXor<&set::HashSet<T, S>>>::bitxor":["/// Returns the symmetric difference of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a ^ &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 4, 5];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitxor(self, rhs: &HashSet<T, S>) -> HashSet<T, S>{\n        self.symmetric_difference(rhs).cloned().collect()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<&set::HashSet<T, S> as core::ops::Sub<&set::HashSet<T, S>>>::sub":["/// Returns the difference of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a - &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn sub(self, rhs: &HashSet<T, S>) -> HashSet<T, S>{\n        self.difference(rhs).cloned().collect()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<map::ConsumeAllOnDrop<'_, T> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        self.0.for_each(drop)\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Drain<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Drain<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Drain<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<(K, V)>{\n        self.inner.next()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Drain<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<Self::Item>{\n        self.inner.next(&mut self.f)\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (0, self.inner.iter.size_hint().1)\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::DrainFilter<'a, K, V, F> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        while let Some(item) = self.next() {\n            let guard = ConsumeAllOnDrop(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Entry<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone":["fn clone(&self) -> Self{\n        HashMap {\n            hash_builder: self.hash_builder.clone(),\n            table: self.table.clone(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone_from":["fn clone_from(&mut self, source: &Self){\n        self.table.clone_from(&source.table);\n\n        // Update hash_builder only if we successfully cloned all elements.\n        self.hash_builder.clone_from(&source.hash_builder);\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::cmp::PartialEq>::eq":["fn eq(&self, other: &Self) -> bool{\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter()\n            .all(|(key, value)| other.get(key).map_or(false, |v| *value == *v))\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::default::Default>::default":["/// Creates an empty `HashMap<K, V, S>`, with the `Default` value for the hasher.\ninline\nfn default() -> Self{\n        Self::with_hasher(Default::default())\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_map().entries(self.iter()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::iter::Extend<(&'a K, &'a V)>>::extend":["inline\nfn extend<T: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: T){\n        self.extend(iter.into_iter().map(|(&key, &value)| (key, value)));\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::iter::Extend<(K, V)>>::extend":["inline\nfn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T){\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let iter = iter.into_iter();\n        let reserve = if self.is_empty() {\n            iter.size_hint().0\n        } else {\n            (iter.size_hint().0 + 1) / 2\n        };\n        self.reserve(reserve);\n        iter.for_each(move |(k, v)| {\n            self.insert(k, v);\n        });\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::iter::FromIterator<(K, V)>>::from_iter":["inline\nfn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> Self{\n        let iter = iter.into_iter();\n        let mut map = Self::with_capacity_and_hasher(iter.size_hint().0, S::default());\n        iter.for_each(|(k, v)| {\n            map.insert(k, v);\n        });\n        map\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["/// Creates a consuming iterator, that is, one that moves each key-value\n/// pair out of the map in arbitrary order. The map cannot be used after\n/// calling this.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// // Not possible with .iter()\n/// let vec: Vec<(&str, i32)> = map.into_iter().collect();\n/// ```\ninline\nfn into_iter(self) -> IntoIter<K, V>{\n        IntoIter {\n            inner: self.table.into_iter(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::HashMap<K, V, S> as core::ops::Index<&Q>>::index":["/// Returns a reference to the value corresponding to the supplied key.\n///\n/// # Panics\n///\n/// Panics if the key is not present in the `HashMap`.\ninline\nfn index(&self, key: &Q) -> &V{\n        self.get(key).expect(\"no entry found for key\")\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IntoIter<K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IntoIter<K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IntoIter<K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<(K, V)>{\n        self.inner.next()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IntoIter<K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Iter<'_, K, V> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Iter<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Iter<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<(&'a K, &'a V)>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_ref();\n                Some((&r.0, &r.1))\n            },\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<(&'a K, &'a mut V)>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_mut();\n                Some((&r.0, &mut r.1))\n            },\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Keys<'_, K, V> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Keys {\n            inner: self.inner.clone(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Keys<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Keys<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::OccupiedEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::RawEntryBuilder<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::RawEntryBuilderMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::RawEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            RawEntryMut::Vacant(ref v) => f.debug_tuple(\"RawEntry\").field(v).finish(),\n            RawEntryMut::Occupied(ref o) => f.debug_tuple(\"RawEntry\").field(o).finish(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::RawOccupiedEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawOccupiedEntryMut\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::RawVacantEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawVacantEntryMut\").finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::VacantEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Values<'_, K, V> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Values {\n            inner: self.inner.clone(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Values<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Values<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a V>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::Values<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.inner.iter()).finish()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a mut V>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }","Real(LocalPath(\"src/map.rs\"))"],"<raw::Bucket<T> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Self { ptr: self.ptr }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::ProbeSeq as core::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<usize>{\n        // We should have found an empty bucket by now and ended the probe.\n        debug_assert!(\n            self.stride <= self.bucket_mask,\n            \"Went past end of probe sequence\"\n        );\n\n        let result = self.pos;\n        self.stride += Group::WIDTH;\n        self.pos += self.stride;\n        self.pos &= self.bucket_mask;\n        Some(result)\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<T>{\n        unsafe {\n            let item = self.iter.next()?;\n            Some(item.read())\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawDrain<'_, T> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        unsafe {\n            // Drop all remaining elements. Note that this may panic.\n            if mem::needs_drop::<T>() && self.iter.len() != 0 {\n                while let Some(item) = self.iter.next() {\n                    item.drop();\n                }\n            }\n\n            // Reset the contents of the table now that all elements have been\n            // dropped.\n            self.table.clear_no_drop();\n\n            // Move the now empty table back to its original location.\n            self.orig_table\n                .as_ptr()\n                .copy_from_nonoverlapping(&*self.table, 1);\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIntoIter<T> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<T>{\n        unsafe { Some(self.iter.next()?.read()) }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIntoIter<T> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIntoIter<T> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        unsafe {\n            // Drop all remaining elements\n            if mem::needs_drop::<T>() && self.iter.len() != 0 {\n                while let Some(item) = self.iter.next() {\n                    item.drop();\n                }\n            }\n\n            // Free the table\n            if let Some((ptr, layout)) = self.alloc {\n                dealloc(ptr.as_ptr(), layout);\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIter<T> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Self {\n            iter: self.iter.clone(),\n            items: self.items,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIter<T> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<Bucket<T>>{\n        if let Some(b) = self.iter.next() {\n            self.items -= 1;\n            Some(b)\n        } else {\n            // We don't check against items == 0 here to allow the\n            // compiler to optimize away the item count entirely if the\n            // iterator length is never queried.\n            debug_assert_eq!(self.items, 0);\n            None\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIter<T> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        (self.items, Some(self.items))\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIterHash<'a, T> as core::iter::Iterator>::next":["fn next(&mut self) -> Option<Bucket<T>>{\n        unsafe {\n            loop {\n                if let Some(bit) = self.bitmask.next() {\n                    let index = (self.pos + bit) & self.table.bucket_mask;\n                    let bucket = self.table.bucket(index);\n                    return Some(bucket);\n                }\n                if likely(self.group.match_empty().any_bit_set()) {\n                    return None;\n                }\n                self.pos = self.probe_seq.next().unwrap();\n                self.group = Group::load(self.table.ctrl(self.pos));\n                self.bitmask = self.group.match_byte(self.h2_hash).into_iter();\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIterRange<T> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Self {\n            data: self.data.clone(),\n            next_ctrl: self.next_ctrl,\n            current_group: self.current_group,\n            end: self.end,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIterRange<T> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<Bucket<T>>{\n        unsafe {\n            loop {\n                if let Some(index) = self.current_group.lowest_set_bit() {\n                    self.current_group = self.current_group.remove_lowest_bit();\n                    return Some(self.data.next_n(index));\n                }\n\n                if self.next_ctrl >= self.end {\n                    return None;\n                }\n\n                // We might read past self.end up to the next group boundary,\n                // but this is fine because it only occurs on tables smaller\n                // than the group size where the trailing control bytes are all\n                // EMPTY. On larger tables self.end is guaranteed to be aligned\n                // to the group size (since tables are power-of-two sized).\n                self.current_group = Group::load_aligned(self.next_ctrl).match_full();\n                self.data = self.data.next_n(Group::WIDTH);\n                self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawIterRange<T> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        // We don't have an item count, so just guess based on the range size.\n        (\n            0,\n            Some(unsafe { offset_from(self.end, self.next_ctrl) + Group::WIDTH }),\n        )\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawTable<T> as core::clone::Clone>::clone":["fn clone(&self) -> Self{\n        if self.is_empty_singleton() {\n            Self::new()\n        } else {\n            unsafe {\n                let mut new_table = ManuallyDrop::new(\n                    // Avoid `Result::ok_or_else` because it bloats LLVM IR.\n                    match Self::new_uninitialized(self.buckets(), Fallibility::Infallible) {\n                        Ok(table) => table,\n                        Err(_) => hint::unreachable_unchecked(),\n                    },\n                );\n\n                new_table.clone_from_spec(self, |new_table| {\n                    // We need to free the memory allocated for the new table.\n                    new_table.free_buckets();\n                });\n\n                // Return the newly created table.\n                ManuallyDrop::into_inner(new_table)\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawTable<T> as core::clone::Clone>::clone_from":["fn clone_from(&mut self, source: &Self){\n        if source.is_empty_singleton() {\n            *self = Self::new();\n        } else {\n            unsafe {\n                // First, drop all our elements without clearing the control bytes.\n                if mem::needs_drop::<T>() && self.len() != 0 {\n                    for item in self.iter() {\n                        item.drop();\n                    }\n                }\n\n                // If necessary, resize our table to match the source.\n                if self.buckets() != source.buckets() {\n                    // Skip our drop by using ptr::write.\n                    if !self.is_empty_singleton() {\n                        self.free_buckets();\n                    }\n                    (self as *mut Self).write(\n                        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                        match Self::new_uninitialized(source.buckets(), Fallibility::Infallible) {\n                            Ok(table) => table,\n                            Err(_) => hint::unreachable_unchecked(),\n                        },\n                    );\n                }\n\n                self.clone_from_spec(source, |self_| {\n                    // We need to leave the table in an empty state.\n                    self_.clear_no_drop()\n                });\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawTable<T> as core::iter::IntoIterator>::into_iter":["inline\nfn into_iter(self) -> RawIntoIter<T>{\n        unsafe {\n            let iter = self.iter();\n            self.into_iter_from(iter)\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawTable<T> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        if !self.is_empty_singleton() {\n            unsafe {\n                if mem::needs_drop::<T>() && self.len() != 0 {\n                    for item in self.iter() {\n                        item.drop();\n                    }\n                }\n                self.free_buckets();\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::RawTable<T> as raw::RawTableClone>::clone_from_spec":["unsafe fn clone_from_spec(&mut self, source: &Self, on_panic: impl FnMut(&mut Self)){\n            self.clone_from_impl(source, on_panic);\n        }","Real(LocalPath(\"src/raw/mod.rs\"))"],"<raw::bitmask::BitMask as core::iter::IntoIterator>::into_iter":["#[inline]\nfn into_iter(self) -> BitMaskIter{\n        BitMaskIter(self)\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"<raw::bitmask::BitMaskIter as core::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<usize>{\n        let bit = self.0.lowest_set_bit()?;\n        self.0 = self.0.remove_lowest_bit();\n        Some(bit)\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref":["inline\nfn deref(&self) -> &T{\n        &self.value\n    }","Real(LocalPath(\"src/scopeguard.rs\"))"],"<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut":["inline\nfn deref_mut(&mut self) -> &mut T{\n        &mut self.value\n    }","Real(LocalPath(\"src/scopeguard.rs\"))"],"<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        (self.dropfn)(&mut self.value)\n    }","Real(LocalPath(\"src/scopeguard.rs\"))"],"<set::Difference<'_, T, S> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Difference {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Difference<'_, T, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Difference<'a, T, S> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a T>{\n        loop {\n            let elt = self.iter.next()?;\n            if !self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Difference<'a, T, S> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Drain<'_, K> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Drain<'_, K> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Drain<'_, K> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Drain<'_, K> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<Self::Item>{\n        let f = &mut self.f;\n        let (k, _) = self.inner.next(&mut |k, _| f(k))?;\n        Some(k)\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (0, self.inner.iter.size_hint().1)\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::DrainFilter<'a, K, F> as core::ops::Drop>::drop":["inline\nfn drop(&mut self){\n        while let Some(item) = self.next() {\n            let guard = ConsumeAllOnDrop(self);\n            drop(item);\n            mem::forget(guard);\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::clone::Clone>::clone":["fn clone(&self) -> Self{\n        HashSet {\n            map: self.map.clone(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::clone::Clone>::clone_from":["fn clone_from(&mut self, source: &Self){\n        self.map.clone_from(&source.map);\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::cmp::PartialEq>::eq":["fn eq(&self, other: &Self) -> bool{\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|key| other.contains(key))\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::default::Default>::default":["/// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher.\ninline\nfn default() -> Self{\n        Self {\n            map: HashMap::default(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_set().entries(self.iter()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend":["inline\nfn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I){\n        self.extend(iter.into_iter().cloned());\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::iter::Extend<T>>::extend":["inline\nfn extend<I: IntoIterator<Item = T>>(&mut self, iter: I){\n        self.map.extend(iter.into_iter().map(|k| (k, ())));\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter":["inline\nfn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self{\n        let mut set = Self::with_hasher(Default::default());\n        set.extend(iter);\n        set\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["/// Creates a consuming iterator, that is, one that moves each value out\n/// of the set in arbitrary order. The set cannot be used after calling\n/// this.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set = HashSet::new();\n/// set.insert(\"a\".to_string());\n/// set.insert(\"b\".to_string());\n///\n/// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n/// let v: Vec<String> = set.into_iter().collect();\n///\n/// // Will print in an arbitrary order.\n/// for x in &v {\n///     println!(\"{}\", x);\n/// }\n/// ```\ninline\nfn into_iter(self) -> IntoIter<T>{\n        IntoIter {\n            iter: self.map.into_iter(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Intersection<'_, T, S> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Intersection {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Intersection<'_, T, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a T>{\n        loop {\n            let elt = self.iter.next()?;\n            if self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::IntoIter<K> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::IntoIter<K> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::IntoIter<K> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::IntoIter<K> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Iter<'_, K> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Iter {\n            iter: self.iter.clone(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Iter<'_, K> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Iter<'a, K> as core::iter::ExactSizeIterator>::len":["inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Iter<'a, K> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a K>{\n        self.iter.next()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Iter<'a, K> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::SymmetricDifference<'_, T, S> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        SymmetricDifference {\n            iter: self.iter.clone(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::SymmetricDifference<'_, T, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a T>{\n        self.iter.next()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Union<'_, T, S> as core::clone::Clone>::clone":["inline\nfn clone(&self) -> Self{\n        Union {\n            iter: self.iter.clone(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Union<'_, T, S> as core::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Union<'a, T, S> as core::iter::Iterator>::next":["inline\nfn next(&mut self) -> Option<&'a T>{\n        self.iter.next()\n    }","Real(LocalPath(\"src/set.rs\"))"],"<set::Union<'a, T, S> as core::iter::Iterator>::size_hint":["inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }","Real(LocalPath(\"src/set.rs\"))"],"TryReserveError":["/// The error type for `try_reserve` methods.\npub enum TryReserveError {\n    /// Error due to the computed capacity exceeding the collection's maximum\n    /// (usually `isize::MAX` bytes).\n    CapacityOverflow,\n\n    /// The memory allocator returned an error\n    AllocError {\n        /// The layout of the allocation request that failed.\n        layout: alloc::alloc::Layout,\n    },\n}","Real(LocalPath(\"src/lib.rs\"))"],"map::ConsumeAllOnDrop":["pub(super) struct ConsumeAllOnDrop<'a, T: Iterator>(pub &'a mut T);","Real(LocalPath(\"src/map.rs\"))"],"map::Drain":["/// A draining iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`drain`]: struct.HashMap.html#method.drain\n/// [`HashMap`]: struct.HashMap.html\npub struct Drain<'a, K, V> {\n    inner: RawDrain<'a, (K, V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::Drain::<'_, K, V>::iter":["/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::DrainFilter":["/// A draining iterator over entries of a `HashMap` which don't satisfy the predicate `f`.\n///\n/// This `struct` is created by the [`drain_filter`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`drain_filter`]: struct.HashMap.html#method.drain_filter\n/// [`HashMap`]: struct.HashMap.html\npub struct DrainFilter<'a, K, V, F>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n{\n    f: F,\n    inner: DrainFilterInner<'a, K, V>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::DrainFilterInner":["/// Portions of `DrainFilter` shared with `set::DrainFilter`\npub(super) struct DrainFilterInner<'a, K, V> {\n    pub iter: RawIter<(K, V)>,\n    pub table: &'a mut RawTable<(K, V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::DrainFilterInner::<'_, K, V>::next":["inline\npub(super) fn next<F>(&mut self, f: &mut F) -> Option<(K, V)>\n    where\n        F: FnMut(&K, &mut V) -> bool,{\n        unsafe {\n            while let Some(item) = self.iter.next() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if f(key, value) {\n                    return Some(self.table.remove(item));\n                }\n            }\n        }\n        None\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry":["/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`HashMap`].\n///\n/// [`HashMap`]: struct.HashMap.html\n/// [`entry`]: struct.HashMap.html#method.entry\npub enum Entry<'a, K, V, S> {\n    /// An occupied entry.\n    Occupied(OccupiedEntry<'a, K, V, S>),\n\n    /// A vacant entry.\n    Vacant(VacantEntry<'a, K, V, S>),\n}","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::and_modify":["/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.entry(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 42);\n///\n/// map.entry(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 43);\n/// ```\ninline\npub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),{\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::and_replace_entry_with":["/// Provides shared access to the key and owned access to the value of\n/// an occupied entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| panic!());\n///\n/// match entry {\n///     Entry::Vacant(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///     }\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"poneyland\");\n///         assert_eq!(v, 42);\n///         Some(v + 1)\n///     });\n///\n/// match entry {\n///     Entry::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| None);\n///\n/// match entry {\n///     Entry::Vacant(e) => assert_eq!(e.key(), &\"poneyland\"),\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        match self {\n            Entry::Occupied(entry) => entry.replace_entry_with(f),\n            Entry::Vacant(_) => self,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::insert":["/// Sets the value of the entry, and returns an OccupiedEntry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let entry = map.entry(\"horseyland\").insert(37);\n///\n/// assert_eq!(entry.key(), &\"horseyland\");\n/// ```\ninline\npub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert_entry(value),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::key":["/// Returns a reference to this entry's key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n/// ```\ninline\npub fn key(&self) -> &K{\n        match *self {\n            Entry::Occupied(ref entry) => entry.key(),\n            Entry::Vacant(ref entry) => entry.key(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::or_default":["/// Ensures a value is in the entry by inserting the default value if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, Option<u32>> = HashMap::new();\n/// map.entry(\"poneyland\").or_default();\n///\n/// assert_eq!(map[\"poneyland\"], None);\n/// ```\ninline\npub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::or_insert":["/// Ensures a value is in the entry by inserting the default if empty, and returns\n/// a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.entry(\"poneyland\").or_insert(3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// *map.entry(\"poneyland\").or_insert(10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::or_insert_with":["/// Ensures a value is in the entry by inserting the result of the default function if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, String> = HashMap::new();\n/// let s = \"hoho\".to_string();\n///\n/// map.entry(\"poneyland\").or_insert_with(|| s);\n///\n/// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n/// ```\ninline\npub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Entry::<'a, K, V, S>::or_insert_with_key":["/// Ensures a value is in the entry by inserting, if empty, the result of the default function,\n/// which takes the key as its argument, and returns a mutable reference to the value in the\n/// entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, usize> = HashMap::new();\n///\n/// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n///\n/// assert_eq!(map[\"poneyland\"], 9);\n/// ```\ninline\npub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap":["/// A hash map implemented with quadratic probing and SIMD lookup.\n///\n/// The default hashing algorithm is currently [`AHash`], though this is\n/// subject to change at any point in the future. This hash function is very\n/// fast for all types of keys, but this algorithm will typically *not* protect\n/// against attacks such as HashDoS.\n///\n/// The hashing algorithm can be replaced on a per-`HashMap` basis using the\n/// [`default`], [`with_hasher`], and [`with_capacity_and_hasher`] methods. Many\n/// alternative algorithms are available on crates.io, such as the [`fnv`] crate.\n///\n/// It is required that the keys implement the [`Eq`] and [`Hash`] traits, although\n/// this can frequently be achieved by using `#[derive(PartialEq, Eq, Hash)]`.\n/// If you implement these yourself, it is important that the following\n/// property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n/// It is a logic error for a key to be modified in such a way that the key's\n/// hash, as determined by the [`Hash`] trait, or its equality, as determined by\n/// the [`Eq`] trait, changes while it is in the map. This is normally only\n/// possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n///\n/// It is also a logic error for the [`Hash`] implementation of a key to panic.\n/// This is generally only possible if the trait is implemented manually. If a\n/// panic does occur then the contents of the `HashMap` may become corrupted and\n/// some items may be dropped from the table.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<String, String>` in this example).\n/// let mut book_reviews = HashMap::new();\n///\n/// // Review some books.\n/// book_reviews.insert(\n///     \"Adventures of Huckleberry Finn\".to_string(),\n///     \"My favorite book.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Grimms' Fairy Tales\".to_string(),\n///     \"Masterpiece.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Pride and Prejudice\".to_string(),\n///     \"Very enjoyable.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"The Adventures of Sherlock Holmes\".to_string(),\n///     \"Eye lyked it alot.\".to_string(),\n/// );\n///\n/// // Check for a specific one.\n/// // When collections store owned values (String), they can still be\n/// // queried using references (&str).\n/// if !book_reviews.contains_key(\"Les Misérables\") {\n///     println!(\"We've got {} reviews, but Les Misérables ain't one.\",\n///              book_reviews.len());\n/// }\n///\n/// // oops, this review has a lot of spelling mistakes, let's delete it.\n/// book_reviews.remove(\"The Adventures of Sherlock Holmes\");\n///\n/// // Look up the values associated with some keys.\n/// let to_find = [\"Pride and Prejudice\", \"Alice's Adventure in Wonderland\"];\n/// for &book in &to_find {\n///     match book_reviews.get(book) {\n///         Some(review) => println!(\"{}: {}\", book, review),\n///         None => println!(\"{} is unreviewed.\", book)\n///     }\n/// }\n///\n/// // Look up the value for a key (will panic if the key is not found).\n/// println!(\"Review for Jane: {}\", book_reviews[\"Pride and Prejudice\"]);\n///\n/// // Iterate over everything.\n/// for (book, review) in &book_reviews {\n///     println!(\"{}: \\\"{}\\\"\", book, review);\n/// }\n/// ```\n///\n/// `HashMap` also implements an [`Entry API`](#method.entry), which allows\n/// for more complex methods of getting, setting, updating and removing keys and\n/// their values:\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// // type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<&str, u8>` in this example).\n/// let mut player_stats = HashMap::new();\n///\n/// fn random_stat_buff() -> u8 {\n///     // could actually return some random value here - let's just return\n///     // some fixed value for now\n///     42\n/// }\n///\n/// // insert a key only if it doesn't already exist\n/// player_stats.entry(\"health\").or_insert(100);\n///\n/// // insert a key using a function that provides a new value only if it\n/// // doesn't already exist\n/// player_stats.entry(\"defence\").or_insert_with(random_stat_buff);\n///\n/// // update a key, guarding against the key possibly not being set\n/// let stat = player_stats.entry(\"attack\").or_insert(100);\n/// *stat += random_stat_buff();\n/// ```\n///\n/// The easiest way to use `HashMap` with a custom key type is to derive [`Eq`] and [`Hash`].\n/// We must also derive [`PartialEq`].\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n/// [`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html\n/// [`RefCell`]: https://doc.rust-lang.org/std/cell/struct.RefCell.html\n/// [`Cell`]: https://doc.rust-lang.org/std/cell/struct.Cell.html\n/// [`default`]: #method.default\n/// [`with_hasher`]: #method.with_hasher\n/// [`with_capacity_and_hasher`]: #method.with_capacity_and_hasher\n/// [`fnv`]: https://crates.io/crates/fnv\n/// [`AHash`]: https://crates.io/crates/ahash\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     country: String,\n/// }\n///\n/// impl Viking {\n///     /// Creates a new Viking.\n///     fn new(name: &str, country: &str) -> Viking {\n///         Viking { name: name.to_string(), country: country.to_string() }\n///     }\n/// }\n///\n/// // Use a HashMap to store the vikings' health points.\n/// let mut vikings = HashMap::new();\n///\n/// vikings.insert(Viking::new(\"Einar\", \"Norway\"), 25);\n/// vikings.insert(Viking::new(\"Olaf\", \"Denmark\"), 24);\n/// vikings.insert(Viking::new(\"Harald\", \"Iceland\"), 12);\n///\n/// // Use derived implementation to print the status of the vikings.\n/// for (viking, health) in &vikings {\n///     println!(\"{:?} has {} hp\", viking, health);\n/// }\n/// ```\n///\n/// A `HashMap` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let timber_resources: HashMap<&str, i32> = [(\"Norway\", 100), (\"Denmark\", 50), (\"Iceland\", 10)]\n///     .iter().cloned().collect();\n/// // use the values stored in map\n/// ```\npub struct HashMap<K, V, S = DefaultHashBuilder> {\n    pub(crate) hash_builder: S,\n    pub(crate) table: RawTable<(K, V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::capacity":["/// Returns the number of elements the map can hold without reallocating.\n///\n/// This number is a lower bound; the `HashMap<K, V>` might be able to hold\n/// more, but is guaranteed to be able to hold at least this many.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// assert!(map.capacity() >= 100);\n/// ```\ninline\npub fn capacity(&self) -> usize{\n        self.table.capacity()\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::clear":["/// Clears the map, removing all key-value pairs. Keeps the allocated memory\n/// for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// a.insert(1, \"a\");\n/// a.clear();\n/// assert!(a.is_empty());\n/// ```\ninline\npub fn clear(&mut self){\n        self.table.clear();\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::contains_key":["/// Returns `true` if the map contains a value for the specified key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.contains_key(&1), true);\n/// assert_eq!(map.contains_key(&2), false);\n/// ```\ninline\npub fn contains_key<Q: ?Sized>(&self, k: &Q) -> bool\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        self.get_inner(k).is_some()\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::drain":["/// Clears the map, returning all key-value pairs as an iterator. Keeps the\n/// allocated memory for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// a.insert(1, \"a\");\n/// a.insert(2, \"b\");\n///\n/// for (k, v) in a.drain().take(1) {\n///     assert!(k == 1 || k == 2);\n///     assert!(v == \"a\" || v == \"b\");\n/// }\n///\n/// assert!(a.is_empty());\n/// ```\ninline\npub fn drain(&mut self) -> Drain<'_, K, V>{\n        Drain {\n            inner: self.table.drain(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::drain_filter":["/// Drains elements which are true under the given predicate,\n/// and returns an iterator over the removed items.\n///\n/// In other words, move all pairs `(k, v)` such that `f(&k,&mut v)` returns `true` out\n/// into another iterator.\n///\n/// When the returned DrainedFilter is dropped, any remaining elements that satisfy\n/// the predicate are dropped from the table.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n/// let drained: HashMap<i32, i32> = map.drain_filter(|k, _v| k % 2 == 0).collect();\n///\n/// let mut evens = drained.keys().cloned().collect::<Vec<_>>();\n/// let mut odds = map.keys().cloned().collect::<Vec<_>>();\n/// evens.sort();\n/// odds.sort();\n///\n/// assert_eq!(evens, vec![0, 2, 4, 6]);\n/// assert_eq!(odds, vec![1, 3, 5, 7]);\n/// ```\ninline\npub fn drain_filter<F>(&mut self, f: F) -> DrainFilter<'_, K, V, F>\n    where\n        F: FnMut(&K, &mut V) -> bool,{\n        DrainFilter {\n            f,\n            inner: DrainFilterInner {\n                iter: unsafe { self.table.iter() },\n                table: &mut self.table,\n            },\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::entry":["/// Gets the given key's corresponding entry in the map for in-place manipulation.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut letters = HashMap::new();\n///\n/// for ch in \"a short treatise on fungi\".chars() {\n///     let counter = letters.entry(ch).or_insert(0);\n///     *counter += 1;\n/// }\n///\n/// assert_eq!(letters[&'s'], 2);\n/// assert_eq!(letters[&'t'], 3);\n/// assert_eq!(letters[&'u'], 1);\n/// assert_eq!(letters.get(&'y'), None);\n/// ```\ninline\npub fn entry(&mut self, key: K) -> Entry<'_, K, V, S>{\n        let hash = make_hash(&self.hash_builder, &key);\n        if let Some(elem) = self.table.find(hash, |q| q.0.eq(&key)) {\n            Entry::Occupied(OccupiedEntry {\n                hash,\n                key: Some(key),\n                elem,\n                table: self,\n            })\n        } else {\n            Entry::Vacant(VacantEntry {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get":["/// Returns a reference to the value corresponding to the key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.get(&1), Some(&\"a\"));\n/// assert_eq!(map.get(&2), None);\n/// ```\n#[inline]\npub fn get<Q: ?Sized>(&self, k: &Q) -> Option<&V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some(&(_, ref v)) => Some(v),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get_inner":["#[inline]\nfn get_inner<Q: ?Sized>(&self, k: &Q) -> Option<&(K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        let hash = make_hash(&self.hash_builder, k);\n        self.table.get(hash, |x| k.eq(x.0.borrow()))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get_inner_mut":["#[inline]\nfn get_inner_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<&mut (K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        let hash = make_hash(&self.hash_builder, k);\n        self.table.get_mut(hash, |x| k.eq(x.0.borrow()))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get_key_value":["/// Returns the key-value pair corresponding to the supplied key.\n///\n/// The supplied key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n/// assert_eq!(map.get_key_value(&2), None);\n/// ```\n#[inline]\npub fn get_key_value<Q: ?Sized>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some(&(ref key, ref value)) => Some((key, value)),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get_key_value_mut":["/// Returns the key-value pair corresponding to the supplied key, with a mutable reference to value.\n///\n/// The supplied key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// let (k, v) = map.get_key_value_mut(&1).unwrap();\n/// assert_eq!(k, &1);\n/// assert_eq!(v, &mut \"a\");\n/// *v = \"b\";\n/// assert_eq!(map.get_key_value_mut(&1), Some((&1, &mut \"b\")));\n/// assert_eq!(map.get_key_value_mut(&2), None);\n/// ```\n#[inline]\npub fn get_key_value_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<(&K, &mut V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (ref key, ref mut value)) => Some((key, value)),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::get_mut":["/// Returns a mutable reference to the value corresponding to the key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// if let Some(x) = map.get_mut(&1) {\n///     *x = \"b\";\n/// }\n/// assert_eq!(map[&1], \"b\");\n/// ```\ninline\npub fn get_mut<Q: ?Sized>(&mut self, k: &Q) -> Option<&mut V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (_, ref mut v)) => Some(v),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::hasher":["/// Returns a reference to the map's [`BuildHasher`].\n///\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);\n/// let hasher: &DefaultHashBuilder = map.hasher();\n/// ```\ninline\npub fn hasher(&self) -> &S{\n        &self.hash_builder\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::insert":["/// Inserts a key-value pair into the map.\n///\n/// If the map did not have this key present, [`None`] is returned.\n///\n/// If the map did have this key present, the value is updated, and the old\n/// value is returned. The key is not updated, though; this matters for\n/// types that can be `==` without being identical. See the [module-level\n/// documentation] for more.\n///\n/// [`None`]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None\n/// [module-level documentation]: index.html#insert-and-complex-keys\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// assert_eq!(map.insert(37, \"a\"), None);\n/// assert_eq!(map.is_empty(), false);\n///\n/// map.insert(37, \"b\");\n/// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n/// assert_eq!(map[&37], \"c\");\n/// ```\ninline\npub fn insert(&mut self, k: K, v: V) -> Option<V>{\n        let hash = make_hash(&self.hash_builder, &k);\n        if let Some((_, item)) = self.table.get_mut(hash, |x| k.eq(&x.0)) {\n            Some(mem::replace(item, v))\n        } else {\n            let hash_builder = &self.hash_builder;\n            self.table\n                .insert(hash, (k, v), |x| make_hash(hash_builder, &x.0));\n            None\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::is_empty":["/// Returns `true` if the map contains no elements.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// assert!(a.is_empty());\n/// a.insert(1, \"a\");\n/// assert!(!a.is_empty());\n/// ```\ninline\npub fn is_empty(&self) -> bool{\n        self.len() == 0\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::iter":["/// An iterator visiting all key-value pairs in arbitrary order.\n/// The iterator element type is `(&'a K, &'a V)`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// for (key, val) in map.iter() {\n///     println!(\"key: {} val: {}\", key, val);\n/// }\n/// ```\ninline\npub fn iter(&self) -> Iter<'_, K, V>{\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            Iter {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::iter_mut":["/// An iterator visiting all key-value pairs in arbitrary order,\n/// with mutable references to the values.\n/// The iterator element type is `(&'a K, &'a mut V)`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// // Update all values\n/// for (_, val) in map.iter_mut() {\n///     *val *= 2;\n/// }\n///\n/// for (key, val) in &map {\n///     println!(\"key: {} val: {}\", key, val);\n/// }\n/// ```\ninline\npub fn iter_mut(&mut self) -> IterMut<'_, K, V>{\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            IterMut {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::keys":["/// An iterator visiting all keys in arbitrary order.\n/// The iterator element type is `&'a K`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// for key in map.keys() {\n///     println!(\"{}\", key);\n/// }\n/// ```\ninline\npub fn keys(&self) -> Keys<'_, K, V>{\n        Keys { inner: self.iter() }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::len":["/// Returns the number of elements in the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// assert_eq!(a.len(), 0);\n/// a.insert(1, \"a\");\n/// assert_eq!(a.len(), 1);\n/// ```\ninline\npub fn len(&self) -> usize{\n        self.table.len()\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::raw_entry":["/// Creates a raw immutable entry builder for the HashMap.\n///\n/// Raw entries provide the lowest level of control for searching and\n/// manipulating a map. They must be manually initialized with a hash and\n/// then manually searched.\n///\n/// This is useful for\n/// * Hash memoization\n/// * Using a search key that doesn't work with the Borrow trait\n/// * Using custom comparison logic without newtype wrappers\n///\n/// Unless you are in such a situation, higher-level and more foolproof APIs like\n/// `get` should be preferred.\n///\n/// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`.\ninline\npub fn raw_entry(&self) -> RawEntryBuilder<'_, K, V, S>{\n        RawEntryBuilder { map: self }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::raw_entry_mut":["/// Creates a raw entry builder for the HashMap.\n///\n/// Raw entries provide the lowest level of control for searching and\n/// manipulating a map. They must be manually initialized with a hash and\n/// then manually searched. After this, insertions into a vacant entry\n/// still require an owned key to be provided.\n///\n/// Raw entries are useful for such exotic situations as:\n///\n/// * Hash memoization\n/// * Deferring the creation of an owned key until it is known to be required\n/// * Using a search key that doesn't work with the Borrow trait\n/// * Using custom comparison logic without newtype wrappers\n///\n/// Because raw entries provide much more low-level control, it's much easier\n/// to put the HashMap into an inconsistent state which, while memory-safe,\n/// will cause the map to produce seemingly random results. Higher-level and\n/// more foolproof APIs like `entry` should be preferred when possible.\n///\n/// In particular, the hash used to initialized the raw entry must still be\n/// consistent with the hash of the key that is ultimately stored in the entry.\n/// This is because implementations of HashMap may need to recompute hashes\n/// when resizing, at which point only the keys are available.\n///\n/// Raw entries give mutable access to the keys. This must not be used\n/// to modify how the key would compare or hash, as the map will not re-evaluate\n/// where the key should go, meaning the keys may become \"lost\" if their\n/// location does not reflect their state. For instance, if you change a key\n/// so that the map now contains keys which compare equal, search may start\n/// acting erratically, with two keys randomly masking each other. Implementations\n/// are free to assume this doesn't happen (within the limits of memory-safety).\ninline\npub fn raw_entry_mut(&mut self) -> RawEntryBuilderMut<'_, K, V, S>{\n        RawEntryBuilderMut { map: self }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::remove":["/// Removes a key from the map, returning the value at the key if the key\n/// was previously in the map.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.remove(&1), Some(\"a\"));\n/// assert_eq!(map.remove(&1), None);\n/// ```\ninline\npub fn remove<Q: ?Sized>(&mut self, k: &Q) -> Option<V>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.remove_entry(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::remove_entry":["/// Removes a key from the map, returning the stored key and value if the\n/// key was previously in the map.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n/// assert_eq!(map.remove(&1), None);\n/// ```\ninline\npub fn remove_entry<Q: ?Sized>(&mut self, k: &Q) -> Option<(K, V)>\n    where\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        let hash = make_hash(&self.hash_builder, &k);\n        self.table.remove_entry(hash, |x| k.eq(x.0.borrow()))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::reserve":["/// Reserves capacity for at least `additional` more elements to be inserted\n/// in the `HashMap`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Panics\n///\n/// Panics if the new allocation size overflows [`usize`].\n///\n/// [`usize`]: https://doc.rust-lang.org/std/primitive.usize.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::new();\n/// map.reserve(10);\n/// ```\ninline\npub fn reserve(&mut self, additional: usize){\n        let hash_builder = &self.hash_builder;\n        self.table\n            .reserve(additional, |x| make_hash(hash_builder, &x.0));\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::retain":["/// Retains only the elements specified by the predicate.\n///\n/// In other words, remove all pairs `(k, v)` such that `f(&k,&mut v)` returns `false`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = (0..8).map(|x|(x, x*10)).collect();\n/// map.retain(|&k, _| k % 2 == 0);\n/// assert_eq!(map.len(), 4);\n/// ```\npub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&K, &mut V) -> bool,{\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.table.iter() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if !f(key, value) {\n                    self.table.erase(item);\n                }\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::shrink_to":["/// Shrinks the capacity of the map with a lower limit. It will drop\n/// down no lower than the supplied limit while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// This function does nothing if the current capacity is smaller than the\n/// supplied minimum capacity.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// map.insert(1, 2);\n/// map.insert(3, 4);\n/// assert!(map.capacity() >= 100);\n/// map.shrink_to(10);\n/// assert!(map.capacity() >= 10);\n/// map.shrink_to(0);\n/// assert!(map.capacity() >= 2);\n/// map.shrink_to(10);\n/// assert!(map.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to(&mut self, min_capacity: usize){\n        let hash_builder = &self.hash_builder;\n        self.table\n            .shrink_to(min_capacity, |x| make_hash(hash_builder, &x.0));\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::shrink_to_fit":["/// Shrinks the capacity of the map as much as possible. It will drop\n/// down as much as possible while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// map.insert(1, 2);\n/// map.insert(3, 4);\n/// assert!(map.capacity() >= 100);\n/// map.shrink_to_fit();\n/// assert!(map.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to_fit(&mut self){\n        let hash_builder = &self.hash_builder;\n        self.table.shrink_to(0, |x| make_hash(hash_builder, &x.0));\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::try_reserve":["/// Tries to reserve capacity for at least `additional` more elements to be inserted\n/// in the given `HashMap<K,V>`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Errors\n///\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, isize> = HashMap::new();\n/// map.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n/// ```\ninline\npub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError>{\n        let hash_builder = &self.hash_builder;\n        self.table\n            .try_reserve(additional, |x| make_hash(hash_builder, &x.0))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::values":["/// An iterator visiting all values in arbitrary order.\n/// The iterator element type is `&'a V`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// for val in map.values() {\n///     println!(\"{}\", val);\n/// }\n/// ```\ninline\npub fn values(&self) -> Values<'_, K, V>{\n        Values { inner: self.iter() }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::values_mut":["/// An iterator visiting all values mutably in arbitrary order.\n/// The iterator element type is `&'a mut V`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n///\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// for val in map.values_mut() {\n///     *val = *val + 10;\n/// }\n///\n/// for val in map.values() {\n///     println!(\"{}\", val);\n/// }\n/// ```\ninline\npub fn values_mut(&mut self) -> ValuesMut<'_, K, V>{\n        ValuesMut {\n            inner: self.iter_mut(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::with_capacity_and_hasher":["/// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n/// to hash the keys.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// Warning: `hash_builder` is normally randomly generated, and\n/// is designed to allow HashMaps to be resistant to attacks that\n/// cause many collisions and very poor performance. Setting it\n/// manually using this function can expose a DoS attack vector.\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the HashMap to be useful, see its documentation for details.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_capacity_and_hasher(10, s);\n/// map.insert(1, 2);\n/// ```\n///\n/// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\ninline\npub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity(capacity),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V, S>::with_hasher":["/// Creates an empty `HashMap` which will use the given hash builder to hash\n/// keys.\n///\n/// The created map has the default initial capacity.\n///\n/// Warning: `hash_builder` is normally randomly generated, and\n/// is designed to allow HashMaps to be resistant to attacks that\n/// cause many collisions and very poor performance. Setting it\n/// manually using this function can expose a DoS attack vector.\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the HashMap to be useful, see its documentation for details.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_hasher(s);\n/// map.insert(1, 2);\n/// ```\n///\n/// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\ninline\npub const fn with_hasher(hash_builder: S) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::new(),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V>::new":["/// Creates an empty `HashMap`.\n///\n/// The hash map is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::new();\n/// ```\ninline\npub fn new() -> Self{\n        Self::default()\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::HashMap::<K, V>::with_capacity":["/// Creates an empty `HashMap` with the specified capacity.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);\n/// ```\ninline\npub fn with_capacity(capacity: usize) -> Self{\n        Self::with_capacity_and_hasher(capacity, DefaultHashBuilder::default())\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::IntoIter":["/// An owning iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashMap`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`into_iter`]: struct.HashMap.html#method.into_iter\n/// [`HashMap`]: struct.HashMap.html\npub struct IntoIter<K, V> {\n    inner: RawIntoIter<(K, V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::IntoIter::<K, V>::iter":["/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Iter":["/// An iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter`]: struct.HashMap.html#method.iter\n/// [`HashMap`]: struct.HashMap.html\npub struct Iter<'a, K, V> {\n    inner: RawIter<(K, V)>,\n    marker: PhantomData<(&'a K, &'a V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::IterMut":["/// A mutable iterator over the entries of a `HashMap`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: struct.HashMap.html#method.iter_mut\n/// [`HashMap`]: struct.HashMap.html\npub struct IterMut<'a, K, V> {\n    inner: RawIter<(K, V)>,\n    // To ensure invariance with respect to V\n    marker: PhantomData<(&'a K, &'a mut V)>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::IterMut::<'_, K, V>::iter":["/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Keys":["/// An iterator over the keys of a `HashMap`.\n///\n/// This `struct` is created by the [`keys`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`keys`]: struct.HashMap.html#method.keys\n/// [`HashMap`]: struct.HashMap.html\npub struct Keys<'a, K, V> {\n    inner: Iter<'a, K, V>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry":["/// A view into an occupied entry in a `HashMap`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\npub struct OccupiedEntry<'a, K, V, S> {\n    hash: u64,\n    key: Option<K>,\n    elem: Bucket<(K, V)>,\n    table: &'a mut HashMap<K, V, S>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::get":["/// Gets a reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     assert_eq!(o.get(), &12);\n/// }\n/// ```\ninline\npub fn get(&self) -> &V{\n        unsafe { &self.elem.as_ref().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::get_mut":["/// Gets a mutable reference to the value in the entry.\n///\n/// If you need a reference to the `OccupiedEntry` which may outlive the\n/// destruction of the `Entry` value, see [`into_mut`].\n///\n/// [`into_mut`]: #method.into_mut\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// assert_eq!(map[\"poneyland\"], 12);\n/// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n///     *o.get_mut() += 10;\n///     assert_eq!(*o.get(), 22);\n///\n///     // We can use the same Entry multiple times.\n///     *o.get_mut() += 2;\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 24);\n/// ```\ninline\npub fn get_mut(&mut self) -> &mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::insert":["/// Sets the value of the entry, and returns the entry's old value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n///     assert_eq!(o.insert(15), 12);\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 15);\n/// ```\ninline\npub fn insert(&mut self, mut value: V) -> V{\n        let old_value = self.get_mut();\n        mem::swap(&mut value, old_value);\n        value\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::into_mut":["/// Converts the OccupiedEntry into a mutable reference to the value in the entry\n/// with a lifetime bound to the map itself.\n///\n/// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n///\n/// [`get_mut`]: #method.get_mut\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// assert_eq!(map[\"poneyland\"], 12);\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     *o.into_mut() += 10;\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 22);\n/// ```\ninline\npub fn into_mut(self) -> &'a mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::key":["/// Gets a reference to the key in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n/// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n/// ```\ninline\npub fn key(&self) -> &K{\n        unsafe { &self.elem.as_ref().0 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::remove":["/// Takes the value out of the entry, and returns it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     assert_eq!(o.remove(), 12);\n/// }\n///\n/// assert_eq!(map.contains_key(\"poneyland\"), false);\n/// ```\ninline\npub fn remove(self) -> V{\n        self.remove_entry().1\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::remove_entry":["/// Take the ownership of the key and value from the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     // We delete the entry from the map.\n///     o.remove_entry();\n/// }\n///\n/// assert_eq!(map.contains_key(\"poneyland\"), false);\n/// ```\ninline\npub fn remove_entry(self) -> (K, V){\n        unsafe { self.table.table.remove(self.elem) }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::replace_entry":["/// Replaces the entry, returning the old key and value. The new key in the hash map will be\n/// the key used to create this entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap};\n/// use std::rc::Rc;\n///\n/// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n/// map.insert(Rc::new(\"Stringthing\".to_string()), 15);\n///\n/// let my_key = Rc::new(\"Stringthing\".to_string());\n///\n/// if let Entry::Occupied(entry) = map.entry(my_key) {\n///     // Also replace the key with a handle to our other key.\n///     let (old_key, old_value): (Rc<String>, u32) = entry.replace_entry(16);\n/// }\n///\n/// ```\ninline\npub fn replace_entry(self, value: V) -> (K, V){\n        let entry = unsafe { self.elem.as_mut() };\n\n        let old_key = mem::replace(&mut entry.0, self.key.unwrap());\n        let old_value = mem::replace(&mut entry.1, value);\n\n        (old_key, old_value)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::replace_entry_with":["/// Provides shared access to the key and owned access to the value of\n/// the entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = match map.entry(\"poneyland\") {\n///     Entry::Occupied(e) => {\n///         e.replace_entry_with(|k, v| {\n///             assert_eq!(k, &\"poneyland\");\n///             assert_eq!(v, 42);\n///             Some(v + 1)\n///         })\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// };\n///\n/// match entry {\n///     Entry::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = match map.entry(\"poneyland\") {\n///     Entry::Occupied(e) => e.replace_entry_with(|_k, _v| None),\n///     Entry::Vacant(_) => panic!(),\n/// };\n///\n/// match entry {\n///     Entry::Vacant(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///     }\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn replace_entry_with<F>(self, f: F) -> Entry<'a, K, V, S>\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        unsafe {\n            let mut spare_key = None;\n\n            self.table\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    if let Some(new_value) = f(&key, value) {\n                        Some((key, new_value))\n                    } else {\n                        spare_key = Some(key);\n                        None\n                    }\n                });\n\n            if let Some(key) = spare_key {\n                Entry::Vacant(VacantEntry {\n                    hash: self.hash,\n                    key,\n                    table: self.table,\n                })\n            } else {\n                Entry::Occupied(self)\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::OccupiedEntry::<'a, K, V, S>::replace_key":["/// Replaces the key in the hash map with the key used to create this entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap};\n/// use std::rc::Rc;\n///\n/// let mut map: HashMap<Rc<String>, u32> = HashMap::new();\n/// let mut known_strings: Vec<Rc<String>> = Vec::new();\n///\n/// // Initialise known strings, run program, etc.\n///\n/// reclaim_memory(&mut map, &known_strings);\n///\n/// fn reclaim_memory(map: &mut HashMap<Rc<String>, u32>, known_strings: &[Rc<String>] ) {\n///     for s in known_strings {\n///         if let Entry::Occupied(entry) = map.entry(s.clone()) {\n///             // Replaces the entry's key with our version of it in `known_strings`.\n///             entry.replace_key();\n///         }\n///     }\n/// }\n/// ```\ninline\npub fn replace_key(self) -> K{\n        let entry = unsafe { self.elem.as_mut() };\n        mem::replace(&mut entry.0, self.key.unwrap())\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilder":["/// A builder for computing where in a [`HashMap`] a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry`] docs for usage examples.\n///\n/// [`HashMap::raw_entry`]: struct.HashMap.html#method.raw_entry\npub struct RawEntryBuilder<'a, K, V, S> {\n    map: &'a HashMap<K, V, S>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilder::<'a, K, V, S>::from_hash":["/// Access an entry by hash.\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_hash<F>(self, hash: u64, is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,{\n        self.search(hash, is_match)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilder::<'a, K, V, S>::from_key":["/// Access an entry by key.\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key<Q: ?Sized>(self, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        S: BuildHasher,\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        let mut hasher = self.map.hash_builder.build_hasher();\n        k.hash(&mut hasher);\n        self.from_key_hashed_nocheck(hasher.finish(), k)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilder::<'a, K, V, S>::from_key_hashed_nocheck":["/// Access an entry by a key and its hash.\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        K: Borrow<Q>,\n        Q: Eq,{\n        self.from_hash(hash, |q| q.borrow().eq(k))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilder::<'a, K, V, S>::search":["inline\nfn search<F>(self, hash: u64, mut is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,{\n        match self.map.table.get(hash, |(k, _)| is_match(k)) {\n            Some(&(ref key, ref value)) => Some((key, value)),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilderMut":["/// A builder for computing where in a [`HashMap`] a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry_mut`] docs for usage examples.\n///\n/// [`HashMap::raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mut\npub struct RawEntryBuilderMut<'a, K, V, S> {\n    map: &'a mut HashMap<K, V, S>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_hash":["/// Creates a `RawEntryMut` from the given hash.\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_hash<F>(self, hash: u64, is_match: F) -> RawEntryMut<'a, K, V, S>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,{\n        self.search(hash, is_match)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key":["/// Creates a `RawEntryMut` from the given key.\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key<Q: ?Sized>(self, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        S: BuildHasher,\n        K: Borrow<Q>,\n        Q: Hash + Eq,{\n        let mut hasher = self.map.hash_builder.build_hasher();\n        k.hash(&mut hasher);\n        self.from_key_hashed_nocheck(hasher.finish(), k)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key_hashed_nocheck":["/// Creates a `RawEntryMut` from the given key and its hash.\n#[inline]\n#[allow(clippy::wrong_self_convention)]\npub fn from_key_hashed_nocheck<Q: ?Sized>(self, hash: u64, k: &Q) -> RawEntryMut<'a, K, V, S>\n    where\n        K: Borrow<Q>,\n        Q: Eq,{\n        self.from_hash(hash, |q| q.borrow().eq(k))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryBuilderMut::<'a, K, V, S>::search":["inline\nfn search<F>(self, hash: u64, mut is_match: F) -> RawEntryMut<'a, K, V, S>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,{\n        match self.map.table.find(hash, |(k, _)| is_match(k)) {\n            Some(elem) => RawEntryMut::Occupied(RawOccupiedEntryMut {\n                elem,\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n            None => RawEntryMut::Vacant(RawVacantEntryMut {\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut":["/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This is a lower-level version of [`Entry`].\n///\n/// This `enum` is constructed through the [`raw_entry_mut`] method on [`HashMap`],\n/// then calling one of the methods of that [`RawEntryBuilderMut`].\n///\n/// [`HashMap`]: struct.HashMap.html\n/// [`Entry`]: enum.Entry.html\n/// [`raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mut\n/// [`RawEntryBuilderMut`]: struct.RawEntryBuilderMut.html\npub enum RawEntryMut<'a, K, V, S> {\n    /// An occupied entry.\n    Occupied(RawOccupiedEntryMut<'a, K, V, S>),\n    /// A vacant entry.\n    Vacant(RawVacantEntryMut<'a, K, V, S>),\n}","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut::<'a, K, V, S>::and_modify":["/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.raw_entry_mut()\n///    .from_key(\"poneyland\")\n///    .and_modify(|_k, v| { *v += 1 })\n///    .or_insert(\"poneyland\", 42);\n/// assert_eq!(map[\"poneyland\"], 42);\n///\n/// map.raw_entry_mut()\n///    .from_key(\"poneyland\")\n///    .and_modify(|_k, v| { *v += 1 })\n///    .or_insert(\"poneyland\", 0);\n/// assert_eq!(map[\"poneyland\"], 43);\n/// ```\ninline\npub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut K, &mut V),{\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                {\n                    let (k, v) = entry.get_key_value_mut();\n                    f(k, v);\n                }\n                RawEntryMut::Occupied(entry)\n            }\n            RawEntryMut::Vacant(entry) => RawEntryMut::Vacant(entry),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut::<'a, K, V, S>::and_replace_entry_with":["/// Provides shared access to the key and owned access to the value of\n/// an occupied entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::RawEntryMut;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| panic!());\n///\n/// match entry {\n///     RawEntryMut::Vacant(_) => {},\n///     RawEntryMut::Occupied(_) => panic!(),\n/// }\n///\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"poneyland\");\n///         assert_eq!(v, 42);\n///         Some(v + 1)\n///     });\n///\n/// match entry {\n///     RawEntryMut::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     },\n///     RawEntryMut::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| None);\n///\n/// match entry {\n///     RawEntryMut::Vacant(_) => {},\n///     RawEntryMut::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.replace_entry_with(f),\n            RawEntryMut::Vacant(_) => self,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut::<'a, K, V, S>::insert":["/// Sets the value of the entry, and returns a RawOccupiedEntryMut.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let entry = map.raw_entry_mut().from_key(\"horseyland\").insert(\"horseyland\", 37);\n///\n/// assert_eq!(entry.remove_entry(), (\"horseyland\", 37));\n/// ```\ninline\npub fn insert(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            RawEntryMut::Vacant(entry) => entry.insert_entry(key, value),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut::<'a, K, V, S>::or_insert":["/// Ensures a value is in the entry by inserting the default if empty, and returns\n/// mutable references to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// *map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 10).1 *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert(self, default_key: K, default_val: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => entry.insert(default_key, default_val),\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawEntryMut::<'a, K, V, S>::or_insert_with":["/// Ensures a value is in the entry by inserting the result of the default function if empty,\n/// and returns mutable references to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, String> = HashMap::new();\n///\n/// map.raw_entry_mut().from_key(\"poneyland\").or_insert_with(|| {\n///     (\"poneyland\", \"hoho\".to_string())\n/// });\n///\n/// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n/// ```\ninline\npub fn or_insert_with<F>(self, default: F) -> (&'a mut K, &'a mut V)\n    where\n        F: FnOnce() -> (K, V),\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => {\n                let (k, v) = default();\n                entry.insert(k, v)\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut":["/// A view into an occupied entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n///\n/// [`RawEntryMut`]: enum.RawEntryMut.html\npub struct RawOccupiedEntryMut<'a, K, V, S> {\n    elem: Bucket<(K, V)>,\n    table: &'a mut RawTable<(K, V)>,\n    hash_builder: &'a S,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get":["/// Gets a reference to the value in the entry.\ninline\npub fn get(&self) -> &V{\n        unsafe { &self.elem.as_ref().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value":["/// Gets a reference to the key and value in the entry.\ninline\npub fn get_key_value(&mut self) -> (&K, &V){\n        unsafe {\n            let &(ref key, ref value) = self.elem.as_ref();\n            (key, value)\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value_mut":["/// Gets a mutable reference to the key and value in the entry.\ninline\npub fn get_key_value_mut(&mut self) -> (&mut K, &mut V){\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_mut":["/// Gets a mutable reference to the value in the entry.\ninline\npub fn get_mut(&mut self) -> &mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert":["/// Sets the value of the entry, and returns the entry's old value.\ninline\npub fn insert(&mut self, value: V) -> V{\n        mem::replace(self.get_mut(), value)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert_key":["/// Sets the value of the entry, and returns the entry's old value.\ninline\npub fn insert_key(&mut self, key: K) -> K{\n        mem::replace(self.key_mut(), key)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key":["/// Converts the entry into a mutable reference to the key in the entry\n/// with a lifetime bound to the map itself.\ninline\npub fn into_key(self) -> &'a mut K{\n        unsafe { &mut self.elem.as_mut().0 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key_value":["/// Converts the OccupiedEntry into a mutable reference to the key and value in the entry\n/// with a lifetime bound to the map itself.\ninline\npub fn into_key_value(self) -> (&'a mut K, &'a mut V){\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_mut":["/// Converts the OccupiedEntry into a mutable reference to the value in the entry\n/// with a lifetime bound to the map itself.\ninline\npub fn into_mut(self) -> &'a mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::key":["/// Gets a reference to the key in the entry.\ninline\npub fn key(&self) -> &K{\n        unsafe { &self.elem.as_ref().0 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::key_mut":["/// Gets a mutable reference to the key in the entry.\ninline\npub fn key_mut(&mut self) -> &mut K{\n        unsafe { &mut self.elem.as_mut().0 }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove":["/// Takes the value out of the entry, and returns it.\ninline\npub fn remove(self) -> V{\n        self.remove_entry().1\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove_entry":["/// Take the ownership of the key and value from the map.\ninline\npub fn remove_entry(self) -> (K, V){\n        unsafe { self.table.remove(self.elem) }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawOccupiedEntryMut::<'a, K, V, S>::replace_entry_with":["/// Provides shared access to the key and owned access to the value of\n/// the entry and allows to replace or remove it based on the\n/// value of the returned option.\ninline\npub fn replace_entry_with<F>(self, f: F) -> RawEntryMut<'a, K, V, S>\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        unsafe {\n            let still_occupied = self\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    f(&key, value).map(|new_value| (key, new_value))\n                });\n\n            if still_occupied {\n                RawEntryMut::Occupied(self)\n            } else {\n                RawEntryMut::Vacant(RawVacantEntryMut {\n                    table: self.table,\n                    hash_builder: self.hash_builder,\n                })\n            }\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawVacantEntryMut":["/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n///\n/// [`RawEntryMut`]: enum.RawEntryMut.html\npub struct RawVacantEntryMut<'a, K, V, S> {\n    table: &'a mut RawTable<(K, V)>,\n    hash_builder: &'a S,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::RawVacantEntryMut::<'a, K, V, S>::insert":["/// Sets the value of the entry with the VacantEntry's key,\n/// and returns a mutable reference to it.\ninline\npub fn insert(self, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let mut hasher = self.hash_builder.build_hasher();\n        key.hash(&mut hasher);\n        self.insert_hashed_nocheck(hasher.finish(), key, value)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_entry":["inline\nfn insert_entry(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash_builder = self.hash_builder;\n        let mut hasher = self.hash_builder.build_hasher();\n        key.hash(&mut hasher);\n\n        let elem = self.table.insert(hasher.finish(), (key, value), |k| {\n            make_hash(hash_builder, &k.0)\n        });\n        RawOccupiedEntryMut {\n            elem,\n            table: self.table,\n            hash_builder: self.hash_builder,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_hashed_nocheck":["/// Sets the value of the entry with the VacantEntry's key,\n/// and returns a mutable reference to it.\ninline\n#[allow(clippy::shadow_unrelated)]\npub fn insert_hashed_nocheck(self, hash: u64, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash_builder = self.hash_builder;\n        self.insert_with_hasher(hash, key, value, |k| make_hash(hash_builder, k))\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::RawVacantEntryMut::<'a, K, V, S>::insert_with_hasher":["/// Set the value of an entry with a custom hasher function.\ninline\npub fn insert_with_hasher<H>(\n        self,\n        hash: u64,\n        key: K,\n        value: V,\n        hasher: H,\n    ) -> (&'a mut K, &'a mut V)\n    where\n        H: Fn(&K) -> u64,{\n        let &mut (ref mut k, ref mut v) = self\n            .table\n            .insert_entry(hash, (key, value), |x| hasher(&x.0));\n        (k, v)\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::VacantEntry":["/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\npub struct VacantEntry<'a, K, V, S> {\n    hash: u64,\n    key: K,\n    table: &'a mut HashMap<K, V, S>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::VacantEntry::<'a, K, V, S>::insert":["/// Sets the value of the entry with the VacantEntry's key,\n/// and returns a mutable reference to it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n///     o.insert(37);\n/// }\n/// assert_eq!(map[\"poneyland\"], 37);\n/// ```\ninline\npub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash_builder = &self.table.hash_builder;\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(self.hash, (self.key, value), |x| {\n            make_hash(hash_builder, &x.0)\n        });\n        &mut entry.1\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::VacantEntry::<'a, K, V, S>::insert_entry":["inline\nfn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash_builder = &self.table.hash_builder;\n        let elem = self.table.table.insert(self.hash, (self.key, value), |x| {\n            make_hash(hash_builder, &x.0)\n        });\n        OccupiedEntry {\n            hash: self.hash,\n            key: None,\n            elem,\n            table: self.table,\n        }\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::VacantEntry::<'a, K, V, S>::into_key":["/// Take ownership of the key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n///     v.into_key();\n/// }\n/// ```\ninline\npub fn into_key(self) -> K{\n        self.key\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::VacantEntry::<'a, K, V, S>::key":["/// Gets a reference to the key that would be used when inserting a value\n/// through the `VacantEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n/// ```\ninline\npub fn key(&self) -> &K{\n        &self.key\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::Values":["/// An iterator over the values of a `HashMap`.\n///\n/// This `struct` is created by the [`values`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values`]: struct.HashMap.html#method.values\n/// [`HashMap`]: struct.HashMap.html\npub struct Values<'a, K, V> {\n    inner: Iter<'a, K, V>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::ValuesMut":["/// A mutable iterator over the values of a `HashMap`.\n///\n/// This `struct` is created by the [`values_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values_mut`]: struct.HashMap.html#method.values_mut\n/// [`HashMap`]: struct.HashMap.html\npub struct ValuesMut<'a, K, V> {\n    inner: IterMut<'a, K, V>,\n}","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance":["#[allow(dead_code)]\nfn assert_covariance(){\n    fn map_key<'new>(v: HashMap<&'static str, u8>) -> HashMap<&'new str, u8> {\n        v\n    }\n    fn map_val<'new>(v: HashMap<u8, &'static str>) -> HashMap<u8, &'new str> {\n        v\n    }\n    fn iter_key<'a, 'new>(v: Iter<'a, &'static str, u8>) -> Iter<'a, &'new str, u8> {\n        v\n    }\n    fn iter_val<'a, 'new>(v: Iter<'a, u8, &'static str>) -> Iter<'a, u8, &'new str> {\n        v\n    }\n    fn into_iter_key<'new>(v: IntoIter<&'static str, u8>) -> IntoIter<&'new str, u8> {\n        v\n    }\n    fn into_iter_val<'new>(v: IntoIter<u8, &'static str>) -> IntoIter<u8, &'new str> {\n        v\n    }\n    fn keys_key<'a, 'new>(v: Keys<'a, &'static str, u8>) -> Keys<'a, &'new str, u8> {\n        v\n    }\n    fn keys_val<'a, 'new>(v: Keys<'a, u8, &'static str>) -> Keys<'a, u8, &'new str> {\n        v\n    }\n    fn values_key<'a, 'new>(v: Values<'a, &'static str, u8>) -> Values<'a, &'new str, u8> {\n        v\n    }\n    fn values_val<'a, 'new>(v: Values<'a, u8, &'static str>) -> Values<'a, u8, &'new str> {\n        v\n    }\n    fn drain<'new>(\n        d: Drain<'static, &'static str, &'static str>,\n    ) -> Drain<'new, &'new str, &'new str> {\n        d\n    }\n}","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::drain":["fn drain<'new>(\n        d: Drain<'static, &'static str, &'static str>,\n    ) -> Drain<'new, &'new str, &'new str>{\n        d\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::into_iter_key":["fn into_iter_key<'new>(v: IntoIter<&'static str, u8>) -> IntoIter<&'new str, u8>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::into_iter_val":["fn into_iter_val<'new>(v: IntoIter<u8, &'static str>) -> IntoIter<u8, &'new str>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::iter_key":["fn iter_key<'a, 'new>(v: Iter<'a, &'static str, u8>) -> Iter<'a, &'new str, u8>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::iter_val":["fn iter_val<'a, 'new>(v: Iter<'a, u8, &'static str>) -> Iter<'a, u8, &'new str>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::keys_key":["fn keys_key<'a, 'new>(v: Keys<'a, &'static str, u8>) -> Keys<'a, &'new str, u8>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::keys_val":["fn keys_val<'a, 'new>(v: Keys<'a, u8, &'static str>) -> Keys<'a, u8, &'new str>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::map_key":["fn map_key<'new>(v: HashMap<&'static str, u8>) -> HashMap<&'new str, u8>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::map_val":["fn map_val<'new>(v: HashMap<u8, &'static str>) -> HashMap<u8, &'new str>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::values_key":["fn values_key<'a, 'new>(v: Values<'a, &'static str, u8>) -> Values<'a, &'new str, u8>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::assert_covariance::values_val":["fn values_val<'a, 'new>(v: Values<'a, u8, &'static str>) -> Values<'a, u8, &'new str>{\n        v\n    }","Real(LocalPath(\"src/map.rs\"))"],"map::make_hash":["inline\npub(crate) fn make_hash<K: Hash + ?Sized>(hash_builder: &impl BuildHasher, val: &K) -> u64{\n    let mut state = hash_builder.build_hasher();\n    val.hash(&mut state);\n    state.finish()\n}","Real(LocalPath(\"src/map.rs\"))"],"raw::Bucket":["/// A reference to a hash table bucket containing a `T`.\n///\n/// This is usually just a pointer to the element itself. However if the element\n/// is a ZST, then we instead track the index of the element in the table so\n/// that `erase` works properly.\npub struct Bucket<T> {\n    // Actually it is pointer to next element than element itself\n    // this is needed to maintain pointer arithmetic invariants\n    // keeping direct pointer to element introduces difficulty.\n    // Using `NonNull` for variance and niche layout\n    ptr: NonNull<T>,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::as_mut":["inline\npub unsafe fn as_mut<'a>(&self) -> &'a mut T{\n        &mut *self.as_ptr()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::as_ptr":["inline\npub unsafe fn as_ptr(&self) -> *mut T{\n        if mem::size_of::<T>() == 0 {\n            // Just return an arbitrary ZST pointer which is properly aligned\n            mem::align_of::<T>() as *mut T\n        } else {\n            self.ptr.as_ptr().sub(1)\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::as_ref":["inline\npub unsafe fn as_ref<'a>(&self) -> &'a T{\n        &*self.as_ptr()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::copy_from_nonoverlapping":["inline\npub unsafe fn copy_from_nonoverlapping(&self, other: &Self){\n        self.as_ptr().copy_from_nonoverlapping(other.as_ptr(), 1);\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::drop":["inline\npub unsafe fn drop(&self){\n        self.as_ptr().drop_in_place();\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::from_base_index":["inline\nunsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self{\n        let ptr = if mem::size_of::<T>() == 0 {\n            // won't overflow because index must be less than length\n            (index + 1) as *mut T\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::next_n":["inline\nunsafe fn next_n(&self, offset: usize) -> Self{\n        let ptr = if mem::size_of::<T>() == 0 {\n            (self.ptr.as_ptr() as usize + offset) as *mut T\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::read":["inline\npub unsafe fn read(&self) -> T{\n        self.as_ptr().read()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::to_base_index":["inline\nunsafe fn to_base_index(&self, base: NonNull<T>) -> usize{\n        if mem::size_of::<T>() == 0 {\n            self.ptr.as_ptr() as usize - 1\n        } else {\n            offset_from(base.as_ptr(), self.ptr.as_ptr())\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Bucket::<T>::write":["inline\npub unsafe fn write(&self, val: T){\n        self.as_ptr().write(val);\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Fallibility":["/// Whether memory allocation errors should return an error or abort.\nenum Fallibility {\n    Fallible,\n    Infallible,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Fallibility::alloc_err":["/// Error to return on allocation error.\ninline\nfn alloc_err(self, layout: Layout) -> TryReserveError{\n        match self {\n            Fallibility::Fallible => TryReserveError::AllocError { layout },\n            Fallibility::Infallible => handle_alloc_error(layout),\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::Fallibility::capacity_overflow":["/// Error to return on capacity overflow.\ninline\nfn capacity_overflow(self) -> TryReserveError{\n        match self {\n            Fallibility::Fallible => TryReserveError::CapacityOverflow,\n            Fallibility::Infallible => panic!(\"Hash table capacity overflow\"),\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::ProbeSeq":["/// Probe sequence based on triangular numbers, which is guaranteed (since our\n/// table size is a power of two) to visit every group of elements exactly once.\n///\n/// A triangular probe has us jump by 1 more group every time. So first we\n/// jump by 1 group (meaning we just continue our linear scan), then 2 groups\n/// (skipping over 1 group), then 3 groups (skipping over 2 groups), and so on.\n///\n/// Proof that the probe will visit every group in the table:\n/// <https://fgiesen.wordpress.com/2015/02/22/triangular-numbers-mod-2n/>\nstruct ProbeSeq {\n    bucket_mask: usize,\n    pos: usize,\n    stride: usize,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawDrain":["/// Iterator which consumes elements without freeing the table storage.\npub struct RawDrain<'a, T> {\n    iter: RawIter<T>,\n\n    // The table is moved into the iterator for the duration of the drain. This\n    // ensures that an empty table is left if the drain iterator is leaked\n    // without dropping.\n    table: ManuallyDrop<RawTable<T>>,\n    orig_table: NonNull<RawTable<T>>,\n\n    // We don't use a &'a mut RawTable<T> because we want RawDrain to be\n    // covariant over T.\n    marker: PhantomData<&'a RawTable<T>>,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawDrain::<'_, T>::iter":["inline\npub fn iter(&self) -> RawIter<T>{\n        self.iter.clone()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIntoIter":["/// Iterator which consumes a table and returns elements.\npub struct RawIntoIter<T> {\n    iter: RawIter<T>,\n    alloc: Option<(NonNull<u8>, Layout)>,\n    marker: PhantomData<T>,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIntoIter::<T>::iter":["inline\npub fn iter(&self) -> RawIter<T>{\n        self.iter.clone()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIter":["/// Iterator which returns a raw pointer to every full bucket in the table.\n///\n/// For maximum flexibility this iterator is not bound by a lifetime, but you\n/// must observe several rules when using it:\n/// - You must not free the hash table while iterating (including via growing/shrinking).\n/// - It is fine to erase a bucket that has been yielded by the iterator.\n/// - Erasing a bucket that has not yet been yielded by the iterator may still\n///   result in the iterator yielding that bucket (unless `reflect_remove` is called).\n/// - It is unspecified whether an element inserted after the iterator was\n///   created will be yielded by that iterator (unless `reflect_insert` is called).\n/// - The order in which the iterator yields bucket is unspecified and may\n///   change in the future.\npub struct RawIter<T> {\n    pub(crate) iter: RawIterRange<T>,\n    items: usize,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIterHash":["/// Iterator over occupied buckets that could match a given hash.\n///\n/// In rare cases, the iterator may return a bucket with a different hash.\npub struct RawIterHash<'a, T> {\n    table: &'a RawTable<T>,\n\n    // The top 7 bits of the hash.\n    h2_hash: u8,\n\n    // The sequence of groups to probe in the search.\n    probe_seq: ProbeSeq,\n\n    // The current group and its position.\n    pos: usize,\n    group: Group,\n\n    // The elements within the group with a matching h2-hash.\n    bitmask: BitMaskIter,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIterHash::<'a, T>::new":["fn new(table: &'a RawTable<T>, hash: u64) -> Self{\n        unsafe {\n            let h2_hash = h2(hash);\n            let mut probe_seq = table.probe_seq(hash);\n            let pos = probe_seq.next().unwrap();\n            let group = Group::load(table.ctrl(pos));\n            let bitmask = group.match_byte(h2_hash).into_iter();\n\n            RawIterHash {\n                table,\n                h2_hash,\n                probe_seq,\n                pos,\n                group,\n                bitmask,\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIterRange":["/// Iterator over a sub-range of a table. Unlike `RawIter` this iterator does\n/// not track an item count.\npub(crate) struct RawIterRange<T> {\n    // Mask of full buckets in the current group. Bits are cleared from this\n    // mask as each element is processed.\n    current_group: BitMask,\n\n    // Pointer to the buckets for the current group.\n    data: Bucket<T>,\n\n    // Pointer to the next group of control bytes,\n    // Must be aligned to the group size.\n    next_ctrl: *const u8,\n\n    // Pointer one past the last control byte of this range.\n    end: *const u8,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawIterRange::<T>::new":["/// Returns a `RawIterRange` covering a subset of a table.\n///\n/// The control byte address must be aligned to the group size.\ninline\nunsafe fn new(ctrl: *const u8, data: Bucket<T>, len: usize) -> Self{\n        debug_assert_ne!(len, 0);\n        debug_assert_eq!(ctrl as usize % Group::WIDTH, 0);\n        let end = ctrl.add(len);\n\n        // Load the first group and advance ctrl to point to the next group\n        let current_group = Group::load_aligned(ctrl).match_full();\n        let next_ctrl = ctrl.add(Group::WIDTH);\n\n        Self {\n            current_group,\n            data,\n            next_ctrl,\n            end,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable":["/// A raw hash table with an unsafe API.\npub struct RawTable<T> {\n    // Mask to get an index from a hash value. The value is one less than the\n    // number of buckets in the table.\n    bucket_mask: usize,\n\n    // [Padding], T1, T2, ..., Tlast, C1, C2, ...\n    //                                ^ points here\n    ctrl: NonNull<u8>,\n\n    // Number of elements that can be inserted before we need to grow the table\n    growth_left: usize,\n\n    // Number of elements in the table, only really used by len()\n    items: usize,\n\n    // Tell dropck that we own instances of T.\n    marker: PhantomData<T>,\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::bucket":["/// Returns a pointer to an element in the table.\ninline\npub unsafe fn bucket(&self, index: usize) -> Bucket<T>{\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::bucket_index":["/// Returns the index of a bucket from a `Bucket`.\ninline\npub unsafe fn bucket_index(&self, bucket: &Bucket<T>) -> usize{\n        bucket.to_base_index(self.data_end())\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::buckets":["/// Returns the number of buckets in the table.\ninline\npub fn buckets(&self) -> usize{\n        self.bucket_mask + 1\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::capacity":["/// Returns the number of elements the map can hold without reallocating.\n///\n/// This number is a lower bound; the table might be able to hold\n/// more, but is guaranteed to be able to hold at least this many.\ninline\npub fn capacity(&self) -> usize{\n        self.items + self.growth_left\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::clear":["/// Removes all elements from the table without freeing the backing memory.\ninline\npub fn clear(&mut self){\n        // Ensure that the table is reset even if one of the drops panic\n        let self_ = guard(self, |self_| self_.clear_no_drop());\n\n        if mem::needs_drop::<T>() && self_.len() != 0 {\n            unsafe {\n                for item in self_.iter() {\n                    item.drop();\n                }\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::clear_no_drop":["/// Marks all table buckets as empty without dropping their contents.\ninline\npub fn clear_no_drop(&mut self){\n        if !self.is_empty_singleton() {\n            unsafe {\n                self.ctrl(0).write_bytes(EMPTY, self.num_ctrl_bytes());\n            }\n        }\n        self.items = 0;\n        self.growth_left = bucket_mask_to_capacity(self.bucket_mask);\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::clone_from_impl":["/// Common code for clone and clone_from. Assumes `self.buckets() == source.buckets()`.\ninline\nunsafe fn clone_from_impl(&mut self, source: &Self, mut on_panic: impl FnMut(&mut Self)){\n        // Copy the control bytes unchanged. We do this in a single pass\n        source\n            .ctrl(0)\n            .copy_to_nonoverlapping(self.ctrl(0), self.num_ctrl_bytes());\n\n        // The cloning of elements may panic, in which case we need\n        // to make sure we drop only the elements that have been\n        // cloned so far.\n        let mut guard = guard((0, &mut *self), |(index, self_)| {\n            if mem::needs_drop::<T>() && self_.len() != 0 {\n                for i in 0..=*index {\n                    if is_full(*self_.ctrl(i)) {\n                        self_.bucket(i).drop();\n                    }\n                }\n            }\n\n            // Depending on whether we were called from clone or clone_from, we\n            // either need to free the memory for the destination table or just\n            // clear the control bytes.\n            on_panic(self_);\n        });\n\n        for from in source.iter() {\n            let index = source.bucket_index(&from);\n            let to = guard.1.bucket(index);\n            to.write(from.as_ref().clone());\n\n            // Update the index in case we need to unwind.\n            guard.0 = index;\n        }\n\n        // Successfully cloned all items, no need to clean up.\n        mem::forget(guard);\n\n        self.items = source.items;\n        self.growth_left = source.growth_left;\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::ctrl":["/// Returns a pointer to a control byte.\ninline\nunsafe fn ctrl(&self, index: usize) -> *mut u8{\n        debug_assert!(index < self.num_ctrl_bytes());\n        self.ctrl.as_ptr().add(index)\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::data_end":["/// Returns pointer to one past last element of data table.\ninline\npub unsafe fn data_end(&self) -> NonNull<T>{\n        NonNull::new_unchecked(self.ctrl.as_ptr() as *mut T)\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::drain":["/// Returns an iterator which removes all elements from the table without\n/// freeing the memory.\ninline\npub fn drain(&mut self) -> RawDrain<'_, T>{\n        unsafe {\n            let iter = self.iter();\n            self.drain_iter_from(iter)\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::drain_iter_from":["/// Returns an iterator which removes all elements from the table without\n/// freeing the memory.\n///\n/// Iteration starts at the provided iterator's current location.\n///\n/// It is up to the caller to ensure that the iterator is valid for this\n/// `RawTable` and covers all items that remain in the table.\ninline\npub unsafe fn drain_iter_from(&mut self, iter: RawIter<T>) -> RawDrain<'_, T>{\n        debug_assert_eq!(iter.len(), self.len());\n        RawDrain {\n            iter,\n            table: ManuallyDrop::new(mem::replace(self, Self::new())),\n            orig_table: NonNull::from(self),\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::erase":["/// Erases an element from the table, dropping it in place.\ninline\n#[allow(clippy::needless_pass_by_value)]\n#[allow(deprecated)]\npub unsafe fn erase(&mut self, item: Bucket<T>){\n        // Erase the element from the table first since drop might panic.\n        self.erase_no_drop(&item);\n        item.drop();\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::erase_no_drop":["/// Erases an element from the table without dropping it.\ninline\n#[deprecated(since = \"0.8.1\", note = \"use erase or remove instead\")]\npub unsafe fn erase_no_drop(&mut self, item: &Bucket<T>){\n        let index = self.bucket_index(item);\n        debug_assert!(is_full(*self.ctrl(index)));\n        let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;\n        let empty_before = Group::load(self.ctrl(index_before)).match_empty();\n        let empty_after = Group::load(self.ctrl(index)).match_empty();\n\n        // If we are inside a continuous block of Group::WIDTH full or deleted\n        // cells then a probe window may have seen a full block when trying to\n        // insert. We therefore need to keep that block non-empty so that\n        // lookups will continue searching to the next probe window.\n        //\n        // Note that in this context `leading_zeros` refers to the bytes at the\n        // end of a group, while `trailing_zeros` refers to the bytes at the\n        // begining of a group.\n        let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {\n            DELETED\n        } else {\n            self.growth_left += 1;\n            EMPTY\n        };\n        self.set_ctrl(index, ctrl);\n        self.items -= 1;\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::fallible_with_capacity":["/// Attempts to allocate a new hash table with at least enough capacity\n/// for inserting the given number of elements without reallocating.\nfn fallible_with_capacity(\n        capacity: usize,\n        fallability: Fallibility,\n    ) -> Result<Self, TryReserveError>{\n        if capacity == 0 {\n            Ok(Self::new())\n        } else {\n            unsafe {\n                // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n                let buckets = match capacity_to_buckets(capacity) {\n                    Some(buckets) => buckets,\n                    None => return Err(fallability.capacity_overflow()),\n                };\n                let result = Self::new_uninitialized(buckets, fallability)?;\n                result.ctrl(0).write_bytes(EMPTY, result.num_ctrl_bytes());\n\n                Ok(result)\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::find":["/// Searches for an element in the table.\n#[inline]\npub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>>{\n        unsafe {\n            for bucket in self.iter_hash(hash) {\n                let elm = bucket.as_ref();\n                if likely(eq(elm)) {\n                    return Some(bucket);\n                }\n            }\n            None\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::find_insert_slot":["/// Searches for an empty or deleted bucket which is suitable for inserting\n/// a new element.\n///\n/// There must be at least 1 empty bucket in the table.\ninline\nfn find_insert_slot(&self, hash: u64) -> usize{\n        for pos in self.probe_seq(hash) {\n            unsafe {\n                let group = Group::load(self.ctrl(pos));\n                if let Some(bit) = group.match_empty_or_deleted().lowest_set_bit() {\n                    let result = (pos + bit) & self.bucket_mask;\n\n                    // In tables smaller than the group width, trailing control\n                    // bytes outside the range of the table are filled with\n                    // EMPTY entries. These will unfortunately trigger a\n                    // match, but once masked may point to a full bucket that\n                    // is already occupied. We detect this situation here and\n                    // perform a second scan starting at the begining of the\n                    // table. This second scan is guaranteed to find an empty\n                    // slot (due to the load factor) before hitting the trailing\n                    // control bytes (containing EMPTY).\n                    if unlikely(is_full(*self.ctrl(result))) {\n                        debug_assert!(self.bucket_mask < Group::WIDTH);\n                        debug_assert_ne!(pos, 0);\n                        return Group::load_aligned(self.ctrl(0))\n                            .match_empty_or_deleted()\n                            .lowest_set_bit_nonzero();\n                    } else {\n                        return result;\n                    }\n                }\n            }\n        }\n\n        // probe_seq never returns.\n        unreachable!();\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::free_buckets":["/// Deallocates the table without dropping any entries.\ninline\nunsafe fn free_buckets(&mut self){\n        // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match calculate_layout::<T>(self.buckets()) {\n            Some(lco) => lco,\n            None => hint::unreachable_unchecked(),\n        };\n        dealloc(self.ctrl.as_ptr().sub(ctrl_offset), layout);\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::get":["/// Gets a reference to an element in the table.\n#[inline]\npub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::get_mut":["/// Gets a mutable reference to an element in the table.\n#[inline]\npub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::insert":["/// Inserts a new element into the table, and returns its raw bucket.\n///\n/// This does not check if the given element already exists in the table.\ninline\npub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T>{\n        unsafe {\n            let mut index = self.find_insert_slot(hash);\n\n            // We can avoid growing the table once we have reached our load\n            // factor if we are replacing a tombstone. This works since the\n            // number of EMPTY slots does not change in this case.\n            let old_ctrl = *self.ctrl(index);\n            if unlikely(self.growth_left == 0 && special_is_empty(old_ctrl)) {\n                self.reserve(1, hasher);\n                index = self.find_insert_slot(hash);\n            }\n\n            let bucket = self.bucket(index);\n            self.growth_left -= special_is_empty(old_ctrl) as usize;\n            self.set_ctrl(index, h2(hash));\n            bucket.write(value);\n            self.items += 1;\n            bucket\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::insert_entry":["/// Inserts a new element into the table, and returns a mutable reference to it.\n///\n/// This does not check if the given element already exists in the table.\ninline\npub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T{\n        unsafe { self.insert(hash, value, hasher).as_mut() }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::into_alloc":["/// Converts the table into a raw allocation. The contents of the table\n/// should be dropped using a `RawIter` before freeing the allocation.\ninline\npub(crate) fn into_alloc(self) -> Option<(NonNull<u8>, Layout)>{\n        let alloc = if self.is_empty_singleton() {\n            None\n        } else {\n            // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n            let (layout, ctrl_offset) = match calculate_layout::<T>(self.buckets()) {\n                Some(lco) => lco,\n                None => unsafe { hint::unreachable_unchecked() },\n            };\n            Some((\n                unsafe { NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)) },\n                layout,\n            ))\n        };\n        mem::forget(self);\n        alloc\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::into_iter_from":["/// Returns an iterator which consumes all elements from the table.\n///\n/// Iteration starts at the provided iterator's current location.\n///\n/// It is up to the caller to ensure that the iterator is valid for this\n/// `RawTable` and covers all items that remain in the table.\npub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T>{\n        debug_assert_eq!(iter.len(), self.len());\n\n        let alloc = self.into_alloc();\n        RawIntoIter {\n            iter,\n            alloc,\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::is_empty_singleton":["/// Returns whether this table points to the empty singleton with a capacity\n/// of 0.\ninline\nfn is_empty_singleton(&self) -> bool{\n        self.bucket_mask == 0\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::iter":["/// Returns an iterator over every element in the table. It is up to\n/// the caller to ensure that the `RawTable` outlives the `RawIter`.\n/// Because we cannot make the `next` method unsafe on the `RawIter`\n/// struct, we have to make the `iter` method unsafe.\ninline\npub unsafe fn iter(&self) -> RawIter<T>{\n        let data = Bucket::from_base_index(self.data_end(), 0);\n        RawIter {\n            iter: RawIterRange::new(self.ctrl.as_ptr(), data, self.buckets()),\n            items: self.items,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::iter_hash":["/// Returns an iterator over occupied buckets that could match a given hash.\n///\n/// In rare cases, the iterator may return a bucket with a different hash.\n///\n/// It is up to the caller to ensure that the `RawTable` outlives the\n/// `RawIterHash`. Because we cannot make the `next` method unsafe on the\n/// `RawIterHash` struct, we have to make the `iter_hash` method unsafe.\ninline\npub unsafe fn iter_hash(&self, hash: u64) -> RawIterHash<'_, T>{\n        RawIterHash::new(self, hash)\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::len":["/// Returns the number of elements in the table.\ninline\npub fn len(&self) -> usize{\n        self.items\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::new":["/// Creates a new empty hash table without allocating any memory.\n///\n/// In effect this returns a table with exactly 1 bucket. However we can\n/// leave the data pointer dangling since that bucket is never written to\n/// due to our load factor forcing us to always have at least 1 free bucket.\ninline\npub const fn new() -> Self{\n        Self {\n            // Be careful to cast the entire slice to a raw pointer.\n            ctrl: unsafe { NonNull::new_unchecked(Group::static_empty() as *const _ as *mut u8) },\n            bucket_mask: 0,\n            items: 0,\n            growth_left: 0,\n            marker: PhantomData,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::new_uninitialized":["/// Allocates a new hash table with the given number of buckets.\n///\n/// The control bytes are left uninitialized.\ninline\nunsafe fn new_uninitialized(\n        buckets: usize,\n        fallability: Fallibility,\n    ) -> Result<Self, TryReserveError>{\n        debug_assert!(buckets.is_power_of_two());\n\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match calculate_layout::<T>(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallability.capacity_overflow()),\n        };\n        let ptr = match NonNull::new(alloc(layout)) {\n            Some(ptr) => ptr,\n            None => return Err(fallability.alloc_err(layout)),\n        };\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n            marker: PhantomData,\n        })\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::num_ctrl_bytes":["/// Returns the number of control bytes in the table.\ninline\nfn num_ctrl_bytes(&self) -> usize{\n        self.bucket_mask + 1 + Group::WIDTH\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::probe_seq":["/// Returns an iterator for a probe sequence on the table.\n///\n/// This iterator never terminates, but is guaranteed to visit each bucket\n/// group exactly once. The loop using `probe_seq` must terminate upon\n/// reaching a group containing an empty bucket.\ninline\nfn probe_seq(&self, hash: u64) -> ProbeSeq{\n        ProbeSeq {\n            bucket_mask: self.bucket_mask,\n            pos: h1(hash) & self.bucket_mask,\n            stride: 0,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::rehash_in_place":["/// Rehashes the contents of the table in place (i.e. without changing the\n/// allocation).\n///\n/// If `hasher` panics then some the table's contents may be lost.\nfn rehash_in_place(&mut self, hasher: impl Fn(&T) -> u64){\n        unsafe {\n            // Bulk convert all full control bytes to DELETED, and all DELETED\n            // control bytes to EMPTY. This effectively frees up all buckets\n            // containing a DELETED entry.\n            for i in (0..self.buckets()).step_by(Group::WIDTH) {\n                let group = Group::load_aligned(self.ctrl(i));\n                let group = group.convert_special_to_empty_and_full_to_deleted();\n                group.store_aligned(self.ctrl(i));\n            }\n\n            // Fix up the trailing control bytes. See the comments in set_ctrl\n            // for the handling of tables smaller than the group width.\n            if self.buckets() < Group::WIDTH {\n                self.ctrl(0)\n                    .copy_to(self.ctrl(Group::WIDTH), self.buckets());\n            } else {\n                self.ctrl(0)\n                    .copy_to(self.ctrl(self.buckets()), Group::WIDTH);\n            }\n\n            // If the hash function panics then properly clean up any elements\n            // that we haven't rehashed yet. We unfortunately can't preserve the\n            // element since we lost their hash and have no way of recovering it\n            // without risking another panic.\n            let mut guard = guard(self, |self_| {\n                if mem::needs_drop::<T>() {\n                    for i in 0..self_.buckets() {\n                        if *self_.ctrl(i) == DELETED {\n                            self_.set_ctrl(i, EMPTY);\n                            self_.bucket(i).drop();\n                            self_.items -= 1;\n                        }\n                    }\n                }\n                self_.growth_left = bucket_mask_to_capacity(self_.bucket_mask) - self_.items;\n            });\n\n            // At this point, DELETED elements are elements that we haven't\n            // rehashed yet. Find them and re-insert them at their ideal\n            // position.\n            'outer: for i in 0..guard.buckets() {\n                if *guard.ctrl(i) != DELETED {\n                    continue;\n                }\n                'inner: loop {\n                    // Hash the current item\n                    let item = guard.bucket(i);\n                    let hash = hasher(item.as_ref());\n\n                    // Search for a suitable place to put it\n                    let new_i = guard.find_insert_slot(hash);\n\n                    // Probing works by scanning through all of the control\n                    // bytes in groups, which may not be aligned to the group\n                    // size. If both the new and old position fall within the\n                    // same unaligned group, then there is no benefit in moving\n                    // it and we can just continue to the next item.\n                    let probe_index = |pos: usize| {\n                        (pos.wrapping_sub(guard.probe_seq(hash).pos) & guard.bucket_mask)\n                            / Group::WIDTH\n                    };\n                    if likely(probe_index(i) == probe_index(new_i)) {\n                        guard.set_ctrl(i, h2(hash));\n                        continue 'outer;\n                    }\n\n                    // We are moving the current item to a new position. Write\n                    // our H2 to the control byte of the new position.\n                    let prev_ctrl = *guard.ctrl(new_i);\n                    guard.set_ctrl(new_i, h2(hash));\n\n                    if prev_ctrl == EMPTY {\n                        // If the target slot is empty, simply move the current\n                        // element into the new slot and clear the old control\n                        // byte.\n                        guard.set_ctrl(i, EMPTY);\n                        guard.bucket(new_i).copy_from_nonoverlapping(&item);\n                        continue 'outer;\n                    } else {\n                        // If the target slot is occupied, swap the two elements\n                        // and then continue processing the element that we just\n                        // swapped into the old slot.\n                        debug_assert_eq!(prev_ctrl, DELETED);\n                        mem::swap(guard.bucket(new_i).as_mut(), item.as_mut());\n                        continue 'inner;\n                    }\n                }\n            }\n\n            guard.growth_left = bucket_mask_to_capacity(guard.bucket_mask) - guard.items;\n            mem::forget(guard);\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::remove":["/// Removes an element from the table, returning it.\ninline\n#[allow(clippy::needless_pass_by_value)]\n#[allow(deprecated)]\npub unsafe fn remove(&mut self, item: Bucket<T>) -> T{\n        self.erase_no_drop(&item);\n        item.read()\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::remove_entry":["/// Finds and removes an element from the table, returning it.\ninline\npub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { self.remove(bucket) }),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::replace_bucket_with":["/// Temporary removes a bucket, applying the given function to the removed\n/// element and optionally put back the returned value in the same bucket.\n///\n/// Returns `true` if the bucket still contains an element\n///\n/// This does not check if the given bucket is actually occupied.\ninline\npub unsafe fn replace_bucket_with<F>(&mut self, bucket: Bucket<T>, f: F) -> bool\n    where\n        F: FnOnce(T) -> Option<T>,{\n        let index = self.bucket_index(&bucket);\n        let old_ctrl = *self.ctrl(index);\n        debug_assert!(is_full(old_ctrl));\n        let old_growth_left = self.growth_left;\n        let item = self.remove(bucket);\n        if let Some(new_item) = f(item) {\n            self.growth_left = old_growth_left;\n            self.set_ctrl(index, old_ctrl);\n            self.items += 1;\n            self.bucket(index).write(new_item);\n            true\n        } else {\n            false\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::reserve":["/// Ensures that at least `additional` items can be inserted into the table\n/// without reallocation.\ninline\npub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64){\n        if additional > self.growth_left {\n            // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n            if self\n                .reserve_rehash(additional, hasher, Fallibility::Infallible)\n                .is_err()\n            {\n                unsafe { hint::unreachable_unchecked() }\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::reserve_rehash":["/// Out-of-line slow path for `reserve` and `try_reserve`.\n#[cold]\n#[inline(never)]\nfn reserve_rehash(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallability: Fallibility,\n    ) -> Result<(), TryReserveError>{\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let new_items = match self.items.checked_add(additional) {\n            Some(new_items) => new_items,\n            None => return Err(fallability.capacity_overflow()),\n        };\n        let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n        if new_items <= full_capacity / 2 {\n            // Rehash in-place without re-allocating if we have plenty of spare\n            // capacity that is locked up due to DELETED entries.\n            self.rehash_in_place(hasher);\n            Ok(())\n        } else {\n            // Otherwise, conservatively resize to at least the next size up\n            // to avoid churning deletes into frequent rehashes.\n            self.resize(\n                usize::max(new_items, full_capacity + 1),\n                hasher,\n                fallability,\n            )\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::resize":["/// Allocates a new table of a different size and moves the contents of the\n/// current table into it.\nfn resize(\n        &mut self,\n        capacity: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallability: Fallibility,\n    ) -> Result<(), TryReserveError>{\n        unsafe {\n            debug_assert!(self.items <= capacity);\n\n            // Allocate and initialize the new table.\n            let mut new_table = Self::fallible_with_capacity(capacity, fallability)?;\n            new_table.growth_left -= self.items;\n            new_table.items = self.items;\n\n            // The hash function may panic, in which case we simply free the new\n            // table without dropping any elements that may have been copied into\n            // it.\n            //\n            // This guard is also used to free the old table on success, see\n            // the comment at the bottom of this function.\n            let mut new_table = guard(ManuallyDrop::new(new_table), |new_table| {\n                if !new_table.is_empty_singleton() {\n                    new_table.free_buckets();\n                }\n            });\n\n            // Copy all elements to the new table.\n            for item in self.iter() {\n                // This may panic.\n                let hash = hasher(item.as_ref());\n\n                // We can use a simpler version of insert() here since:\n                // - there are no DELETED entries.\n                // - we know there is enough space in the table.\n                // - all elements are unique.\n                let index = new_table.find_insert_slot(hash);\n                new_table.set_ctrl(index, h2(hash));\n                new_table.bucket(index).copy_from_nonoverlapping(&item);\n            }\n\n            // We successfully copied all elements without panicking. Now replace\n            // self with the new table. The old table will have its memory freed but\n            // the items will not be dropped (since they have been moved into the\n            // new table).\n            mem::swap(self, &mut new_table);\n\n            Ok(())\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::set_ctrl":["/// Sets a control byte, and possibly also the replicated control byte at\n/// the end of the array.\ninline\nunsafe fn set_ctrl(&self, index: usize, ctrl: u8){\n        // Replicate the first Group::WIDTH control bytes at the end of\n        // the array without using a branch:\n        // - If index >= Group::WIDTH then index == index2.\n        // - Otherwise index2 == self.bucket_mask + 1 + index.\n        //\n        // The very last replicated control byte is never actually read because\n        // we mask the initial index for unaligned loads, but we write it\n        // anyways because it makes the set_ctrl implementation simpler.\n        //\n        // If there are fewer buckets than Group::WIDTH then this code will\n        // replicate the buckets at the end of the trailing group. For example\n        // with 2 buckets and a group size of 4, the control bytes will look\n        // like this:\n        //\n        //     Real    |             Replicated\n        // ---------------------------------------------\n        // | [A] | [B] | [EMPTY] | [EMPTY] | [A] | [B] |\n        // ---------------------------------------------\n        let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;\n\n        *self.ctrl(index) = ctrl;\n        *self.ctrl(index2) = ctrl;\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::shrink_to":["/// Shrinks the table to fit `max(self.len(), min_size)` elements.\ninline\npub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64){\n        // Calculate the minimal number of elements that we need to reserve\n        // space for.\n        let min_size = usize::max(self.items, min_size);\n        if min_size == 0 {\n            *self = Self::new();\n            return;\n        }\n\n        // Calculate the number of buckets that we need for this number of\n        // elements. If the calculation overflows then the requested bucket\n        // count must be larger than what we have right and nothing needs to be\n        // done.\n        let min_buckets = match capacity_to_buckets(min_size) {\n            Some(buckets) => buckets,\n            None => return,\n        };\n\n        // If we have more buckets than we need, shrink the table.\n        if min_buckets < self.buckets() {\n            // Fast path if the table is empty\n            if self.items == 0 {\n                *self = Self::with_capacity(min_size)\n            } else {\n                // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                if self\n                    .resize(min_size, hasher, Fallibility::Infallible)\n                    .is_err()\n                {\n                    unsafe { hint::unreachable_unchecked() }\n                }\n            }\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::try_reserve":["/// Tries to ensure that at least `additional` items can be inserted into\n/// the table without reallocation.\ninline\npub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError>{\n        if additional > self.growth_left {\n            self.reserve_rehash(additional, hasher, Fallibility::Fallible)\n        } else {\n            Ok(())\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTable::<T>::with_capacity":["/// Allocates a new hash table with at least enough capacity for inserting\n/// the given number of elements without reallocating.\npub fn with_capacity(capacity: usize) -> Self{\n        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n        match Self::fallible_with_capacity(capacity, Fallibility::Infallible) {\n            Ok(capacity) => capacity,\n            Err(_) => unsafe { hint::unreachable_unchecked() },\n        }\n    }","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::RawTableClone":["/// Specialization of `clone_from` for `Copy` types\ntrait RawTableClone {\n    unsafe fn clone_from_spec(&mut self, source: &Self, on_panic: impl FnMut(&mut Self));\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::bitmask::BitMask":["/// A bit mask which contains the result of a `Match` operation on a `Group` and\n/// allows iterating through them.\n///\n/// The bit mask is arranged so that low-order bits represent lower memory\n/// addresses for group match results.\n///\n/// For implementation reasons, the bits in the set may be sparsely packed, so\n/// that there is only one bit-per-byte used (the high bit, 7). If this is the\n/// case, `BITMASK_STRIDE` will be 8 to indicate a divide-by-8 should be\n/// performed on counts/indices to normalize this difference. `BITMASK_MASK` is\n/// similarly a mask of all the actually-used bits.\npub struct BitMask(pub BitMaskWord);","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::any_bit_set":["/// Returns whether the `BitMask` has at least one set bit.\n#[inline]\npub fn any_bit_set(self) -> bool{\n        self.0 != 0\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::invert":["/// Returns a new `BitMask` with all bits inverted.\n#[inline]\n#[must_use]\npub fn invert(self) -> Self{\n        BitMask(self.0 ^ BITMASK_MASK)\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::leading_zeros":["/// Returns the number of leading zeroes in the `BitMask`.\n#[inline]\npub fn leading_zeros(self) -> usize{\n        self.0.leading_zeros() as usize / BITMASK_STRIDE\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::lowest_set_bit":["/// Returns the first set bit in the `BitMask`, if there is one.\n#[inline]\npub fn lowest_set_bit(self) -> Option<usize>{\n        if self.0 == 0 {\n            None\n        } else {\n            Some(unsafe { self.lowest_set_bit_nonzero() })\n        }\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::lowest_set_bit_nonzero":["#[inline]\n#[cfg(not(feature = \"nightly\"))]\npub unsafe fn lowest_set_bit_nonzero(self) -> usize{\n        self.trailing_zeros()\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::remove_lowest_bit":["/// Returns a new `BitMask` with the lowest bit removed.\n#[inline]\n#[must_use]\npub fn remove_lowest_bit(self) -> Self{\n        BitMask(self.0 & (self.0 - 1))\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMask::trailing_zeros":["/// Returns the number of trailing zeroes in the `BitMask`.\n#[inline]\npub fn trailing_zeros(self) -> usize{\n        // ARM doesn't have a trailing_zeroes instruction, and instead uses\n        // reverse_bits (RBIT) + leading_zeroes (CLZ). However older ARM\n        // versions (pre-ARMv7) don't have RBIT and need to emulate it\n        // instead. Since we only have 1 bit set in each byte on ARM, we can\n        // use swap_bytes (REV) + leading_zeroes instead.\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            self.0.swap_bytes().leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            self.0.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bitmask::BitMaskIter":["/// Iterator over the contents of a `BitMask`, returning the indicies of set\n/// bits.\npub struct BitMaskIter(BitMask);","Real(LocalPath(\"src/raw/bitmask.rs\"))"],"raw::bucket_mask_to_capacity":["/// Returns the maximum effective capacity for the given bucket mask, taking\n/// the maximum load factor into account.\n#[inline]\nfn bucket_mask_to_capacity(bucket_mask: usize) -> usize{\n    if bucket_mask < 8 {\n        // For tables with 1/2/4/8 buckets, we always reserve one empty slot.\n        // Keep in mind that the bucket mask is one less than the bucket count.\n        bucket_mask\n    } else {\n        // For larger tables we reserve 12.5% of the slots as empty.\n        ((bucket_mask + 1) / 8) * 7\n    }\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::calculate_layout":["/// Returns a Layout which describes the allocation required for a hash table,\n/// and the offset of the control bytes in the allocation.\n/// (the offset is also one past last element of buckets)\n///\n/// Returns `None` if an overflow occurs.\ninline\n#[cfg(not(feature = \"nightly\"))]\nfn calculate_layout<T>(buckets: usize) -> Option<(Layout, usize)>{\n    debug_assert!(buckets.is_power_of_two());\n\n    // Manual layout calculation since Layout methods are not yet stable.\n    let ctrl_align = usize::max(mem::align_of::<T>(), Group::WIDTH);\n    let ctrl_offset = mem::size_of::<T>()\n        .checked_mul(buckets)?\n        .checked_add(ctrl_align - 1)?\n        & !(ctrl_align - 1);\n    let len = ctrl_offset.checked_add(buckets + Group::WIDTH)?;\n\n    Some((\n        unsafe { Layout::from_size_align_unchecked(len, ctrl_align) },\n        ctrl_offset,\n    ))\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::capacity_to_buckets":["/// Returns the number of buckets needed to hold the given number of items,\n/// taking the maximum load factor into account.\n///\n/// Returns `None` if an overflow occurs.\ninline\nfn capacity_to_buckets(cap: usize) -> Option<usize>{\n    debug_assert_ne!(cap, 0);\n\n    // For small tables we require at least 1 empty bucket so that lookups are\n    // guaranteed to terminate if an element doesn't exist in the table.\n    if cap < 8 {\n        // We don't bother with a table size of 2 buckets since that can only\n        // hold a single element. Instead we skip directly to a 4 bucket table\n        // which can hold 3 elements.\n        return Some(if cap < 4 { 4 } else { 8 });\n    }\n\n    // Otherwise require 1/8 buckets to be empty (87.5% load)\n    //\n    // Be careful when modifying this, calculate_layout relies on the\n    // overflow check here.\n    let adjusted_cap = cap.checked_mul(8)? / 7;\n\n    // Any overflows will have been caught by the checked_mul. Also, any\n    // rounding errors from the division above will be cleaned up by\n    // next_power_of_two (which can't overflow because of the previous divison).\n    Some(adjusted_cap.next_power_of_two())\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::h1":["/// Primary hash function, used to select the initial bucket to probe from.\n#[inline]\n#[allow(clippy::cast_possible_truncation)]\nfn h1(hash: u64) -> usize{\n    // On 32-bit platforms we simply ignore the higher hash bits.\n    hash as usize\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::h2":["/// Secondary hash function, saved in the low 7 bits of the control byte.\n#[inline]\n#[allow(clippy::cast_possible_truncation)]\nfn h2(hash: u64) -> u8{\n    // Grab the top 7 bits of the hash. While the hash is normally a full 64-bit\n    // value, some hash functions (such as FxHash) produce a usize result\n    // instead, which means that the top 32 bits are 0 on 32-bit platforms.\n    let hash_len = usize::min(mem::size_of::<usize>(), mem::size_of::<u64>());\n    let top7 = hash >> (hash_len * 8 - 7);\n    (top7 & 0x7f) as u8 // truncation\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::is_full":["/// Checks whether a control byte represents a full bucket (top bit is clear).\n#[inline]\nfn is_full(ctrl: u8) -> bool{\n    ctrl & 0x80 == 0\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::is_special":["/// Checks whether a control byte represents a special value (top bit is set).\n#[inline]\nfn is_special(ctrl: u8) -> bool{\n    ctrl & 0x80 != 0\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::likely":["#[cfg(not(feature = \"nightly\"))]\n#[inline]\nfn likely(b: bool) -> bool{\n    b\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::offset_from":["#[cfg(not(feature = \"nightly\"))]\ninline\nunsafe fn offset_from<T>(to: *const T, from: *const T) -> usize{\n    (to as usize - from as usize) / mem::size_of::<T>()\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::special_is_empty":["/// Checks whether a special control value is EMPTY (just check 1 bit).\n#[inline]\nfn special_is_empty(ctrl: u8) -> bool{\n    debug_assert!(is_special(ctrl));\n    ctrl & 0x01 != 0\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"raw::sse2::Group":["/// Abstraction over a group of control bytes which can be scanned in\n/// parallel.\n///\n/// This implementation uses a 128-bit SSE value.\npub struct Group(x86::__m128i);","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::convert_special_to_empty_and_full_to_deleted":["/// Performs the following transformation on all bytes in the group:\n/// - `EMPTY => EMPTY`\n/// - `DELETED => EMPTY`\n/// - `FULL => DELETED`\n#[inline]\npub fn convert_special_to_empty_and_full_to_deleted(self) -> Self{\n        // Map high_bit = 1 (EMPTY or DELETED) to 1111_1111\n        // and high_bit = 0 (FULL) to 1000_0000\n        //\n        // Here's this logic expanded to concrete values:\n        //   let special = 0 > byte = 1111_1111 (true) or 0000_0000 (false)\n        //   1111_1111 | 1000_0000 = 1111_1111\n        //   0000_0000 | 1000_0000 = 1000_0000\n        #[allow(\n            clippy::cast_possible_wrap, // byte: 0x80_u8 as i8\n        )]\n        unsafe {\n            let zero = x86::_mm_setzero_si128();\n            let special = x86::_mm_cmpgt_epi8(zero, self.0);\n            Group(x86::_mm_or_si128(\n                special,\n                x86::_mm_set1_epi8(0x80_u8 as i8),\n            ))\n        }\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::load":["/// Loads a group of bytes starting at the given address.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub unsafe fn load(ptr: *const u8) -> Self{\n        Group(x86::_mm_loadu_si128(ptr as *const _))\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::load_aligned":["/// Loads a group of bytes starting at the given address, which must be\n/// aligned to `mem::align_of::<Group>()`.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub unsafe fn load_aligned(ptr: *const u8) -> Self{\n        // FIXME: use align_offset once it stabilizes\n        debug_assert_eq!(ptr as usize & (mem::align_of::<Self>() - 1), 0);\n        Group(x86::_mm_load_si128(ptr as *const _))\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::match_byte":["/// Returns a `BitMask` indicating all bytes in the group which have\n/// the given value.\n#[inline]\npub fn match_byte(self, byte: u8) -> BitMask{\n        #[allow(\n            clippy::cast_possible_wrap, // byte: u8 as i8\n            // byte: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            let cmp = x86::_mm_cmpeq_epi8(self.0, x86::_mm_set1_epi8(byte as i8));\n            BitMask(x86::_mm_movemask_epi8(cmp) as u16)\n        }\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::match_empty":["/// Returns a `BitMask` indicating all bytes in the group which are\n/// `EMPTY`.\n#[inline]\npub fn match_empty(self) -> BitMask{\n        self.match_byte(EMPTY)\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::match_empty_or_deleted":["/// Returns a `BitMask` indicating all bytes in the group which are\n/// `EMPTY` or `DELETED`.\n#[inline]\npub fn match_empty_or_deleted(self) -> BitMask{\n        #[allow(\n            // byte: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            // A byte is EMPTY or DELETED iff the high bit is set\n            BitMask(x86::_mm_movemask_epi8(self.0) as u16)\n        }\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::match_full":["/// Returns a `BitMask` indicating all bytes in the group which are full.\n#[inline]\npub fn match_full(&self) -> BitMask{\n        self.match_empty_or_deleted().invert()\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::static_empty":["/// Returns a full group of empty bytes, suitable for use as the initial\n/// value for an empty hash table.\n///\n/// This is guaranteed to be aligned to the group size.\npub const fn static_empty() -> &'static [u8; Group::WIDTH]{\n        #[repr(C)]\n        struct AlignedBytes {\n            _align: [Group; 0],\n            bytes: [u8; Group::WIDTH],\n        };\n        const ALIGNED_BYTES: AlignedBytes = AlignedBytes {\n            _align: [],\n            bytes: [EMPTY; Group::WIDTH],\n        };\n        &ALIGNED_BYTES.bytes\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::static_empty::AlignedBytes":["#[repr(C)]\nstruct AlignedBytes {\n            _align: [Group; 0],\n            bytes: [u8; Group::WIDTH],\n        }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::sse2::Group::store_aligned":["/// Stores the group of bytes to the given address, which must be\n/// aligned to `mem::align_of::<Group>()`.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub unsafe fn store_aligned(self, ptr: *mut u8){\n        // FIXME: use align_offset once it stabilizes\n        debug_assert_eq!(ptr as usize & (mem::align_of::<Self>() - 1), 0);\n        x86::_mm_store_si128(ptr as *mut _, self.0);\n    }","Real(LocalPath(\"src/raw/sse2.rs\"))"],"raw::unlikely":["#[cfg(not(feature = \"nightly\"))]\n#[inline]\nfn unlikely(b: bool) -> bool{\n    b\n}","Real(LocalPath(\"src/raw/mod.rs\"))"],"scopeguard::ScopeGuard":["pub struct ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    dropfn: F,\n    value: T,\n}","Real(LocalPath(\"src/scopeguard.rs\"))"],"scopeguard::guard":["inline\npub fn guard<T, F>(value: T, dropfn: F) -> ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),{\n    ScopeGuard { dropfn, value }\n}","Real(LocalPath(\"src/scopeguard.rs\"))"],"set::Difference":["/// A lazy iterator producing elements in the difference of `HashSet`s.\n///\n/// This `struct` is created by the [`difference`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`difference`]: struct.HashSet.html#method.difference\npub struct Difference<'a, T, S> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::Drain":["/// A draining iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`drain`]: struct.HashSet.html#method.drain\npub struct Drain<'a, K> {\n    iter: map::Drain<'a, K, ()>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::DrainFilter":["/// A draining iterator over entries of a `HashSet` which don't satisfy the predicate `f`.\n///\n/// This `struct` is created by the [`drain_filter`] method on [`HashSet`]. See its\n/// documentation for more.\n///\n/// [`drain_filter`]: struct.HashSet.html#method.drain_filter\n/// [`HashSet`]: struct.HashSet.html\npub struct DrainFilter<'a, K, F>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    f: F,\n    inner: DrainFilterInner<'a, K, ()>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet":["/// A hash set implemented as a `HashMap` where the value is `()`.\n///\n/// As with the [`HashMap`] type, a `HashSet` requires that the elements\n/// implement the [`Eq`] and [`Hash`] traits. This can frequently be achieved by\n/// using `#[derive(PartialEq, Eq, Hash)]`. If you implement these yourself,\n/// it is important that the following property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n///\n/// It is a logic error for an item to be modified in such a way that the\n/// item's hash, as determined by the [`Hash`] trait, or its equality, as\n/// determined by the [`Eq`] trait, changes while it is in the set. This is\n/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or\n/// unsafe code.\n///\n/// It is also a logic error for the [`Hash`] implementation of a key to panic.\n/// This is generally only possible if the trait is implemented manually. If a\n/// panic does occur then the contents of the `HashSet` may become corrupted and\n/// some items may be dropped from the table.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashSet<String>` in this example).\n/// let mut books = HashSet::new();\n///\n/// // Add some books.\n/// books.insert(\"A Dance With Dragons\".to_string());\n/// books.insert(\"To Kill a Mockingbird\".to_string());\n/// books.insert(\"The Odyssey\".to_string());\n/// books.insert(\"The Great Gatsby\".to_string());\n///\n/// // Check for a specific one.\n/// if !books.contains(\"The Winds of Winter\") {\n///     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n///              books.len());\n/// }\n///\n/// // Remove a book.\n/// books.remove(\"The Odyssey\");\n///\n/// // Iterate over everything.\n/// for book in &books {\n///     println!(\"{}\", book);\n/// }\n/// ```\n///\n/// The easiest way to use `HashSet` with a custom type is to derive\n/// [`Eq`] and [`Hash`]. We must also derive [`PartialEq`], this will in the\n/// future be implied by [`Eq`].\n///\n/// ```\n/// use hashbrown::HashSet;\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     power: usize,\n/// }\n///\n/// let mut vikings = HashSet::new();\n///\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Olaf\".to_string(), power: 4 });\n/// vikings.insert(Viking { name: \"Harald\".to_string(), power: 8 });\n///\n/// // Use derived implementation to print the vikings.\n/// for x in &vikings {\n///     println!(\"{:?}\", x);\n/// }\n/// ```\n///\n/// A `HashSet` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let viking_names: HashSet<&'static str> =\n///     [ \"Einar\", \"Olaf\", \"Harald\" ].iter().cloned().collect();\n/// // use the values stored in the set\n/// ```\n///\n/// [`Cell`]: https://doc.rust-lang.org/std/cell/struct.Cell.html\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n/// [`HashMap`]: struct.HashMap.html\n/// [`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html\n/// [`RefCell`]: https://doc.rust-lang.org/std/cell/struct.RefCell.html\npub struct HashSet<T, S = DefaultHashBuilder> {\n    pub(crate) map: HashMap<T, (), S>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::capacity":["/// Returns the number of elements the set can hold without reallocating.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::with_capacity(100);\n/// assert!(set.capacity() >= 100);\n/// ```\ninline\npub fn capacity(&self) -> usize{\n        self.map.capacity()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::clear":["/// Clears the set, removing all values.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// v.insert(1);\n/// v.clear();\n/// assert!(v.is_empty());\n/// ```\ninline\npub fn clear(&mut self){\n        self.map.clear()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::contains":["/// Returns `true` if the set contains a value.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// assert_eq!(set.contains(&1), true);\n/// assert_eq!(set.contains(&4), false);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn contains<Q: ?Sized>(&self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,{\n        self.map.contains_key(value)\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::difference":["/// Visits the values representing the difference,\n/// i.e., the values that are in `self` but not in `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// // Can be seen as `a - b`.\n/// for x in a.difference(&b) {\n///     println!(\"{}\", x); // Print 1\n/// }\n///\n/// let diff: HashSet<_> = a.difference(&b).collect();\n/// assert_eq!(diff, [1].iter().collect());\n///\n/// // Note that difference is not symmetric,\n/// // and `b - a` means something else:\n/// let diff: HashSet<_> = b.difference(&a).collect();\n/// assert_eq!(diff, [4].iter().collect());\n/// ```\ninline\npub fn difference<'a>(&'a self, other: &'a Self) -> Difference<'a, T, S>{\n        Difference {\n            iter: self.iter(),\n            other,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::drain":["/// Clears the set, returning all elements in an iterator.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// assert!(!set.is_empty());\n///\n/// // print 1, 2, 3 in an arbitrary order\n/// for i in set.drain() {\n///     println!(\"{}\", i);\n/// }\n///\n/// assert!(set.is_empty());\n/// ```\ninline\npub fn drain(&mut self) -> Drain<'_, T>{\n        Drain {\n            iter: self.map.drain(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::drain_filter":["/// Drains elements which are true under the given predicate,\n/// and returns an iterator over the removed items.\n///\n/// In other words, move all elements `e` such that `f(&e)` returns `true` out\n/// into another iterator.\n///\n/// When the returned DrainedFilter is dropped, any remaining elements that satisfy\n/// the predicate are dropped from the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<i32> = (0..8).collect();\n/// let drained: HashSet<i32> = set.drain_filter(|v| v % 2 == 0).collect();\n///\n/// let mut evens = drained.into_iter().collect::<Vec<_>>();\n/// let mut odds = set.into_iter().collect::<Vec<_>>();\n/// evens.sort();\n/// odds.sort();\n///\n/// assert_eq!(evens, vec![0, 2, 4, 6]);\n/// assert_eq!(odds, vec![1, 3, 5, 7]);\n/// ```\ninline\npub fn drain_filter<F>(&mut self, f: F) -> DrainFilter<'_, T, F>\n    where\n        F: FnMut(&T) -> bool,{\n        DrainFilter {\n            f,\n            inner: DrainFilterInner {\n                iter: unsafe { self.map.table.iter() },\n                table: &mut self.map.table,\n            },\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::get":["/// Returns a reference to the value in the set, if any, that is equal to the given value.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// assert_eq!(set.get(&2), Some(&2));\n/// assert_eq!(set.get(&4), None);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn get<Q: ?Sized>(&self, value: &Q) -> Option<&T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.get_key_value(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::get_or_insert":["/// Inserts the given `value` into the set if it is not present, then\n/// returns a reference to the value in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// assert_eq!(set.len(), 3);\n/// assert_eq!(set.get_or_insert(2), &2);\n/// assert_eq!(set.get_or_insert(100), &100);\n/// assert_eq!(set.len(), 4); // 100 was inserted\n/// ```\ninline\npub fn get_or_insert(&mut self, value: T) -> &T{\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(&value)\n            .or_insert(value, ())\n            .0\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::get_or_insert_owned":["/// Inserts an owned copy of the given `value` into the set if it is not\n/// present, then returns a reference to the value in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n///     .iter().map(|&pet| pet.to_owned()).collect();\n///\n/// assert_eq!(set.len(), 3);\n/// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n///     let value = set.get_or_insert_owned(pet);\n///     assert_eq!(value, pet);\n/// }\n/// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n/// ```\n#[inline]\npub fn get_or_insert_owned<Q: ?Sized>(&mut self, value: &Q) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq + ToOwned<Owned = T>,{\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(value)\n            .or_insert_with(|| (value.to_owned(), ()))\n            .0\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::get_or_insert_with":["/// Inserts a value computed from `f` into the set if the given `value` is\n/// not present, then returns a reference to the value in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n///     .iter().map(|&pet| pet.to_owned()).collect();\n///\n/// assert_eq!(set.len(), 3);\n/// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n///     let value = set.get_or_insert_with(pet, str::to_owned);\n///     assert_eq!(value, pet);\n/// }\n/// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n/// ```\ninline\npub fn get_or_insert_with<Q: ?Sized, F>(&mut self, value: &Q, f: F) -> &T\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,\n        F: FnOnce(&Q) -> T,{\n        // Although the raw entry gives us `&mut T`, we only return `&T` to be consistent with\n        // `get`. Key mutation is \"raw\" because you're not supposed to affect `Eq` or `Hash`.\n        self.map\n            .raw_entry_mut()\n            .from_key(value)\n            .or_insert_with(|| (f(value), ()))\n            .0\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::hasher":["/// Returns a reference to the set's [`BuildHasher`].\n///\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let set: HashSet<i32> = HashSet::with_hasher(hasher);\n/// let hasher: &DefaultHashBuilder = set.hasher();\n/// ```\ninline\npub fn hasher(&self) -> &S{\n        self.map.hasher()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::insert":["/// Adds a value to the set.\n///\n/// If the set did not have this value present, `true` is returned.\n///\n/// If the set did have this value present, `false` is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.insert(2), true);\n/// assert_eq!(set.insert(2), false);\n/// assert_eq!(set.len(), 1);\n/// ```\ninline\npub fn insert(&mut self, value: T) -> bool{\n        self.map.insert(value, ()).is_none()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::intersection":["/// Visits the values representing the intersection,\n/// i.e., the values that are both in `self` and `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// // Print 2, 3 in arbitrary order.\n/// for x in a.intersection(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let intersection: HashSet<_> = a.intersection(&b).collect();\n/// assert_eq!(intersection, [2, 3].iter().collect());\n/// ```\ninline\npub fn intersection<'a>(&'a self, other: &'a Self) -> Intersection<'a, T, S>{\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Intersection {\n            iter: smaller.iter(),\n            other: larger,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::is_disjoint":["/// Returns `true` if `self` has no elements in common with `other`.\n/// This is equivalent to checking for an empty intersection.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let mut b = HashSet::new();\n///\n/// assert_eq!(a.is_disjoint(&b), true);\n/// b.insert(4);\n/// assert_eq!(a.is_disjoint(&b), true);\n/// b.insert(1);\n/// assert_eq!(a.is_disjoint(&b), false);\n/// ```\npub fn is_disjoint(&self, other: &Self) -> bool{\n        self.iter().all(|v| !other.contains(v))\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::is_empty":["/// Returns `true` if the set contains no elements.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// assert!(v.is_empty());\n/// v.insert(1);\n/// assert!(!v.is_empty());\n/// ```\ninline\npub fn is_empty(&self) -> bool{\n        self.map.is_empty()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::is_subset":["/// Returns `true` if the set is a subset of another,\n/// i.e., `other` contains at least all the values in `self`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let sup: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.is_subset(&sup), true);\n/// set.insert(2);\n/// assert_eq!(set.is_subset(&sup), true);\n/// set.insert(4);\n/// assert_eq!(set.is_subset(&sup), false);\n/// ```\npub fn is_subset(&self, other: &Self) -> bool{\n        self.len() <= other.len() && self.iter().all(|v| other.contains(v))\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::is_superset":["/// Returns `true` if the set is a superset of another,\n/// i.e., `self` contains at least all the values in `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let sub: HashSet<_> = [1, 2].iter().cloned().collect();\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.is_superset(&sub), false);\n///\n/// set.insert(0);\n/// set.insert(1);\n/// assert_eq!(set.is_superset(&sub), false);\n///\n/// set.insert(2);\n/// assert_eq!(set.is_superset(&sub), true);\n/// ```\ninline\npub fn is_superset(&self, other: &Self) -> bool{\n        other.is_subset(self)\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::iter":["/// An iterator visiting all elements in arbitrary order.\n/// The iterator element type is `&'a T`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set = HashSet::new();\n/// set.insert(\"a\");\n/// set.insert(\"b\");\n///\n/// // Will print in an arbitrary order.\n/// for x in set.iter() {\n///     println!(\"{}\", x);\n/// }\n/// ```\ninline\npub fn iter(&self) -> Iter<'_, T>{\n        Iter {\n            iter: self.map.keys(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::len":["/// Returns the number of elements in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// assert_eq!(v.len(), 0);\n/// v.insert(1);\n/// assert_eq!(v.len(), 1);\n/// ```\ninline\npub fn len(&self) -> usize{\n        self.map.len()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::remove":["/// Removes a value from the set. Returns whether the value was\n/// present in the set.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n///\n/// set.insert(2);\n/// assert_eq!(set.remove(&2), true);\n/// assert_eq!(set.remove(&2), false);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn remove<Q: ?Sized>(&mut self, value: &Q) -> bool\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,{\n        self.map.remove(value).is_some()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::replace":["/// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n/// one. Returns the replaced value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n/// set.insert(Vec::<i32>::new());\n///\n/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n/// set.replace(Vec::with_capacity(10));\n/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n/// ```\ninline\npub fn replace(&mut self, value: T) -> Option<T>{\n        match self.map.entry(value) {\n            map::Entry::Occupied(occupied) => Some(occupied.replace_key()),\n            map::Entry::Vacant(vacant) => {\n                vacant.insert(());\n                None\n            }\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::reserve":["/// Reserves capacity for at least `additional` more elements to be inserted\n/// in the `HashSet`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Panics\n///\n/// Panics if the new allocation size overflows `usize`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set: HashSet<i32> = HashSet::new();\n/// set.reserve(10);\n/// assert!(set.capacity() >= 10);\n/// ```\ninline\npub fn reserve(&mut self, additional: usize){\n        self.map.reserve(additional)\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::retain":["/// Retains only the elements specified by the predicate.\n///\n/// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let xs = [1,2,3,4,5,6];\n/// let mut set: HashSet<i32> = xs.iter().cloned().collect();\n/// set.retain(|&k| k % 2 == 0);\n/// assert_eq!(set.len(), 3);\n/// ```\npub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,{\n        self.map.retain(|k, _| f(k));\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::shrink_to":["/// Shrinks the capacity of the set with a lower limit. It will drop\n/// down no lower than the supplied limit while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// Panics if the current capacity is smaller than the supplied\n/// minimum capacity.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::with_capacity(100);\n/// set.insert(1);\n/// set.insert(2);\n/// assert!(set.capacity() >= 100);\n/// set.shrink_to(10);\n/// assert!(set.capacity() >= 10);\n/// set.shrink_to(0);\n/// assert!(set.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to(&mut self, min_capacity: usize){\n        self.map.shrink_to(min_capacity)\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::shrink_to_fit":["/// Shrinks the capacity of the set as much as possible. It will drop\n/// down as much as possible while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::with_capacity(100);\n/// set.insert(1);\n/// set.insert(2);\n/// assert!(set.capacity() >= 100);\n/// set.shrink_to_fit();\n/// assert!(set.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to_fit(&mut self){\n        self.map.shrink_to_fit()\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::symmetric_difference":["/// Visits the values representing the symmetric difference,\n/// i.e., the values that are in `self` or in `other` but not in both.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// // Print 1, 4 in arbitrary order.\n/// for x in a.symmetric_difference(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();\n/// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();\n///\n/// assert_eq!(diff1, diff2);\n/// assert_eq!(diff1, [1, 4].iter().collect());\n/// ```\ninline\npub fn symmetric_difference<'a>(&'a self, other: &'a Self) -> SymmetricDifference<'a, T, S>{\n        SymmetricDifference {\n            iter: self.difference(other).chain(other.difference(self)),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::take":["/// Removes and returns the value in the set, if any, that is equal to the given one.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// assert_eq!(set.take(&2), Some(2));\n/// assert_eq!(set.take(&2), None);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn take<Q: ?Sized>(&mut self, value: &Q) -> Option<T>\n    where\n        T: Borrow<Q>,\n        Q: Hash + Eq,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.remove_entry(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::try_reserve":["/// Tries to reserve capacity for at least `additional` more elements to be inserted\n/// in the given `HashSet<K,V>`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Errors\n///\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set: HashSet<i32> = HashSet::new();\n/// set.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n/// ```\ninline\npub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError>{\n        self.map.try_reserve(additional)\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::union":["/// Visits the values representing the union,\n/// i.e., all the values in `self` or `other`, without duplicates.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();\n///\n/// // Print 1, 2, 3, 4 in arbitrary order.\n/// for x in a.union(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let union: HashSet<_> = a.union(&b).collect();\n/// assert_eq!(union, [1, 2, 3, 4].iter().collect());\n/// ```\ninline\npub fn union<'a>(&'a self, other: &'a Self) -> Union<'a, T, S>{\n        let (smaller, larger) = if self.len() >= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Union {\n            iter: larger.iter().chain(smaller.difference(larger)),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::with_capacity_and_hasher":["/// Creates an empty `HashSet` with the specified capacity, using\n/// `hasher` to hash the keys.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// Warning: `hasher` is normally randomly generated, and\n/// is designed to allow `HashSet`s to be resistant to attacks that\n/// cause many collisions and very poor performance. Setting it\n/// manually using this function can expose a DoS attack vector.\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the HashMap to be useful, see its documentation for details.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_capacity_and_hasher(10, s);\n/// set.insert(1);\n/// ```\n///\n/// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\ninline\npub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> Self{\n        Self {\n            map: HashMap::with_capacity_and_hasher(capacity, hasher),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T, S>::with_hasher":["/// Creates a new empty hash set which will use the given hasher to hash\n/// keys.\n///\n/// The hash set is also created with the default initial capacity.\n///\n/// Warning: `hasher` is normally randomly generated, and\n/// is designed to allow `HashSet`s to be resistant to attacks that\n/// cause many collisions and very poor performance. Setting it\n/// manually using this function can expose a DoS attack vector.\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the HashMap to be useful, see its documentation for details.\n///\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_map::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_hasher(s);\n/// set.insert(2);\n/// ```\n///\n/// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html\ninline\npub const fn with_hasher(hasher: S) -> Self{\n        Self {\n            map: HashMap::with_hasher(hasher),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T>::new":["/// Creates an empty `HashSet`.\n///\n/// The hash set is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::new();\n/// ```\ninline\npub fn new() -> Self{\n        Self {\n            map: HashMap::new(),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::HashSet::<T>::with_capacity":["/// Creates an empty `HashSet` with the specified capacity.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::with_capacity(10);\n/// assert!(set.capacity() >= 10);\n/// ```\ninline\npub fn with_capacity(capacity: usize) -> Self{\n        Self {\n            map: HashMap::with_capacity(capacity),\n        }\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::Intersection":["/// A lazy iterator producing elements in the intersection of `HashSet`s.\n///\n/// This `struct` is created by the [`intersection`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`intersection`]: struct.HashSet.html#method.intersection\npub struct Intersection<'a, T, S> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::IntoIter":["/// An owning iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashSet`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`into_iter`]: struct.HashSet.html#method.into_iter\npub struct IntoIter<K> {\n    iter: map::IntoIter<K, ()>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::Iter":["/// An iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`iter`]: struct.HashSet.html#method.iter\npub struct Iter<'a, K> {\n    iter: Keys<'a, K, ()>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::SymmetricDifference":["/// A lazy iterator producing elements in the symmetric difference of `HashSet`s.\n///\n/// This `struct` is created by the [`symmetric_difference`] method on\n/// [`HashSet`]. See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`symmetric_difference`]: struct.HashSet.html#method.symmetric_difference\npub struct SymmetricDifference<'a, T, S> {\n    iter: Chain<Difference<'a, T, S>, Difference<'a, T, S>>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::Union":["/// A lazy iterator producing elements in the union of `HashSet`s.\n///\n/// This `struct` is created by the [`union`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`union`]: struct.HashSet.html#method.union\npub struct Union<'a, T, S> {\n    iter: Chain<Iter<'a, T>, Difference<'a, T, S>>,\n}","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance":["#[allow(dead_code)]\nfn assert_covariance(){\n    fn set<'new>(v: HashSet<&'static str>) -> HashSet<&'new str> {\n        v\n    }\n    fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str> {\n        v\n    }\n    fn into_iter<'new>(v: IntoIter<&'static str>) -> IntoIter<&'new str> {\n        v\n    }\n    fn difference<'a, 'new>(\n        v: Difference<'a, &'static str, DefaultHashBuilder>,\n    ) -> Difference<'a, &'new str, DefaultHashBuilder> {\n        v\n    }\n    fn symmetric_difference<'a, 'new>(\n        v: SymmetricDifference<'a, &'static str, DefaultHashBuilder>,\n    ) -> SymmetricDifference<'a, &'new str, DefaultHashBuilder> {\n        v\n    }\n    fn intersection<'a, 'new>(\n        v: Intersection<'a, &'static str, DefaultHashBuilder>,\n    ) -> Intersection<'a, &'new str, DefaultHashBuilder> {\n        v\n    }\n    fn union<'a, 'new>(\n        v: Union<'a, &'static str, DefaultHashBuilder>,\n    ) -> Union<'a, &'new str, DefaultHashBuilder> {\n        v\n    }\n    fn drain<'new>(d: Drain<'static, &'static str>) -> Drain<'new, &'new str> {\n        d\n    }\n}","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::difference":["fn difference<'a, 'new>(\n        v: Difference<'a, &'static str, DefaultHashBuilder>,\n    ) -> Difference<'a, &'new str, DefaultHashBuilder>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::drain":["fn drain<'new>(d: Drain<'static, &'static str>) -> Drain<'new, &'new str>{\n        d\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::intersection":["fn intersection<'a, 'new>(\n        v: Intersection<'a, &'static str, DefaultHashBuilder>,\n    ) -> Intersection<'a, &'new str, DefaultHashBuilder>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::into_iter":["fn into_iter<'new>(v: IntoIter<&'static str>) -> IntoIter<&'new str>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::iter":["fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::set":["fn set<'new>(v: HashSet<&'static str>) -> HashSet<&'new str>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::symmetric_difference":["fn symmetric_difference<'a, 'new>(\n        v: SymmetricDifference<'a, &'static str, DefaultHashBuilder>,\n    ) -> SymmetricDifference<'a, &'new str, DefaultHashBuilder>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"],"set::assert_covariance::union":["fn union<'a, 'new>(\n        v: Union<'a, &'static str, DefaultHashBuilder>,\n    ) -> Union<'a, &'new str, DefaultHashBuilder>{\n        v\n    }","Real(LocalPath(\"src/set.rs\"))"]},"struct_constructor":{"&'static [u8; _]":["static_empty"],"(&'a mut K, &'a mut V)":["insert","insert_hashed_nocheck","insert_with_hasher","into_key_value","or_insert","or_insert_with"],"(&K, &V)":["get_key_value"],"(&mut K, &mut V)":["get_key_value_mut"],"(K, V)":["remove_entry","replace_entry"],"(usize, core::option::Option<usize>)":["size_hint"],"*mut u8":["ctrl"],"TryReserveError":["alloc_err","capacity_overflow","clone"],"bool":["any_bit_set","contains","contains_key","eq","insert","is_disjoint","is_empty","is_empty_singleton","is_full","is_special","is_subset","is_superset","remove","replace_bucket_with","special_is_empty"],"core::option::Option":["calculate_layout","capacity_to_buckets","find","from_hash","from_key","from_key_hashed_nocheck","get","get_inner","get_inner_mut","get_key_value","get_key_value_mut","get_mut","insert","into_alloc","lowest_set_bit","next","remove","remove_entry","replace","search","take"],"core::ptr::NonNull":["data_end"],"core::result::Result":["fallible_with_capacity","fmt","new_uninitialized","reserve_rehash","resize","try_reserve"],"map::Drain":["drain"],"map::DrainFilter":["drain_filter"],"map::Entry":["entry","replace_entry_with"],"map::HashMap":["clone","default","from_iter","new","with_capacity","with_capacity_and_hasher","with_hasher"],"map::IntoIter":["into_iter"],"map::Iter":["clone","into_iter","iter"],"map::IterMut":["into_iter","iter_mut"],"map::Keys":["clone","keys"],"map::OccupiedEntry":["insert","insert_entry"],"map::RawEntryBuilder":["raw_entry"],"map::RawEntryBuilderMut":["raw_entry_mut"],"map::RawEntryMut":["from_hash","from_key","from_key_hashed_nocheck","replace_entry_with","search"],"map::RawOccupiedEntryMut":["insert","insert_entry"],"map::Values":["clone","values"],"map::ValuesMut":["values_mut"],"raw::Bucket":["bucket","clone","from_base_index","insert","next_n"],"raw::Fallibility":["clone"],"raw::ProbeSeq":["probe_seq"],"raw::RawDrain":["drain","drain_iter_from"],"raw::RawIntoIter":["into_iter","into_iter_from"],"raw::RawIter":["clone","iter"],"raw::RawIterHash":["iter_hash","new"],"raw::RawIterRange":["clone","new"],"raw::RawTable":["clone","new","with_capacity"],"raw::bitmask::BitMask":["clone","match_byte","match_empty","match_empty_or_deleted","match_full"],"raw::bitmask::BitMaskIter":["into_iter"],"raw::sse2::Group":["clone","load","load_aligned"],"scopeguard::ScopeGuard":["guard"],"set::Difference":["clone","difference"],"set::Drain":["drain"],"set::DrainFilter":["drain_filter"],"set::HashSet":["bitand","bitor","bitxor","clone","default","from_iter","new","sub","with_capacity","with_capacity_and_hasher","with_hasher"],"set::Intersection":["clone","intersection"],"set::IntoIter":["into_iter"],"set::Iter":["clone","into_iter","iter"],"set::SymmetricDifference":["clone","symmetric_difference"],"set::Union":["clone","union"],"u64":["make_hash"],"u8":["h2"],"usize":["bucket_index","buckets","capacity","find_insert_slot","h1","leading_zeros","len","lowest_set_bit_nonzero","num_ctrl_bytes","offset_from","to_base_index","trailing_zeros"]},"struct_to_trait":{"TryReserveError":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::marker::StructuralEq","core::marker::StructuralPartialEq"],"map::ConsumeAllOnDrop":["core::ops::Drop"],"map::Drain":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"map::DrainFilter":["core::iter::FusedIterator","core::iter::Iterator","core::ops::Drop"],"map::Entry":["core::fmt::Debug"],"map::HashMap":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::default::Default","core::fmt::Debug","core::iter::Extend","core::iter::FromIterator","core::iter::IntoIterator","core::ops::Index"],"map::IntoIter":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"map::Iter":["core::clone::Clone","core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"map::IterMut":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator","core::marker::Send"],"map::Keys":["core::clone::Clone","core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"map::OccupiedEntry":["core::fmt::Debug","core::marker::Send","core::marker::Sync"],"map::RawEntryBuilder":["core::fmt::Debug"],"map::RawEntryBuilderMut":["core::fmt::Debug"],"map::RawEntryMut":["core::fmt::Debug"],"map::RawOccupiedEntryMut":["core::fmt::Debug","core::marker::Send","core::marker::Sync"],"map::RawVacantEntryMut":["core::fmt::Debug"],"map::VacantEntry":["core::fmt::Debug"],"map::Values":["core::clone::Clone","core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"map::ValuesMut":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"raw::Bucket":["core::clone::Clone","core::marker::Send"],"raw::Fallibility":["core::clone::Clone","core::marker::Copy"],"raw::ProbeSeq":["core::iter::Iterator"],"raw::RawDrain":["core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator","core::marker::Send","core::marker::Sync","core::ops::Drop"],"raw::RawIntoIter":["core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator","core::marker::Send","core::marker::Sync","core::ops::Drop"],"raw::RawIter":["core::clone::Clone","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"raw::RawIterHash":["core::iter::Iterator"],"raw::RawIterRange":["core::clone::Clone","core::iter::FusedIterator","core::iter::Iterator","core::marker::Send","core::marker::Sync"],"raw::RawTable":["core::clone::Clone","core::iter::IntoIterator","core::marker::Send","core::marker::Sync","core::ops::Drop","raw::RawTableClone"],"raw::bitmask::BitMask":["core::clone::Clone","core::iter::IntoIterator","core::marker::Copy"],"raw::bitmask::BitMaskIter":["core::iter::Iterator"],"raw::sse2::Group":["core::clone::Clone","core::marker::Copy"],"scopeguard::ScopeGuard":["core::ops::Deref","core::ops::DerefMut","core::ops::Drop"],"set::Difference":["core::clone::Clone","core::fmt::Debug","core::iter::FusedIterator","core::iter::Iterator"],"set::Drain":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"set::DrainFilter":["core::iter::FusedIterator","core::iter::Iterator","core::ops::Drop"],"set::HashSet":["core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::default::Default","core::fmt::Debug","core::iter::Extend","core::iter::FromIterator","core::iter::IntoIterator"],"set::Intersection":["core::clone::Clone","core::fmt::Debug","core::iter::FusedIterator","core::iter::Iterator"],"set::IntoIter":["core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"set::Iter":["core::clone::Clone","core::fmt::Debug","core::iter::ExactSizeIterator","core::iter::FusedIterator","core::iter::Iterator"],"set::SymmetricDifference":["core::clone::Clone","core::fmt::Debug","core::iter::FusedIterator","core::iter::Iterator"],"set::Union":["core::clone::Clone","core::fmt::Debug","core::iter::FusedIterator","core::iter::Iterator"]},"targets":{"<&'a map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/map.rs\"))","core::iter::IntoIterator"],"<&'a mut map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/map.rs\"))","core::iter::IntoIterator"],"<&'a set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/set.rs\"))","core::iter::IntoIterator"],"<&set::HashSet<T, S> as core::ops::BitAnd<&set::HashSet<T, S>>>::bitand":["bitand","Real(LocalPath(\"src/set.rs\"))","core::ops::BitAnd"],"<&set::HashSet<T, S> as core::ops::BitOr<&set::HashSet<T, S>>>::bitor":["bitor","Real(LocalPath(\"src/set.rs\"))","core::ops::BitOr"],"<&set::HashSet<T, S> as core::ops::BitXor<&set::HashSet<T, S>>>::bitxor":["bitxor","Real(LocalPath(\"src/set.rs\"))","core::ops::BitXor"],"<&set::HashSet<T, S> as core::ops::Sub<&set::HashSet<T, S>>>::sub":["sub","Real(LocalPath(\"src/set.rs\"))","core::ops::Sub"],"<map::ConsumeAllOnDrop<'_, T> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/map.rs\"))","core::ops::Drop"],"<map::Drain<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::Drain<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::Drain<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Drain<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::DrainFilter<'_, K, V, F> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::DrainFilter<'a, K, V, F> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/map.rs\"))","core::ops::Drop"],"<map::Entry<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/map.rs\"))","core::clone::Clone"],"<map::HashMap<K, V, S> as core::clone::Clone>::clone_from":["clone_from","Real(LocalPath(\"src/map.rs\"))","core::clone::Clone"],"<map::HashMap<K, V, S> as core::cmp::PartialEq>::eq":["eq","Real(LocalPath(\"src/map.rs\"))","core::cmp::PartialEq"],"<map::HashMap<K, V, S> as core::default::Default>::default":["default","Real(LocalPath(\"src/map.rs\"))","core::default::Default"],"<map::HashMap<K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::HashMap<K, V, S> as core::iter::Extend<(&'a K, &'a V)>>::extend":["extend","Real(LocalPath(\"src/map.rs\"))","core::iter::Extend"],"<map::HashMap<K, V, S> as core::iter::Extend<(K, V)>>::extend":["extend","Real(LocalPath(\"src/map.rs\"))","core::iter::Extend"],"<map::HashMap<K, V, S> as core::iter::FromIterator<(K, V)>>::from_iter":["from_iter","Real(LocalPath(\"src/map.rs\"))","core::iter::FromIterator"],"<map::HashMap<K, V, S> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/map.rs\"))","core::iter::IntoIterator"],"<map::HashMap<K, V, S> as core::ops::Index<&Q>>::index":["index","Real(LocalPath(\"src/map.rs\"))","core::ops::Index"],"<map::IntoIter<K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::IntoIter<K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::IntoIter<K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::IntoIter<K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Iter<'_, K, V> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/map.rs\"))","core::clone::Clone"],"<map::Iter<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::Iter<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Keys<'_, K, V> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/map.rs\"))","core::clone::Clone"],"<map::Keys<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::Keys<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::OccupiedEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::RawEntryBuilder<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::RawEntryBuilderMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::RawEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::RawOccupiedEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::RawVacantEntryMut<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::VacantEntry<'_, K, V, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::Values<'_, K, V> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/map.rs\"))","core::clone::Clone"],"<map::Values<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::Values<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::Values<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/map.rs\"))","core::fmt::Debug"],"<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/map.rs\"))","core::iter::ExactSizeIterator"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/map.rs\"))","core::iter::Iterator"],"<raw::Bucket<T> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/raw/mod.rs\"))","core::clone::Clone"],"<raw::ProbeSeq as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawDrain<'_, T> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawDrain<'_, T> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/raw/mod.rs\"))","core::ops::Drop"],"<raw::RawIntoIter<T> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIntoIter<T> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIntoIter<T> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/raw/mod.rs\"))","core::ops::Drop"],"<raw::RawIter<T> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/raw/mod.rs\"))","core::clone::Clone"],"<raw::RawIter<T> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIter<T> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIterHash<'a, T> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIterRange<T> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/raw/mod.rs\"))","core::clone::Clone"],"<raw::RawIterRange<T> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawIterRange<T> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::Iterator"],"<raw::RawTable<T> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/raw/mod.rs\"))","core::clone::Clone"],"<raw::RawTable<T> as core::clone::Clone>::clone_from":["clone_from","Real(LocalPath(\"src/raw/mod.rs\"))","core::clone::Clone"],"<raw::RawTable<T> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/raw/mod.rs\"))","core::iter::IntoIterator"],"<raw::RawTable<T> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/raw/mod.rs\"))","core::ops::Drop"],"<raw::RawTable<T> as raw::RawTableClone>::clone_from_spec":["clone_from_spec","Real(LocalPath(\"src/raw/mod.rs\"))","raw::RawTableClone"],"<raw::bitmask::BitMask as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/raw/bitmask.rs\"))","core::iter::IntoIterator"],"<raw::bitmask::BitMaskIter as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/raw/bitmask.rs\"))","core::iter::Iterator"],"<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref":["deref","Real(LocalPath(\"src/scopeguard.rs\"))","core::ops::Deref"],"<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut":["deref_mut","Real(LocalPath(\"src/scopeguard.rs\"))","core::ops::DerefMut"],"<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/scopeguard.rs\"))","core::ops::Drop"],"<set::Difference<'_, T, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::Difference<'_, T, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::Difference<'a, T, S> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Difference<'a, T, S> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Drain<'_, K> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::Drain<'_, K> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/set.rs\"))","core::iter::ExactSizeIterator"],"<set::Drain<'_, K> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Drain<'_, K> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::DrainFilter<'_, K, F> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::DrainFilter<'a, K, F> as core::ops::Drop>::drop":["drop","Real(LocalPath(\"src/set.rs\"))","core::ops::Drop"],"<set::HashSet<T, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::HashSet<T, S> as core::clone::Clone>::clone_from":["clone_from","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::HashSet<T, S> as core::cmp::PartialEq>::eq":["eq","Real(LocalPath(\"src/set.rs\"))","core::cmp::PartialEq"],"<set::HashSet<T, S> as core::default::Default>::default":["default","Real(LocalPath(\"src/set.rs\"))","core::default::Default"],"<set::HashSet<T, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::HashSet<T, S> as core::iter::Extend<&'a T>>::extend":["extend","Real(LocalPath(\"src/set.rs\"))","core::iter::Extend"],"<set::HashSet<T, S> as core::iter::Extend<T>>::extend":["extend","Real(LocalPath(\"src/set.rs\"))","core::iter::Extend"],"<set::HashSet<T, S> as core::iter::FromIterator<T>>::from_iter":["from_iter","Real(LocalPath(\"src/set.rs\"))","core::iter::FromIterator"],"<set::HashSet<T, S> as core::iter::IntoIterator>::into_iter":["into_iter","Real(LocalPath(\"src/set.rs\"))","core::iter::IntoIterator"],"<set::Intersection<'_, T, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::Intersection<'_, T, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Intersection<'a, T, S> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::IntoIter<K> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::IntoIter<K> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/set.rs\"))","core::iter::ExactSizeIterator"],"<set::IntoIter<K> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::IntoIter<K> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Iter<'_, K> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::Iter<'_, K> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::Iter<'a, K> as core::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/set.rs\"))","core::iter::ExactSizeIterator"],"<set::Iter<'a, K> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Iter<'a, K> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::SymmetricDifference<'_, T, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::SymmetricDifference<'_, T, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::SymmetricDifference<'a, T, S> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Union<'_, T, S> as core::clone::Clone>::clone":["clone","Real(LocalPath(\"src/set.rs\"))","core::clone::Clone"],"<set::Union<'_, T, S> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/set.rs\"))","core::fmt::Debug"],"<set::Union<'a, T, S> as core::iter::Iterator>::next":["next","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"<set::Union<'a, T, S> as core::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/set.rs\"))","core::iter::Iterator"],"map::Drain::<'_, K, V>::iter":["iter","Real(LocalPath(\"src/map.rs\"))",""],"map::DrainFilterInner::<'_, K, V>::next":["next","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::and_modify":["and_modify","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::and_replace_entry_with":["and_replace_entry_with","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::key":["key","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::or_default":["or_default","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::or_insert":["or_insert","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::or_insert_with":["or_insert_with","Real(LocalPath(\"src/map.rs\"))",""],"map::Entry::<'a, K, V, S>::or_insert_with_key":["or_insert_with_key","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::capacity":["capacity","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::clear":["clear","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::contains_key":["contains_key","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::drain":["drain","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::drain_filter":["drain_filter","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::entry":["entry","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get":["get","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get_inner":["get_inner","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get_inner_mut":["get_inner_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get_key_value":["get_key_value","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get_key_value_mut":["get_key_value_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::get_mut":["get_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::hasher":["hasher","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::is_empty":["is_empty","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::iter":["iter","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::iter_mut":["iter_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::keys":["keys","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::len":["len","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::raw_entry":["raw_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::raw_entry_mut":["raw_entry_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::remove":["remove","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::remove_entry":["remove_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::reserve":["reserve","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::retain":["retain","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::shrink_to":["shrink_to","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::shrink_to_fit":["shrink_to_fit","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::try_reserve":["try_reserve","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::values":["values","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::values_mut":["values_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::with_capacity_and_hasher":["with_capacity_and_hasher","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V, S>::with_hasher":["with_hasher","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V>::new":["new","Real(LocalPath(\"src/map.rs\"))",""],"map::HashMap::<K, V>::with_capacity":["with_capacity","Real(LocalPath(\"src/map.rs\"))",""],"map::IntoIter::<K, V>::iter":["iter","Real(LocalPath(\"src/map.rs\"))",""],"map::IterMut::<'_, K, V>::iter":["iter","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::get":["get","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::get_mut":["get_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::into_mut":["into_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::key":["key","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::remove":["remove","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::remove_entry":["remove_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::replace_entry":["replace_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::replace_entry_with":["replace_entry_with","Real(LocalPath(\"src/map.rs\"))",""],"map::OccupiedEntry::<'a, K, V, S>::replace_key":["replace_key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilder::<'a, K, V, S>::from_hash":["from_hash","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilder::<'a, K, V, S>::from_key":["from_key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilder::<'a, K, V, S>::from_key_hashed_nocheck":["from_key_hashed_nocheck","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilder::<'a, K, V, S>::search":["search","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilderMut::<'a, K, V, S>::from_hash":["from_hash","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key":["from_key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilderMut::<'a, K, V, S>::from_key_hashed_nocheck":["from_key_hashed_nocheck","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryBuilderMut::<'a, K, V, S>::search":["search","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryMut::<'a, K, V, S>::and_modify":["and_modify","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryMut::<'a, K, V, S>::and_replace_entry_with":["and_replace_entry_with","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryMut::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryMut::<'a, K, V, S>::or_insert":["or_insert","Real(LocalPath(\"src/map.rs\"))",""],"map::RawEntryMut::<'a, K, V, S>::or_insert_with":["or_insert_with","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::get":["get","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value":["get_key_value","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_key_value_mut":["get_key_value_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::get_mut":["get_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::insert_key":["insert_key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key":["into_key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_key_value":["into_key_value","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::into_mut":["into_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::key":["key","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::key_mut":["key_mut","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove":["remove","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::remove_entry":["remove_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::RawOccupiedEntryMut::<'a, K, V, S>::replace_entry_with":["replace_entry_with","Real(LocalPath(\"src/map.rs\"))",""],"map::RawVacantEntryMut::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::RawVacantEntryMut::<'a, K, V, S>::insert_entry":["insert_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::RawVacantEntryMut::<'a, K, V, S>::insert_hashed_nocheck":["insert_hashed_nocheck","Real(LocalPath(\"src/map.rs\"))",""],"map::RawVacantEntryMut::<'a, K, V, S>::insert_with_hasher":["insert_with_hasher","Real(LocalPath(\"src/map.rs\"))",""],"map::VacantEntry::<'a, K, V, S>::insert":["insert","Real(LocalPath(\"src/map.rs\"))",""],"map::VacantEntry::<'a, K, V, S>::insert_entry":["insert_entry","Real(LocalPath(\"src/map.rs\"))",""],"map::VacantEntry::<'a, K, V, S>::into_key":["into_key","Real(LocalPath(\"src/map.rs\"))",""],"map::VacantEntry::<'a, K, V, S>::key":["key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance":["assert_covariance","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::drain":["drain","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::into_iter_key":["into_iter_key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::into_iter_val":["into_iter_val","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::iter_key":["iter_key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::iter_val":["iter_val","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::keys_key":["keys_key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::keys_val":["keys_val","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::map_key":["map_key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::map_val":["map_val","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::values_key":["values_key","Real(LocalPath(\"src/map.rs\"))",""],"map::assert_covariance::values_val":["values_val","Real(LocalPath(\"src/map.rs\"))",""],"map::make_hash":["make_hash","Real(LocalPath(\"src/map.rs\"))",""],"raw::Bucket::<T>::as_mut":["as_mut","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::as_ptr":["as_ptr","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::as_ref":["as_ref","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::copy_from_nonoverlapping":["copy_from_nonoverlapping","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::drop":["drop","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::from_base_index":["from_base_index","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::next_n":["next_n","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::read":["read","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::to_base_index":["to_base_index","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Bucket::<T>::write":["write","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Fallibility::alloc_err":["alloc_err","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::Fallibility::capacity_overflow":["capacity_overflow","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawDrain::<'_, T>::iter":["iter","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawIntoIter::<T>::iter":["iter","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawIterHash::<'a, T>::new":["new","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawIterRange::<T>::new":["new","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::bucket":["bucket","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::bucket_index":["bucket_index","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::buckets":["buckets","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::capacity":["capacity","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::clear":["clear","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::clear_no_drop":["clear_no_drop","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::clone_from_impl":["clone_from_impl","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::ctrl":["ctrl","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::data_end":["data_end","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::drain":["drain","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::drain_iter_from":["drain_iter_from","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::erase":["erase","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::erase_no_drop":["erase_no_drop","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::fallible_with_capacity":["fallible_with_capacity","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::find":["find","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::find_insert_slot":["find_insert_slot","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::free_buckets":["free_buckets","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::get":["get","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::get_mut":["get_mut","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::insert":["insert","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::insert_entry":["insert_entry","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::into_alloc":["into_alloc","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::into_iter_from":["into_iter_from","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::is_empty_singleton":["is_empty_singleton","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::iter":["iter","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::iter_hash":["iter_hash","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::len":["len","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::new":["new","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::new_uninitialized":["new_uninitialized","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::num_ctrl_bytes":["num_ctrl_bytes","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::probe_seq":["probe_seq","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::rehash_in_place":["rehash_in_place","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::remove":["remove","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::remove_entry":["remove_entry","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::replace_bucket_with":["replace_bucket_with","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::reserve":["reserve","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::reserve_rehash":["reserve_rehash","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::resize":["resize","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::set_ctrl":["set_ctrl","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::shrink_to":["shrink_to","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::try_reserve":["try_reserve","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::RawTable::<T>::with_capacity":["with_capacity","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::bitmask::BitMask::any_bit_set":["any_bit_set","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::invert":["invert","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::leading_zeros":["leading_zeros","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::lowest_set_bit":["lowest_set_bit","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::lowest_set_bit_nonzero":["lowest_set_bit_nonzero","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::remove_lowest_bit":["remove_lowest_bit","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bitmask::BitMask::trailing_zeros":["trailing_zeros","Real(LocalPath(\"src/raw/bitmask.rs\"))",""],"raw::bucket_mask_to_capacity":["bucket_mask_to_capacity","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::calculate_layout":["calculate_layout","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::capacity_to_buckets":["capacity_to_buckets","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::h1":["h1","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::h2":["h2","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::is_full":["is_full","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::is_special":["is_special","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::likely":["likely","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::offset_from":["offset_from","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::special_is_empty":["special_is_empty","Real(LocalPath(\"src/raw/mod.rs\"))",""],"raw::sse2::Group::convert_special_to_empty_and_full_to_deleted":["convert_special_to_empty_and_full_to_deleted","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::load":["load","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::load_aligned":["load_aligned","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::match_byte":["match_byte","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::match_empty":["match_empty","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::match_empty_or_deleted":["match_empty_or_deleted","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::match_full":["match_full","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::static_empty":["static_empty","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::sse2::Group::store_aligned":["store_aligned","Real(LocalPath(\"src/raw/sse2.rs\"))",""],"raw::unlikely":["unlikely","Real(LocalPath(\"src/raw/mod.rs\"))",""],"scopeguard::guard":["guard","Real(LocalPath(\"src/scopeguard.rs\"))",""],"set::HashSet::<T, S>::capacity":["capacity","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::clear":["clear","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::contains":["contains","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::difference":["difference","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::drain":["drain","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::drain_filter":["drain_filter","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::get":["get","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::get_or_insert":["get_or_insert","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::get_or_insert_owned":["get_or_insert_owned","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::get_or_insert_with":["get_or_insert_with","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::hasher":["hasher","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::insert":["insert","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::intersection":["intersection","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::is_disjoint":["is_disjoint","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::is_empty":["is_empty","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::is_subset":["is_subset","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::is_superset":["is_superset","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::iter":["iter","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::len":["len","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::remove":["remove","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::replace":["replace","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::reserve":["reserve","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::retain":["retain","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::shrink_to":["shrink_to","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::shrink_to_fit":["shrink_to_fit","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::symmetric_difference":["symmetric_difference","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::take":["take","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::try_reserve":["try_reserve","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::union":["union","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::with_capacity_and_hasher":["with_capacity_and_hasher","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T, S>::with_hasher":["with_hasher","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T>::new":["new","Real(LocalPath(\"src/set.rs\"))",""],"set::HashSet::<T>::with_capacity":["with_capacity","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance":["assert_covariance","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::difference":["difference","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::drain":["drain","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::intersection":["intersection","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::into_iter":["into_iter","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::iter":["iter","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::set":["set","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::symmetric_difference":["symmetric_difference","Real(LocalPath(\"src/set.rs\"))",""],"set::assert_covariance::union":["union","Real(LocalPath(\"src/set.rs\"))",""]},"trait_to_struct":{"core::clone::Clone":["TryReserveError","map::HashMap","map::Iter","map::Keys","map::Values","raw::Bucket","raw::Fallibility","raw::RawIter","raw::RawIterRange","raw::RawTable","raw::bitmask::BitMask","raw::sse2::Group","set::Difference","set::HashSet","set::Intersection","set::Iter","set::SymmetricDifference","set::Union"],"core::cmp::Eq":["TryReserveError","map::HashMap","set::HashSet"],"core::cmp::PartialEq":["TryReserveError","map::HashMap","set::HashSet"],"core::default::Default":["map::HashMap","set::HashSet"],"core::fmt::Debug":["TryReserveError","map::Drain","map::Entry","map::HashMap","map::IntoIter","map::Iter","map::IterMut","map::Keys","map::OccupiedEntry","map::RawEntryBuilder","map::RawEntryBuilderMut","map::RawEntryMut","map::RawOccupiedEntryMut","map::RawVacantEntryMut","map::VacantEntry","map::Values","map::ValuesMut","set::Difference","set::Drain","set::HashSet","set::Intersection","set::IntoIter","set::Iter","set::SymmetricDifference","set::Union"],"core::iter::ExactSizeIterator":["map::Drain","map::IntoIter","map::Iter","map::IterMut","map::Keys","map::Values","map::ValuesMut","raw::RawDrain","raw::RawIntoIter","raw::RawIter","set::Drain","set::IntoIter","set::Iter"],"core::iter::Extend":["map::HashMap","set::HashSet"],"core::iter::FromIterator":["map::HashMap","set::HashSet"],"core::iter::FusedIterator":["map::Drain","map::DrainFilter","map::IntoIter","map::Iter","map::IterMut","map::Keys","map::Values","map::ValuesMut","raw::RawDrain","raw::RawIntoIter","raw::RawIter","raw::RawIterRange","set::Difference","set::Drain","set::DrainFilter","set::Intersection","set::IntoIter","set::Iter","set::SymmetricDifference","set::Union"],"core::iter::IntoIterator":["map::HashMap","raw::RawTable","raw::bitmask::BitMask","set::HashSet"],"core::iter::Iterator":["map::Drain","map::DrainFilter","map::IntoIter","map::Iter","map::IterMut","map::Keys","map::Values","map::ValuesMut","raw::ProbeSeq","raw::RawDrain","raw::RawIntoIter","raw::RawIter","raw::RawIterHash","raw::RawIterRange","raw::bitmask::BitMaskIter","set::Difference","set::Drain","set::DrainFilter","set::Intersection","set::IntoIter","set::Iter","set::SymmetricDifference","set::Union"],"core::marker::Copy":["raw::Fallibility","raw::bitmask::BitMask","raw::sse2::Group"],"core::marker::Send":["map::IterMut","map::OccupiedEntry","map::RawOccupiedEntryMut","raw::Bucket","raw::RawDrain","raw::RawIntoIter","raw::RawIterRange","raw::RawTable"],"core::marker::StructuralEq":["TryReserveError"],"core::marker::StructuralPartialEq":["TryReserveError"],"core::marker::Sync":["map::OccupiedEntry","map::RawOccupiedEntryMut","raw::RawDrain","raw::RawIntoIter","raw::RawIterRange","raw::RawTable"],"core::ops::Deref":["scopeguard::ScopeGuard"],"core::ops::DerefMut":["scopeguard::ScopeGuard"],"core::ops::Drop":["map::ConsumeAllOnDrop","map::DrainFilter","raw::RawDrain","raw::RawIntoIter","raw::RawTable","scopeguard::ScopeGuard","set::DrainFilter"],"core::ops::Index":["map::HashMap"],"raw::RawTableClone":["raw::RawTable"]},"type_to_def_path":{"TryReserveError":"TryReserveError","map::ConsumeAllOnDrop<'a, T>":"map::ConsumeAllOnDrop","map::Drain<'a, K, V>":"map::Drain","map::DrainFilter<'a, K, V, F>":"map::DrainFilter","map::DrainFilterInner<'a, K, V>":"map::DrainFilterInner","map::Entry<'a, K, V, S>":"map::Entry","map::HashMap<K, V, S>":"map::HashMap","map::IntoIter<K, V>":"map::IntoIter","map::Iter<'a, K, V>":"map::Iter","map::IterMut<'a, K, V>":"map::IterMut","map::Keys<'a, K, V>":"map::Keys","map::OccupiedEntry<'a, K, V, S>":"map::OccupiedEntry","map::RawEntryBuilder<'a, K, V, S>":"map::RawEntryBuilder","map::RawEntryBuilderMut<'a, K, V, S>":"map::RawEntryBuilderMut","map::RawEntryMut<'a, K, V, S>":"map::RawEntryMut","map::RawOccupiedEntryMut<'a, K, V, S>":"map::RawOccupiedEntryMut","map::RawVacantEntryMut<'a, K, V, S>":"map::RawVacantEntryMut","map::VacantEntry<'a, K, V, S>":"map::VacantEntry","map::Values<'a, K, V>":"map::Values","map::ValuesMut<'a, K, V>":"map::ValuesMut","raw::Bucket<T>":"raw::Bucket","raw::Fallibility":"raw::Fallibility","raw::ProbeSeq":"raw::ProbeSeq","raw::RawDrain<'a, T>":"raw::RawDrain","raw::RawIntoIter<T>":"raw::RawIntoIter","raw::RawIter<T>":"raw::RawIter","raw::RawIterHash<'a, T>":"raw::RawIterHash","raw::RawIterRange<T>":"raw::RawIterRange","raw::RawTable<T>":"raw::RawTable","raw::bitmask::BitMask":"raw::bitmask::BitMask","raw::bitmask::BitMaskIter":"raw::bitmask::BitMaskIter","raw::sse2::Group":"raw::sse2::Group","raw::sse2::Group::static_empty::AlignedBytes":"raw::sse2::Group::static_empty::AlignedBytes","scopeguard::ScopeGuard<T, F>":"scopeguard::ScopeGuard","set::Difference<'a, T, S>":"set::Difference","set::Drain<'a, K>":"set::Drain","set::DrainFilter<'a, K, F>":"set::DrainFilter","set::HashSet<T, S>":"set::HashSet","set::Intersection<'a, T, S>":"set::Intersection","set::IntoIter<K>":"set::IntoIter","set::Iter<'a, K>":"set::Iter","set::SymmetricDifference<'a, T, S>":"set::SymmetricDifference","set::Union<'a, T, S>":"set::Union"}}