{"dependencies":{"<A as view::AsBits<T>>::as_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<A as view::AsBitsMut<T>>::as_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<T as view::BitView>::const_elts":[],"<T as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<T as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 0] as view::BitView>::const_elts":[],"<[T; 0] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 0] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 10] as view::BitView>::const_elts":[],"<[T; 10] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 10] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 11] as view::BitView>::const_elts":[],"<[T; 11] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 11] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 12] as view::BitView>::const_elts":[],"<[T; 12] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 12] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 13] as view::BitView>::const_elts":[],"<[T; 13] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 13] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 14] as view::BitView>::const_elts":[],"<[T; 14] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 14] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 15] as view::BitView>::const_elts":[],"<[T; 15] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 15] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 16] as view::BitView>::const_elts":[],"<[T; 16] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 16] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 17] as view::BitView>::const_elts":[],"<[T; 17] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 17] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 18] as view::BitView>::const_elts":[],"<[T; 18] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 18] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 19] as view::BitView>::const_elts":[],"<[T; 19] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 19] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 1] as view::BitView>::const_elts":[],"<[T; 1] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 1] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 20] as view::BitView>::const_elts":[],"<[T; 20] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 20] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 21] as view::BitView>::const_elts":[],"<[T; 21] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 21] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 22] as view::BitView>::const_elts":[],"<[T; 22] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 22] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 23] as view::BitView>::const_elts":[],"<[T; 23] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 23] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 24] as view::BitView>::const_elts":[],"<[T; 24] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 24] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 25] as view::BitView>::const_elts":[],"<[T; 25] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 25] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 26] as view::BitView>::const_elts":[],"<[T; 26] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 26] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 27] as view::BitView>::const_elts":[],"<[T; 27] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 27] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 28] as view::BitView>::const_elts":[],"<[T; 28] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 28] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 29] as view::BitView>::const_elts":[],"<[T; 29] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 29] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 2] as view::BitView>::const_elts":[],"<[T; 2] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 2] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 30] as view::BitView>::const_elts":[],"<[T; 30] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 30] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 31] as view::BitView>::const_elts":[],"<[T; 31] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 31] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 32] as view::BitView>::const_elts":[],"<[T; 32] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 32] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 33] as view::BitView>::const_elts":[],"<[T; 33] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 33] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 34] as view::BitView>::const_elts":[],"<[T; 34] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 34] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 35] as view::BitView>::const_elts":[],"<[T; 35] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 35] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 36] as view::BitView>::const_elts":[],"<[T; 36] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 36] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 37] as view::BitView>::const_elts":[],"<[T; 37] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 37] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 38] as view::BitView>::const_elts":[],"<[T; 38] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 38] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 39] as view::BitView>::const_elts":[],"<[T; 39] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 39] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 3] as view::BitView>::const_elts":[],"<[T; 3] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 3] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 40] as view::BitView>::const_elts":[],"<[T; 40] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 40] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 41] as view::BitView>::const_elts":[],"<[T; 41] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 41] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 42] as view::BitView>::const_elts":[],"<[T; 42] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 42] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 43] as view::BitView>::const_elts":[],"<[T; 43] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 43] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 44] as view::BitView>::const_elts":[],"<[T; 44] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 44] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 45] as view::BitView>::const_elts":[],"<[T; 45] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 45] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 46] as view::BitView>::const_elts":[],"<[T; 46] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 46] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 47] as view::BitView>::const_elts":[],"<[T; 47] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 47] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 48] as view::BitView>::const_elts":[],"<[T; 48] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 48] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 49] as view::BitView>::const_elts":[],"<[T; 49] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 49] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 4] as view::BitView>::const_elts":[],"<[T; 4] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 4] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 50] as view::BitView>::const_elts":[],"<[T; 50] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 50] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 51] as view::BitView>::const_elts":[],"<[T; 51] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 51] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 52] as view::BitView>::const_elts":[],"<[T; 52] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 52] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 53] as view::BitView>::const_elts":[],"<[T; 53] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 53] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 54] as view::BitView>::const_elts":[],"<[T; 54] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 54] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 55] as view::BitView>::const_elts":[],"<[T; 55] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 55] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 56] as view::BitView>::const_elts":[],"<[T; 56] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 56] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 57] as view::BitView>::const_elts":[],"<[T; 57] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 57] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 58] as view::BitView>::const_elts":[],"<[T; 58] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 58] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 59] as view::BitView>::const_elts":[],"<[T; 59] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 59] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 5] as view::BitView>::const_elts":[],"<[T; 5] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 5] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 60] as view::BitView>::const_elts":[],"<[T; 60] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 60] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 61] as view::BitView>::const_elts":[],"<[T; 61] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 61] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 62] as view::BitView>::const_elts":[],"<[T; 62] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 62] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 63] as view::BitView>::const_elts":[],"<[T; 63] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 63] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 64] as view::BitView>::const_elts":[],"<[T; 64] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 64] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 6] as view::BitView>::const_elts":[],"<[T; 6] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 6] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 7] as view::BitView>::const_elts":[],"<[T; 7] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 7] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 8] as view::BitView>::const_elts":[],"<[T; 8] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 8] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 9] as view::BitView>::const_elts":[],"<[T; 9] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T; 9] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T] as view::BitView>::const_elts":[],"<[T] as view::BitView>::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<[T] as view::BitView>::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<array::BitArray<O, V> as field::BitField>::load_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"<array::BitArray<O, V> as field::BitField>::load_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"<array::BitArray<O, V> as field::BitField>::store_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"<array::BitArray<O, V> as field::BitField>::store_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"<array::BitArray<O, V> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"<array::traits::TryFromBitSliceError as std::clone::Clone>::clone":["array::traits::TryFromBitSliceError"],"<array::traits::TryFromBitSliceError as std::fmt::Debug>::fmt":["array::traits::TryFromBitSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<array::traits::TryFromBitSliceError as std::fmt::Display>::fmt":["array::traits::TryFromBitSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<boxed::BitBox<O, T> as field::BitField>::load_be":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<boxed::BitBox<O, T> as field::BitField>::load_le":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<boxed::BitBox<O, T> as field::BitField>::store_be":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<boxed::BitBox<O, T> as field::BitField>::store_le":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::BitDomain<'_, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::BitDomain<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::BitDomainMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::fmt::Binary>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::fmt::LowerHex>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::fmt::Octal>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::fmt::UpperHex>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'_, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'a, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'a, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::Domain<'a, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<domain::DomainMut<'a, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<index::BitIdx<M> as std::clone::Clone>::clone":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitIdx<M> as std::cmp::Eq>::assert_receiver_is_total_eq":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitIdx<M> as std::cmp::Ord>::cmp":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cmp::Ordering","std::marker::PhantomData","std::marker::Sized"],"<index::BitIdx<M> as std::cmp::PartialEq>::eq":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitIdx<M> as std::cmp::PartialOrd>::partial_cmp":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized","std::option::Option"],"<index::BitIdx<M> as std::default::Default>::default":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitIdx<M> as std::fmt::Binary>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitIdx<M> as std::fmt::Debug>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitIdx<M> as std::fmt::Display>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitIdx<M> as std::hash::Hash>::hash":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized"],"<index::BitMask<M> as std::clone::Clone>::clone":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::cmp::Eq>::assert_receiver_is_total_eq":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::cmp::Ord>::cmp":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cmp::Ordering","std::marker::Sized"],"<index::BitMask<M> as std::cmp::PartialEq>::eq":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::cmp::PartialOrd>::partial_cmp":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized","std::option::Option"],"<index::BitMask<M> as std::default::Default>::default":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::fmt::Debug>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<index::BitMask<M> as std::fmt::Display>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<index::BitMask<M> as std::hash::Hash>::hash":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::hash::Hasher","std::marker::Sized"],"<index::BitMask<M> as std::iter::Sum<index::BitSel<M>>>::sum":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitMask","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<index::BitMask<M> as std::ops::BitAnd<M>>::bitand":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::ops::BitOr<M>>::bitor":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitMask<M> as std::ops::Not>::not":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitPos<M> as std::clone::Clone>::clone":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitPos<M> as std::cmp::Eq>::assert_receiver_is_total_eq":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitPos<M> as std::cmp::Ord>::cmp":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cmp::Ordering","std::marker::PhantomData","std::marker::Sized"],"<index::BitPos<M> as std::cmp::PartialEq>::eq":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitPos<M> as std::cmp::PartialOrd>::partial_cmp":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized","std::option::Option"],"<index::BitPos<M> as std::default::Default>::default":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitPos<M> as std::fmt::Debug>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitPos<M> as std::hash::Hash>::hash":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized"],"<index::BitSel<M> as std::clone::Clone>::clone":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitSel<M> as std::cmp::Eq>::assert_receiver_is_total_eq":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitSel<M> as std::cmp::Ord>::cmp":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cmp::Ordering","std::marker::Sized"],"<index::BitSel<M> as std::cmp::PartialEq>::eq":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitSel<M> as std::cmp::PartialOrd>::partial_cmp":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized","std::option::Option"],"<index::BitSel<M> as std::default::Default>::default":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"<index::BitSel<M> as std::fmt::Debug>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<index::BitSel<M> as std::fmt::Display>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<index::BitSel<M> as std::hash::Hash>::hash":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::hash::Hasher","std::marker::Sized"],"<index::BitTail<M> as std::clone::Clone>::clone":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitTail<M> as std::cmp::Eq>::assert_receiver_is_total_eq":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitTail<M> as std::cmp::Ord>::cmp":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cmp::Ordering","std::marker::PhantomData","std::marker::Sized"],"<index::BitTail<M> as std::cmp::PartialEq>::eq":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitTail<M> as std::cmp::PartialOrd>::partial_cmp":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized","std::option::Option"],"<index::BitTail<M> as std::default::Default>::default":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<index::BitTail<M> as std::fmt::Debug>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitTail<M> as std::fmt::Display>::fmt":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result"],"<index::BitTail<M> as std::hash::Hash>::hash":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized"],"<order::Lsb0 as order::BitOrder>::at":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<order::Lsb0 as order::BitOrder>::mask":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<order::Lsb0 as order::BitOrder>::select":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<order::Lsb0 as std::clone::Clone>::clone":["order::Lsb0"],"<order::Lsb0 as std::cmp::Eq>::assert_receiver_is_total_eq":["order::Lsb0"],"<order::Lsb0 as std::cmp::Ord>::cmp":["order::Lsb0","std::cmp::Ordering"],"<order::Lsb0 as std::cmp::PartialEq>::eq":["order::Lsb0"],"<order::Lsb0 as std::cmp::PartialOrd>::partial_cmp":["order::Lsb0","std::marker::Sized","std::option::Option"],"<order::Lsb0 as std::default::Default>::default":["order::Lsb0"],"<order::Lsb0 as std::fmt::Debug>::fmt":["order::Lsb0","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<order::Lsb0 as std::hash::Hash>::hash":["order::Lsb0","std::hash::Hasher","std::marker::Sized"],"<order::Msb0 as order::BitOrder>::at":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<order::Msb0 as order::BitOrder>::mask":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<order::Msb0 as order::BitOrder>::select":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"<order::Msb0 as std::clone::Clone>::clone":["order::Msb0"],"<order::Msb0 as std::cmp::Eq>::assert_receiver_is_total_eq":["order::Msb0"],"<order::Msb0 as std::cmp::Ord>::cmp":["order::Msb0","std::cmp::Ordering"],"<order::Msb0 as std::cmp::PartialEq>::eq":["order::Msb0"],"<order::Msb0 as std::cmp::PartialOrd>::partial_cmp":["order::Msb0","std::marker::Sized","std::option::Option"],"<order::Msb0 as std::default::Default>::default":["order::Msb0"],"<order::Msb0 as std::fmt::Debug>::fmt":["order::Msb0","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<order::Msb0 as std::hash::Hash>::hash":["order::Msb0","std::hash::Hasher","std::marker::Sized"],"<pointer::Address<T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::cmp::Eq>::assert_receiver_is_total_eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::cmp::Ord>::cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::cmp::Ordering","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::cmp::PartialEq>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::cmp::PartialOrd>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::convert::From<&T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::convert::From<&mut T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::convert::From<*const T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::convert::From<*mut T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::fmt::Pointer>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::Address<T> as std::hash::Hash>::hash":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::cmp::Eq>::assert_receiver_is_total_eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::cmp::PartialEq<pointer::BitPtr<U>>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::default::Default>::default":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::fmt::Pointer>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<pointer::BitPtr<T> as std::hash::Hash>::hash":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'_, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'a, O, T, P> as slice::iter::SplitIter>::finish":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'a, O, T, P> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'a, O, T, P> as slice::iter::SplitIter>::finish":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'a, O, T, P> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::proxy::BitMut<'_, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Deref>::deref":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::proxy::BitMut<'_, O, T> as std::ops::DerefMut>::deref_mut":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Drop>::drop":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"<slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::Range","std::option::Option"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::Range","std::option::Option"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::marker::Sized","std::ops::Range"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::marker::Sized","std::ops::Range"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["std::marker::Sized","std::ops::Range"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::marker::Sized","std::ops::Range"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::RangeFrom","std::option::Option"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::RangeFrom","std::option::Option"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::marker::Sized","std::ops::RangeFrom"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::marker::Sized","std::ops::RangeFrom"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["std::marker::Sized","std::ops::RangeFrom"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::marker::Sized","std::ops::RangeFrom"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::RangeFull","std::option::Option"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::RangeFull","std::option::Option"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::ops::RangeFull"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::ops::RangeFull"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index":["std::ops::RangeFull"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::ops::RangeFull"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::RangeInclusive","std::option::Option"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::RangeInclusive","std::option::Option"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::marker::Sized","std::ops::RangeInclusive"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::marker::Sized","std::ops::RangeInclusive"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["std::marker::Sized","std::ops::RangeInclusive"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::marker::Sized","std::ops::RangeInclusive"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::RangeTo","std::option::Option"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::RangeTo","std::option::Option"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::marker::Sized","std::ops::RangeTo"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::marker::Sized","std::ops::RangeTo"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["std::marker::Sized","std::ops::RangeTo"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::marker::Sized","std::ops::RangeTo"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["std::marker::Sized","std::ops::RangeToInclusive","std::option::Option"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["std::marker::Sized","std::ops::RangeToInclusive","std::option::Option"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["std::marker::Sized","std::ops::RangeToInclusive"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["std::marker::Sized","std::ops::RangeToInclusive"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["std::marker::Sized","std::ops::RangeToInclusive"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["std::marker::Sized","std::ops::RangeToInclusive"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"<vec::BitVec<O, T> as field::BitField>::load_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"<vec::BitVec<O, T> as field::BitField>::load_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"<vec::BitVec<O, T> as field::BitField>::store_be":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"<vec::BitVec<O, T> as field::BitField>::store_le":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'_, O, T> as std::ops::Drop>::drop":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::Drain<'a, O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"<vec::iter::FillStatus as std::clone::Clone>::clone":["vec::iter::FillStatus"],"<vec::iter::FillStatus as std::cmp::Eq>::assert_receiver_is_total_eq":["vec::iter::FillStatus"],"<vec::iter::FillStatus as std::cmp::Ord>::cmp":["std::cmp::Ordering","vec::iter::FillStatus"],"<vec::iter::FillStatus as std::cmp::PartialEq>::eq":["vec::iter::FillStatus"],"<vec::iter::FillStatus as std::cmp::PartialOrd>::partial_cmp":["std::marker::Sized","std::option::Option","vec::iter::FillStatus"],"<vec::iter::FillStatus as std::fmt::Debug>::fmt":["std::fmt::Formatter","std::marker::Sized","std::result::Result","vec::iter::FillStatus"],"<vec::iter::IntoIter<O, T> as std::clone::Clone>::clone":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::last":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::nth":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::next_back":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::nth_back":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::ExactSizeIterator>::len":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::count":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::next":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::size_hint":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'_, O, T, I> as std::ops::Drop>::drop":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"<vec::iter::Splice<'a, O, T, I> as std::fmt::Debug>::fmt":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"access::BitAccess::clear_bit":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::clear_bits":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"access::BitAccess::get_bit":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::get_bits":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"access::BitAccess::get_writer":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::get_writers":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"access::BitAccess::invert_bit":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::invert_bits":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"access::BitAccess::load_value":[],"access::BitAccess::set_bit":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::set_bits":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"access::BitAccess::store_value":[],"access::BitAccess::write_bit":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"access::BitAccess::write_bits":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"array::BitArray":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::as_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::BitArray::<O, V>::as_mut_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::BitArray::<O, V>::as_mut_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::as_raw_mut_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::as_raw_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::as_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::unwrap":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::BitArray::<O, V>::zeroed":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitAnd<Rhs> for array::BitArray<O, V>>::bitand":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitAndAssign<Rhs> for array::BitArray<O, V>>::bitand_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitOr<Rhs> for array::BitArray<O, V>>::bitor":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitOrAssign<Rhs> for array::BitArray<O, V>>::bitor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitXor<Rhs> for array::BitArray<O, V>>::bitxor":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::BitXorAssign<Rhs> for array::BitArray<O, V>>::bitxor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::Deref for array::BitArray<O, V>>::deref":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::DerefMut for array::BitArray<O, V>>::deref_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::Index<Idx> for array::BitArray<O, V>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::IndexMut<Idx> for array::BitArray<O, V>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::ops::<impl std::ops::Not for array::BitArray<O, V>>::not":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::borrow::Borrow<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::cmp::Ord for array::BitArray<O, V>>::cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cmp::Ordering","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::cmp::PartialEq<Rhs> for array::BitArray<O, V>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::cmp::PartialEq<array::BitArray<O, V>> for slice::BitSlice<O, T>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::cmp::PartialOrd<Rhs> for array::BitArray<O, V>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","std::option::Option","view::BitView"],"array::traits::<impl std::cmp::PartialOrd<array::BitArray<O, V>> for slice::BitSlice<O, T>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::convert::AsMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::convert::AsRef<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_ref":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::convert::From<V> for array::BitArray<O, V>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::convert::TryFrom<&'a mut slice::BitSlice<O, <V as view::BitView>::Store>> for &'a mut array::BitArray<O, V>>::try_from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::convert::TryFrom<&'a slice::BitSlice<O, <V as view::BitView>::Store>> for &'a array::BitArray<O, V>>::try_from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::convert::TryFrom<&slice::BitSlice<O2, T>> for array::BitArray<O, V>>::try_from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"array::traits::<impl std::default::Default for array::BitArray<O, V>>::default":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::fmt::Binary for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::fmt::Debug for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::fmt::Display for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::fmt::LowerHex for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::fmt::Octal for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::fmt::UpperHex for array::BitArray<O, V>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","view::BitView"],"array::traits::<impl std::hash::Hash for array::BitArray<O, V>>::hash":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::iter::IntoIterator for &'a array::BitArray<O, V>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::<impl std::iter::IntoIterator for &'a mut array::BitArray<O, V>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::marker::PhantomData","std::marker::Sized","view::BitView"],"array::traits::TryFromBitSliceError":["array::traits::TryFromBitSliceError"],"array::traits::TryFromBitSliceError::err":["std::marker::Sized","std::result::Result"],"boxed::BitBox":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::as_bitslice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::as_mut_bitslice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::as_mut_slice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::as_slice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::bitptr":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::from_bitslice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::from_boxed_slice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::boxed::Box","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::into_boxed_slice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::boxed::Box","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::BitBox::<O, T>::try_from_boxed_slice":["std::alloc::Allocator","std::boxed::Box","std::marker::Sized","std::result::Result"],"boxed::BitBox::<O, T>::with_box":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnOnce","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::from_raw":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::into_bitvec":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::into_raw":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::leak":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::new":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::api::<impl boxed::BitBox<O, T>>::pin":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::marker::Unpin","std::pin::Pin","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitAnd<Rhs> for boxed::BitBox<O, T>>::bitand":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitAndAssign<Rhs> for boxed::BitBox<O, T>>::bitand_assign":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitOr<Rhs> for boxed::BitBox<O, T>>::bitor":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitOrAssign<Rhs> for boxed::BitBox<O, T>>::bitor_assign":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitXor<Rhs> for boxed::BitBox<O, T>>::bitxor":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::BitXorAssign<Rhs> for boxed::BitBox<O, T>>::bitxor_assign":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::Deref for boxed::BitBox<O, T>>::deref":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::DerefMut for boxed::BitBox<O, T>>::deref_mut":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::Drop for boxed::BitBox<O, T>>::drop":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::Index<Idx> for boxed::BitBox<O, T>>::index":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::IndexMut<Idx> for boxed::BitBox<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::ops::<impl std::ops::Not for boxed::BitBox<O, T>>::not":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow_mut":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::clone::Clone for boxed::BitBox<O, T>>::clone":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::Ord for boxed::BitBox<O, T>>::cmp":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::cmp::Ordering","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialEq<Rhs> for boxed::BitBox<O, T>>::eq":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialOrd<Rhs> for boxed::BitBox<O, T>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::cmp::PartialOrd<boxed::BitBox<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_mut":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_ref":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::from":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::convert::From<vec::BitVec<O, T>> for boxed::BitBox<O, T>>::from":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"boxed::traits::<impl std::convert::Into<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::into":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::boxed::Box","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::convert::TryFrom<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::try_from":["std::alloc::Allocator","std::boxed::Box","std::marker::Sized","std::result::Result"],"boxed::traits::<impl std::default::Default for boxed::BitBox<O, T>>::default":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::Binary for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::Debug for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::Display for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::LowerHex for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::Octal for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::Pointer for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::fmt::UpperHex for boxed::BitBox<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"boxed::traits::<impl std::hash::Hash for boxed::BitBox<O, T>>::hash":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"devel::accessor":["std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::alias_mask":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::alias_mem":["std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::assert_range":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"devel::load_aliased_local":["std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::mem_mut":["std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::nonnull_slice_to_base":["std::marker::Sized","std::ptr::NonNull"],"devel::normalize_range":["std::marker::Sized","std::ops::Range","std::ops::RangeBounds"],"devel::remove_alias":["std::cell::Cell","std::marker::Sized","store::BitStore"],"devel::remove_bitptr_alias":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"devel::remove_mem":["std::cell::Cell","std::marker::Sized","store::BitStore"],"domain::BitDomain":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::empty":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::enclave":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::major":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::minor":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::partial_head":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::partial_tail":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::region":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomain::<'a, O, T>::spanning":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::empty":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::enclave":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::major":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::minor":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::partial_head":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::partial_tail":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::region":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::BitDomainMut::<'a, O, T>::spanning":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::empty":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::enclave":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::major":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::minor":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::new":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::partial_head":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::partial_tail":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::region":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::Domain::<'a, T>::spanning":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::empty":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::enclave":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::major":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::minor":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::new":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::partial_head":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::partial_tail":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::region":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"domain::DomainMut::<'a, T>::spanning":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"field::BitField::load":["mem::BitMemory","std::marker::Sized"],"field::BitField::load_be":["mem::BitMemory","std::marker::Sized"],"field::BitField::load_le":["mem::BitMemory","std::marker::Sized"],"field::BitField::store":["mem::BitMemory","std::marker::Sized"],"field::BitField::store_be":["mem::BitMemory","std::marker::Sized"],"field::BitField::store_le":["mem::BitMemory","std::marker::Sized"],"field::check":[],"field::get":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cell::Cell","std::marker::Sized","store::BitStore"],"field::io::<impl std::io::Read for &'a slice::BitSlice<O, T>>::read":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::flush":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::write":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::flush":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::write":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"field::resize":["mem::BitMemory","std::marker::Sized"],"field::resize_inner":["std::marker::Sized"],"field::set":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::cell::Cell","std::marker::Sized","store::BitStore"],"index::BitIdx":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::decr":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::incr":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::mask":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitMask","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::new":["std::marker::Sized","std::option::Option"],"index::BitIdx::<M>::new_unchecked":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::offset":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::position":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitPos","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::range":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::range_all":[],"index::BitIdx::<M>::select":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitSel","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::span":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitIdx::<M>::value":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitMask":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitMask::<M>::combine":["funty::IsInteger","funty::IsUnsigned","index::BitMask","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitMask::<M>::insert":["funty::IsInteger","funty::IsUnsigned","index::BitMask","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitMask::<M>::new":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitMask::<M>::test":["funty::IsInteger","funty::IsUnsigned","index::BitMask","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitMask::<M>::value":["funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitPos":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitPos::<M>::mask":["funty::IsInteger","funty::IsUnsigned","index::BitMask","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitPos::<M>::new":["std::marker::Sized","std::option::Option"],"index::BitPos::<M>::new_unchecked":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitPos::<M>::select":["funty::IsInteger","funty::IsUnsigned","index::BitPos","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitPos::<M>::value":["funty::IsInteger","funty::IsUnsigned","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitSel":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitSel::<M>::mask":["funty::IsInteger","funty::IsUnsigned","index::BitMask","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitSel::<M>::new":["std::marker::Sized","std::option::Option"],"index::BitSel::<M>::new_unchecked":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitSel::<M>::range_all":[],"index::BitSel::<M>::value":["funty::IsInteger","funty::IsUnsigned","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::Sized"],"index::BitTail":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitTail::<M>::new_unchecked":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitTail::<M>::range_from":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitTail::<M>::span":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"index::BitTail::<M>::value":["funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"macros::internal::u8_from_be_bits":[],"macros::internal::u8_from_le_bits":[],"mem::aligned_to_size":["std::marker::Sized"],"mem::cmp_layout":["std::marker::Sized"],"mem::elts":["std::marker::Sized"],"order::BitOrder::at":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitPos","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"order::BitOrder::mask":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","funty::IsInteger","funty::IsUnsigned","index::BitMask","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"order::BitOrder::select":["funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitSel","mem::BitMemory","mem::seal::Sealed","radium::marker::BitOps","std::marker::PhantomData","std::marker::Sized"],"order::Lsb0":["order::Lsb0"],"order::Msb0":["order::Msb0"],"order::verify":["order::BitOrder","order::Lsb0","std::marker::Sized"],"order::verify_for_type":["mem::BitMemory","order::BitOrder","order::Lsb0","std::marker::Sized"],"pointer::Address":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::to_access":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::to_alias":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::to_const":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::to_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::Address::<T>::value":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::as_aliased_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::elements":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::from_bitslice_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::from_bitslice_ptr_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::head":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","pointer::BitPtr","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::incr_head":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::new":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::new_unchecked":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","pointer::BitPtr","radium::marker::BitOps","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::pointer":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::Address","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::raw_parts":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","pointer::Address","pointer::BitPtr","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::read":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::render":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::iter::IntoIterator","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"pointer::BitPtr::<T>::set_head":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","pointer::BitPtr","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::set_len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::set_pointer":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::tail":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","pointer::BitPtr","radium::marker::BitOps","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::to_bitslice_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::to_bitslice_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::to_bitslice_ptr_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::to_bitslice_ref":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::to_nonnull":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::uninhabited":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::convert::Into","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"pointer::BitPtr::<T>::write":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::alias":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::alias_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::all":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::any":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::as_aliased_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::as_mut_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::as_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::bit_domain":["<T as view::BitView>::T","array::BitArray","domain::BitDomain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::bit_domain_mut":["<T as view::BitView>::T","array::BitArray","domain::BitDomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::bitptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::copy_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::copy_within_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeBounds","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::count_ones":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::count_zeros":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::domain":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::domain_mut":["<T as view::BitView>::T","array::BitArray","domain::DomainMut","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::empty":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::empty_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::for_each":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::from_aliased_slice_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::from_element":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::from_element_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::from_slice":["std::marker::Sized","std::option::Option"],"slice::BitSlice::<O, T>::from_slice_mut":["std::marker::Sized","std::option::Option"],"slice::BitSlice::<O, T>::from_slice_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::from_slice_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::not_all":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::not_any":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::set":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::set_all":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::set_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::some":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::split_at_aliased_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::split_at_aliased_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::split_at_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::split_at_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::swap_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::BitSlice::<O, T>::unalias_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::align_to":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::align_to_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::as_mut_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::as_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::chunks":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::contains":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::copy_within":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeBounds","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::ends_with":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::first":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::first_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::get":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::api::BitSliceIndex","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::get_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::api::BitSliceIndex","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::api::BitSliceIndex","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::api::BitSliceIndex","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::is_empty":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::iter":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::iter_mut":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::last_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::repeat":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::reverse":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rotate_left":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rotate_right":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rsplit":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rsplit_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_at":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_at_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_first":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_first_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_last":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_last_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::split_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::splitn":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::splitn_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::starts_with":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::swap":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::to_bitvec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::to_vec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"slice::api::<impl slice::BitSlice<O, T>>::windows":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::get":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::get_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::get_unchecked":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::get_unchecked_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::BitSliceIndex::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::from_mut":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::from_raw_parts":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::from_raw_parts_mut":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::api::from_ref":["<T as view::BitView>::T","array::BitArray","mem::BitMemory","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::bits_from_raw_parts":["mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::marker::Sized","std::option::Option","store::BitStore"],"slice::bits_from_raw_parts_mut":["mem::BitMemory","order::BitOrder","order::Lsb0","std::cell::Cell","std::marker::Sized","std::option::Option","store::BitStore"],"slice::iter::<impl std::iter::IntoIterator for &'a mut slice::BitSlice<O, T>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::<impl std::iter::IntoIterator for &'a slice::BitSlice<O, T>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Chunks":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Chunks::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Chunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExact":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExact::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExact::<'a, O, T>::remainder":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExactMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExactMut::<'a, O, T>::into_remainder":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksExactMut::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::ChunksMut::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::ChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter::<'a, O, T>::as_bitslice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter::<'a, O, T>::as_slice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter::<'a, O, T>::inherent_is_empty":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter::<'a, O, T>::pop_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Iter::<'a, O, T>::pop_front":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut::<'a, O, T>::inherent_is_empty":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut::<'a, O, T>::into_bitslice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut::<'a, O, T>::into_slice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut::<'a, O, T>::pop_back":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::IterMut::<'a, O, T>::pop_front":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::IterMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunks":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunks::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunks","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExact":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExact::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExact::<'a, O, T>::remainder":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExact","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExactMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExactMut::<'a, O, T>::into_remainder":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksExactMut::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksExactMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RChunksMut::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RChunksMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplit":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplit::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitMut::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitN":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitN::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplit","slice::iter::RSplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitNMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::RSplitNMut::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::RSplitMut","slice::iter::RSplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Split":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Split::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitIter::finish":["std::marker::Sized","std::option::Option"],"slice::iter::SplitMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitMut::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitN":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitN::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Split","slice::iter::SplitN","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitNMut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::SplitNMut::<'a, O, T, P>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::SplitMut","slice::iter::SplitNMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Windows":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::iter::Windows::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","slice::iter::Windows","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::BitAndAssign<Rhs> for slice::BitSlice<O, T>>::bitand_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::BitOrAssign<Rhs> for slice::BitSlice<O, T>>::bitor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::BitXorAssign<Rhs> for slice::BitSlice<O, T>>::bitxor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeFrom","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::RangeFull> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeFull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeInclusive","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeTo","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeToInclusive","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Index<usize> for slice::BitSlice<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeFrom","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFull> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeFull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeInclusive","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeTo","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::RangeToInclusive","store::BitStore","store::seal::Sealed","view::BitView"],"slice::ops::<impl std::ops::Not for &'a mut slice::BitSlice<O, T>>::not":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::proxy::BitMut":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::proxy::BitMut::<'_, O, T>::new_unchecked":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::proxy::BitMut::<'_, O, T>::set":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::proxy::BitMut::<'_, O, T>::write":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::proxy::BitMut","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::borrow::ToOwned for slice::BitSlice<O, T>>::to_owned":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::Ord for slice::BitSlice<O, T>>::cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::cmp::Ordering","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialEq<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialEq<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::convert::TryFrom<&'a [T]> for &'a slice::BitSlice<O, T>>::try_from":["std::marker::Sized","std::result::Result"],"slice::traits::<impl std::default::Default for &mut slice::BitSlice<O, T>>::default":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::default::Default for &slice::BitSlice<O, T>>::default":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq":["slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq"],"slice::traits::<impl std::fmt::Debug for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::Display for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq":["slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq":["slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq"],"slice::traits::<impl std::fmt::Pointer for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::result::Result","store::BitStore","store::seal::Sealed","view::BitView"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq":["slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq"],"slice::traits::<impl std::hash::Hash for slice::BitSlice<O, T>>::hash":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"vec::BitVec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::as_bitptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::as_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::as_mut_bitptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::as_mut_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::bitptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","pointer::BitPtr","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::elements":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::extend_from_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::force_align":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::from_bitslice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::from_vec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::vec::Vec","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::into_boxed_bitslice":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::into_vec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::vec::Vec","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::repeat":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::set_elements":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::BitVec::<O, T>::try_from_vec":["std::alloc::Allocator","std::marker::Sized","std::result::Result","std::vec::Vec"],"vec::BitVec::<O, T>::with_vec":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnOnce","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::append":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::as_mut_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::as_mut_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::as_ptr":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::as_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::capacity":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::clear":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::drain":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ops::RangeBounds","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::Drain","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::extend_from_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::from_raw_parts":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::insert":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::into_boxed_slice":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::boxed::Box","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::new":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::pop":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::push":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::remove":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::reserve":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::reserve_exact":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::resize":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::resize_with":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::retain":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::FnMut","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::set_len":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::shrink_to_fit":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::splice":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ops::RangeBounds","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::Drain","vec::iter::Splice","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::split_off":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::swap_remove":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::truncate":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::api::<impl vec::BitVec<O, T>>::with_capacity":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::Extend<&'a bool> for vec::BitVec<O, T>>::extend":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::Extend<bool> for vec::BitVec<O, T>>::extend":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::FromIterator<&'a bool> for vec::BitVec<O, T>>::from_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::FromIterator<bool> for vec::BitVec<O, T>>::from_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::IntoIterator for &'a mut vec::BitVec<O, T>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::IntoIterator for &'a vec::BitVec<O, T>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::<impl std::iter::IntoIterator for vec::BitVec<O, T>>::into_iter":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::iter::Drain":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"vec::iter::Drain::<'a, O, T>::as_bitslice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"vec::iter::Drain::<'a, O, T>::fill":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::FillStatus","view::BitView"],"vec::iter::Drain::<'a, O, T>::move_tail":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","view::BitView"],"vec::iter::Drain::<'a, O, T>::new":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::ops::RangeBounds","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::Drain","view::BitView"],"vec::iter::FillStatus":["vec::iter::FillStatus"],"vec::iter::IntoIter":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"vec::iter::IntoIter::<O, T>::as_bitslice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"vec::iter::IntoIter::<O, T>::as_mut_bitslice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"vec::iter::IntoIter::<O, T>::as_mut_slice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"vec::iter::IntoIter::<O, T>::as_slice":["<T as view::BitView>::T","array::BitArray","funty::IsInteger","funty::IsUnsigned","index::BitIdx","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::BitSlice","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::IntoIter","view::BitView"],"vec::iter::Splice":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::iter::Drain","vec::iter::Splice","view::BitView"],"vec::iter::Splice::<'a, O, T, I>::new":["<T as view::BitView>::T","array::BitArray","domain::Domain","funty::IsInteger","funty::IsUnsigned","index::BitIdx","index::BitTail","mem::BitMemory","mem::seal::Sealed","order::BitOrder","order::Lsb0","radium::marker::BitOps","slice::iter::Iter","std::cell::Cell","std::fmt::Debug","std::iter::IntoIterator","std::iter::Iterator","std::marker::PhantomData","std::marker::Sized","std::ops::Range","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","vec::iter::Drain","vec::iter::Splice","view::BitView"],"vec::ops::<impl std::ops::BitAnd<Rhs> for vec::BitVec<O, T>>::bitand":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::BitAndAssign<Rhs> for vec::BitVec<O, T>>::bitand_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::BitOr<Rhs> for vec::BitVec<O, T>>::bitor":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::BitOrAssign<Rhs> for vec::BitVec<O, T>>::bitor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::BitXor<Rhs> for vec::BitVec<O, T>>::bitxor":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::BitXorAssign<Rhs> for vec::BitVec<O, T>>::bitxor_assign":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::Deref for vec::BitVec<O, T>>::deref":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::DerefMut for vec::BitVec<O, T>>::deref_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::Drop for vec::BitVec<O, T>>::drop":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::Index<Idx> for vec::BitVec<O, T>>::index":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::IndexMut<Idx> for vec::BitVec<O, T>>::index_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::ops::<impl std::ops::Not for vec::BitVec<O, T>>::not":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone_from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::Ord for vec::BitVec<O, T>>::cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::cmp::Ordering","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialEq<Rhs> for vec::BitVec<O, T>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialOrd<Rhs> for vec::BitVec<O, T>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::cmp::PartialOrd<vec::BitVec<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::option::Option","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_ref":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::From<&'a mut slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::From<boxed::BitBox<O, T>> for vec::BitVec<O, T>>::from":["<T as view::BitView>::T","array::BitArray","boxed::BitBox","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::Into<std::vec::Vec<T>> for vec::BitVec<O, T>>::into":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::alloc::Allocator","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::vec::Vec","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::convert::TryFrom<std::vec::Vec<T>> for vec::BitVec<O, T>>::try_from":["std::alloc::Allocator","std::marker::Sized","std::result::Result","std::vec::Vec"],"vec::traits::<impl std::default::Default for vec::BitVec<O, T>>::default":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::Binary for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::Debug for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::Display for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::LowerHex for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::Octal for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::Pointer for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::fmt::UpperHex for vec::BitVec<O, T>>::fmt":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::fmt::Formatter","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","std::result::Result","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"vec::traits::<impl std::hash::Hash for vec::BitVec<O, T>>::hash":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","std::cell::Cell","std::fmt::Debug","std::hash::Hasher","std::marker::PhantomData","std::marker::Sized","std::ptr::NonNull","store::BitStore","store::seal::Sealed","vec::BitVec","view::BitView"],"view::AsBits::as_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"view::AsBitsMut::as_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"view::BitView::bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"view::BitView::bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"view::BitView::const_bits":["std::marker::Sized"],"view::BitView::const_elts":["std::marker::Sized"],"view::BitView::view_bits":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"],"view::BitView::view_bits_mut":["<T as view::BitView>::T","array::BitArray","order::BitOrder","order::Lsb0","slice::BitSlice","std::cell::Cell","std::fmt::Debug","std::marker::PhantomData","std::marker::Sized","store::BitStore","store::seal::Sealed","view::BitView"]},"glob_path_import":{"prelude::macros":"prelude::","prelude::trait_methods":"prelude::base::","prelude::traits":"prelude::","prelude::types":"prelude::"},"self_to_fn":{"<A as view::AsBits<T>>::A":["impl<A, T> AsBits<T> for A\nwhere\n\tA: AsRef<[T]>,\n\tT: BitStore + BitMemory,\n{\n\t#[inline]\n\tfn as_bits<O>(&self) -> &BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tself.as_ref().view_bits::<O>()\n\t}\n}"],"<A as view::AsBitsMut<T>>::A":["impl<A, T> AsBitsMut<T> for A\nwhere\n\tA: AsMut<[T]>,\n\tT: BitStore + BitMemory,\n{\n\t#[inline]\n\tfn as_bits_mut<O>(&mut self) -> &mut BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tself.as_mut().view_bits_mut::<O>()\n\t}\n}"],"<R as access::BitAccess<M>>::R":["impl<M, R> BitAccess<M> for R\nwhere\n\tM: BitMemory,\n\tR: Debug + Radium<M>,\n{\n}"],"<T as view::BitView>::T":["impl<T> BitView for T\nwhere T: BitStore + BitMemory\n{\n\ttype Mem = T::Mem;\n\ttype Store = Self;\n\n\t#[inline(always)]\n\tfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder {\n\t\tBitSlice::from_element(self)\n\t}\n\n\t#[inline(always)]\n\tfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\twhere O: BitOrder {\n\t\tBitSlice::from_element_mut(self)\n\t}\n\n\t#[doc(hidden)]\n\t#[inline(always)]\n\tfn const_elts() -> usize {\n\t\t1\n\t}\n}"],"array::BitArray":["Clone","Copy","impl<O, O2, T, V> TryFrom<&'_ BitSlice<O2, T>> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tO2: BitOrder,\n\tT: BitStore,\n\tV: BitView + Sized,\n{\n\ttype Error = TryFromBitSliceError;\n\n\t#[inline]\n\tfn try_from(src: &BitSlice<O2, T>) -> Result<Self, Self::Error> {\n\t\tlet mut out = Self::zeroed();\n\t\tif src.len() != out.len() {\n\t\t\treturn Self::Error::err();\n\t\t}\n\t\tout.clone_from_bitslice(src);\n\t\tOk(out)\n\t}\n}","impl<O, V, Idx> Index<Idx> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: Index<Idx>,\n{\n\ttype Output = <BitSlice<O, V::Store> as Index<Idx>>::Output;\n\n\t#[inline]\n\tfn index(&self, index: Idx) -> &Self::Output {\n\t\tself.as_bitslice().index(index)\n\t}\n}","impl<O, V, Idx> IndexMut<Idx> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: IndexMut<Idx>,\n{\n\t#[inline]\n\tfn index_mut(&mut self, index: Idx) -> &mut Self::Output {\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}\n}","impl<O, V, Rhs> BitAnd<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitAndAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitand(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}\n}","impl<O, V, Rhs> BitAndAssign<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitAndAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitand_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}\n}","impl<O, V, Rhs> BitOr<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitOrAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}\n}","impl<O, V, Rhs> BitOrAssign<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitOrAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}\n}","impl<O, V, Rhs> BitXor<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitXorAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitxor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}\n}","impl<O, V, Rhs> BitXorAssign<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tBitSlice<O, V::Store>: BitXorAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitxor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}\n}","impl<O, V, Rhs> PartialEq<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tRhs: ?Sized,\n\tBitSlice<O, V::Store>: PartialEq<Rhs>,\n{\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tfn eq(&self, other: &Rhs) -> bool {\n\t\tself.as_bitslice() == other\n\t}\n}","impl<O, V, Rhs> PartialOrd<Rhs> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tRhs: ?Sized,\n\tBitSlice<O, V::Store>: PartialOrd<Rhs>,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering> {\n\t\tself.as_bitslice().partial_cmp(other)\n\t}\n}","impl<O, V> AsMut<BitSlice<O, V::Store>> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn as_mut(&mut self) -> &mut BitSlice<O, V::Store> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, V> AsRef<BitSlice<O, V::Store>> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn as_ref(&self) -> &BitSlice<O, V::Store> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, V> Binary for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, V> BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t/// Constructs a new `BitArray` with zeroed memory.\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn zeroed() -> Self {\n\t\tSelf {\n\t\t\t_ord: PhantomData,\n\t\t\tdata: unsafe { MaybeUninit::zeroed().assume_init() },\n\t\t}\n\t}\n\n\t/// Constructs a new `BitArray` from a data store.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t/// ```\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn new(data: V) -> Self {\n\t\tSelf {\n\t\t\t_ord: PhantomData,\n\t\t\tdata,\n\t\t}\n\t}\n\n\t/// Removes the bit-array wrapper, returning the contained data.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bitarr: BitArray<Local, [usize; 1]> = bitarr![0; 30];\n\t/// let native: [usize; 1] = bitarr.unwrap();\n\t/// ```\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn unwrap(self) -> V {\n\t\tself.data\n\t}\n\n\t/// Views the array as a bit-slice.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitslice(&self) -> &BitSlice<O, V::Store> {\n\t\tself.data.view_bits::<O>()\n\t}\n\n\t/// Views the array as a mutable bit-slice.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, V::Store> {\n\t\tself.data.view_bits_mut::<O>()\n\t}\n\n\t/// Views the array as a slice of its underlying elements.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_slice(&self) -> &[V::Store] {\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(\n\t\t\t\t&self.data as *const V as *const V::Store,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}\n\n\t/// Views the array as a mutable slice of its underlying elements.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_slice(&mut self) -> &mut [V::Store] {\n\t\tunsafe {\n\t\t\tslice::from_raw_parts_mut(\n\t\t\t\t&mut self.data as *mut V as *mut V::Store,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}\n\n\t/// Views the array as a slice of its raw underlying memory type.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_raw_slice(&self) -> &[V::Mem] {\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(\n\t\t\t\t&self.data as *const V as *const V::Mem,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}\n\n\t/// Views the array as a mutable slice of its raw underlying memory type.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_raw_mut_slice(&mut self) -> &mut [V::Mem] {\n\t\tunsafe {\n\t\t\tslice::from_raw_parts_mut(\n\t\t\t\t&mut self.data as *mut V as *mut V::Mem,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}\n}","impl<O, V> BitField for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView,\n\tBitSlice<O, V::Store>: BitField,\n{\n\t#[inline]\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_le()\n\t}\n\n\t#[inline]\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_be()\n\t}\n\n\t#[inline]\n\tfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_le(value)\n\t}\n\n\t#[inline]\n\tfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_be(value)\n\t}\n}","impl<O, V> Borrow<BitSlice<O, V::Store>> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn borrow(&self) -> &BitSlice<O, V::Store> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, V> BorrowMut<BitSlice<O, V::Store>> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn borrow_mut(&mut self) -> &mut BitSlice<O, V::Store> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, V> Debug for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tif fmt.alternate() {\n\t\t\tself.bitptr().render(\n\t\t\t\tfmt,\n\t\t\t\t\"Array\",\n\t\t\t\tSome(core::any::type_name::<O>()),\n\t\t\t\tNone,\n\t\t\t)?;\n\t\t}\n\t\tBinary::fmt(self, fmt)\n\t}\n}","impl<O, V> Default for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn default() -> Self {\n\t\tSelf::zeroed()\n\t}\n}","impl<O, V> Deref for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\ttype Target = BitSlice<O, V::Store>;\n\n\t#[inline(always)]\n\tfn deref(&self) -> &Self::Target {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, V> DerefMut for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn deref_mut(&mut self) -> &mut Self::Target {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, V> Display for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, V> Eq for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n}","impl<O, V> From<V> for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline(always)]\n\tfn from(data: V) -> Self {\n\t\tSelf::new(data)\n\t}\n}","impl<O, V> Hash for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn hash<H>(&self, hasher: &mut H)\n\twhere H: Hasher {\n\t\tself.as_bitslice().hash(hasher)\n\t}\n}","impl<O, V> LowerHex for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, V> Not for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn not(mut self) -> Self::Output {\n\t\tlet _ = !self.as_mut_bitslice();\n\t\tself\n\t}\n}","impl<O, V> Octal for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, V> Ord for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn cmp(&self, other: &Self) -> cmp::Ordering {\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}\n}","impl<O, V> Unpin for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n}","impl<O, V> UpperHex for BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}\n}"],"array::traits::TryFromBitSliceError":["Clone","Copy","Debug","impl Display for TryFromBitSliceError {\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tfmt.write_str(\"could not convert bitslice to bitarray\")\n\t}\n}","impl TryFromBitSliceError {\n\t#[inline]\n\tfn err<T>() -> Result<T, Self> {\n\t\tErr(Self)\n\t}\n}","impl std::error::Error for TryFromBitSliceError {\n}"],"boxed::BitBox":["impl<'a, O, T> From<&'a BitSlice<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn from(slice: &'a BitSlice<O, T>) -> Self {\n\t\tSelf::from_bitslice(slice)\n\t}\n}","impl<O, T, Idx> Index<Idx> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: Index<Idx>,\n{\n\ttype Output = <BitSlice<O, T> as Index<Idx>>::Output;\n\n\t#[inline]\n\tfn index(&self, index: Idx) -> &Self::Output {\n\t\tself.as_bitslice().index(index)\n\t}\n}","impl<O, T, Idx> IndexMut<Idx> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: IndexMut<Idx>,\n{\n\t#[inline]\n\tfn index_mut(&mut self, index: Idx) -> &mut Self::Output {\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}\n}","impl<O, T, Rhs> BitAnd<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitAndAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitand(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitAndAssign<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitAndAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitand_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}\n}","impl<O, T, Rhs> BitOr<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitOrAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitOrAssign<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitOrAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}\n}","impl<O, T, Rhs> BitXor<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitXorAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitxor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitXorAssign<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitXorAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitxor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}\n}","impl<O, T, Rhs> PartialEq<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: ?Sized + PartialEq<BitSlice<O, T>>,\n{\n\t#[inline]\n\tfn eq(&self, other: &Rhs) -> bool {\n\t\tother == self.as_bitslice()\n\t}\n}","impl<O, T, Rhs> PartialOrd<Rhs> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: ?Sized + PartialOrd<BitSlice<O, T>>,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering> {\n\t\tother.partial_cmp(self.as_bitslice())\n\t}\n}","impl<O, T> AsMut<BitSlice<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn as_mut(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> AsRef<BitSlice<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn as_ref(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> Binary for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Allocates memory on the heap and copies `x` into it.\n\t///\n\t/// This doesn’t actually allocate if `x` is zero-length.\n\t///\n\t/// # Original\n\t///\n\t/// [`Box::new`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.new)\n\t///\n\t/// # API Differences\n\t///\n\t/// `Box::<[T]>::new` does not exist, because `new` cannot take unsized\n\t/// types by value. Instead, this takes a slice reference, and boxes the\n\t/// referent slice.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let boxed = BitBox::new(bits![0; 5]);\n\t/// ```\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t#[deprecated(since = \"0.18.0\", note = \"Prefer `::from_bitslice`\")]\n\tpub fn new(x: &BitSlice<O, T>) -> Self {\n\t\tSelf::from_bitslice(x)\n\t}\n\n\t/// Constructs a new `Pin<BitBox<O, T>>`.\n\t///\n\t/// `BitSlice` is always `Unpin`, so this has no actual immobility effect.\n\t///\n\t/// # Original\n\t///\n\t/// [`Box::pin`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.pin)\n\t///\n\t/// # API Differences\n\t///\n\t/// As with `::new`, this only exists on `Box` when `T` is not unsized. This\n\t/// takes a slice reference, and pins the referent slice.\n\t#[inline]\n\tpub fn pin(x: &BitSlice<O, T>) -> Pin<Self>\n\twhere\n\t\tO: Unpin,\n\t\tT: Unpin,\n\t{\n\t\tx.pipe(Self::from_bitslice).pipe(Pin::new)\n\t}\n\n\t/// Constructs a box from a raw pointer.\n\t///\n\t/// After calling this function, the raw pointer is owned by the\n\t/// resulting `BitBox`. Specifically, the `Box` destructor will free the\n\t/// allocated memory. For this to be safe, the memory must have been\n\t/// allocated in accordance with the [memory layout] used by `Box` .\n\t///\n\t/// # Original\n\t///\n\t/// [`Box::from_raw`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.from_raw)\n\t///\n\t/// # Safety\n\t///\n\t/// This function is unsafe because improper use may lead to\n\t/// memory problems. For example, a double-free may occur if the\n\t/// function is called twice on the same raw pointer.\n\t///\n\t/// # Examples\n\t///\n\t/// Recreate a `BitBox` which was previously converted to a raw pointer\n\t/// using [`BitBox::into_raw`]:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let x = bitbox![0; 10];\n\t/// let ptr = BitBox::into_raw(x);\n\t/// let x = unsafe { BitBox::from_raw(ptr) };\n\t/// ```\n\t///\n\t/// [memory layout]: https://doc.rust-lang.org/alloc/boxed/index.html#memory-layout\n\t/// [`Layout`]: https://doc.rust-lang.org/alloc/struct.Layout.html\n\t/// [`BitBox::into_raw`]: #method.into_raw\n\t#[inline]\n\tpub unsafe fn from_raw(raw: *mut BitSlice<O, T>) -> Self {\n\t\traw.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.to_nonnull()\n\t\t\t.pipe(|pointer| Self { pointer })\n\t}\n\n\t/// Consumes the `BitBox`, returning a wrapped raw pointer.\n\t///\n\t/// The pointer will be properly aligned and non-null.\n\t///\n\t/// After calling this function, the caller is responsible for the memory\n\t/// previously managed by the `BitBox`. In particular, the caller should\n\t/// properly release the memory by converting the pointer back into a\n\t/// `BitBox` with the [`BitBox::from_raw`] function, allowing the `BitBox`\n\t/// destructor to perform the cleanup.\n\t///\n\t/// Note: this is an associated function, which means that you have to call\n\t/// it as `BitBox::into_raw(b)` instead of `b.into_raw()`. This is to match\n\t/// layout with the standard library’s `Box` API; there will never be a name\n\t/// conflict with `BitSlice`.\n\t///\n\t/// # Original\n\t///\n\t/// [`Box::into_raw`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.into_raw)\n\t///\n\t/// # Examples\n\t///\n\t/// Converting the raw pointer back into a `BitBox` with\n\t/// [`BitBox::from_raw`] for automatic cleanup:\n\t///\n\t/// ```rust\n\t/// # use bitvec::prelude::*;\n\t/// let b = BitBox::new(bits![Msb0, u32; 0; 32]);\n\t/// let ptr = BitBox::into_raw(b);\n\t/// let b = unsafe { BitBox::<Msb0, _>::from_raw(ptr) };\n\t/// ```\n\t///\n\t/// [`BitBox::from_raw`]: #method.from_raw\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn into_raw(b: Self) -> *mut BitSlice<O, T> {\n\t\tSelf::leak(b)\n\t}\n\n\t/// Consumes and leaks the `BitBox`, returning a mutable reference,\n\t/// `&'a mut BitSlice<O, T>`. Note that the memory region `[T]` must outlive\n\t/// the chosen lifetime `'a`.\n\t///\n\t/// This function is mainly useful for bit regions that live for the\n\t/// remainder of the program’s life. Dropping the returned reference will\n\t/// cause a memory leak. If this is not acceptable, the reference should\n\t/// first be wrapped with the [`BitBox::from_raw`] function, producing a\n\t/// `BitBox`. This `BitBox` can then be dropped which will properly\n\t/// deallocate the memory.\n\t///\n\t/// Note: this is an associated function, which means that you have to call\n\t/// it as `BitBox::leak(b)` instead of `b.leak()`. This is to match layout\n\t/// with the standard library’s `Box` API; there will never be a name\n\t/// conflict with `BitSlice`.\n\t///\n\t/// # Original\n\t///\n\t/// [`Box::leak`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.leak)\n\t///\n\t/// # Examples\n\t///\n\t/// Simple usage:\n\t///\n\t/// ```rust\n\t/// # use bitvec::prelude::*;\n\t/// let b = BitBox::new(bits![Local, u32; 0; 32]);\n\t/// let static_ref: &'static mut BitSlice<Local, u32> = BitBox::leak(b);\n\t/// static_ref.set(0, true);\n\t/// assert_eq!(static_ref.count_ones(), 1);\n\t/// ```\n\t///\n\t/// [`BitBox::from_raw`]: #method.from_raw\n\t#[inline]\n\tpub fn leak<'a>(b: Self) -> &'a mut BitSlice<O, T>\n\twhere T: 'a {\n\t\tb.pipe(ManuallyDrop::new).bitptr().to_bitslice_mut()\n\t}\n\n\t/// Converts `self` into a vector without clones or allocation.\n\t///\n\t/// The resulting vector can be converted back into a box via `BitVec<O,\n\t/// T>`’s `into_boxed_bitslice` method.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::into_vec`](https://doc.rust-lang.org/std/primitive.slice.html#method.into_vec)\n\t///\n\t/// Despite taking a `Box<[T]>` receiver, this function is written in an\n\t/// `impl<T> [T]` block.\n\t///\n\t/// Rust does not allow the text\n\t///\n\t/// ```rust,ignore\n\t/// impl<O, T> BitSlice<O, T> {\n\t///   fn into_bitvec(self: BitBox<O, T>);\n\t/// }\n\t/// ```\n\t///\n\t/// to be written, so this function must be implemented directly on `BitBox`\n\t/// rather than on `BitSlice` with a boxed receiver.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bb = bitbox![0, 1, 0, 1];\n\t/// let bv = bb.into_bitvec();\n\t///\n\t/// assert_eq!(bv, bitvec![0, 1, 0, 1]);\n\t/// ```\n\t#[inline]\n\tpub fn into_bitvec(self) -> BitVec<O, T> {\n\t\tlet bitptr = self.bitptr();\n\t\tlet raw = self\n\t\t\t//  Disarm the `self` destructor\n\t\t\t.pipe(ManuallyDrop::new)\n\t\t\t//  Extract the `Box<[T]>` handle, invalidating `self`\n\t\t\t.with_box(|b| unsafe { ManuallyDrop::take(b) })\n\t\t\t//  The distribution guarantees this to be correct and in-place.\n\t\t\t.into_vec()\n\t\t\t//  Disarm the `Vec<T>` destructor *also*.\n\t\t\t.pipe(ManuallyDrop::new);\n\t\t/* The distribution claims that `[T]::into_vec(Box<[T]>) -> Vec<T>` does\n\t\tnot alter the address of the heap allocation, and only modifies the\n\t\tbuffer handle. Since the address does not change, the `BitPtr` does not\n\t\tneed to be updated; the only change is that buffer capacity is now\n\t\tcarried locally, rather than frozen in the allocator’s state.\n\n\t\tInspection of the distribution’s implementation shows that the\n\t\tconversion from `(buf, len)` to `(buf, cap, len)` is done by using the\n\t\tslice length as the buffer capacity. However, this is *not* a behavior\n\t\tguaranteed by the distribution, and so the pipeline above must remain in\n\t\tplace in the event that this behavior ever changes. It should compile\n\t\taway to nothing, as it is almost entirely typesystem manipulation.\n\t\t*/\n\t\tunsafe {\n\t\t\tBitVec::from_raw_parts(bitptr.to_bitslice_ptr_mut(), raw.capacity())\n\t\t}\n\t}\n}","impl<O, T> BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Clones a `&BitSlice` into a `BitVec`.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Box<T: Clone> as Clone>::clone`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-Clone)\n\t///\n\t/// # Effects\n\t///\n\t/// This performs a direct element-wise copy from the source slice to the\n\t/// newly-allocated buffer, then sets the box to have the same starting bit\n\t/// as the slice did. This allows for faster behavior.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = bits![0, 1, 0, 1, 1, 0, 1, 1];\n\t/// let bb = BitBox::from_bitslice(&bits[2 ..]);\n\t/// assert_eq!(bb, bits[2 ..]);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn from_bitslice(slice: &BitSlice<O, T>) -> Self {\n\t\tslice.to_bitvec().into_boxed_bitslice()\n\t}\n\n\t/// Converts a `Box<[T]>` into a `BitBox`<O, T>` without copying its buffer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `boxed`: A boxed slice to view as bits.\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitBox` over the `boxed` buffer.\n\t///\n\t/// # Panics\n\t///\n\t/// This panics if `boxed` is too long to convert into a `BitBox`. See\n\t/// [`BitSlice::MAX_ELTS`].\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let boxed: Box<[u8]> = Box::new([0; 4]);\n\t/// let bb = BitBox::<Local, _>::from_boxed_slice(boxed);\n\t/// assert_eq!(bb, bits![0; 32]);\n\t/// ```\n\t///\n\t/// [`BitSlice::MAX_ELTS`]:\n\t/// ../slice/struct.BitSlice.html#associatedconstant.MAX_ELTS\n\t#[inline]\n\tpub fn from_boxed_slice(boxed: Box<[T]>) -> Self {\n\t\tSelf::try_from_boxed_slice(boxed)\n\t\t\t.expect(\"Slice was too long to be converted into a `BitBox`\")\n\t}\n\n\t/// Converts a `Box<[T]>` into a `BitBox<O, T>` without copying its buffer.\n\t///\n\t/// This method takes ownership of a memory buffer and enables it to be used\n\t/// as a bit-box. Because `Box<[T]>` can be longer than `BitBox`es, this is\n\t/// a fallible method, and the original box will be returned if it cannot be\n\t/// converted.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `boxed`: Some boxed slice of memory, to be viewed as bits.\n\t///\n\t/// # Returns\n\t///\n\t/// If `boxed` is short enough to be viewed as a `BitBox`, then this returns\n\t/// a `BitBox` over the `boxed` buffer. If `boxed` is too long, then this\n\t/// returns `boxed` unmodified.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let boxed: Box<[u8]> = Box::new([0; 4]);\n\t/// let bb = BitBox::<Local, _>::try_from_boxed_slice(boxed).unwrap();\n\t/// assert_eq!(bb[..], bits![0; 32]);\n\t/// ```\n\t#[inline]\n\tpub fn try_from_boxed_slice(boxed: Box<[T]>) -> Result<Self, Box<[T]>> {\n\t\tlet len = boxed.len();\n\t\tif len > BitSlice::<O, T>::MAX_ELTS {\n\t\t\treturn Err(boxed);\n\t\t}\n\n\t\tlet boxed = ManuallyDrop::new(boxed);\n\t\tlet base = boxed.as_ptr();\n\t\tOk(Self {\n\t\t\tpointer: unsafe {\n\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\tbase,\n\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\tlen * T::Mem::BITS as usize,\n\t\t\t\t)\n\t\t\t}\n\t\t\t.to_nonnull(),\n\t\t})\n\t}\n\n\t/// Converts the slice back into an ordinary slice of memory elements.\n\t///\n\t/// This does not affect the slice’s buffer, only the handle used to control\n\t/// it.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t///\n\t/// # Returns\n\t///\n\t/// An ordinary boxed slice containing all of the bit-slice’s memory buffer.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bb = bitbox![0; 5];\n\t/// let boxed = bb.into_boxed_slice();\n\t/// assert_eq!(boxed[..], [0][..]);\n\t/// ```\n\t#[inline]\n\tpub fn into_boxed_slice(self) -> Box<[T]> {\n\t\tlet mut this = ManuallyDrop::new(self);\n\t\tunsafe { Box::from_raw(this.as_mut_slice()) }\n\t}\n\n\t/// Views the buffer’s contents as a `BitSlice`.\n\t///\n\t/// This is equivalent to `&bb[..]`.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Box<[T]> as AsRef<[T]>>::as_ref`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsRef%3CT%3E)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bb = bitbox![0, 1, 1, 0];\n\t/// let bits = bb.as_bitslice();\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitslice(&self) -> &BitSlice<O, T> {\n\t\tself.bitptr().to_bitslice_ref()\n\t}\n\n\t/// Extracts a mutable bit-slice of the entire vector.\n\t///\n\t/// Equivalent to `&mut bv[..]`.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Box<[T]> as AsMut<[T]>>::as_mut`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsMut%3CT%3E)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 0, 1];\n\t/// let bits = bv.as_mut_bitslice();\n\t/// bits.set(0, true);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.bitptr().to_bitslice_mut()\n\t}\n\n\t/// Extracts an element slice containing the entire box.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Box<[T]> as AsRef<[T]>>::as_ref`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsRef%3CT%3E)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_bitslice`] for a `&BitBox -> &BitSlice` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t/// use std::io::{self, Write};\n\t/// let buffer = bitbox![Msb0, u8; 0, 1, 0, 1, 1, 0, 0, 0];\n\t/// io::sink().write(buffer.as_slice()).unwrap();\n\t/// # }\n\t/// ```\n\t///\n\t/// [`as_bitslice`]: #method.as_bitslice\n\t#[inline]\n\tpub fn as_slice(&self) -> &[T] {\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_const(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}\n\n\t/// Extracts a mutable slice of the entire box.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Box<[T]> as AsMut<[T]>>::as_mut`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsMut%3CT%3E)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_mut_bitslice`] for a `&mut BitBox -> &mut BitSlice` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t/// use std::io::{self, Read};\n\t/// let mut buffer = bitbox![Msb0, u8; 0; 24];\n\t/// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();\n\t/// # }\n\t/// ```\n\t///\n\t/// [`as_mut_bitslice`]: #method.as_mut_bitslice\n\t#[inline]\n\tpub fn as_mut_slice(&mut self) -> &mut [T] {\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_mut(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts_mut(base, elts) }\n\t}\n\n\t#[inline]\n\tpub(crate) fn bitptr(&self) -> BitPtr<T> {\n\t\tself.pointer.as_ptr().pipe(BitPtr::from_bitslice_ptr_mut)\n\t}\n\n\t/// Permits a function to modify the `Box<[T]>` backing storage of a\n\t/// `BitBox<_, T>`.\n\t///\n\t/// This produces a temporary `Box<[T::Mem]>` structure governing the\n\t/// `BitBox`’s buffer and allows a function to view it mutably. After the\n\t/// callback returns, the `Box` is written back into `self` and forgotten.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `F`: A function which operates on a mutable borrow of a\n\t///   `Box<[T::Mem]>` buffer controller.\n\t/// - `R`: The return type of the `F` function.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `func`: A function which receives a mutable borrow of a\n\t///   `Box<[T::Mem]>` controlling `self`’s buffer.\n\t///\n\t/// # Returns\n\t///\n\t/// The return value of `func`. `func` is forbidden from borrowing any part\n\t/// of the `Box<[T::Mem]>` temporary view.\n\tfn with_box<F, R>(&mut self, func: F) -> R\n\twhere F: FnOnce(&mut ManuallyDrop<Box<[T::Mem]>>) -> R {\n\t\tlet mut bitptr = self.bitptr();\n\n\t\tlet mut boxed = self\n\t\t\t.as_mut_slice()\n\t\t\t.pipe(|s| s as *mut [T] as *mut [T::Mem])\n\t\t\t.pipe(|raw| unsafe { Box::from_raw(raw) })\n\t\t\t.pipe(ManuallyDrop::new);\n\t\tlet out = func(&mut boxed);\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(boxed.as_ptr() as *mut T);\n\t\t}\n\t\tself.pointer = bitptr.to_nonnull();\n\t\tout\n\t}\n}","impl<O, T> BitField for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitField,\n{\n\t#[inline]\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_le()\n\t}\n\n\t#[inline]\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_be()\n\t}\n\n\t#[inline]\n\tfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_le(value)\n\t}\n\n\t#[inline]\n\tfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_be(value)\n\t}\n}","impl<O, T> Borrow<BitSlice<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn borrow(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> BorrowMut<BitSlice<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn borrow_mut(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> Clone for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn clone(&self) -> Self {\n\t\tself.as_bitslice().pipe(Self::from_bitslice)\n\t}\n}","impl<O, T> Debug for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tif fmt.alternate() {\n\t\t\tself.bitptr().render(\n\t\t\t\tfmt,\n\t\t\t\t\"Box\",\n\t\t\t\tSome(any::type_name::<O>()),\n\t\t\t\tNone,\n\t\t\t)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Default for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn default() -> Self {\n\t\tSelf {\n\t\t\tpointer: BitPtr::EMPTY.to_nonnull(),\n\t\t}\n\t}\n}","impl<O, T> Deref for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Target = BitSlice<O, T>;\n\n\t#[inline(always)]\n\tfn deref(&self) -> &Self::Target {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> DerefMut for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn deref_mut(&mut self) -> &mut Self::Target {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> Display for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Drop for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn drop(&mut self) {\n\t\t//  Run the `Box` destructor to deällocate the buffer.\n\t\tself.with_box(|boxed| unsafe { ManuallyDrop::drop(boxed) });\n\t}\n}","impl<O, T> Eq for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> From<BitVec<O, T>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn from(bv: BitVec<O, T>) -> Self {\n\t\tbv.into_boxed_bitslice()\n\t}\n}","impl<O, T> Hash for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn hash<H>(&self, state: &mut H)\n\twhere H: Hasher {\n\t\tself.as_bitslice().hash(state)\n\t}\n}","impl<O, T> Into<Box<[T]>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn into(self) -> Box<[T]> {\n\t\tself.into_boxed_slice()\n\t}\n}","impl<O, T> LowerHex for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Not for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn not(mut self) -> Self::Output {\n\t\tfor elem in self.as_mut_slice().iter_mut().map(dvl::mem_mut) {\n\t\t\t*elem = !*elem;\n\t\t}\n\t\tself\n\t}\n}","impl<O, T> Octal for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Ord for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn cmp(&self, other: &Self) -> cmp::Ordering {\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}\n}","impl<O, T> Pointer for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Box\", Some(any::type_name::<O>()), None)\n\t}\n}","impl<O, T> TryFrom<Box<[T]>> for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Error = Box<[T]>;\n\n\t#[inline(always)]\n\tfn try_from(boxed: Box<[T]>) -> Result<Self, Self::Error> {\n\t\tSelf::try_from_boxed_slice(boxed)\n\t}\n}","impl<O, T> Unpin for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> UpperHex for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}\n}","unsafe impl<O, T> Send for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","unsafe impl<O, T> Sync for BitBox<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}"],"domain::BitDomain":["Debug","impl<'a, O, T> $t<'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Attempts to view the domain as an enclave variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n\t\t\t/// enclave fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Enclave`]: #variant.Enclave\n\t\t\t#[inline]\n\t\t\tpub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)> {\n\t\t\t\tif let Self::Enclave { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Attempts to view the domain as a region variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Region`] variant, this returns `Some` of the\n\t\t\t/// region fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Region`]: #variant.Region\n\t\t\t#[inline]\n\t\t\tpub fn region(self) -> Option<(\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\t&'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t)> {\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Constructs a bit-domain view from a bitslice.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `slice`: The source bitslice for which the view is constructed\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// A bit-domain view over the source slice.\n\t\t\t#[inline]\n\t\t\tpub(crate) fn new(slice: &'a $($m)? BitSlice<O, T>) -> Self {\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet h = bitptr.head();\n\t\t\t\tlet (e, t) = h.span(bitptr.len());\n\t\t\t\tlet w = T::Mem::BITS;\n\n\t\t\t\tmatch (h.value(), e, t.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == w => Self::spanning(slice),\n\t\t\t\t\t(_, _, t) if t == w => Self::partial_head(slice, h),\n\t\t\t\t\t(0, ..) => Self::partial_tail(slice, h, t),\n\t\t\t\t\t(_, 1, _) => Self::minor(slice, h, t),\n\t\t\t\t\t_ => Self::major(slice, h, t),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn empty() -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: Default::default(),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn major(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = bit_domain!(split $($m)?\n\t\t\t\t\trest,\n\t\t\t\t\trest.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: bit_domain!(retype $($m)? head),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? body),\n\t\t\t\t\ttail: bit_domain!(retype $($m)? tail),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn minor(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\tbody: slice,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_head(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (head, body) = (\n\t\t\t\t\tbit_domain!(retype $($m)? head),\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_tail(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/* This discarded head argument makes all constructor functions\n\t\t\t\thave the same register layout for the call, allowing the `::new`\n\t\t\t\tfunction to establish the arguments ahead of time, then select a\n\t\t\t\tconstructor function to jump into.\n\t\t\t\t*/\n\t\t\t\t_head: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (rest, tail) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\tslice.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = (\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t\tbit_domain!(retype $($m)? tail),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn spanning(slice: &'a $($m)? BitSlice<O, T>) -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? slice),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<O, T> Clone for BitDomain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tfn clone(&self) -> Self {\n\t\t*self\n\t}\n}","impl<O, T> Copy for BitDomain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}"],"domain::BitDomainMut":["Debug","impl<'a, O, T> $t<'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Attempts to view the domain as an enclave variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n\t\t\t/// enclave fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Enclave`]: #variant.Enclave\n\t\t\t#[inline]\n\t\t\tpub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)> {\n\t\t\t\tif let Self::Enclave { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Attempts to view the domain as a region variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Region`] variant, this returns `Some` of the\n\t\t\t/// region fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Region`]: #variant.Region\n\t\t\t#[inline]\n\t\t\tpub fn region(self) -> Option<(\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\t&'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t)> {\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Constructs a bit-domain view from a bitslice.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `slice`: The source bitslice for which the view is constructed\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// A bit-domain view over the source slice.\n\t\t\t#[inline]\n\t\t\tpub(crate) fn new(slice: &'a $($m)? BitSlice<O, T>) -> Self {\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet h = bitptr.head();\n\t\t\t\tlet (e, t) = h.span(bitptr.len());\n\t\t\t\tlet w = T::Mem::BITS;\n\n\t\t\t\tmatch (h.value(), e, t.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == w => Self::spanning(slice),\n\t\t\t\t\t(_, _, t) if t == w => Self::partial_head(slice, h),\n\t\t\t\t\t(0, ..) => Self::partial_tail(slice, h, t),\n\t\t\t\t\t(_, 1, _) => Self::minor(slice, h, t),\n\t\t\t\t\t_ => Self::major(slice, h, t),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn empty() -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: Default::default(),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn major(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = bit_domain!(split $($m)?\n\t\t\t\t\trest,\n\t\t\t\t\trest.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: bit_domain!(retype $($m)? head),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? body),\n\t\t\t\t\ttail: bit_domain!(retype $($m)? tail),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn minor(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\tbody: slice,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_head(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (head, body) = (\n\t\t\t\t\tbit_domain!(retype $($m)? head),\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_tail(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/* This discarded head argument makes all constructor functions\n\t\t\t\thave the same register layout for the call, allowing the `::new`\n\t\t\t\tfunction to establish the arguments ahead of time, then select a\n\t\t\t\tconstructor function to jump into.\n\t\t\t\t*/\n\t\t\t\t_head: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet (rest, tail) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\tslice.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = (\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t\tbit_domain!(retype $($m)? tail),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn spanning(slice: &'a $($m)? BitSlice<O, T>) -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? slice),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}\n\t\t}"],"domain::Domain":["Debug","impl<'a, T> $t <'a, T>\n\t\twhere\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Attempts to view the domain as an enclave variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n\t\t\t/// enclave fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Enclave`]: #variant.Enclave\n\t\t\t#[inline]\n\t\t\tpub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a T::Alias,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)> {\n\t\t\t\tif let Self::Enclave { head, elem, tail } = self {\n\t\t\t\t\tSome((head, elem, tail))\n\t\t\t\t} else {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Attempts to view the domain as the region variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Region`] variant, this returns `Some` of the\n\t\t\t/// region fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Region`]: #variant.Region\n\t\t\t#[inline]\n\t\t\tpub fn region(self) -> Option<(\n\t\t\t\tOption<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t&'a $($m)? [T::Mem],\n\t\t\t\tOption<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t)> {\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head,body,tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tpub(crate) fn new<O>(slice: &'a $($m)? BitSlice<O, T>) -> Self\n\t\t\twhere O: BitOrder {\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet head = bitptr.head();\n\t\t\t\tlet elts = bitptr.elements();\n\t\t\t\tlet tail = bitptr.tail();\n\t\t\t\tlet bits = T::Mem::BITS;\n\t\t\t\tlet base = bitptr.pointer().to_alias();\n\t\t\t\tmatch (head.value(), elts, tail.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == bits => Self::spanning(base, elts),\n\t\t\t\t\t(_, _, t) if t == bits => Self::partial_head(base, elts, head),\n\t\t\t\t\t(0, ..) => Self::partial_tail(base, elts, tail),\n\t\t\t\t\t(_, 1, _) => Self::minor(base, head, tail),\n\t\t\t\t\t_ => Self::major(base, elts, head, tail),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn empty() -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: & $($m)? [],\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn major(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 2);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn minor(\n\t\t\t\taddr: *const T::Alias,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\telem: unsafe { &*addr },\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_head(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_tail(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base, elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn spanning(base: *const T::Alias, elts: usize) -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: domain!(slice $($m)? base, elts),\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, T> DoubleEndedIterator for Domain<'a, T>\nwhere T: 'a + BitStore\n{\n\t#[inline]\n\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\tmatch self {\n\t\t\tSelf::Enclave { elem, .. } => (*elem)\n\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t.pipe(Some)\n\t\t\t\t.tap(|_| *self = Self::empty()),\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, _)) = *tail {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *tail = None);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, rest)) = body.split_last() {\n\t\t\t\t\t*body = rest;\n\t\t\t\t\treturn Some(*elem);\n\t\t\t\t}\n\t\t\t\tif let Some((_, elem)) = *head {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *head = None);\n\t\t\t\t}\n\t\t\t\tNone\n\t\t\t},\n\t\t}\n\t}\n}","impl<'a, T> Iterator for Domain<'a, T>\nwhere T: 'a + BitStore\n{\n\ttype Item = T::Mem;\n\n\t#[inline]\n\tfn next(&mut self) -> Option<Self::Item> {\n\t\tmatch self {\n\t\t\tSelf::Enclave { elem, .. } => (*elem)\n\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t.pipe(Some)\n\t\t\t\t.tap(|_| *self = Self::empty()),\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\tif let Some((_, elem)) = *head {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *head = None);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, rest)) = body.split_first() {\n\t\t\t\t\t*body = rest;\n\t\t\t\t\treturn Some(*elem);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, _)) = *tail {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *tail = None);\n\t\t\t\t}\n\t\t\t\tNone\n\t\t\t},\n\t\t}\n\t}\n}","impl<T> $f for Domain<'_, T>\n\t\twhere T: BitStore\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_list()\n\t\t\t\t\t.entries(self.into_iter().map(FmtForward::$fwd))\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}","impl<T> Clone for Domain<'_, T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tfn clone(&self) -> Self {\n\t\t*self\n\t}\n}","impl<T> Copy for Domain<'_, T> where T: BitStore\n{\n}","impl<T> ExactSizeIterator for Domain<'_, T>\nwhere T: BitStore\n{\n\t#[inline]\n\tfn len(&self) -> usize {\n\t\tmatch self {\n\t\t\tSelf::Enclave { .. } => 1,\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\thead.is_some() as usize + body.len() + tail.is_some() as usize\n\t\t\t},\n\t\t}\n\t}\n}","impl<T> core::iter::FusedIterator for Domain<'_, T> where T: BitStore\n{\n}"],"domain::DomainMut":["Debug","impl<'a, T> $t <'a, T>\n\t\twhere\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Attempts to view the domain as an enclave variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n\t\t\t/// enclave fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Enclave`]: #variant.Enclave\n\t\t\t#[inline]\n\t\t\tpub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a T::Alias,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)> {\n\t\t\t\tif let Self::Enclave { head, elem, tail } = self {\n\t\t\t\t\tSome((head, elem, tail))\n\t\t\t\t} else {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/// Attempts to view the domain as the region variant.\n\t\t\t///\n\t\t\t/// # Parameters\n\t\t\t///\n\t\t\t/// - `self`\n\t\t\t///\n\t\t\t/// # Returns\n\t\t\t///\n\t\t\t/// If `self` is the [`Region`] variant, this returns `Some` of the\n\t\t\t/// region fields, as a tuple. Otherwise, it returns `None`.\n\t\t\t///\n\t\t\t/// [`Region`]: #variant.Region\n\t\t\t#[inline]\n\t\t\tpub fn region(self) -> Option<(\n\t\t\t\tOption<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t&'a $($m)? [T::Mem],\n\t\t\t\tOption<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t)> {\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head,body,tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tpub(crate) fn new<O>(slice: &'a $($m)? BitSlice<O, T>) -> Self\n\t\t\twhere O: BitOrder {\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet head = bitptr.head();\n\t\t\t\tlet elts = bitptr.elements();\n\t\t\t\tlet tail = bitptr.tail();\n\t\t\t\tlet bits = T::Mem::BITS;\n\t\t\t\tlet base = bitptr.pointer().to_alias();\n\t\t\t\tmatch (head.value(), elts, tail.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == bits => Self::spanning(base, elts),\n\t\t\t\t\t(_, _, t) if t == bits => Self::partial_head(base, elts, head),\n\t\t\t\t\t(0, ..) => Self::partial_tail(base, elts, tail),\n\t\t\t\t\t(_, 1, _) => Self::minor(base, head, tail),\n\t\t\t\t\t_ => Self::major(base, elts, head, tail),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn empty() -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: & $($m)? [],\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn major(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 2);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn minor(\n\t\t\t\taddr: *const T::Alias,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\telem: unsafe { &*addr },\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_head(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn partial_tail(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self {\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base, elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn spanning(base: *const T::Alias, elts: usize) -> Self {\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: domain!(slice $($m)? base, elts),\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}\n\t\t}"],"index::BitIdx":["Clone","Copy","Default","Eq","Hash","Ord","PartialEq","PartialOrd","impl<M> Binary for BitIdx<M>\nwhere M: BitMemory\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"{:0>1$b}\", self.idx, M::INDX as usize)\n\t}\n}","impl<M> BitIdx<M>\nwhere M: BitMemory\n{\n\t/// The inclusive-maximum index.\n\tpub(crate) const LAST: Self = make!(idx M::MASK);\n\t/// The zero index.\n\tpub(crate) const ZERO: Self = make!(idx 0);\n\n\t/// Wraps a counter value as a known-good index into an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `idx`: A semantic index of a bit within an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// If `idx` is outside the valid range `0 .. M::BITS`, this returns `None`;\n\t/// otherwise, it returns a `BitIdx` wrapping the `idx` value.\n\t#[inline]\n\tpub(crate) fn new(idx: u8) -> Option<Self> {\n\t\tif idx >= M::BITS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(idx idx))\n\t}\n\n\t/// Wraps a counter value as an assumed-good index into an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `idx`: A semantic index of a bit within an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// `idx` wrapped in a `BitIdx`.\n\t///\n\t/// # Safety\n\t///\n\t/// `idx` **must** be within the valid range `0 .. M::BITS`. In debug\n\t/// builds, invalid `idx` values cause a panic; release builds do not check\n\t/// the input.\n\t#[inline]\n\tpub(crate) unsafe fn new_unchecked(idx: u8) -> Self {\n\t\tdebug_assert!(\n\t\t\tidx < M::BITS,\n\t\t\t\"Bit index {} cannot exceed type width {}\",\n\t\t\tidx,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(idx idx)\n\t}\n\n\t/// Increments an index counter, wrapping at the back edge of the element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`: The index to increment.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The next index after `self`.\n\t/// - `.1`: Indicates that the new index is in the next memory element.\n\t#[inline]\n\tpub(crate) fn incr(self) -> (Self, bool) {\n\t\tlet next = self.idx + 1;\n\t\t(make!(idx next & M::MASK), next == M::BITS)\n\t}\n\n\t/// Decrements an index counter, wrapping at the front edge of the element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`: The inedx to decrement.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The previous index before `self`.\n\t/// - `.1`: Indicates that the new index is in the previous memory element.\n\t#[inline]\n\tpub(crate) fn decr(self) -> (Self, bool) {\n\t\tlet next = self.idx.wrapping_sub(1);\n\t\t(make!(idx next & M::MASK), self.idx == 0)\n\t}\n\n\t/// Computes the bit position corresponding to `self` under some ordering.\n\t///\n\t/// This forwards to `O::at::<M>`, and is the only public, safe, constructor\n\t/// for a position counter.\n\t#[inline]\n\tpub fn position<O>(self) -> BitPos<M>\n\twhere O: BitOrder {\n\t\tO::at::<M>(self)\n\t}\n\n\t/// Computes the bit selector corresponding to `self` under an ordering.\n\t///\n\t/// This forwards to `O::select::<M>`, and is the only public, safe,\n\t/// constructor for a bit selector.\n\t#[inline]\n\tpub fn select<O>(self) -> BitSel<M>\n\twhere O: BitOrder {\n\t\tO::select::<M>(self)\n\t}\n\n\t/// Computes the bit selector for `self` as an accessor mask.\n\t///\n\t/// This is a type-cast over `Self::select`. It is one of the few public,\n\t/// safe, constructors of a multi-bit mask.\n\t#[inline]\n\tpub fn mask<O>(self) -> BitMask<M>\n\twhere O: BitOrder {\n\t\tself.select::<O>().mask()\n\t}\n\n\t/// Views the internal index value.\n\t#[inline]\n\tpub fn value(self) -> u8 {\n\t\tself.idx\n\t}\n\n\t/// Ranges over all possible index values.\n\tpub(crate) fn range_all() -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator {\n\t\t(Self::ZERO.idx ..= Self::LAST.idx).map(|val| make!(idx val))\n\t}\n\n\t/// Constructs a range over all indices between a start and end point.\n\t///\n\t/// Because implementation details of the `RangeOps` family are not yet\n\t/// stable, and heterogenous ranges are not supported, this must be an\n\t/// opaque iterator rather than a direct `Range<BitIdx<M>>`.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `from`: The inclusive low bound of the range. This will be the first\n\t///   index produced by the iterator.\n\t/// - `upto`: The exclusive high bound of the range. The iterator will halt\n\t///   before yielding an index of this value.\n\t///\n\t/// # Returns\n\t///\n\t/// An opaque iterator that is equivalent to the range `from .. upto`.\n\t///\n\t/// # Requirements\n\t///\n\t/// `from` must be no greater than `upto`.\n\tpub fn range(\n\t\tfrom: Self,\n\t\tupto: BitTail<M>,\n\t) -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator\n\t{\n\t\tdebug_assert!(\n\t\t\tfrom.value() <= upto.value(),\n\t\t\t\"Ranges must run from low to high\"\n\t\t);\n\t\t(from.value() .. upto.value()).map(|val| make!(idx val))\n\t}\n\n\t/// Computes the the jump distance for a number of bits away from a start.\n\t///\n\t/// This produces the number of elements to move from the starting point,\n\t/// and then the bit index of the destination bit in the destination\n\t/// element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`: A bit index in some memory element, used as the starting\n\t///   position for the offset calculation.\n\t/// - `by`: The number of bits by which to move. Negative values go towards\n\t///   the zero bit index and element address; positive values go towards the\n\t///   maximal bit index and element address.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The number of elements by which to offset the caller’s element\n\t///   address. This value can be passed directly into [`ptr::offset`].\n\t/// - `.1`: The bit index of the destination bit in the element selected by\n\t///   applying the `.0` pointer offset.\n\t///\n\t/// [`ptr::offset`]: https://doc.rust-lang.org/std/primitive.pointer.html#method.offset\n\tpub(crate) fn offset(self, by: isize) -> (isize, Self) {\n\t\tlet val = self.value();\n\n\t\t/* Signed-add `*self` and the jump distance. Overflowing is the unlikely\n\t\tbranch. The result is a bit index, and an overflow marker. `far` is\n\t\tpermitted to be negative; this means that it is lower in memory than the\n\t\torigin bit. The number line has its origin at the front edge of the\n\t\torigin element, so `-1` is the *last* bit of the prior memory element.\n\t\t*/\n\t\tlet (far, ovf) = by.overflowing_add(val as isize);\n\t\t//  If the `isize` addition does not overflow, then the sum can be used\n\t\t//  directly.\n\t\tif !ovf {\n\t\t\t//  If `far` is in the origin element, then the jump moves zero\n\t\t\t//  elements and produces `far` as an absolute index directly.\n\t\t\tif (0 .. M::BITS as isize).contains(&far) {\n\t\t\t\t(0, make!(idx far as u8))\n\t\t\t}\n\t\t\t/* Otherwise, downshift the bit distance to compute the number of\n\t\t\telements moved in either direction, and mask to compute the absolute\n\t\t\tbit index in the destination element.\n\t\t\t*/\n\t\t\telse {\n\t\t\t\t(far >> M::INDX, make!(idx far as u8 & M::MASK))\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t/* Overflowing `isize` addition happens to produce ordinary `usize`\n\t\t\taddition. In point of fact, `isize` addition and `usize` addition\n\t\t\tare the same machine instruction to perform the sum; it is merely\n\t\t\tthe signed interpretation of the sum that differs. The sum can be\n\t\t\trecast back to `usize` without issue.\n\t\t\t*/\n\t\t\tlet far = far as usize;\n\t\t\t//  This is really only needed in order to prevent sign-extension of\n\t\t\t//  the downshift; once shifted, the value can be safely re-signed.\n\t\t\t((far >> M::INDX) as isize, make!(idx far as u8 & M::MASK))\n\t\t}\n\t}\n\n\t/// Computes the span information for a region beginning at `self` for `len`\n\t/// bits.\n\t///\n\t/// The span information is the number of elements in the region that hold\n\t/// live bits, and the position of the tail marker after the live bits.\n\t///\n\t/// This forwards to [`BitTail::span`], as the computation is identical for\n\t/// the two types. Beginning a span at any `Idx` is equivalent to beginning\n\t/// it at the tail of a previous span.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`: The start bit of the span.\n\t/// - `len`: The number of bits in the span.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The number of elements, starting in the element that contains\n\t///   `self`, that contain live bits of the span.\n\t/// - `.1`: The tail counter of the span’s end point.\n\tpub(crate) fn span(self, len: usize) -> (usize, BitTail<M>) {\n\t\tmake!(tail self.value()).span(len)\n\t}\n}","impl<M> Debug for BitIdx<M>\nwhere M: BitMemory\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitIdx<{}>({})\", type_name::<M>(), self.idx)\n\t}\n}","impl<M> Display for BitIdx<M>\nwhere M: BitMemory\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tDisplay::fmt(&self.idx, fmt)\n\t}\n}"],"index::BitMask":["Clone","Copy","Default","Eq","Hash","Ord","PartialEq","PartialOrd","impl<M> BitAnd<M> for BitMask<M>\nwhere M: BitMemory\n{\n\ttype Output = Self;\n\n\tfn bitand(self, rhs: M) -> Self {\n\t\tmake!(mask self.mask & rhs)\n\t}\n}","impl<M> BitMask<M>\nwhere M: BitMemory\n{\n\t/// A full mask.\n\tpub const ALL: Self = make!(mask M::ALL);\n\t/// An empty mask.\n\tpub const ZERO: Self = make!(mask M::ZERO);\n\n\t/// Wraps any `M` value as a bit-mask.\n\t///\n\t/// This constructor is provided to explicitly declare that an operation is\n\t/// discarding the numeric value of an integer and reading it only as a\n\t/// bit-mask.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `mask`: Some integer value\n\t///\n\t/// # Returns\n\t///\n\t/// `mask` wrapped as a bit-mask, with its numeric context discarded.\n\t///\n\t/// # Safety\n\t///\n\t/// This function must only be called within a `BitOrder::mask`\n\t/// implementation which is verified to be correct.\n\t///\n\t/// Prefer accumulating `BitSel` values using the `Sum` implementation.\n\t#[inline]\n\tpub unsafe fn new(mask: M) -> Self {\n\t\tmake!(mask mask)\n\t}\n\n\t/// Creates a new mask with a selector bit activated.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t/// - `sel`: The selector bit to activate in the new mask.\n\t///\n\t/// # Returns\n\t///\n\t/// A copy of `self`, with the selector at `sel` activated.\n\t#[inline]\n\tpub fn combine(mut self, sel: BitSel<M>) -> Self {\n\t\tself.insert(sel);\n\t\tself\n\t}\n\n\t/// Inserts a selector into an existing mask.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `sel`: The selector bit to insert into the mask.\n\t///\n\t/// # Effects\n\t///\n\t/// The selector’s bit in the `self` mask is activated.\n\t#[inline]\n\tpub fn insert(&mut self, sel: BitSel<M>) {\n\t\tself.mask |= sel.sel;\n\t}\n\n\t/// Tests whether a mask contains a given selector bit.\n\t///\n\t/// # Paramters\n\t///\n\t/// - `self`\n\t/// - `sel`: The selector bit to test in the `self` mask.\n\t///\n\t/// # Returns\n\t///\n\t/// Whether `self` has set the bit at `sel`.\n\t#[inline]\n\tpub fn test(self, sel: BitSel<M>) -> bool {\n\t\tself.mask & sel.sel != M::ZERO\n\t}\n\n\t/// Views the internal mask value.\n\t#[inline]\n\tpub fn value(self) -> M {\n\t\tself.mask\n\t}\n}","impl<M> BitOr<M> for BitMask<M>\nwhere M: BitMemory\n{\n\ttype Output = Self;\n\n\tfn bitor(self, rhs: M) -> Self {\n\t\tmake!(mask self.mask | rhs)\n\t}\n}","impl<M> Debug for BitMask<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitMask<{}>(\", type_name::<M>())?;\n\t\tDisplay::fmt(&self, fmt)?;\n\t\tfmt.write_str(\")\")\n\t}\n}","impl<M> Display for BitMask<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"{:0>1$b}\", self.mask, M::BITS as usize)\n\t}\n}","impl<M> Not for BitMask<M>\nwhere M: BitMemory\n{\n\ttype Output = Self;\n\n\tfn not(self) -> Self::Output {\n\t\tmake!(mask !self.mask)\n\t}\n}","impl<M> Sum<BitSel<M>> for BitMask<M>\nwhere M: BitMemory\n{\n\tfn sum<I>(iter: I) -> Self\n\twhere I: Iterator<Item = BitSel<M>> {\n\t\titer.fold(Self::ZERO, Self::combine)\n\t}\n}"],"index::BitPos":["Clone","Copy","Default","Eq","Hash","Ord","PartialEq","PartialOrd","impl<M> BitPos<M>\nwhere M: BitMemory\n{\n\t/// Wraps a value as a known-good position within an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `pos`: An electrical position of a bit within an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// If `pos` is outside the valid range `0 .. M::BITS`, this returns `None`;\n\t/// otherwise, it returns a `BitPos` wrapping the `pos` value.\n\t///\n\t/// # Safety\n\t///\n\t/// This function must only be called within a `BitOrder::at` implementation\n\t/// which is verified to be correct.\n\t#[inline]\n\tpub unsafe fn new(pos: u8) -> Option<Self> {\n\t\t//  Reject a position value that is not within the range `0 .. M::BITS`.\n\t\tif pos >= M::BITS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(pos pos))\n\t}\n\n\t/// Wraps a value as an assumed-good position within an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `pos`: An electrical position within an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// `pos` wrapped in a `BitPos`.\n\t///\n\t/// # Safety\n\t///\n\t/// `pos` **must** be within the valid range `0 .. M::BITS`. In debug\n\t/// builds, invalid `pos` values cause a panic; release builds do not check\n\t/// the input.\n\t///\n\t/// This function must only be called in a correct `BitOrder::at`\n\t/// implementation.\n\t#[inline]\n\tpub unsafe fn new_unchecked(pos: u8) -> Self {\n\t\tdebug_assert!(\n\t\t\tpos < M::BITS,\n\t\t\t\"Bit position {} cannot exceed type width {}\",\n\t\t\tpos,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(pos pos)\n\t}\n\n\t/// Constructs a one-hot selection mask from the position counter.\n\t///\n\t/// This is a well-typed `1 << pos`.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t///\n\t/// # Returns\n\t///\n\t/// A one-hot mask for `M` selecting the bit specified by `self`.\n\t#[inline]\n\tpub fn select(self) -> BitSel<M> {\n\t\tmake!(sel M::ONE << self.pos)\n\t}\n\n\t/// Constructs an untyped bitmask from the position counter.\n\t///\n\t/// This removes the one-hot requirement from the selection mask.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t///\n\t/// # Returns\n\t///\n\t/// A mask for `M` selecting only the bit specified by `self`.\n\t#[inline]\n\tpub fn mask(self) -> BitMask<M> {\n\t\tmake!(mask self.select().sel)\n\t}\n\n\t/// Views the internal position value.\n\t#[inline]\n\tpub fn value(self) -> u8 {\n\t\tself.pos\n\t}\n}","impl<M> Debug for BitPos<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitPos<{}>({})\", type_name::<M>(), self.pos)\n\t}\n}"],"index::BitSel":["Clone","Copy","Default","Eq","Hash","Ord","PartialEq","PartialOrd","impl<M> BitSel<M>\nwhere M: BitMemory\n{\n\t/// Wraps a selector value as a known-good selection of an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `sel`: A one-hot selection mask of a bit in an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// If `sel` does not have exactly one bit set, this returns `None`;\n\t/// otherwise, it returns a `BitSel` wrapping the `sel` value.\n\t///\n\t/// # Safety\n\t///\n\t/// This function must only be called within a `BitOrder::select`\n\t/// implementation that is verified to be correct.\n\t#[inline]\n\tpub unsafe fn new(sel: M) -> Option<Self> {\n\t\tif sel.count_ones() != 1 {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(sel sel))\n\t}\n\n\t/// Wraps a selector value as an assumed-good selection of an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `sel`: A one-hot selection mask of a bit in an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// `sel` wrapped in a `BitSel`.\n\t///\n\t/// # Safety\n\t///\n\t/// `sel` **must** have exactly one bit set high and all others low. In\n\t/// debug builds, invalid `sel` values cause a panic; release builds do not\n\t/// check the input.\n\t///\n\t/// This function must only be called in a correct `BitOrder::select`\n\t/// implementation.\n\t#[inline]\n\tpub unsafe fn new_unchecked(sel: M) -> Self {\n\t\tdebug_assert!(\n\t\t\tsel.count_ones() == 1,\n\t\t\t\"Selections are required to have exactly one set bit: {:0>1$b}\",\n\t\t\tsel,\n\t\t\tM::BITS as usize\n\t\t);\n\t\tmake!(sel sel)\n\t}\n\n\t/// Converts the selector into a bit mask.\n\t///\n\t/// This is a type-cast.\n\t#[inline]\n\tpub fn mask(self) -> BitMask<M>\n\twhere M: BitMemory {\n\t\tmake!(mask self.sel)\n\t}\n\n\t/// Views the internal selector value.\n\t#[inline]\n\tpub fn value(self) -> M {\n\t\tself.sel\n\t}\n\n\t/// Ranges over all possible selector values.\n\tpub fn range_all() -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator {\n\t\tBitIdx::<M>::range_all().map(|i| make!(pos i.idx).select())\n\t}\n}","impl<M> Debug for BitSel<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitSel<{}>(\", type_name::<M>())?;\n\t\tDisplay::fmt(&self, fmt)?;\n\t\tfmt.write_str(\")\")\n\t}\n}","impl<M> Display for BitSel<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"{:0>1$b}\", self.sel, M::BITS as usize)\n\t}\n}"],"index::BitTail":["Clone","Copy","Default","Eq","Hash","Ord","PartialEq","PartialOrd","impl<M> BitTail<M>\nwhere M: BitMemory\n{\n\t/// The inclusive-maximum tail counter.\n\tpub(crate) const END: Self = make!(tail M::BITS);\n\t/// The zero tail.\n\tpub(crate) const ZERO: Self = make!(tail 0);\n\n\t/// Wraps a counter value as an assumed-good tail of an `M` element.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `end`: A semantic index of a dead bit in or after an `M` element.\n\t///\n\t/// # Returns\n\t///\n\t/// `end` wrapped in a `BitTail`.\n\t///\n\t/// # Safety\n\t///\n\t/// `end` **must** be within the valid range `0 ..= M::BITS`. In debug\n\t/// builds, invalid `end` values cause a panic; release builds do not check\n\t/// the input.\n\t#[inline]\n\tpub(crate) unsafe fn new_unchecked(end: u8) -> Self {\n\t\tdebug_assert!(\n\t\t\tend <= M::BITS,\n\t\t\t\"Bit tail {} cannot exceed type width {}\",\n\t\t\tend,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(tail end)\n\t}\n\n\t/// Views the internal tail value.\n\t#[inline]\n\tpub fn value(self) -> u8 {\n\t\tself.end\n\t}\n\n\t/// Ranges over all valid tails for a starting index.\n\t#[inline]\n\tpub(crate) fn range_from(\n\t\tstart: BitIdx<M>,\n\t) -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator {\n\t\t(start.idx ..= Self::END.end).map(|val| make!(tail val))\n\t}\n\n\t/// Computes span information for a region beginning immediately after a\n\t/// preceding region.\n\t///\n\t/// The computed region of `len` bits has its start at the *live* bit that\n\t/// corresponds to the `self` dead tail. The return value is the number of\n\t/// memory elements containing live bits of the computed span and its tail\n\t/// marker.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t/// - `len`: The number of live bits in the span starting after `self`.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The number of elements `M` that contain live bits in the\n\t///   computed region.\n\t/// - `.1`: The tail counter of the first dead bit after the new span.\n\t///\n\t/// # Behavior\n\t///\n\t/// If `len` is `0`, this returns `(0, self)`, as the span has no live bits.\n\t/// If `self` is `BitTail::END`, then the new region starts at\n\t/// `BitIdx::ZERO` in the next element.\n\tpub(crate) fn span(self, len: usize) -> (usize, Self) {\n\t\tif len == 0 {\n\t\t\treturn (0, self);\n\t\t}\n\n\t\tlet val = self.end;\n\n\t\tlet head = val & M::MASK;\n\t\tlet bits_in_head = (M::BITS - head) as usize;\n\n\t\tif len <= bits_in_head {\n\t\t\treturn (1, make!(tail head + len as u8));\n\t\t}\n\n\t\tlet bits_after_head = len - bits_in_head;\n\t\tlet elts = bits_after_head >> M::INDX;\n\t\tlet tail = bits_after_head as u8 & M::MASK;\n\n\t\tlet is_zero = (tail == 0) as u8;\n\t\tlet edges = 2 - is_zero as usize;\n\t\t(elts + edges, make!(tail(is_zero << M::INDX) | tail))\n\t}\n}","impl<M> Debug for BitTail<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitTail<{}>({})\", type_name::<M>(), self.end)\n\t}\n}","impl<M> Display for BitTail<M>\nwhere M: BitMemory\n{\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tDisplay::fmt(&self.end, fmt)\n\t}\n}"],"order::Lsb0":["Clone","Copy","Debug","Default","Eq","Hash","Ord","PartialEq","PartialOrd","unsafe impl BitOrder for Lsb0 {\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tfn at<M>(index: BitIdx<M>) -> BitPos<M>\n\twhere M: BitMemory {\n\t\tunsafe { BitPos::new_unchecked(index.value()) }\n\t}\n\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory {\n\t\tunsafe { BitSel::new_unchecked(M::ONE << index.value()) }\n\t}\n\n\tfn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,\n\t{\n\t\tlet from = from.into().unwrap_or(BitIdx::ZERO).value();\n\t\tlet upto = upto.into().unwrap_or(BitTail::END).value();\n\t\tdebug_assert!(upto >= from, \"Ranges must run from low index to high\");\n\t\tlet ct = upto - from;\n\t\tif ct == M::BITS {\n\t\t\treturn BitMask::ALL;\n\t\t}\n\t\t//  1. Set all bits high.\n\t\t//  2. Shift left by the number of bits in the mask. These are now low.\n\t\t//  3. Invert. The mask bits are high, the rest are low, but at LSedge.\n\t\t//  4. Shift left by the distance from LSedge.\n\t\tunsafe { BitMask::new(!(M::ALL << ct) << from) }\n\t}\n}"],"order::Msb0":["Clone","Copy","Debug","Default","Eq","Hash","Ord","PartialEq","PartialOrd","unsafe impl BitOrder for Msb0 {\n\t#[inline]\n\tfn at<M>(index: BitIdx<M>) -> BitPos<M>\n\twhere M: BitMemory {\n\t\tunsafe { BitPos::new_unchecked(M::MASK - index.value()) }\n\t}\n\n\t#[inline]\n\tfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory {\n\t\t/* Set the MSbit, then shift it down. The left expr is const-folded.\n\t\tNote: this is not equivalent to `1 << (mask - index)`, because that\n\t\trequires a runtime subtraction, but the expression below is only a\n\t\tsingle right-shift.\n\t\t*/\n\t\tunsafe { BitSel::new_unchecked((M::ONE << M::MASK) >> index.value()) }\n\t}\n\n\tfn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,\n\t{\n\t\tlet from = from.into().unwrap_or(BitIdx::ZERO).value();\n\t\tlet upto = upto.into().unwrap_or(BitTail::END).value();\n\t\tdebug_assert!(upto >= from, \"Ranges must run from low index to high\");\n\t\tlet ct = upto - from;\n\t\tif ct == M::BITS {\n\t\t\treturn BitMask::ALL;\n\t\t}\n\t\t//  1. Set all bits high\n\t\t//  2. Shift right by the number of bits in the mask. These are now low.\n\t\t//  3. Invert. The mask bits are high, the rest are low, but at MSedge.\n\t\t//  4. Shift right by the distance from MSedge.\n\t\tunsafe { BitMask::new(!(M::ALL >> ct) >> from) }\n\t}\n}"],"pointer::Address":["Eq","Hash","Ord","PartialEq","PartialOrd","impl<T> Address<T>\nwhere T: BitStore\n{\n\t/// Views a numeric address as a typed data address.\n\t#[inline(always)]\n\tpub(crate) fn new(addr: usize) -> Self {\n\t\tSelf {\n\t\t\taddr,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}\n\n\t/// Views the memory address as an access pointer.\n\t#[inline(always)]\n\tpub(crate) fn to_access(self) -> *const T::Access {\n\t\tself.addr as *const T::Access\n\t}\n\n\t/// Views the memory address as an alias pointer.\n\t#[inline(always)]\n\tpub(crate) fn to_alias(self) -> *const T::Alias {\n\t\tself.addr as *const T::Alias\n\t}\n\n\t/// Views the memory address as an immutable pointer.\n\t#[inline(always)]\n\tpub(crate) fn to_const(self) -> *const T {\n\t\tself.addr as *const T\n\t}\n\n\t/// Views the memory address as a mutable pointer.\n\t#[inline(always)]\n\t#[allow(clippy::wrong_self_convention)]\n\tpub(crate) fn to_mut(self) -> *mut T {\n\t\tself.addr as *mut T\n\t}\n\n\t/// Gets the numeric value of the address.\n\t#[inline(always)]\n\tpub(crate) fn value(self) -> usize {\n\t\tself.addr\n\t}\n}","impl<T> Clone for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn clone(&self) -> Self {\n\t\tSelf { ..*self }\n\t}\n}","impl<T> Copy for Address<T> where T: BitStore\n{\n}","impl<T> Debug for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t<Self as Pointer>::fmt(&self, fmt)\n\t}\n}","impl<T> From<&T> for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn from(addr: &T) -> Self {\n\t\t(addr as *const T).into()\n\t}\n}","impl<T> From<&mut T> for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn from(addr: &mut T) -> Self {\n\t\t(addr as *mut T).into()\n\t}\n}","impl<T> From<*const T> for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn from(addr: *const T) -> Self {\n\t\tSelf::new((addr) as usize)\n\t}\n}","impl<T> From<*mut T> for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn from(addr: *mut T) -> Self {\n\t\tSelf::new(addr as usize)\n\t}\n}","impl<T> Pointer for Address<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tPointer::fmt(&self.to_const(), fmt)\n\t}\n}"],"pointer::BitPtr":["Eq","Hash","impl<T, U> PartialEq<BitPtr<U>> for BitPtr<T>\nwhere\n\tT: BitStore,\n\tU: BitStore,\n{\n\tfn eq(&self, other: &BitPtr<U>) -> bool {\n\t\tlet (addr_a, head_a, bits_a) = self.raw_parts();\n\t\tlet (addr_b, head_b, bits_b) = other.raw_parts();\n\t\t//  Since ::BITS is an associated const, the compiler will automatically\n\t\t//  replace the entire function with `false` when the types don’t match.\n\t\tT::Mem::BITS == U::Mem::BITS\n\t\t\t&& addr_a.value() == addr_b.value()\n\t\t\t&& head_a.value() == head_b.value()\n\t\t\t&& bits_a == bits_b\n\t}\n}","impl<T> BitPtr<T>\nwhere T: BitStore\n{\n\t/// The canonical representation of a pointer to an empty region.\n\tpub(crate) const EMPTY: Self = Self {\n\t\t/* Note: this must always construct the `T` dangling pointer, and then\n\t\tconvert it into a pointer to `u8`. Creating `NonNull::dangling()`\n\t\tdirectly will always instantiate the `NonNull::<u8>::dangling()`\n\t\tpointer, which is VERY incorrect for any other `T` typarams.\n\t\t*/\n\t\tptr: unsafe {\n\t\t\tNonNull::new_unchecked(NonNull::<T>::dangling().as_ptr() as *mut u8)\n\t\t},\n\t\tlen: 0,\n\t\t_ty: PhantomData,\n\t};\n\t/// The number of low bits of `self.len` required to hold the low bits of\n\t/// the head `BitIdx` cursor.\n\t///\n\t/// This is always `3`, until Rust tries to target an architecture that does\n\t/// not have 8-bit bytes.\n\tpub(crate) const LEN_HEAD_BITS: usize = 3;\n\t/// Marks the bits of `self.len` that hold part of the `head` logical field.\n\tpub(crate) const LEN_HEAD_MASK: usize = 0b0111;\n\t/// Marks the bits of `self.ptr` that hold the `addr` logical field.\n\tpub(crate) const PTR_ADDR_MASK: usize = !0 << Self::PTR_HEAD_BITS;\n\t/// The number of low bits of `self.ptr` required to hold the high bits of\n\t/// the head `BitIdx` cursor.\n\tpub(crate) const PTR_HEAD_BITS: usize =\n\t\tT::Mem::INDX as usize - Self::LEN_HEAD_BITS;\n\t/// Marks the bits of `self.ptr` that hold part of the `head` logical field.\n\tpub(crate) const PTR_HEAD_MASK: usize = !Self::PTR_ADDR_MASK;\n\t/// The inclusive maximum number of bits that a `BitPtr` can cover.\n\tpub(crate) const REGION_MAX_BITS: usize = !0 >> Self::LEN_HEAD_BITS;\n\t/// The inclusive maximum number of elements that the region described by a\n\t/// `BitPtr` can cover in memory.\n\t///\n\t/// This is the number of elements required to store `MAX_BITS`, plus one\n\t/// because a region could start in the middle of its base element and thus\n\t/// push the final bits into a new element.\n\t///\n\t/// Since the region is ⅛th the bit span of a `usize` counter already, this\n\t/// number is guaranteed to be well below the limits of arithmetic or Rust’s\n\t/// own constraints on memory region handles.\n\tpub(crate) const REGION_MAX_ELTS: usize =\n\t\tcrate::mem::elts::<T::Mem>(Self::REGION_MAX_BITS) + 1;\n\n\t/// Constructs an empty `BitPtr` at a bare pointer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `addr`: Some allocated address of a `T` element or region.\n\t///\n\t/// # Returns\n\t///\n\t/// A zero-length `BitPtr` at `addr`.\n\t///\n\t/// # Panics\n\t///\n\t/// This function panics if `addr` is not well-aligned to `T`. All addresses\n\t/// received from the Rust allocation system are required to satisfy this\n\t/// constraint.\n\t#[cfg(feature = \"alloc\")]\n\tpub(crate) fn uninhabited(addr: impl Into<Address<T>>) -> Self {\n\t\tlet addr = addr.into();\n\t\tassert!(\n\t\t\taddr.value().trailing_zeros() as usize >= Self::PTR_HEAD_BITS,\n\t\t\t\"Pointer {:p} does not satisfy minimum alignment requirements {}\",\n\t\t\taddr.to_const(),\n\t\t\tSelf::PTR_HEAD_BITS\n\t\t);\n\t\tSelf {\n\t\t\tptr: match NonNull::new(addr.to_mut() as *mut u8) {\n\t\t\t\tSome(nn) => nn,\n\t\t\t\tNone => return Self::EMPTY,\n\t\t\t},\n\t\t\tlen: 0,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}\n\n\t/// Constructs a new `BitPtr` from its components.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `addr`: A well-aligned pointer to a storage element.\n\t/// - `head`: The bit index of the first live bit in the element under\n\t///   `*addr`.\n\t/// - `bits`: The number of live bits in the region the produced `BitPtr<T>`\n\t///   describes.\n\t///\n\t/// # Returns\n\t///\n\t/// This returns `None` in the following cases:\n\t///\n\t/// - `addr` is the null pointer, or is not adequately aligned for `T`.\n\t/// - `bits` is greater than `Self::REGION_MAX_BITS`, and cannot be encoded\n\t///   into a `BitPtr`.\n\t/// - addr` is so high in the address space that the element slice wraps\n\t///   around the address space boundary.\n\t///\n\t/// # Safety\n\t///\n\t/// The caller must provide an `addr` pointer and a `bits` counter which\n\t/// describe a `[T]` region which is correctly aligned and validly allocated\n\t/// in the caller’s memory space. The caller is responsible for ensuring\n\t/// that the slice of memory the produced `BitPtr<T>` describes is all\n\t/// governable in the caller’s context.\n\tpub(crate) fn new(\n\t\taddr: impl Into<Address<T>>,\n\t\thead: BitIdx<T::Mem>,\n\t\tbits: usize,\n\t) -> Option<Self>\n\t{\n\t\tlet addr = addr.into();\n\n\t\tif addr.to_const().is_null() {\n\t\t\treturn None;\n\t\t}\n\n\t\tif (addr.value().trailing_zeros() as usize) < Self::PTR_HEAD_BITS {\n\t\t\treturn None;\n\t\t}\n\n\t\tif bits > Self::REGION_MAX_BITS {\n\t\t\treturn None;\n\t\t}\n\n\t\tlet elts = head.span(bits).0;\n\t\tlet last = addr.to_const().wrapping_add(elts);\n\t\tif last < addr.to_const() {\n\t\t\treturn None;\n\t\t}\n\n\t\tSome(unsafe { Self::new_unchecked(addr, head, bits) })\n\t}\n\n\t/// Creates a new `BitPtr<T>` from its components, without any validity\n\t/// checks.\n\t///\n\t/// # Safety\n\t///\n\t/// ***ABSOLUTELY NONE.*** This function *only* packs its arguments into the\n\t/// bit pattern of the `BitPtr<T>` type. It should only be used in contexts\n\t/// where a previously extant `BitPtr<T>` was constructed with ancestry\n\t/// known to have survived [`::new`], and any manipulations of its raw\n\t/// components are known to be valid for reconstruction.\n\t///\n\t/// # Parameters\n\t///\n\t/// See [`::new`].\n\t///\n\t/// # Returns\n\t///\n\t/// See [`::new`].\n\t///\n\t/// [`::new`]: #method.new\n\t#[inline]\n\tpub(crate) unsafe fn new_unchecked(\n\t\taddr: impl Into<Address<T>>,\n\t\thead: BitIdx<T::Mem>,\n\t\tbits: usize,\n\t) -> Self\n\t{\n\t\tlet (addr, head) = (addr.into(), head.value() as usize);\n\n\t\tlet ptr_data = addr.value() & Self::PTR_ADDR_MASK;\n\t\tlet ptr_head = head >> Self::LEN_HEAD_BITS;\n\n\t\tlet len_head = head & Self::LEN_HEAD_MASK;\n\t\tlet len_bits = bits << Self::LEN_HEAD_BITS;\n\n\t\tlet ptr = Address::new(ptr_data | ptr_head);\n\n\t\tSelf {\n\t\t\tptr: NonNull::new_unchecked(ptr.to_mut()),\n\t\t\tlen: len_bits | len_head,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}\n\n\t/// Gets the base element address of the referent region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// The address of the starting element of the memory region. This address\n\t/// is weakly typed so that it can be cast by call sites to the most useful\n\t/// access type.\n\t#[inline]\n\tpub(crate) fn pointer(&self) -> Address<T> {\n\t\tAddress::new(self.ptr.as_ptr() as usize & Self::PTR_ADDR_MASK)\n\t}\n\n\t/// Overwrites the data pointer with a new address. This method does not\n\t/// perform safety checks on the new pointer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `ptr`: The new address of the `BitPtr<T>`’s domain.\n\t///\n\t/// # Safety\n\t///\n\t/// None. The invariants of `::new` must be checked at the caller.\n\t#[inline]\n\t#[cfg(feature = \"alloc\")]\n\tpub(crate) unsafe fn set_pointer(&mut self, addr: impl Into<Address<T>>) {\n\t\tlet mut addr = addr.into();\n\t\tif addr.to_const().is_null() {\n\t\t\t*self = Self::EMPTY;\n\t\t\treturn;\n\t\t}\n\t\taddr.addr &= Self::PTR_ADDR_MASK;\n\t\taddr.addr |= self.ptr.as_ptr() as usize & Self::PTR_HEAD_MASK;\n\t\tself.ptr = NonNull::new_unchecked(addr.to_mut() as *mut u8);\n\t}\n\n\t/// Gets the starting bit index of the referent region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitIdx` of the first live bit in the element at the `self.pointer()`\n\t/// address.\n\tpub(crate) fn head(&self) -> BitIdx<T::Mem> {\n\t\t//  Get the high part of the head counter out of the pointer.\n\t\tlet ptr = self.ptr.as_ptr() as usize;\n\t\tlet ptr_head = (ptr & Self::PTR_HEAD_MASK) << Self::LEN_HEAD_BITS;\n\t\t//  Get the low part of the head counter out of the length.\n\t\tlet len_head = self.len & Self::LEN_HEAD_MASK;\n\t\t//  Combine and mark as an index.\n\t\tunsafe { BitIdx::new_unchecked((ptr_head | len_head) as u8) }\n\t}\n\n\t/// Write a new `head` value into the pointer, with no other effects.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `head`: A new starting index.\n\t///\n\t/// # Effects\n\t///\n\t/// `head` is written into the `.head` logical field, without affecting\n\t/// `.addr` or `.bits`.\n\t#[cfg(feature = \"alloc\")]\n\tpub(crate) unsafe fn set_head(&mut self, head: BitIdx<T::Mem>) {\n\t\tlet head = head.value() as usize;\n\t\tlet mut ptr = self.ptr.as_ptr() as usize;\n\n\t\tptr &= Self::PTR_ADDR_MASK;\n\t\tptr |= head >> Self::LEN_HEAD_BITS;\n\t\tself.ptr = NonNull::new_unchecked(ptr as *mut u8);\n\n\t\tself.len &= !Self::LEN_HEAD_MASK;\n\t\tself.len |= head & Self::LEN_HEAD_MASK;\n\t}\n\n\t/// Gets the number of live bits in the referent region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A count of how many live bits the region pointer describes.\n\t#[inline]\n\tpub(crate) fn len(&self) -> usize {\n\t\tself.len >> Self::LEN_HEAD_BITS\n\t}\n\n\t/// Sets the `.bits` logical member to a new value.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `len`: A new bit length. This must not be greater than\n\t///   `Self::REGION_MAX_BITS`.\n\t///\n\t/// # Effects\n\t///\n\t/// The `new_len` value is written directly into the `.bits` logical field.\n\t#[inline]\n\tpub(crate) unsafe fn set_len(&mut self, new_len: usize) {\n\t\tdebug_assert!(\n\t\t\tnew_len <= Self::REGION_MAX_BITS,\n\t\t\t\"Length {} out of range\",\n\t\t\tnew_len,\n\t\t);\n\t\tself.len &= Self::LEN_HEAD_MASK;\n\t\tself.len |= new_len << Self::LEN_HEAD_BITS;\n\t}\n\n\t/// Gets the three logical components of the pointer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: The base address of the referent memory region.\n\t/// - `.1`: The index of the first live bit in the first element of the\n\t///   region.\n\t/// - `.2`: The number of live bits in the region.\n\t#[inline]\n\tpub(crate) fn raw_parts(&self) -> (Address<T>, BitIdx<T::Mem>, usize) {\n\t\t(self.pointer(), self.head(), self.len())\n\t}\n\n\t/// Computes the number of elements, starting at `self.pointer()`, that the\n\t/// region touches.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// The count of all elements, starting at `self.pointer()`, that contain\n\t/// live bits included in the referent region.\n\tpub(crate) fn elements(&self) -> usize {\n\t\t//  Find the distance of the last bit from the base address.\n\t\tlet total = self.len() + self.head().value() as usize;\n\t\t//  The element count is always the bit count divided by the bit width,\n\t\tlet base = total >> T::Mem::INDX;\n\t\t//  plus whether any fractional element exists after the division.\n\t\tlet tail = total as u8 & T::Mem::MASK;\n\t\tbase + (tail != 0) as usize\n\t}\n\n\t/// Computes the tail index for the first dead bit after the live bits.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitTail` that is the index of the first dead bit after the last live\n\t/// bit in the last element. This will almost always be in the range `1 ..=\n\t/// T::Mem::BITS`.\n\t///\n\t/// It will be zero only when `self` is empty.\n\t#[inline]\n\tpub(crate) fn tail(&self) -> BitTail<T::Mem> {\n\t\tlet (head, len) = (self.head(), self.len());\n\n\t\tif head.value() == 0 && len == 0 {\n\t\t\treturn BitTail::ZERO;\n\t\t}\n\n\t\t//  Compute the in-element tail index as the head plus the length,\n\t\t//  modulated by the element width.\n\t\tlet tail = (head.value() as usize + len) & T::Mem::MASK as usize;\n\t\t/* If the tail is zero, wrap it to `T::Mem::BITS` as the maximal. This\n\t\tupshifts `1` (tail is zero) or `0` (tail is not), then sets the upshift\n\t\ton the rest of the tail, producing something in the range\n\t\t`1 ..= T::Mem::BITS`.\n\t\t*/\n\t\tunsafe {\n\t\t\tBitTail::new_unchecked(\n\t\t\t\t(((tail == 0) as u8) << T::Mem::INDX) | tail as u8,\n\t\t\t)\n\t\t}\n\t}\n\n\t/// Increments the `.head` logical field, rolling over into `.addr`.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t///\n\t/// # Effects\n\t///\n\t/// Increments `.head` by one. If the increment resulted in a rollover to\n\t/// `0`, then the `.addr` field is increased to the next `T::Mem` stepping.\n\t#[inline]\n\tpub(crate) unsafe fn incr_head(&mut self) {\n\t\t//  Increment the cursor, permitting rollover to `T::Mem::BITS`.\n\t\tlet head = self.head().value() as usize + 1;\n\n\t\t//  Write the low bits into the `.len` field, then discard them.\n\t\tself.len &= !Self::LEN_HEAD_MASK;\n\t\tself.len |= head & Self::LEN_HEAD_MASK;\n\t\tlet head = head >> Self::LEN_HEAD_BITS;\n\n\t\t//  Erase the high bits of `.head` from `.ptr`,\n\t\tlet mut ptr = self.ptr.as_ptr() as usize;\n\t\tptr &= Self::PTR_ADDR_MASK;\n\t\t/* Then numerically add the high bits of `.head` into the low bits of\n\t\t`.ptr`. If the head increment rolled over into a new element, this will\n\t\thave the effect of raising the `.addr` logical field to the next element\n\t\taddress, in one instruction.\n\t\t*/\n\t\tptr += head;\n\t\tself.ptr = NonNull::new_unchecked(ptr as *mut u8);\n\t}\n\n\t/// Views the referent memory region as a slice of aliased elements.\n\t///\n\t/// This view will cause UB if it is used simultaneously with views of the\n\t/// referent region that assume full immutability of referent data.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A slice handle over all memory elements this pointer describes.\n\t///\n\t/// # Safety\n\t///\n\t/// `T` will be marked as `::Alias` where necessary by `BitSlice`, and so\n\t/// this pointer already contains the aliasing information it needs to be\n\t/// safe.\n\t#[inline]\n\tpub(crate) fn as_aliased_slice<'a>(&self) -> &'a [T::Alias] {\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(self.pointer().to_alias(), self.elements())\n\t\t}\n\t}\n\n\t/// Reads a bit some distance away from `self`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The bit distance away from `self` at which to read.\n\t///\n\t/// # Returns\n\t///\n\t/// The value of the bit `index` bits away from `self.head()`, according to\n\t/// the `O` ordering.\n\t#[inline]\n\tpub(crate) unsafe fn read<O>(&self, index: usize) -> bool\n\twhere O: BitOrder {\n\t\tlet (elt, bit) = self.head().offset(index as isize);\n\t\tlet base = self.pointer().to_access();\n\t\t(&*base.offset(elt)).get_bit::<O>(bit)\n\t}\n\n\t/// Writes a bit some distance away from `self`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: The `self` pointer must be describing a write-capable region.\n\t/// - `index`: The bit distance away from `self` at which to write,\n\t///   according to the `O` ordering.\n\t/// - `value`: The bit value to insert at `index`.\n\t///\n\t/// # Effects\n\t///\n\t/// `value` is written to the bit specified by `index`, relative to\n\t/// `self.head()` and `self.pointer()`.\n\t#[inline]\n\tpub(crate) unsafe fn write<O>(&self, index: usize, value: bool)\n\twhere O: BitOrder {\n\t\tlet (elt, bit) = self.head().offset(index as isize);\n\t\tlet base = self.pointer().to_access();\n\t\t(&*base.offset(elt)).write_bit::<O>(bit, value);\n\t}\n\n\t/// Typecasts a raw region pointer into a pointer structure.\n\t#[inline]\n\tpub(crate) fn from_bitslice_ptr<O>(raw: *const BitSlice<O, T>) -> Self\n\twhere O: BitOrder {\n\t\tlet slice_nn = match NonNull::new(raw as *const [()] as *mut [()]) {\n\t\t\tSome(r) => r,\n\t\t\tNone => return Self::EMPTY,\n\t\t};\n\t\tlet ptr = dvl::nonnull_slice_to_base(slice_nn).cast::<u8>();\n\t\tlet len = unsafe { slice_nn.as_ref() }.len();\n\t\tSelf {\n\t\t\tptr,\n\t\t\tlen,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}\n\n\t/// Typecasts a raw region pointer into a pointer structure.\n\t#[inline(always)]\n\t#[cfg(feature = \"alloc\")]\n\tpub(crate) fn from_bitslice_ptr_mut<O>(raw: *mut BitSlice<O, T>) -> Self\n\twhere O: BitOrder {\n\t\tSelf::from_bitslice_ptr(raw as *const BitSlice<O, T>)\n\t}\n\n\t/// Type-casts the pointer structure into a raw region pointer.\n\t#[inline]\n\tpub(crate) fn to_bitslice_ptr<O>(self) -> *const BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tptr::slice_from_raw_parts(\n\t\t\tself.ptr.as_ptr() as *const u8 as *const (),\n\t\t\tself.len,\n\t\t) as *const BitSlice<O, T>\n\t}\n\n\t/// Typecasts the pointer structure into a raw mutable-region pointer.\n\t#[inline(always)]\n\tpub(crate) fn to_bitslice_ptr_mut<O>(self) -> *mut BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tself.to_bitslice_ptr::<O>() as *mut BitSlice<O, T>\n\t}\n\n\t/// Typecasts the pointer structure into a region reference.\n\t///\n\t/// # Safety\n\t///\n\t/// This must only be used when the pointer refers to a region that is\n\t/// correctly initialized in the caller’s context. There must be no `&mut\n\t/// BitSlice<O, T>` references to the referent region.\n\t///\n\t/// # Lifetimes\n\t///\n\t/// - `'a`: The minimum lifetime of the referent region, as understood by\n\t///   the caller.\n\tpub(crate) fn to_bitslice_ref<'a, O>(self) -> &'a BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tunsafe { &*self.to_bitslice_ptr::<O>() }\n\t}\n\n\t/// Typecasts the pointer structure into a mutable-region reference.\n\t///\n\t/// # Safety\n\t///\n\t/// This must only be used when the pointer refers to a region that is\n\t/// correctly initialized *and uniquely mutable* in the caller’s context.\n\t/// There must be no other references of any kind to the referent region.\n\t///\n\t/// # Lifetimes\n\t///\n\t/// - `'a`: The minimum lifetime of the referent region, as understood by\n\t///   the caller.\n\tpub(crate) fn to_bitslice_mut<'a, O>(self) -> &'a mut BitSlice<O, T>\n\twhere O: BitOrder {\n\t\tunsafe { &mut *self.to_bitslice_ptr_mut::<O>() }\n\t}\n\n\t/// Typecasts the pointer structure into a `NonNull<BitSlice>` pointer.\n\t///\n\t/// This function is used by the owning indirect handles, and does not yet\n\t/// have any purpose in non-`alloc` programs.\n\t#[cfg(feature = \"alloc\")]\n\tpub(crate) fn to_nonnull<O>(self) -> NonNull<BitSlice<O, T>>\n\twhere\n\t\tO: BitOrder,\n\t\tT: BitStore,\n\t{\n\t\tunsafe { NonNull::new_unchecked(self.to_bitslice_ptr_mut()) }\n\t}\n\n\t/// Renders the pointer structure into a formatter for use during\n\t/// higher-level type `Debug` implementations.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t/// - `fmt`: The formatter into which the pointer is written.\n\t/// - `name`: The suffix of the higher-level object rendering its pointer.\n\t///   The `Bit` prefix is applied to the object type name in this format.\n\t/// - `ord`: The name of a `BitOrder` type parameter, if any.\n\t/// - `fields`: Any additional fields in the object’s debuginfo to be\n\t///   rendered.\n\t///\n\t/// # Returns\n\t///\n\t/// The result of formatting the pointer into the receiver.\n\t///\n\t/// # Behavior\n\t///\n\t/// This function writes `Bit{name}<[{ord}, ]T> {{ {fields} }}` into the\n\t/// `fmt` formatter, where `{fields}` includes the address, head index, and\n\t/// bit count of the pointer, as well as any additional fields provided by\n\t/// the caller.\n\t///\n\t/// Higher types in the crate should use this function to drive their\n\t/// `Debug` implementations, and then use `BitSlice`’s list formatters to\n\t/// display their contents if appropriate.\n\tpub(crate) fn render<'a>(\n\t\t&'a self,\n\t\tfmt: &'a mut Formatter,\n\t\tname: &'a str,\n\t\tord: Option<&'a str>,\n\t\tfields: impl IntoIterator<Item = &'a (&'static str, &'a dyn Debug)>,\n\t) -> fmt::Result\n\t{\n\t\twrite!(fmt, \"Bit{}<\", name)?;\n\t\tif let Some(ord) = ord {\n\t\t\twrite!(fmt, \"{}, \", ord)?;\n\t\t}\n\t\twrite!(fmt, \"{}>\", any::type_name::<T::Mem>())?;\n\t\tlet mut builder = fmt.debug_struct(\"\");\n\t\tbuilder\n\t\t\t.field(\"addr\", &self.pointer().fmt_pointer())\n\t\t\t.field(\"head\", &self.head().fmt_binary())\n\t\t\t.field(\"bits\", &self.len());\n\t\tfor (name, value) in fields {\n\t\t\tbuilder.field(name, value);\n\t\t}\n\t\tbuilder.finish()\n\t}\n}","impl<T> Clone for BitPtr<T>\nwhere T: BitStore\n{\n\tfn clone(&self) -> Self {\n\t\tSelf { ..*self }\n\t}\n}","impl<T> Copy for BitPtr<T> where T: BitStore\n{\n}","impl<T> Debug for BitPtr<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tPointer::fmt(self, fmt)\n\t}\n}","impl<T> Default for BitPtr<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn default() -> Self {\n\t\tSelf::EMPTY\n\t}\n}","impl<T> Pointer for BitPtr<T>\nwhere T: BitStore\n{\n\t#[inline(always)]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tself.render(fmt, \"Ptr\", None, None)\n\t}\n}"],"slice::BitSlice":["impl<O, T, Rhs> BitAndAssign<Rhs> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: IntoIterator<Item = bool>,\n{\n\tfn bitand_assign(&mut self, rhs: Rhs) {\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit & iter.next().unwrap_or(false));\n\t}\n}","impl<O, T, Rhs> BitOrAssign<Rhs> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: IntoIterator<Item = bool>,\n{\n\tfn bitor_assign(&mut self, rhs: Rhs) {\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit | iter.next().unwrap_or(false));\n\t}\n}","impl<O, T, Rhs> BitXorAssign<Rhs> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: IntoIterator<Item = bool>,\n{\n\tfn bitxor_assign(&mut self, rhs: Rhs) {\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit ^ iter.next().unwrap_or(false));\n\t}\n}","impl<O, T> $trait for BitSlice<O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t/// Renders an accumulated text buffer as UTF-8.\n\t\t\t\tstruct Seq<'a>(&'a [u8]);\n\t\t\t\timpl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//  If the alternate flag is set, include the radix prefix.\n\t\t\t\tlet start = if fmt.alternate() { 0 } else { 2 };\n\t\t\t\t//  Create a list format accumulator.\n\t\t\t\tlet mut dbg = fmt.debug_list();\n\t\t\t\t/* Create a static buffer of the maximum number of UTF-8 bytes\n\t\t\t\tneeded to render a `usize` in the selected radix. Rust does not\n\t\t\t\tyet grant access to trait constants for use in constant\n\t\t\t\texpressions within generics.\n\t\t\t\t*/\n\t\t\t\tlet mut w: [u8; (usize::BITS as usize / $blksz) + 2] =\n\t\t\t\t\t[b'0'; (usize::BITS as usize / $blksz) + 2];\n\t\t\t\t//  Write the prefix symbol into the buffer.\n\t\t\t\tw[1] = $pfx;\n\t\t\t\t//  This closure does the main work of rendering a bit slice as\n\t\t\t\t//  text. It will be called on each memory element of the slice\n\t\t\t\t//  undergoing formatting.\n\t\t\t\tlet mut writer = |bits: &BitSlice<O, T::Mem>| {\n\t\t\t\t\t//  Set the end index of the format buffer.\n\t\t\t\t\tlet mut end = 2;\n\t\t\t\t\t/* Taking `rchunks` clusters the bits to the right edge, so\n\t\t\t\t\tthat any remainder is in the left-most (first-rendered)\n\t\t\t\t\tdigit, in the same manner as how English clusters digits in\n\t\t\t\t\tordinary writing.\n\n\t\t\t\t\tSince `rchunks` takes from the back, it must be reversed in\n\t\t\t\t\torder to traverse from front to back. The enumeration\n\t\t\t\t\tprovides the offset from the buffer start for writing the\n\t\t\t\t\tcomputed digit into the format buffer.\n\t\t\t\t\t*/\n\t\t\t\t\tfor (index, chunk) in bits.rchunks($blksz).rev().enumerate()\n\t\t\t\t\t{\n\t\t\t\t\t\t//  Accumulate an Lsb0 representation of the slice\n\t\t\t\t\t\t//  contents.\n\t\t\t\t\t\tlet mut val = 0u8;\n\t\t\t\t\t\tfor bit in chunk {\n\t\t\t\t\t\t\tval <<= 1;\n\t\t\t\t\t\t\tval |= *bit as u8;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//  Translate the accumulator into ASCII hexadecimal\n\t\t\t\t\t\t//  glyphs, and write the glyph into the format buffer.\n\t\t\t\t\t\tw[2 + index] = match val {\n\t\t\t\t\t\t\tv @ 0 ..= 9 => b'0' + v,\n\t\t\t\t\t\t\tv @ 10 ..= 16 => $base + (v - 10),\n\t\t\t\t\t\t\t_ => unsafe { core::hint::unreachable_unchecked() },\n\t\t\t\t\t\t};\n\t\t\t\t\t\tend += 1;\n\t\t\t\t\t}\n\t\t\t\t\t//  View the format buffer as UTF-8 and write it into the\n\t\t\t\t\t//  main formatter.\n\t\t\t\t\tdbg.entry(&Seq(&w[start .. end]));\n\t\t\t\t};\n\t\t\t\t//  Break the source `BitSlice` into its element-wise components.\n\t\t\t\tmatch self.domain() {\n\t\t\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t\t\t//  Load a copy of `*elem` into the stack,\n\t\t\t\t\t\tlet tmp: T::Mem =\n\t\t\t\t\t\t\telem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t//  View it as a `BitSlice` over the whole element,\n\t\t\t\t\t\t// narrow it to the live range, and render it.\n\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\tbits.get_unchecked(\n\t\t\t\t\t\t\t\thead.value() as usize .. tail.value() as usize,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t.pipe(writer);\n\t\t\t\t\t},\n\t\t\t\t\t//  Same process as above, but with different truncations.\n\t\t\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(head.value() as usize ..)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor elem in body.iter() {\n\t\t\t\t\t\t\telem.pipe(BitSlice::<O, T::Mem>::from_element)\n\t\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(.. tail.value() as usize)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tdbg.finish()\n\t\t\t}\n\t\t}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore + BitMemory,\n{\n\t/// Constructs a shared `&BitSlice` reference over a shared element.\n\t///\n\t/// The [`BitView`] trait, implemented on all `T` elements, provides a\n\t/// method [`.view_bits::<O>()`] which delegates to this function and may be\n\t/// more convenient for you to write.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `elem`: A shared reference to a memory element.\n\t///\n\t/// # Returns\n\t///\n\t/// A shared `&BitSlice` over the `elem` element.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let elem = 0u8;\n\t/// let bits = BitSlice::<Local, _>::from_element(&elem);\n\t/// assert_eq!(bits.len(), 8);\n\t/// ```\n\t///\n\t/// [`BitView`]: ../view/trait.BitView.html\n\t/// [`.view_bits::<O>()`]: ../view/trait.BitView.html#method.view_bits\n\t#[inline]\n\tpub fn from_element(elem: &T) -> &Self {\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(elem, BitIdx::ZERO, T::Mem::BITS as usize)\n\t\t}\n\t\t.to_bitslice_ref()\n\t}\n\n\t/// Constructs an exclusive `&mut BitSlice` reference over an element.\n\t///\n\t/// The [`BitView`] trait, implemented on all `T` elements, provides a\n\t/// method [`.view_bits_mut::<O>()`] which delegates to this function and\n\t/// may be more convenient for you to write.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `elem`: An exclusive reference to a memory element.\n\t///\n\t/// # Returns\n\t///\n\t/// An exclusive `&mut BitSlice` over the `elem` element.\n\t///\n\t/// Note that the original `elem` reference will be inaccessible for the\n\t/// duration of the returned slice handle’s lifetime.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut elem = 0u16;\n\t/// let bits = BitSlice::<Msb0, _>::from_element_mut(&mut elem);\n\t/// bits.set(15, true);\n\t/// assert!(bits.get(15).unwrap());\n\t/// assert_eq!(elem, 1);\n\t/// ```\n\t///\n\t/// [`BitView`]: ../view/trait.BitView.html\n\t/// [`.view_bits_mut::<O>()`]:\n\t/// ../view/trait.BitView.html#method.view_bits_mut\n\t#[inline]\n\tpub fn from_element_mut(elem: &mut T) -> &mut Self {\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(elem, BitIdx::ZERO, T::Mem::BITS as usize)\n\t\t}\n\t\t.to_bitslice_mut()\n\t}\n\n\t/// Constructs a shared `&BitSlice` reference over a shared element slice.\n\t///\n\t/// The [`BitView`] trait, implemented on all `[T]` slices, provides a\n\t/// method [`.view_bits::<O>()`] that is equivalent to this function and may\n\t/// be more convenient for you to write.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `slice`: A shared reference over a sequence of memory elements.\n\t///\n\t/// # Returns\n\t///\n\t/// If `slice` does not have fewer than [`MAX_ELTS`] elements, this returns\n\t/// `None`. Otherwise, it returns a shared `&BitSlice` over the `slice`\n\t/// elements.\n\t///\n\t/// # Conditions\n\t///\n\t/// The produced `&BitSlice` handle always begins at the zeroth bit.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let slice = &[0u8, 1];\n\t/// let bits = BitSlice::<Msb0, _>::from_slice(slice).unwrap();\n\t/// assert!(bits[15]);\n\t/// ```\n\t///\n\t/// An example showing this function failing would require a slice exceeding\n\t/// `!0usize >> 3` bytes in size, which is infeasible to produce.\n\t///\n\t/// [`BitView`]: ../view/trait.BitView.html\n\t/// [`MAX_ELTS`]: #associatedconstant.MAX_ELTS\n\t/// [`.view_bits::<O>()`]: ../view/trait.BitView.html#method.view_bits\n\t#[inline]\n\tpub fn from_slice(slice: &[T]) -> Option<&Self> {\n\t\tlet elts = slice.len();\n\t\t//  Starting at the zeroth bit makes this counter an exclusive cap, not\n\t\t//  an inclusive cap.\n\t\tif elts >= Self::MAX_ELTS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(unsafe { Self::from_slice_unchecked(slice) })\n\t}\n\n\t/// Converts a slice reference into a `BitSlice` reference without checking\n\t/// that its size can be safely used.\n\t///\n\t/// # Safety\n\t///\n\t/// If the `slice` length is too long, then it will be capped at\n\t/// [`MAX_BITS`]. You are responsible for ensuring that the input slice is\n\t/// not unduly truncated.\n\t///\n\t/// Prefer [`from_slice`].\n\t///\n\t/// [`MAX_BITS`]: #associatedconstant.MAX_BITS\n\t/// [`from_slice`]: #method.from_slice\n\t#[inline]\n\tpub unsafe fn from_slice_unchecked(slice: &[T]) -> &Self {\n\t\t//  This branch could be removed by lowering the element ceiling by one,\n\t\t//  but `from_slice` should not be in any tight loops, so it’s fine.\n\t\tlet bits = cmp::min(slice.len() * T::Mem::BITS as usize, Self::MAX_BITS);\n\t\tBitPtr::new_unchecked(slice.as_ptr(), BitIdx::ZERO, bits)\n\t\t\t.to_bitslice_ref()\n\t}\n\n\t/// Constructs an exclusive `&mut BitSlice` reference over a slice.\n\t///\n\t/// The [`BitView`] trait, implemented on all `[T]` slices, provides a\n\t/// method [`.view_bits_mut::<O>()`] that is equivalent to this function and\n\t/// may be more convenient for you to write.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `slice`: An exclusive reference over a sequence of memory elements.\n\t///\n\t/// # Returns\n\t///\n\t/// An exclusive `&mut BitSlice` over the `slice` elements.\n\t///\n\t/// Note that the original `slice` reference will be inaccessible for the\n\t/// duration of the returned slice handle’s lifetime.\n\t///\n\t/// # Panics\n\t///\n\t/// This panics if `slice` does not have fewer than [`MAX_ELTS`] elements.\n\t///\n\t/// [`MAX_ELTS`]: #associatedconstant.MAX_ELTS\n\t///\n\t/// # Conditions\n\t///\n\t/// The produced `&mut BitSlice` handle always begins at the zeroth bit of\n\t/// the zeroth element in `slice`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut slice = [0u8; 2];\n\t/// let bits = BitSlice::<Lsb0, _>::from_slice_mut(&mut slice).unwrap();\n\t///\n\t/// assert!(!bits[0]);\n\t/// bits.set(0, true);\n\t/// assert!(bits[0]);\n\t/// assert_eq!(slice[0], 1);\n\t/// ```\n\t///\n\t/// This example attempts to construct a `&mut BitSlice` handle from a slice\n\t/// that is too large to index. Either the `vec!` allocation will fail, or\n\t/// the bit-slice constructor will fail.\n\t///\n\t/// ```rust,should_panic\n\t/// # #[cfg(feature = \"alloc\")] {\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = vec![0usize; BitSlice::<Local, usize>::MAX_ELTS];\n\t/// let bits = BitSlice::<Local, _>::from_slice_mut(&mut data[..]).unwrap();\n\t/// # }\n\t/// # #[cfg(not(feature = \"alloc\"))] panic!(\"No allocator present\");\n\t/// ```\n\t///\n\t/// [`BitView`]: ../view/trait.BitView.html\n\t/// [`.view_bits_mut::<O>()`]:\n\t/// ../view/trait.BitView.html#method.view_bits_mut\n\t#[inline]\n\tpub fn from_slice_mut(slice: &mut [T]) -> Option<&mut Self> {\n\t\tlet elts = slice.len();\n\t\tif elts >= Self::MAX_ELTS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(unsafe { Self::from_slice_unchecked_mut(slice) })\n\t}\n\n\t/// Converts a slice reference into a `BitSlice` reference without checking\n\t/// that its size can be safely used.\n\t///\n\t/// # Safety\n\t///\n\t/// If the `slice` length is too long, then it will be capped at\n\t/// [`MAX_BITS`]. You are responsible for ensuring that the input slice is\n\t/// not unduly truncated.\n\t///\n\t/// Prefer [`from_slice_mut`].\n\t///\n\t/// [`MAX_BITS`]: #associatedconstant.MAX_BITS\n\t/// [`from_slice_mut`]: #method.from_slice_mut\n\t#[inline]\n\tpub unsafe fn from_slice_unchecked_mut(slice: &mut [T]) -> &mut Self {\n\t\tlet bits = cmp::min(slice.len() * T::Mem::BITS as usize, Self::MAX_BITS);\n\t\tBitPtr::new_unchecked(slice.as_ptr(), BitIdx::ZERO, bits)\n\t\t\t.to_bitslice_mut()\n\t}\n}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore + Radium<<T as BitStore>::Mem>,\n{\n\t/// Constructs a `BitSlice` over aliased memory.\n\t///\n\t/// This is restricted so that it can only be used within the crate.\n\t/// Construction of a `BitSlice` over externally-aliased memory is unsound.\n\tpub(crate) unsafe fn from_aliased_slice_unchecked(slice: &[T]) -> &Self {\n\t\tBitPtr::new_unchecked(\n\t\t\tslice.as_ptr(),\n\t\t\tBitIdx::ZERO,\n\t\t\tslice.len() * T::Mem::BITS as usize,\n\t\t)\n\t\t.to_bitslice_ref()\n\t}\n\n\t/// Splits a mutable slice at some mid-point.\n\t///\n\t/// This method has the same behavior as [`split_at_mut`], except that it\n\t/// does not apply an aliasing marker to the partitioned subslices.\n\t///\n\t/// # Safety\n\t///\n\t/// Because this method is defined only on `BitSlice`s whose `T` type is\n\t/// alias-safe, the subslices do not need to be additionally marked.\n\t///\n\t/// [`split_at_mut`]: #method.split_at_mut\n\t#[inline]\n\t//  `.split_at_mut` is already tested, and `::unalias_mut` is a noöp.\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn split_at_aliased_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut Self, &mut Self)\n\t{\n\t\tlet (head, tail) = self.split_at_mut(mid);\n\t\tunsafe { (Self::unalias_mut(head), Self::unalias_mut(tail)) }\n\t}\n\n\t/// Splits a mutable slice at some mid-point, without checking boundary\n\t/// conditions.\n\t///\n\t/// This method has the same behavior as [`split_at_unchecked_mut`], except\n\t/// that it does not apply an aliasing marker to the partitioned subslices.\n\t///\n\t/// # Safety\n\t///\n\t/// See [`split_at_unchecked_mut`] for safety requirements.\n\t///\n\t/// Because this method is defined only on `BitSlice`s whose `T` type is\n\t/// alias-safe, the subslices do not need to be additionally marked.\n\t///\n\t/// [`split_at_unchecked_mut`]: #method.split_at_unchecked_mut\n\t#[inline]\n\tpub unsafe fn split_at_aliased_unchecked_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut Self, &mut Self)\n\t{\n\t\t//  Split the slice at the requested midpoint, adding an alias layer\n\t\tlet (head, tail) = self.split_at_unchecked_mut(mid);\n\t\t//  Remove the new alias layer.\n\t\t(Self::unalias_mut(head), Self::unalias_mut(tail))\n\t}\n}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Copies `self` into a new `BitVec`.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::to_vec`](https://doc.rust-lang.org/std.primitive.html#method.to_vec)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"stde\")] {\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = bits![0, 1, 0, 1];\n\t/// let bv = bits.to_bitvec();\n\t/// assert_eq!(bits, bv);\n\t/// # }\n\t/// ```\n\t#[inline]\n\tpub fn to_bitvec(&self) -> BitVec<O, T> {\n\t\tself.pipe(BitVec::from_bitslice)\n\t}\n\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.to_bitvec` to convert a bit slice into a vector\")]\n\tpub fn to_vec(&self) -> BitVec<O, T> {\n\t\tself.to_bitvec()\n\t}\n\n\t/// Creates a vector by repeating a slice `n` times.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::repeat`](https://doc.rust-lang.org/std/primitive.slice.html#method.repeat)\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if the capacity would overflow.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// assert_eq!(bits![0, 1].repeat(3), bits![0, 1, 0, 1, 0, 1]);\n\t/// ```\n\t///\n\t/// A panic upon overflow:\n\t///\n\t/// ```rust,should_panic\n\t/// use bitvec::prelude::*;\n\t///\n\t/// // this will panic at runtime\n\t/// bits![0, 1].repeat(BitSlice::<Local, usize>::MAX_BITS);\n\t/// ```\n\t#[inline]\n\tpub fn repeat(&self, n: usize) -> BitVec<O, T>\n\twhere\n\t\tO: BitOrder,\n\t\tT: BitStore,\n\t{\n\t\tlet len = self.len();\n\t\tlet total = len.checked_mul(n).expect(\"capacity overflow\");\n\t\tlet mut out = BitVec::with_capacity(total);\n\t\tfor span in (0 .. n).map(|rep| rep * len .. (rep + 1) * len) {\n\t\t\tunsafe { out.get_unchecked_mut(span) }.clone_from_bitslice(self);\n\t\t}\n\t\tunsafe {\n\t\t\tout.set_len(total);\n\t\t}\n\t\tout\n\t}\n\n\t/* As of 1.43, the `concat` and `join` methods use still-unstable traits to\n\tgovern the collection of multiple subslices into one vector. These are\n\tpossible to copy over and redefine locally, but unless a user asks for it,\n\tdoing so is considered a low priority.\n\t*/\n}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Produces the empty slice. This is equivalent to `&[]` for ordinary\n\t/// slices.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits: &BitSlice = BitSlice::empty();\n\t/// assert!(bits.is_empty());\n\t/// ```\n\t#[inline]\n\tpub fn empty<'a>() -> &'a Self {\n\t\tBitPtr::EMPTY.to_bitslice_ref()\n\t}\n\n\t/// Produces the empty mutable slice. This is equivalent to `&mut []` for\n\t/// ordinary slices.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits: &mut BitSlice = BitSlice::empty_mut();\n\t/// assert!(bits.is_empty());\n\t/// ```\n\t#[inline]\n\tpub fn empty_mut<'a>() -> &'a mut Self {\n\t\tBitPtr::EMPTY.to_bitslice_mut()\n\t}\n\n\t/// Sets the bit value at the given position.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `index`: The bit index to set. It must be in the range `0 ..\n\t///   self.len()`.\n\t/// - `value`: The value to be set, `true` for `1` and `false` for `0`.\n\t///\n\t/// # Effects\n\t///\n\t/// If `index` is valid, then the bit to which it refers is set to `value`.\n\t///\n\t/// # Panics\n\t///\n\t/// This method panics if `index` is outside the slice domain.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// assert!(!bits.get(7).unwrap());\n\t/// bits.set(7, true);\n\t/// assert!(bits.get(7).unwrap());\n\t/// assert_eq!(data, 1);\n\t/// ```\n\t///\n\t/// This example panics when it attempts to set a bit that is out of bounds.\n\t///\n\t/// ```rust,should_panic\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = BitSlice::<Local, usize>::empty_mut();\n\t/// bits.set(0, false);\n\t/// ```\n\t#[inline]\n\tpub fn set(&mut self, index: usize, value: bool) {\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index out of range: {} >= {}\", index, len);\n\t\tunsafe {\n\t\t\tself.set_unchecked(index, value);\n\t\t}\n\t}\n\n\t/// Sets a bit at an index, without checking boundary conditions.\n\t///\n\t/// This is generally not recommended; use with caution! For a safe\n\t/// alternative, see [`set`].\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `index`: The bit index to set. It must be in the range `0 ..\n\t///   self.len()`. It will not be checked.\n\t///\n\t/// # Effects\n\t///\n\t/// The bit at `index` is set to `value`.\n\t///\n\t/// # Safety\n\t///\n\t/// This method is **not** safe. It performs raw pointer arithmetic to seek\n\t/// from the start of the slice to the requested index, and set the bit\n\t/// there. It does not inspect the length of `self`, and it is free to\n\t/// perform out-of-bounds memory *write* access.\n\t///\n\t/// Use this method **only** when you have already performed the bounds\n\t/// check, and can guarantee that the call occurs with a safely in-bounds\n\t/// index.\n\t///\n\t/// # Examples\n\t///\n\t/// This example uses a bit slice of length 2, and demonstrates\n\t/// out-of-bounds access to the last bit in the element.\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = &mut data.view_bits_mut::<Msb0>()[2 .. 4];\n\t///\n\t/// assert_eq!(bits.len(), 2);\n\t/// unsafe {\n\t///   bits.set_unchecked(5, true);\n\t/// }\n\t/// assert_eq!(data, 1);\n\t/// ```\n\t///\n\t/// [`set`]: #method.set\n\t#[inline]\n\tpub unsafe fn set_unchecked(&mut self, index: usize, value: bool) {\n\t\tself.bitptr().write::<O>(index, value);\n\t}\n\n\t/// Tests if *all* bits in the slice domain are set (logical `∧`).\n\t///\n\t/// # Truth Table\n\t///\n\t/// ```text\n\t/// 0 0 => 0\n\t/// 0 1 => 0\n\t/// 1 0 => 0\n\t/// 1 1 => 1\n\t/// ```\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// Whether all bits in the slice domain are set. The empty slice returns\n\t/// `true`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = 0xFDu8.view_bits::<Msb0>();\n\t/// assert!(bits[.. 4].all());\n\t/// assert!(!bits[4 ..].all());\n\t/// ```\n\t#[inline]\n\tpub fn all(&self) -> bool {\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t/* Due to a bug in `rustc`, calling `.value()` on the two\n\t\t\t\t`BitMask` types, to use `T::Mem | T::Mem == T::Mem`, causes type\n\t\t\t\tresolution failure and only discovers the\n\t\t\t\t`for<'a> BitOr<&'a Self>` implementation in the trait bounds\n\t\t\t\t`T::Mem: BitMemory: IsUnsigned: BitOr<Self> + for<'a> BitOr<&'a Self>`.\n\n\t\t\t\tUntil this is fixed, routing through the `BitMask`\n\t\t\t\timplementation suffices. The by-val and by-ref operator traits\n\t\t\t\tare at the same position in the bounds chain, making this quite\n\t\t\t\ta strange bug.\n\t\t\t\t*/\n\t\t\t\t!O::mask(head, tail) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t== BitMask::ALL\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(true, |(head, elem)| {\n\t\t\t\t\t!O::mask(head, None) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t== BitMask::ALL\n\t\t\t\t}) && body.iter().copied().all(|e| e == T::Mem::ALL)\n\t\t\t\t\t&& tail.map_or(true, |(elem, tail)| {\n\t\t\t\t\t\t!O::mask(None, tail) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t\t== BitMask::ALL\n\t\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Tests if *any* bit in the slice is set (logical `∨`).\n\t///\n\t/// # Truth Table\n\t///\n\t/// ```text\n\t/// 0 0 => 0\n\t/// 0 1 => 1\n\t/// 1 0 => 1\n\t/// 1 1 => 1\n\t/// ```\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// Whether any bit in the slice domain is set. The empty slice returns\n\t/// `false`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = 0x40u8.view_bits::<Msb0>();\n\t/// assert!(bits[.. 4].any());\n\t/// assert!(!bits[4 ..].any());\n\t/// ```\n\t#[inline]\n\tpub fn any(&self) -> bool {\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tO::mask(head, tail) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t!= BitMask::ZERO\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(false, |(head, elem)| {\n\t\t\t\t\tO::mask(head, None) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t!= BitMask::ZERO\n\t\t\t\t}) || body.iter().copied().any(|e| e != T::Mem::ZERO)\n\t\t\t\t\t|| tail.map_or(false, |(elem, tail)| {\n\t\t\t\t\t\tO::mask(None, tail) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t\t!= BitMask::ZERO\n\t\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Tests if *any* bit in the slice is unset (logical `¬∧`).\n\t///\n\t/// # Truth Table\n\t///\n\t/// ```text\n\t/// 0 0 => 1\n\t/// 0 1 => 1\n\t/// 1 0 => 1\n\t/// 1 1 => 0\n\t/// ```\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self\n\t///\n\t/// # Returns\n\t///\n\t/// Whether any bit in the slice domain is unset.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = 0xFDu8.view_bits::<Msb0>();\n\t/// assert!(!bits[.. 4].not_all());\n\t/// assert!(bits[4 ..].not_all());\n\t/// ```\n\t#[inline]\n\tpub fn not_all(&self) -> bool {\n\t\t!self.all()\n\t}\n\n\t/// Tests if *all* bits in the slice are unset (logical `¬∨`).\n\t///\n\t/// # Truth Table\n\t///\n\t/// ```text\n\t/// 0 0 => 1\n\t/// 0 1 => 0\n\t/// 1 0 => 0\n\t/// 1 1 => 0\n\t/// ```\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// Whether all bits in the slice domain are unset.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = 0x40u8.view_bits::<Msb0>();\n\t/// assert!(!bits[.. 4].not_any());\n\t/// assert!(bits[4 ..].not_any());\n\t/// ```\n\t#[inline]\n\tpub fn not_any(&self) -> bool {\n\t\t!self.any()\n\t}\n\n\t/// Tests whether the slice has some, but not all, bits set and some, but\n\t/// not all, bits unset.\n\t///\n\t/// This is `false` if either [`.all`] or [`.not_any`] are `true`.\n\t///\n\t/// # Truth Table\n\t///\n\t/// ```text\n\t/// 0 0 => 0\n\t/// 0 1 => 1\n\t/// 1 0 => 1\n\t/// 1 1 => 0\n\t/// ```\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// Whether the slice domain has mixed content. The empty slice returns\n\t/// `false`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b111_000_10u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// assert!(!bits[.. 3].some());\n\t/// assert!(!bits[3 .. 6].some());\n\t/// assert!(bits.some());\n\t/// ```\n\t///\n\t/// [`.all`]: #method.all\n\t/// [`.not_any`]: #method.not_any\n\t#[inline]\n\tpub fn some(&self) -> bool {\n\t\tself.any() && self.not_all()\n\t}\n\n\t/// Returns the number of ones in the memory region backing `self`.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// The number of high bits in the slice domain.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xF0u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// assert_eq!(bits[.. 4].count_ones(), 4);\n\t/// assert_eq!(bits[4 ..].count_ones(), 0);\n\t/// ```\n\t#[inline]\n\tpub fn count_ones(&self) -> usize {\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => (O::mask(head, tail)\n\t\t\t\t& dvl::load_aliased_local::<T>(elem))\n\t\t\t.value()\n\t\t\t.count_ones() as usize,\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(0, |(head, elem)| {\n\t\t\t\t\t(O::mask(head, None) & dvl::load_aliased_local::<T>(elem))\n\t\t\t\t\t\t.value()\n\t\t\t\t\t\t.count_ones() as usize\n\t\t\t\t}) + body\n\t\t\t\t\t.iter()\n\t\t\t\t\t.copied()\n\t\t\t\t\t.map(|e| e.count_ones() as usize)\n\t\t\t\t\t.sum::<usize>() + tail.map_or(0, |(elem, tail)| {\n\t\t\t\t\t(O::mask(None, tail) & dvl::load_aliased_local::<T>(elem))\n\t\t\t\t\t\t.value()\n\t\t\t\t\t\t.count_ones() as usize\n\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Returns the number of zeros in the memory region backing `self`.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// The number of low bits in the slice domain.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xF0u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// assert_eq!(bits[.. 4].count_zeros(), 0);\n\t/// assert_eq!(bits[4 ..].count_zeros(), 4);\n\t/// ```\n\t#[inline]\n\tpub fn count_zeros(&self) -> usize {\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => (!O::mask(head, tail)\n\t\t\t\t| dvl::load_aliased_local::<T>(elem))\n\t\t\t.value()\n\t\t\t.count_zeros() as usize,\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(0, |(head, elem)| {\n\t\t\t\t\t(!O::mask(head, None)\n\t\t\t\t\t\t| elem.pipe(dvl::load_aliased_local::<T>))\n\t\t\t\t\t.value()\n\t\t\t\t\t.count_zeros() as usize\n\t\t\t\t}) + body\n\t\t\t\t\t.iter()\n\t\t\t\t\t.copied()\n\t\t\t\t\t.map(|e| e.count_zeros() as usize)\n\t\t\t\t\t.sum::<usize>() + tail.map_or(0, |(elem, tail)| {\n\t\t\t\t\t(!O::mask(None, tail)\n\t\t\t\t\t\t| elem.pipe(dvl::load_aliased_local::<T>))\n\t\t\t\t\t.value()\n\t\t\t\t\t.count_zeros() as usize\n\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Sets all bits in the slice to a value.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `value`: The bit value to which all bits in the slice will be set.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut src = 0u8;\n\t/// let bits = src.view_bits_mut::<Msb0>();\n\t/// bits[2 .. 6].set_all(true);\n\t/// assert_eq!(bits.as_slice(), &[0b0011_1100]);\n\t/// bits[3 .. 5].set_all(false);\n\t/// assert_eq!(bits.as_slice(), &[0b0010_0100]);\n\t/// bits[.. 1].set_all(true);\n\t/// assert_eq!(bits.as_slice(), &[0b1010_0100]);\n\t/// ```\n\t#[inline]\n\tpub fn set_all(&mut self, value: bool) {\n\t\t//  Grab the function pointers used to commit bit-masks into memory.\n\t\tlet setter = <<T::Alias as BitStore>::Access>::get_writers(value);\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\t//  Step three: write the bitmask through the accessor.\n\t\t\t\tsetter(\n\t\t\t\t\t//  Step one: attach an `::Access` marker to the reference\n\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t//  Step two: insert an `::Alias` marker *into the bitmask*\n\t\t\t\t\t//  because typechecking is “fun”\n\t\t\t\t\tO::mask(head, tail).pipe(dvl::alias_mask::<T>),\n\t\t\t\t);\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tsetter(\n\t\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t\tO::mask(head, None).pipe(dvl::alias_mask::<T>),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\t//  loop assignment is `memset`’s problem, not ours\n\t\t\t\tunsafe {\n\t\t\t\t\tptr::write_bytes(\n\t\t\t\t\t\tbody.as_mut_ptr(),\n\t\t\t\t\t\t[0, !0][value as usize],\n\t\t\t\t\t\tbody.len(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tsetter(\n\t\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t\tO::mask(None, tail).pipe(dvl::alias_mask::<T>),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Applies a function to each bit in the slice.\n\t///\n\t/// `BitSlice` cannot implement `IndexMut`, as it cannot manifest `&mut\n\t/// bool` references, and the [`BitMut`] proxy reference has an unavoidable\n\t/// overhead. This method bypasses both problems, by applying a function to\n\t/// each pair of index and value in the slice, without constructing a proxy\n\t/// reference.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `func`: A function which receives two arguments, `index: usize` and\n\t///   `value: bool`, and returns a `bool`.\n\t///\n\t/// # Effects\n\t///\n\t/// For each index in the slice, the result of invoking `func` with the\n\t/// index number and current bit value is written into the slice.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits.for_each(|idx, _bit| idx % 3 == 0);\n\t/// assert_eq!(data, 0b100_100_10);\n\t/// ```\n\t#[inline]\n\tpub fn for_each<F>(&mut self, mut func: F)\n\twhere F: FnMut(usize, bool) -> bool {\n\t\tfor idx in 0 .. self.len() {\n\t\t\tunsafe {\n\t\t\t\tlet tmp = *self.get_unchecked(idx);\n\t\t\t\tlet new = func(idx, tmp);\n\t\t\t\tself.set_unchecked(idx, new);\n\t\t\t}\n\t\t}\n\t}\n\n\t/// Accesses the total backing storage of the `BitSlice`, as a slice of its\n\t/// aliased elements.\n\t///\n\t/// Because `BitSlice` is permitted to create aliasing views to memory at\n\t/// runtime, this method is required to mark the entire slice as aliased in\n\t/// order to include the maybe-aliased edge elements.\n\t///\n\t/// You should prefer using [`.domain`] to produce a fine-grained view that\n\t/// only aliases when necessary. This method is only appropriate when you\n\t/// require a single, contiguous, slice, for some API.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// An aliased view of the entire memory region this slice covers, including\n\t/// contended edge elements.\n\t///\n\t/// [`.domain`]: #method.domain\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_aliased_slice(&self) -> &[T::Alias] {\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_alias(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}\n\n\t/// Views the wholly-filled elements of the `BitSlice`.\n\t///\n\t/// This will not include partially-owned edge elements, as they may be\n\t/// aliased by other handles. To gain access to all elements that the\n\t/// `BitSlice` region covers, use one of the following:\n\t///\n\t/// - [`.as_aliased_slice`] produces a shared slice over all elements,\n\t///   marked as aliased to allow for the possibliity of external mutation.\n\t/// - [`.domain`] produces a view describing each component of the region,\n\t///   marking only the contended edges as aliased and the uncontended\n\t///   interior as unaliased.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A slice of all the wholly-utilised elements in the `BitSlice` backing\n\t/// storage.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = [1u8, 66];\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// let accum = bits\n\t///   .as_slice()\n\t///   .iter()\n\t///   .copied()\n\t///   .map(u8::count_ones)\n\t///   .sum::<u32>();\n\t/// assert_eq!(accum, 3);\n\t/// ```\n\t///\n\t/// [`.as_aliased_slice`]: #method.as_aliased_slice]\n\t/// [`.domain`]: #method.domain\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_slice(&self) -> &[T::Mem] {\n\t\tself.domain().region().map_or(&[], |(_, b, _)| b)\n\t}\n\n\t/// Views the wholly-filled elements of the `BitSlice`.\n\t///\n\t/// This will not include partially-owned edge elements, as they may be\n\t/// aliased by other handles. To gain access to all elements that the\n\t/// `BitSlice` region covers, use one of the following:\n\t///\n\t/// - [`.as_aliased_slice`] produces a shared slice over all elements,\n\t///   marked as aliased to allow for the possibliity of mutation.\n\t/// - [`.domain_mut`] produces a view describing each component of the\n\t///   region, marking only the contended edges as aliased and the\n\t///   uncontended interior as unaliased.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t///\n\t/// # Returns\n\t///\n\t/// A mutable slice of all the wholly-filled elements in the `BitSlice`\n\t/// backing storage.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = [1u8, 64];\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// for elt in bits.as_mut_slice() {\n\t///   *elt |= 2;\n\t/// }\n\t/// assert_eq!(&[3, 66], bits.as_slice());\n\t/// ```\n\t///\n\t/// [`.as_aliased_slice`]: #method.as_aliased_slice\n\t/// [`.domain_mut`]: #method.domain_mut\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_slice(&mut self) -> &mut [T::Mem] {\n\t\tself.domain_mut().region().map_or(&mut [], |(_, b, _)| b)\n\t}\n\n\t/// Splits the slice into the logical components of its memory domain.\n\t///\n\t/// This produces a set of read-only subslices, marking as much as possible\n\t/// as affirmatively lacking any write-capable view (`T::NoAlias`). The\n\t/// unaliased view is able to safely perform unsynchronized reads from\n\t/// memory without causing undefined behavior, as the type system is able to\n\t/// statically prove that no other write-capable views exist.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitDomain` structure representing the logical components of the\n\t/// memory region.\n\t///\n\t/// # Safety Exception\n\t///\n\t/// The following snippet describes a means of constructing a `T::NoAlias`\n\t/// view into memory that is, in fact, aliased:\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"atomic\")] {\n\t/// use bitvec::prelude::*;\n\t/// use core::sync::atomic::AtomicU8;\n\t/// type Bs<T> = BitSlice<Local, T>;\n\t///\n\t/// let data = [AtomicU8::new(0), AtomicU8::new(0), AtomicU8::new(0)];\n\t/// let bits: &Bs<AtomicU8> = data.view_bits::<Local>();\n\t/// let subslice: &Bs<AtomicU8> = &bits[4 .. 20];\n\t///\n\t/// let (_, noalias, _): (_, &Bs<u8>, _) =\n\t///   subslice.bit_domain().region().unwrap();\n\t/// # }\n\t/// ```\n\t///\n\t/// The `noalias` reference, which has memory type `u8`, assumes that it can\n\t/// act as an `&u8` reference: unsynchronized loads are permitted, as no\n\t/// handle exists which is capable of modifying the middle bit of `data`.\n\t/// This means that LLVM is permitted to issue loads from memory *wherever*\n\t/// it wants in the block during which `noalias` is live, as all loads are\n\t/// equivalent.\n\t///\n\t/// Use of the `bits` or `subslice` handles, which are still live for the\n\t/// lifetime of `noalias`, to issue [`.set_aliased`] calls into the middle\n\t/// element introduce **undefined behavior**. `bitvec` permits safe code to\n\t/// introduce this undefined behavior solely because it requires deliberate\n\t/// opt-in – you must start from atomic data; this cannot occur when `data`\n\t/// is non-atomic – and use of the shared-mutation facility simultaneously\n\t/// with the unaliasing view.\n\t///\n\t/// The [`.set_aliased`] method is speculative, and will be marked as\n\t/// `unsafe` or removed at any suspicion that its presence in the library\n\t/// has any costs.\n\t///\n\t/// # Examples\n\t///\n\t/// This method can be used to accelerate reads from a slice that is marked\n\t/// as aliased.\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t/// type Bs<T> = BitSlice<Local, T>;\n\t///\n\t/// let mut data = [0u8; 3];\n\t/// let bits = data.view_bits_mut::<Local>();\n\t/// let (a, b): (\n\t///   &mut Bs<<u8 as BitStore>::Alias>,\n\t///   &mut Bs<<u8 as BitStore>::Alias>,\n\t/// ) = bits.split_at_mut(4);\n\t/// let (partial, full, _): (\n\t///   &Bs<<u8 as BitStore>::Alias>,\n\t///   &Bs<<u8 as BitStore>::Mem>,\n\t///   _,\n\t/// ) = b.bit_domain().region().unwrap();\n\t/// read_from(partial); // uses alias-aware reads\n\t/// read_from(full); // uses ordinary reads\n\t/// # fn read_from<T: BitStore>(_: &BitSlice<Local, T>) {}\n\t/// ```\n\t///\n\t/// [`.set_aliased`]: #method.set_aliased\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn bit_domain(&self) -> BitDomain<O, T> {\n\t\tBitDomain::new(self)\n\t}\n\n\t/// Splits the slice into the logical components of its memory domain.\n\t///\n\t/// This produces a set of mutable subslices, marking as much as possible as\n\t/// affirmatively lacking any other view (`T::Mem`). The bare view is able\n\t/// to safely perform unsynchronized reads from and writes to memory without\n\t/// causing undefined behavior, as the type system is able to statically\n\t/// prove that no other views exist.\n\t///\n\t/// # Why This Is More Sound Than `.bit_domain`\n\t///\n\t/// The `&mut` exclusion rule makes it impossible to construct two\n\t/// references over the same memory where one of them is marked `&mut`. This\n\t/// makes it impossible to hold a live reference to memory *separately* from\n\t/// any references produced from this method. For the duration of all\n\t/// references produced by this method, all ancestor references used to\n\t/// reach this method call are either suspended or dead, and the compiler\n\t/// will not allow you to use them.\n\t///\n\t/// As such, this method cannot introduce undefined behavior where a\n\t/// reference incorrectly believes that the referent memory region is\n\t/// immutable.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn bit_domain_mut(&mut self) -> BitDomainMut<O, T> {\n\t\tBitDomainMut::new(self)\n\t}\n\n\t/// Splits the slice into immutable references to its underlying memory\n\t/// components.\n\t///\n\t/// Unlike [`.bit_domain`] and [`.bit_domain_mut`], this does not return\n\t/// smaller `BitSlice` handles but rather appropriately-marked references to\n\t/// the underlying memory elements.\n\t///\n\t/// The aliased references allow mutation of these elements. You are\n\t/// required to not use mutating methods on these references *at all*. This\n\t/// function is not marked `unsafe`, but this is a contract you must uphold.\n\t/// Use [`.domain_mut`] to modify the underlying elements.\n\t///\n\t/// > It is not currently possible to forbid mutation through these\n\t/// > references. This may change in the future.\n\t///\n\t/// # Safety Exception\n\t///\n\t/// As with [`.bit_domain`], this produces unsynchronized immutable\n\t/// references over the fully-populated interior elements. If this view is\n\t/// constructed from a `BitSlice` handle over atomic memory, then it will\n\t/// remove the atomic access behavior for the interior elements. This *by\n\t/// itself* is safe, as long as no contemporaneous atomic writes to that\n\t/// memory can occur. You must not retain and use an atomic reference to the\n\t/// memory region marked as `NoAlias` for the duration of this view’s\n\t/// existence.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A read-only descriptor of the memory elements backing `*self`.\n\t///\n\t/// [`.bit_domain`]: #method.bit_domain\n\t/// [`.bit_domain_mut`]: #method.bit_domain_mut\n\t/// [`.domain_mut`]: #method.domain_mut\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn domain(&self) -> Domain<T> {\n\t\tDomain::new(self)\n\t}\n\n\t/// Splits the slice into mutable references to its underlying memory\n\t/// elements.\n\t///\n\t/// Like [`.domain`], this returns appropriately-marked references to the\n\t/// underlying memory elements. These references are all writable.\n\t///\n\t/// The aliased edge references permit modifying memory beyond their bit\n\t/// marker. You are required to only mutate the region of these edge\n\t/// elements that you currently govern. This function is not marked\n\t/// `unsafe`, but this is a contract you must uphold.\n\t///\n\t/// > It is not currently possible to forbid out-of-bounds mutation through\n\t/// > these references. This may change in the future.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t///\n\t/// # Returns\n\t///\n\t/// A descriptor of the memory elements underneath `*self`, permitting\n\t/// mutation.\n\t///\n\t/// [`.domain`]: #method.domain\n\t#[inline]\n\tpub fn domain_mut(&mut self) -> DomainMut<T> {\n\t\tDomainMut::new(self)\n\t}\n\n\t/// Splits a slice at some mid-point, without checking boundary conditions.\n\t///\n\t/// This is generally not recommended; use with caution! For a safe\n\t/// alternative, see [`split_at`].\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mid`: The index at which to split the slice. This must be in the\n\t///   range `0 .. self.len()`.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: `&self[.. mid]`\n\t/// - `.1`: `&self[mid ..]`\n\t///\n\t/// # Safety\n\t///\n\t/// This function is **not** safe. It performs raw pointer arithmetic to\n\t/// construct two new references. If `mid` is out of bounds, then the first\n\t/// slice will be too large, and the second will be *catastrophically*\n\t/// incorrect. As both are references to invalid memory, they are undefined\n\t/// to *construct*, and may not ever be used.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0x0180u16;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// let (one, two) = unsafe { bits.split_at_unchecked(8) };\n\t/// assert!(one[7]);\n\t/// assert!(two[0]);\n\t/// ```\n\t///\n\t/// [`split_at`]: #method.split_at\n\t#[inline]\n\tpub unsafe fn split_at_unchecked(&self, mid: usize) -> (&Self, &Self) {\n\t\tmatch mid {\n\t\t\t0 => (Self::empty(), self),\n\t\t\tn if n == self.len() => (self, Self::empty()),\n\t\t\t_ => (self.get_unchecked(.. mid), self.get_unchecked(mid ..)),\n\t\t}\n\t}\n\n\t/// Splits a mutable slice at some mid-point, without checking boundary\n\t/// conditions.\n\t///\n\t/// This is generally not recommended; use with caution! For a safe\n\t/// alternative, see [`split_at_mut`].\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `mid`: The index at which to split the slice. This must be in the\n\t///   range `0 .. self.len()`.\n\t///\n\t/// # Returns\n\t///\n\t/// - `.0`: `&mut self[.. mid]`\n\t/// - `.1`: `&mut self[mid ..]`\n\t///\n\t/// # Safety\n\t///\n\t/// This function is **not** safe. It performs raw pointer arithmetic to\n\t/// construct two new references. If `mid` is out of bounds, then the first\n\t/// slice will be too large, and the second will be *catastrophically*\n\t/// incorrect. As both are references to invalid memory, they are undefined\n\t/// to *construct*, and may not ever be used.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u16;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// let (one, two) = unsafe { bits.split_at_unchecked_mut(8) };\n\t/// one.set(7, true);\n\t/// two.set(0, true);\n\t/// assert_eq!(data, 0x0180u16);\n\t/// ```\n\t///\n\t/// [`split_at_mut`]: #method.split_at_mut\n\t#[inline]\n\t#[allow(clippy::type_complexity)]\n\tpub unsafe fn split_at_unchecked_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut BitSlice<O, T::Alias>, &mut BitSlice<O, T::Alias>)\n\t{\n\t\tlet bp = self.alias_mut().bitptr();\n\t\tmatch mid {\n\t\t\t0 => (BitSlice::empty_mut(), bp.to_bitslice_mut()),\n\t\t\tn if n == self.len() => {\n\t\t\t\t(bp.to_bitslice_mut(), BitSlice::empty_mut())\n\t\t\t},\n\t\t\t_ => (\n\t\t\t\tbp.to_bitslice_mut().get_unchecked_mut(.. mid),\n\t\t\t\tbp.to_bitslice_mut().get_unchecked_mut(mid ..),\n\t\t\t),\n\t\t}\n\t}\n\n\t/// Swaps the bits at two indices without checking boundary conditions.\n\t///\n\t/// This is generally not recommended; use with caution! For a safe\n\t/// alternative, see [`swap`].\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `a`: One index to swap.\n\t/// - `b`: The other index to swap.\n\t///\n\t/// # Effects\n\t///\n\t/// The bit at index `a` is written into index `b`, and the bit at index `b`\n\t/// is written into `a`.\n\t///\n\t/// # Safety\n\t///\n\t/// Both `a` and `b` must be less than `self.len()`. Indices greater than\n\t/// the length will cause out-of-bounds memory access, which can lead to\n\t/// memory unsafety and a program crash.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 8u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// unsafe { bits.swap_unchecked(0, 4); }\n\t///\n\t/// assert_eq!(data, 128);\n\t/// ```\n\t///\n\t/// [`swap`]: #method.swap\n\t#[inline]\n\tpub unsafe fn swap_unchecked(&mut self, a: usize, b: usize) {\n\t\tlet bit_a = *self.get_unchecked(a);\n\t\tlet bit_b = *self.get_unchecked(b);\n\t\tself.set_unchecked(a, bit_b);\n\t\tself.set_unchecked(b, bit_a);\n\t}\n\n\t/// Copies a bit from one index to another without checking boundary\n\t/// conditions.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `from`: The index whose bit is to be copied\n\t/// - `to`: The index into which the copied bit is written.\n\t///\n\t/// # Effects\n\t///\n\t/// The bit at `from` is written into `to`.\n\t///\n\t/// # Safety\n\t///\n\t/// Both `from` and `to` must be less than `self.len()`, in order for\n\t/// `self` to legally read from and write to them, respectively.\n\t///\n\t/// If `self` had been split from a larger slice, reading from `from` or\n\t/// writing to `to` may not *necessarily* cause a memory-safety violation in\n\t/// the Rust model, due to the aliasing system `bitvec` employs. However,\n\t/// writing outside the bounds of a slice reference is *always* a logical\n\t/// error, as it causes changes observable by another reference handle.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 1u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// unsafe { bits.copy_unchecked(0, 2) };\n\t///\n\t/// assert_eq!(data, 5);\n\t/// ```\n\t#[inline]\n\tpub unsafe fn copy_unchecked(&mut self, from: usize, to: usize) {\n\t\tlet tmp = *self.get_unchecked(from);\n\t\tself.set_unchecked(to, tmp);\n\t}\n\n\t/// Copies bits from one part of the slice to another part of itself.\n\t///\n\t/// `src` is the range within `self` to copy from. `dest` is the starting\n\t/// index of the range within `self` to copy to, which will have the same\n\t/// length as `src`. The two ranges may overlap. The ends of the two ranges\n\t/// must be less than or equal to `self.len()`.\n\t///\n\t/// # Effects\n\t///\n\t/// `self[src]` is copied to `self[dest .. dest + src.end() - src.start()]`.\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if either range exceeds the end of the slice,\n\t/// or if the end of `src` is before the start.\n\t///\n\t/// # Safety\n\t///\n\t/// Both the `src` range and the target range `dest .. dest + src.len()`\n\t/// must not exceed the `self.len()` slice range.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0x07u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// unsafe { bits.copy_within_unchecked(5 .., 0); }\n\t///\n\t/// assert_eq!(data, 0xE7);\n\t/// ```\n\t#[inline]\n\tpub unsafe fn copy_within_unchecked<R>(&mut self, src: R, dest: usize)\n\twhere R: RangeBounds<usize> {\n\t\tlet len = self.len();\n\t\tlet rev = src.contains(&dest);\n\t\tlet source = dvl::normalize_range(src, len);\n\t\tlet iter = source.zip(dest .. len);\n\t\tif rev {\n\t\t\tfor (from, to) in iter.rev() {\n\t\t\t\tself.copy_unchecked(from, to);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor (from, to) in iter {\n\t\t\t\tself.copy_unchecked(from, to);\n\t\t\t}\n\t\t}\n\t}\n\n\t/// Marks an immutable slice as referring to aliased memory region.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub(crate) fn alias(&self) -> &BitSlice<O, T::Alias> {\n\t\tunsafe { &*(self.as_ptr() as *const BitSlice<O, T::Alias>) }\n\t}\n\n\t/// Marks a mutable slice as describing an aliased memory region.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub(crate) fn alias_mut(&mut self) -> &mut BitSlice<O, T::Alias> {\n\t\tunsafe { &mut *(self as *mut Self as *mut BitSlice<O, T::Alias>) }\n\t}\n\n\t/// Removes the aliasing marker from a mutable slice handle.\n\t///\n\t/// # Safety\n\t///\n\t/// This must only be used when the slice is either known to be unaliased,\n\t/// or this call is combined with an operation that adds an aliasing marker\n\t/// and the total number of aliasing markers must remain unchanged.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub(crate) unsafe fn unalias_mut(\n\t\tthis: &mut BitSlice<O, T::Alias>,\n\t) -> &mut Self {\n\t\t&mut *(this as *mut BitSlice<O, T::Alias> as *mut Self)\n\t}\n\n\t/// Type-cast the slice reference to its pointer structure.\n\t#[inline]\n\tpub(crate) fn bitptr(&self) -> BitPtr<T> {\n\t\tBitPtr::from_bitslice_ptr(self.as_ptr())\n\t}\n}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Returns the number of bits in the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::len`](https://doc.rust-lang.org/std/primitive.slice.html#method.len)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0u32;\n\t/// let bits = data.view_bits::<Local>();\n\t/// assert_eq!(bits.len(), 32);\n\t/// ```\n\t#[inline]\n\tpub fn len(&self) -> usize {\n\t\tself.bitptr().len()\n\t}\n\n\t/// Returns `true` if the slice has a length of 0.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::is_empty`](https://doc.rust-lang.org/std/primitive.slice.html#method.is_empty)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// assert!(BitSlice::<Local, u8>::empty().is_empty());\n\t/// assert!(!(0u32.view_bits::<Local>()).is_empty());\n\t/// ```\n\t#[inline]\n\tpub fn is_empty(&self) -> bool {\n\t\t/* TODO(myrrlyn): Investigate coercing all empty slices to `empty()`\n\n\t\tThe empty slice pointer represents its entire `.len` field as zero,\n\t\twhich removes a shift operation in the pointer decoding. `BitSlice` only\n\t\tmonotonically decreases, so when it becomes empty, writing `0` to `.len`\n\t\tmay be more advantageous than preserving the `head` component.\n\t\t*/\n\t\tself.bitptr().len() == 0\n\t}\n\n\t/// Returns the first bit of the slice, or `None` if it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::first`](https://doc.rust-lang.org/std/primitive.slice.html#method.first)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 1u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// assert_eq!(Some(&true), bits.first());\n\t///\n\t/// let empty = BitSlice::<Local, usize>::empty();\n\t/// assert_eq!(None, empty.first());\n\t/// ```\n\t#[inline]\n\tpub fn first(&self) -> Option<&bool> {\n\t\tself.get(0)\n\t}\n\n\t/// Returns a mutable pointer to the first bit of the slice, or `None` if it\n\t/// is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::first_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.first_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// This crate cannot manifest `&mut bool` references, and must use the\n\t/// `BitMut` proxy type where `&mut bool` exists in the standard library\n\t/// API. The proxy value must be bound as `mut` in order to write through\n\t/// it.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// if let Some(mut first) = bits.first_mut() {\n\t///   *first = true;\n\t/// }\n\t/// assert_eq!(data, 1);\n\t/// ```\n\t#[inline]\n\tpub fn first_mut(&mut self) -> Option<BitMut<O, T>> {\n\t\tself.get_mut(0)\n\t}\n\n\t/// Returns the first and all the rest of the bits of the slice, or `None`\n\t/// if it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_first`](https://doc.rust-lang.org/std/primitive.slice.html#split_first)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 1u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// if let Some((first, rest)) = bits.split_first() {\n\t///   assert!(*first);\n\t/// }\n\t/// ```\n\t#[inline]\n\tpub fn split_first(&self) -> Option<(&bool, &Self)> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\t_ => unsafe {\n\t\t\t\tlet (head, rest) = self.split_at_unchecked(1);\n\t\t\t\tSome((head.get_unchecked(0), rest))\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Returns the first and all the rest of the bits of the slice, or `None`\n\t/// if it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_first_mut`](https://doc.rust-lang.org/std/primitive.slice.html#split_first_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// This crate cannot manifest `&mut bool` references, and must use the\n\t/// `BitMut` proxy type where `&mut bool` exists in the standard library\n\t/// API. The proxy value must be bound as `mut` in order to write through\n\t/// it.\n\t///\n\t/// Because the references are permitted to use the same memory address,\n\t/// they are marked as aliasing in order to satisfy Rust’s requirements\n\t/// about freedom from data races.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0usize;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// if let Some((mut first, rest)) = bits.split_first_mut() {\n\t///   *first = true;\n\t///   *rest.get_mut(1).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 5);\n\t///\n\t/// assert!(BitSlice::<Local, usize>::empty_mut().split_first_mut().is_none());\n\t/// ```\n\t#[inline]\n\t//  `pub type Aliased = BitSlice<O, T::Alias>;` is not allowed in inherents,\n\t//  so this will not be aliased.\n\t#[allow(clippy::type_complexity)]\n\tpub fn split_first_mut(\n\t\t&mut self,\n\t) -> Option<(BitMut<O, T::Alias>, &mut BitSlice<O, T::Alias>)> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\t_ => unsafe {\n\t\t\t\tlet (head, rest) = self.split_at_unchecked_mut(1);\n\t\t\t\tSome((head.get_unchecked_mut(0), rest))\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Returns the last and all the rest of the bits of the slice, or `None` if\n\t/// it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_last`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_last)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 1u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// if let Some((last, rest)) = bits.split_last() {\n\t///   assert!(*last);\n\t/// }\n\t/// ```\n\t#[inline]\n\tpub fn split_last(&self) -> Option<(&bool, &Self)> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => unsafe {\n\t\t\t\tlet (rest, tail) = self.split_at_unchecked(len.wrapping_sub(1));\n\t\t\t\tSome((tail.get_unchecked(0), rest))\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Returns the last and all the rest of the bits of the slice, or `None` if\n\t/// it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_last_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_last_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// This crate cannot manifest `&mut bool` references, and must use the\n\t/// `BitMut` proxy type where `&mut bool` exists in the standard library\n\t/// API. The proxy value must be bound as `mut` in order to write through\n\t/// it.\n\t///\n\t/// Because the references are permitted to use the same memory address,\n\t/// they are marked as aliasing in order to satisfy Rust’s requirements\n\t/// about freedom from data races.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// if let Some((mut last, rest)) = bits.split_last_mut() {\n\t///   *last = true;\n\t///   *rest.get_mut(5).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 5);\n\t///\n\t/// assert!(BitSlice::<Local, usize>::empty_mut().split_last_mut().is_none());\n\t/// ```\n\t#[inline]\n\t//  `pub type Aliased = BitSlice<O, T::Alias>;` is not allowed in inherents,\n\t//  so this will not be aliased.\n\t#[allow(clippy::type_complexity)]\n\tpub fn split_last_mut(\n\t\t&mut self,\n\t) -> Option<(BitMut<O, T::Alias>, &mut BitSlice<O, T::Alias>)> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => unsafe {\n\t\t\t\tlet (rest, tail) = self.split_at_unchecked_mut(len - 1);\n\t\t\t\tSome((tail.get_unchecked_mut(0), rest))\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Returns the last bit of the slice, or `None` if it is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::last`](https://doc.rust-lang.org/std/primitive.slice.html#method.last)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 1u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// assert_eq!(Some(&true), bits.last());\n\t///\n\t/// let empty = BitSlice::<Local, usize>::empty();\n\t/// assert_eq!(None, empty.last());\n\t/// ```\n\t#[inline]\n\tpub fn last(&self) -> Option<&bool> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => Some(unsafe { self.get_unchecked(len - 1) }),\n\t\t}\n\t}\n\n\t/// Returns a mutable pointer to the last bit of the slice, or `None` if it\n\t/// is empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::last_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.last_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// This crate cannot manifest `&mut bool` references, and must use the\n\t/// `BitMut` proxy type where `&mut bool` exists in the standard library\n\t/// API. The proxy value must be bound as `mut` in order to write through\n\t/// it.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// if let Some(mut last) = bits.last_mut() {\n\t///   *last = true;\n\t/// }\n\t/// assert_eq!(data, 1);\n\t/// ```\n\t#[inline]\n\tpub fn last_mut(&mut self) -> Option<BitMut<O, T>> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => Some(unsafe { self.get_unchecked_mut(len - 1) }),\n\t\t}\n\t}\n\n\t/// Returns a reference to an element or subslice depending on the type of\n\t/// index.\n\t///\n\t/// - If given a position, returns a reference to the element at that\n\t///   position or `None` if out of bounds.\n\t/// - If given a range, returns the subslice corresponding to that range, or\n\t///   `None` if out of bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::get`](https://doc.rust-lang.org/std/primitive.slice.html#method.get)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 2u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t///\n\t/// assert_eq!(Some(&true), bits.get(1));\n\t/// assert_eq!(Some(&bits[1 .. 3]), bits.get(1 .. 3));\n\t/// assert_eq!(None, bits.get(9));\n\t/// assert_eq!(None, bits.get(8 .. 10));\n\t/// ```\n\t#[inline]\n\tpub fn get<'a, I>(&'a self, index: I) -> Option<I::Immut>\n\twhere I: BitSliceIndex<'a, O, T> {\n\t\tindex.get(self)\n\t}\n\n\t/// Returns a mutable reference to an element or subslice depending on the\n\t/// type of index (see [`get`]) or `None` if the index is out of bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::get_mut`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// When `I` is `usize`, this returns `BitMut` instead of `&mut bool`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u16;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// assert!(!bits.get(1).unwrap());\n\t/// *bits.get_mut(1).unwrap() = true;\n\t/// assert!(bits.get(1).unwrap());\n\t/// ```\n\t///\n\t/// [`get`]: #method.get\n\t#[inline]\n\tpub fn get_mut<'a, I>(&'a mut self, index: I) -> Option<I::Mut>\n\twhere I: BitSliceIndex<'a, O, T> {\n\t\tindex.get_mut(self)\n\t}\n\n\t/// Returns a reference to an element or subslice, without doing bounds\n\t/// checking.\n\t///\n\t/// This is generally not recommended; use with caution!\n\t///\n\t/// Unlike the original slice function, calling this with an out-of-bounds\n\t/// index is not *technically* compile-time [undefined behavior], as the\n\t/// references produced do not actually describe local memory. However, the\n\t/// use of an out-of-bounds index will eventually cause an out-of-bounds\n\t/// memory read, which is a runtime safety violation. For a safe alternative\n\t/// see [`get`].\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::get_unchecked`](https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 2u16;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t///\n\t/// unsafe{\n\t///   assert_eq!(bits.get_unchecked(1), &true);\n\t/// }\n\t/// ```\n\t///\n\t/// [`get`]: #method.get\n\t/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n\t#[inline]\n\t#[allow(clippy::missing_safety_doc)]\n\tpub unsafe fn get_unchecked<'a, I>(&'a self, index: I) -> I::Immut\n\twhere I: BitSliceIndex<'a, O, T> {\n\t\tindex.get_unchecked(self)\n\t}\n\n\t/// Returns a mutable reference to the output at this location, without\n\t/// doing bounds checking.\n\t///\n\t/// This is generally not recommended; use with caution!\n\t///\n\t/// Unlike the original slice function, calling this with an out-of-bounds\n\t/// index is not *technically* compile-time [undefined behavior], as the\n\t/// references produced do not actually describe local memory. However, the\n\t/// use of an out-of-bounds index will eventually cause an out-of-bounds\n\t/// memory write, which is a runtime safety violation. For a safe\n\t/// alternative see [`get_mut`].\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::get_unchecked_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked_mut)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u16;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// unsafe {\n\t///   let mut bit = bits.get_unchecked_mut(1);\n\t///   *bit = true;\n\t/// }\n\t/// assert_eq!(data, 2);\n\t/// ```\n\t///\n\t/// [`get_mut`]: #method.get_mut\n\t/// [undefined behavior]: ../../reference/behavior-considered-undefined.html\n\t#[inline]\n\t#[allow(clippy::missing_safety_doc)]\n\tpub unsafe fn get_unchecked_mut<'a, I>(&'a mut self, index: I) -> I::Mut\n\twhere I: BitSliceIndex<'a, O, T> {\n\t\tindex.get_unchecked_mut(self)\n\t}\n\n\t/// Returns a raw bit-slice pointer to the region.\n\t///\n\t/// The caller must ensure that the slice outlives the pointer this function\n\t/// returns, or else it will end up pointing to garbage.\n\t///\n\t/// The caller must also ensure that the memory the pointer\n\t/// (non-transitively) points to is only written to if `T` allows shared\n\t/// mutation, using this pointer or any pointer derived from it. If you need\n\t/// to mutate the contents of the slice, use [`as_mut_ptr`].\n\t///\n\t/// Modifying the container (such as `BitVec`) referenced by this slice may\n\t/// cause its buffer to be reällocated, which would also make any pointers\n\t/// to it invalid.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::as_ptr`](https://doc.rust-lang.org/std/primitive.slice.html#method.as_ptr)\n\t///\n\t/// # API Differences\n\t///\n\t/// This returns `*const BitSlice`, which is the equivalent of `*const [T]`\n\t/// instead of `*const T`. The pointer encoding used requires more than one\n\t/// CPU word of space to address a single bit, so there is no advantage to\n\t/// removing the length information from the encoded pointer value.\n\t///\n\t/// # Notes\n\t///\n\t/// You **cannot** use any of the methods in the `pointer` fundamental type\n\t/// or the `core::ptr` module on the `*_ BitSlice` type. This pointer\n\t/// retains the `bitvec`-specific value encoding, and is incomprehensible by\n\t/// the Rust standard library.\n\t///\n\t/// The only thing you can do with this pointer is dereference it.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 2u16;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let bits_ptr = bits.as_ptr();\n\t///\n\t/// for i in 0 .. bits.len() {\n\t///   assert_eq!(bits[i], unsafe {\n\t///     (&*bits_ptr)[i]\n\t///   });\n\t/// }\n\t/// ```\n\t///\n\t/// [`as_mut_ptr`]: #method.as_mut_ptr\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_ptr(&self) -> *const Self {\n\t\tself as *const Self\n\t}\n\n\t/// Returns an unsafe mutable bit-slice pointer to the region.\n\t///\n\t/// The caller must ensure that the slice outlives the pointer this function\n\t/// returns, or else it will end up pointing to garbage.\n\t///\n\t/// Modifying the container (such as `BitVec`) referenced by this slice may\n\t/// cause its buffer to be reällocated, which would also make any pointers\n\t/// to it invalid.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::as_mut_ptr`](https://doc.rust-lang.org/std/primitive.slice.html#method.as_mut_ptr)\n\t///\n\t/// # API Differences\n\t///\n\t/// This returns `*mut BitSlice`, which is the equivalont of `*mut [T]`\n\t/// instead of `*mut T`. The pointer encoding used requires more than one\n\t/// CPU word of space to address a single bit, so there is no advantage to\n\t/// removing the length information from the encoded pointer value.\n\t///\n\t/// # Notes\n\t///\n\t/// You **cannot** use any of the methods in the `pointer` fundamental type\n\t/// or the `core::ptr` module on the `*_ BitSlice` type. This pointer\n\t/// retains the `bitvec`-specific value encoding, and is incomprehensible by\n\t/// the Rust standard library.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u16;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t/// let bits_ptr = bits.as_mut_ptr();\n\t///\n\t/// for i in 0 .. bits.len() {\n\t///   unsafe { &mut *bits_ptr }.set(i, i % 2 == 0);\n\t/// }\n\t/// assert_eq!(data, 0b0101_0101_0101_0101);\n\t/// ```\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_ptr(&mut self) -> *mut Self {\n\t\tself as *mut Self\n\t}\n\n\t/// Swaps two bits in the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::swap`](https://doc.rust-lang.org/std/primitive.slice.html#method.swap)\n\t///\n\t/// # Arguments\n\t///\n\t/// - `a`: The index of the first bit\n\t/// - `b`: The index of the second bit\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `a` or `b` are out of bounds.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 2u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t/// bits.swap(1, 3);\n\t/// assert_eq!(data, 8);\n\t/// ```\n\t#[inline]\n\tpub fn swap(&mut self, a: usize, b: usize) {\n\t\tlet len = self.len();\n\t\tassert!(a < len, \"Index {} out of bounds: {}\", a, len);\n\t\tassert!(b < len, \"Index {} out of bounds: {}\", b, len);\n\t\tunsafe {\n\t\t\tself.swap_unchecked(a, b);\n\t\t}\n\t}\n\n\t/// Reverses the order of bits in the slice, in place.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::reverse`](https://doc.rust-lang.org/std/primitive.slice.html#method.reverse)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0b1_1001100u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits[1 ..].reverse();\n\t/// assert_eq!(data, 0b1_0011001);\n\t/// ```\n\t#[inline]\n\tpub fn reverse(&mut self) {\n\t\t/* This would be better written as a recursive algorithm that swaps the\n\t\tedge bits and recurses on `[1 .. len - 1]`, but Rust does not guarantee\n\t\ttail-call optimization, and manual iteration allows for slight\n\t\tperformance optimization on the range reduction.\n\n\t\tBegin with raw pointer manipulation. That’s how you know this is a good\n\t\tfunction.\n\t\t*/\n\t\tlet mut bitptr = self.bitptr();\n\t\tloop {\n\t\t\t//  Reversing 1 or 0 bits has no effect.\n\t\t\tlet len = bitptr.len();\n\t\t\tif len < 2 {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tunsafe {\n\t\t\t\t//  Swap the 0 and `len - 1` indices,\n\t\t\t\tlet back = len - 1;\n\t\t\t\tbitptr.to_bitslice_mut::<O>().swap_unchecked(0, back);\n\n\t\t\t\t//  Move the pointer upwards by one bit.\n\t\t\t\tbitptr.incr_head();\n\t\t\t\t//  The length is unchanged, and must now be brought down by 2\n\t\t\t\t//  in order to remove both the front and back bits.\n\t\t\t\tbitptr.set_len(len - 2);\n\n\t\t\t\t//  TODO(myrrlyn): See if range subslicing can be made faster.\n\t\t\t}\n\t\t}\n\t}\n\n\t/// Returns an iterator over the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::iter`](https://doc.rust-lang.org/std/primitive.slice.html#method.iter)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 130u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let mut iterator = bits.iter();\n\t///\n\t/// assert_eq!(iterator.next(), Some(&false));\n\t/// assert_eq!(iterator.next(), Some(&true));\n\t/// assert_eq!(iterator.nth(5), Some(&true));\n\t/// assert_eq!(iterator.next(), None);\n\t/// ```\n\t#[inline]\n\tpub fn iter(&self) -> Iter<O, T> {\n\t\tself.into_iter()\n\t}\n\n\t/// Returns an iterator that allows modifying each bit.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::iter_mut`](https://doc.rust-lang.org/std/primitive.slice.html#Method.iter_mut)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// for (idx, mut elem) in bits.iter_mut().enumerate() {\n\t///   *elem = idx % 3 == 0;\n\t/// }\n\t/// assert_eq!(data, 0b100_100_10);\n\t/// ```\n\t#[inline]\n\tpub fn iter_mut(&mut self) -> IterMut<O, T> {\n\t\tself.into_iter()\n\t}\n\n\t/// Returns an iterator over all contiguous windows of length `size`. The\n\t/// windows overlap. If the slice is shorter than `size`, the iterator\n\t/// returns no values.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::windows`](https://doc.rust-lang.org/std/primitive.slice.html#method.windows)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.windows(6);\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 6]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[1 .. 7]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[2 ..]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// If the slice is shorter than `size`:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = BitSlice::<Local, usize>::empty();\n\t/// let mut iter = bits.windows(1);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t#[inline]\n\tpub fn windows(&self, size: usize) -> Windows<O, T> {\n\t\tassert_ne!(size, 0, \"Window width cannot be 0\");\n\t\tWindows::new(self, size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the beginning of the slice.\n\t///\n\t/// The chunks are slices and do not overlap. If `chunk_size` does not\n\t/// divide the length of the slice, then the last chunk will not have length\n\t/// `chunk_size`.\n\t///\n\t/// See [`chunks_exact`] for a variant of this iterator that returns chunks\n\t/// of always exactly `chunk_size` bits, and [`rchunks`] for the same\n\t/// iterator but starting at the end of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::chunks`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let mut iter = bits.chunks(3);\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[3 .. 6]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[6 ..]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// [`chunks_exact`]: #method.chunks_exact\n\t/// [`rchunks`]: #method.rchunks\n\t#[inline]\n\tpub fn chunks(&self, chunk_size: usize) -> Chunks<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunks::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the beginning of the slice.\n\t///\n\t/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n\t/// not divide the length of the slice, then the last chunk will not have\n\t/// length `chunk_size`.\n\t///\n\t/// See [`chunks_exact_mut`] for a variant of this iterator that returns\n\t/// chunks of always exactly `chunk_size` bits, and [`rchunks_mut`] for the\n\t/// same iterator but starting at the end of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::chunks_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_mut)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// for (idx, chunk) in bits.chunks_mut(3).enumerate() {\n\t///   chunk.set(2 - idx, true);\n\t/// }\n\t/// assert_eq!(data, 0b01_010_100);\n\t/// ```\n\t///\n\t/// [`chunks_exact_mut`]: #method.chunks_exact_mut\n\t/// [`rchunks_mut`]: #method.rchunks_mut\n\t#[inline]\n\tpub fn chunks_mut(&mut self, chunk_size: usize) -> ChunksMut<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksMut::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the beginning of the slice.\n\t///\n\t/// The chunks are slices and do not overlap. If `chunk_size` does not\n\t/// divide the length of the slice, then the last up to `chunk_size-1` bits\n\t/// will be omitted and can be retrieved from the `remainder` function of\n\t/// the iterator.\n\t///\n\t/// Due to each chunk having exactly `chunk_size` bits, the compiler may\n\t/// optimize the resulting code better than in the case of [`chunks`].\n\t///\n\t/// See [`chunks`] for a variant of this iterator that also returns the\n\t/// remainder as a smaller chunk, and [`rchunks_exact`] for the same\n\t/// iterator but starting at the end of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::chunks_exact`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let mut iter = bits.chunks_exact(3);\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[3 .. 6]);\n\t/// assert!(iter.next().is_none());\n\t/// assert_eq!(iter.remainder(), &bits[6 ..]);\n\t/// ```\n\t///\n\t/// [`chunks`]: #method.chunks\n\t/// [`rchunks_exact`]: #method.rchunks_exact\n\t#[inline]\n\tpub fn chunks_exact(&self, chunk_size: usize) -> ChunksExact<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksExact::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the beginning of the slice.\n\t///\n\t/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n\t/// not divide the beginning length of the slice, then the last up to\n\t/// `chunk_size-1` bits will be omitted and can be retrieved from the\n\t/// `into_remainder` function of the iterator.\n\t///\n\t/// Due to each chunk having exactly `chunk_size` bits, the compiler may\n\t/// optimize the resulting code better than in the case of [`chunks_mut`].\n\t///\n\t/// See [`chunks_mut`] for a variant of this iterator that also returns the\n\t/// remainder as a smaller chunk, and [`rchunks_exact_mut`] for the same\n\t/// iterator but starting at the end of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::chunks_exact_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact_mut)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// for (idx, chunk) in bits.chunks_exact_mut(3).enumerate() {\n\t///   chunk.set(idx, true);\n\t/// }\n\t/// assert_eq!(data, 0b00_010_001);\n\t/// ```\n\t///\n\t/// [`chunks_mut`]: #method.chunks_mut\n\t/// [`rchunks_exact_mut`]: #method.rchunks_exact_mut\n\t#[inline]\n\tpub fn chunks_exact_mut(\n\t\t&mut self,\n\t\tchunk_size: usize,\n\t) -> ChunksExactMut<O, T>\n\t{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksExactMut::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the end of the slice.\n\t///\n\t/// The chunks are slices and do not overlap. If `chunk_size` does not\n\t/// divide the length of the slice, then the last chunk will not have length\n\t/// `chunk_size`.\n\t///\n\t/// See [`rchunks_exact`] for a variant of this iterator that returns chunks\n\t/// of always exactly `chunk_size` bits, and [`chunks`] for the same\n\t/// iterator but starting at the beginning of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rchunks`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let mut iter = bits.rchunks(3);\n\t/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[2 .. 5]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 2]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// [`chunks`]: #method.chunks\n\t/// [`rchunks_exact`]: #method.rchunks_exact\n\t#[inline]\n\tpub fn rchunks(&self, chunk_size: usize) -> RChunks<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunks::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the end of the slice.\n\t///\n\t/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n\t/// not divide the length of the slice, then the last chunk will not have\n\t/// length `chunk_size`.\n\t///\n\t/// See [`rchunks_exact_mut`] for a variant of this iterator that returns\n\t/// chunks of always exactly `chunk_size` bits, and [`chunks_mut`] for the\n\t/// same iterator but starting at the beginning of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rchunks_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks_mut)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// for (idx, chunk) in bits.rchunks_mut(3).enumerate() {\n\t///   chunk.set(2 - idx, true);\n\t/// }\n\t/// assert_eq!(data, 0b100_010_01);\n\t/// ```\n\t///\n\t/// [`chunks_mut`]: #method.chunks_mut\n\t/// [`rchunks_exact_mut`]: #method.rchunks_exact_mut\n\t#[inline]\n\tpub fn rchunks_mut(&mut self, chunk_size: usize) -> RChunksMut<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksMut::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the end of the slice.\n\t///\n\t/// The chunks are slices and do not overlap. If `chunk_size` does not\n\t/// divide the length of the slice, then the last up to `chunk_size-1` bits\n\t/// will be omitted and can be retrieved from the `remainder` function of\n\t/// the iterator.\n\t///\n\t/// Due to each chunk having exactly `chunk_size` bits, the compiler can\n\t/// often optimize the resulting code better than in the case of [`chunks`].\n\t///\n\t/// See [`rchunks`] for a variant of this iterator that also returns the\n\t/// remainder as a smaller chunk, and [`chunks_exact`] for the same iterator\n\t/// but starting at the beginning of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rchunks_exact`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks_exact)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Lsb0>();\n\t/// let mut iter = bits.rchunks_exact(3);\n\t/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[2 .. 5]);\n\t/// assert!(iter.next().is_none());\n\t/// assert_eq!(iter.remainder(), &bits[.. 2]);\n\t/// ```\n\t///\n\t/// [`chunks`]: #method.chunks\n\t/// [`rchunks`]: #method.rchunks\n\t/// [`chunks_exact`]: #method.chunks_exact\n\t#[inline]\n\tpub fn rchunks_exact(&self, chunk_size: usize) -> RChunksExact<O, T> {\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksExact::new(self, chunk_size)\n\t}\n\n\t/// Returns an iterator over `chunk_size` bits of the slice at a time,\n\t/// starting at the end of the slice.\n\t///\n\t/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n\t/// not divide the length of the slice, then the last up to `chunk_size-1`\n\t/// bits will be omitted and can be retrieved from the `into_remainder`\n\t/// function of the iterator.\n\t///\n\t/// Due to each chunk having exactly `chunk_size` bits, the compiler can\n\t/// often optimize the resulting code better than in the case of\n\t/// [`chunks_mut`].\n\t///\n\t/// See [`rchunks_mut`] for a variant of this iterator that also returns the\n\t/// remainder as a smaller chunk, and [`chunks_exact_mut`] for the same\n\t/// iterator but starting at the beginning of the slice.\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `chunk_size` is 0.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// for (idx, chunk) in bits.rchunks_exact_mut(3).enumerate() {\n\t///   chunk.set(idx, true);\n\t/// }\n\t/// assert_eq!(data, 0b001_010_00);\n\t/// ```\n\t///\n\t/// [`chunks_mut`]: #method.chunks_mut\n\t/// [`rchunks_mut`]: #method.rchunks_mut\n\t/// [`chunks_exact_mut`]: #method.chunks_exact_mut\n\t#[inline]\n\tpub fn rchunks_exact_mut(\n\t\t&mut self,\n\t\tchunk_size: usize,\n\t) -> RChunksExactMut<O, T>\n\t{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksExactMut::new(self, chunk_size)\n\t}\n\n\t/// Divides one slice into two at an index.\n\t///\n\t/// The first will contain all indices from `[0, mid)` (excluding the index\n\t/// `mid` itself) and the second will contain all indices from `[mid, len)`\n\t/// (excluding the index `len` itself).\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_at`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `mid > len`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xC3u8;\n\t/// let bits = data.view_bits::<Local>();\n\t///\n\t/// let (left, right) = bits.split_at(0);\n\t/// assert!(left.is_empty());\n\t/// assert_eq!(right, bits);\n\t///\n\t/// let (left, right) = bits.split_at(2);\n\t/// assert_eq!(left, &bits[.. 2]);\n\t/// assert_eq!(right, &bits[2 ..]);\n\t///\n\t/// let (left, right) = bits.split_at(8);\n\t/// assert_eq!(left, bits);\n\t/// assert!(right.is_empty());\n\t/// ```\n\t#[inline]\n\tpub fn split_at(&self, mid: usize) -> (&Self, &Self) {\n\t\tlet len = self.len();\n\t\tassert!(mid <= len, \"Index {} out of bounds: {}\", mid, len);\n\t\tunsafe { self.split_at_unchecked(mid) }\n\t}\n\n\t/// Divides one mutable slice into two at an index.\n\t///\n\t/// The first will contain all indices from `[0, mid)` (excluding the index\n\t/// `mid` itself) and the second will contain all indices from `[mid, len)`\n\t/// (excluding the index `len` itself).\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_at_mut`](https://doc.rust-lang.org/std/primitive.html#method.split_at_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// Because the partition point `mid` is permitted to occur in the interior\n\t/// of a memory element `T`, this method is required to mark the returned\n\t/// slices as being to aliased memory. This marking ensures that writes to\n\t/// the covered memory use the appropriate synchronization behavior of your\n\t/// build to avoid data races – by default, this makes all writes atomic; on\n\t/// builds with the `atomic` feature disabled, this uses `Cell`s and\n\t/// forbids the produced subslices from leaving the current thread.\n\t///\n\t/// See the [`BitStore`] documentation for more information.\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `mid > len`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// // scoped to restrict the lifetime of the borrows\n\t/// {\n\t///   let (left, right) = bits.split_at_mut(3);\n\t///   *left.get_mut(1).unwrap() = true;\n\t///   *right.get_mut(2).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 0b010_00100);\n\t/// ```\n\t///\n\t/// [`BitStore`]: ../store/trait.BitStore.html\n\t#[inline]\n\t//  `pub type Aliased = BitSlice<O, T::Alias>;` is not allowed in inherents,\n\t//  so this will not be aliased.\n\t#[allow(clippy::type_complexity)]\n\tpub fn split_at_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut BitSlice<O, T::Alias>, &mut BitSlice<O, T::Alias>)\n\t{\n\t\tlet len = self.len();\n\t\tassert!(mid <= len, \"Index {} out of bounds: {}\", mid, len);\n\t\tunsafe { self.split_at_unchecked_mut(mid) }\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`.\n\t/// The matched bit is not contained in the subslices.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split`](https://doc.rust-lang.org/std/primitive.slice.html#method.split)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b01_001_000u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.split(|_pos, bit| *bit);\n\t///\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 1]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[2 .. 4]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// If the first bit is matched, an empty slice will be the first item\n\t/// returned by the iterator. Similarly, if the last element in the slice is\n\t/// matched, an empty slice will be the last item returned by the iterator:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 1u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.split(|_pos, bit| *bit);\n\t///\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 7]);\n\t/// assert!(iter.next().unwrap().is_empty());\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// If two matched bits are directly adjacent, an empty slice will be\n\t/// present between them:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b001_100_00u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.split(|pos, bit| *bit);\n\t///\n\t/// assert_eq!(iter.next().unwrap(), &bits[0 .. 2]);\n\t/// assert!(iter.next().unwrap().is_empty());\n\t/// assert_eq!(iter.next().unwrap(), &bits[4 .. 8]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t#[inline]\n\tpub fn split<F>(&self, pred: F) -> Split<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tSplit::new(self, pred)\n\t}\n\n\t/// Returns an iterator over mutable subslices separated by bits that match\n\t/// `pred`. The matched bit is not contained in the subslices.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::split_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0b001_000_10u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// for group in bits.split_mut(|_pos, bit| *bit) {\n\t///   *group.get_mut(0).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 0b101_100_11);\n\t/// ```\n\t#[inline]\n\tpub fn split_mut<F>(&mut self, pred: F) -> SplitMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tSplitMut::new(self.alias_mut(), pred)\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`,\n\t/// starting at the end of the slice and working backwards. The matched bit\n\t/// is not contained in the subslices.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rsplit`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplit)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b0001_0000u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.rsplit(|_pos, bit| *bit);\n\t///\n\t/// assert_eq!(iter.next().unwrap(), &bits[4 ..]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t///\n\t/// As with `split()`, if the first or last bit is matched, an empty slice\n\t/// will be the first (or last) item returned by the iterator.\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b1001_0001u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t/// let mut iter = bits.rsplit(|_pos, bit| *bit);\n\t/// assert!(iter.next().unwrap().is_empty());\n\t/// assert_eq!(iter.next().unwrap(), &bits[4 .. 7]);\n\t/// assert_eq!(iter.next().unwrap(), &bits[1 .. 3]);\n\t/// assert!(iter.next().unwrap().is_empty());\n\t/// assert!(iter.next().is_none());\n\t/// ```\n\t#[inline]\n\tpub fn rsplit<F>(&self, pred: F) -> RSplit<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tRSplit::new(self, pred)\n\t}\n\n\t/// Returns an iterator over mutable subslices separated by bits that match\n\t/// `pred`, starting at the end of the slice and working backwards. The\n\t/// matched bit is not contained in the subslices.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rsplit_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplit_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0b001_000_10u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// for group in bits.rsplit_mut(|_pos, bit| *bit) {\n\t///   *group.get_mut(0).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 0b101_100_11);\n\t/// ```\n\t#[inline]\n\tpub fn rsplit_mut<F>(&mut self, pred: F) -> RSplitMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tRSplitMut::new(self.alias_mut(), pred)\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`,\n\t/// limited to returning at most `n` items. The matched bit is not contained\n\t/// in the subslices.\n\t///\n\t/// The last item returned, if any, will contain the remainder of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::splitn`](https://doc.rust-lang.org/std/primitive.slice.html#method.splitn)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// for group in bits.splitn(2, |pos, _bit| pos % 3 == 2) {\n\t/// # #[cfg(feature = \"std\")] {\n\t///   println!(\"{}\", group.len());\n\t/// # }\n\t/// }\n\t/// //  2\n\t/// //  5\n\t/// # //  [10]\n\t/// # //  [00101]\n\t/// ```\n\t#[inline]\n\tpub fn splitn<F>(&self, n: usize, pred: F) -> SplitN<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tSplitN::new(self, pred, n)\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`,\n\t/// limited to returning at most `n` items. The matched element is not\n\t/// contained in the subslices.\n\t///\n\t/// The last item returned, if any, will contain the remainder of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::splitn_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.splitn_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0b001_000_10u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// for group in bits.splitn_mut(2, |_pos, bit| *bit) {\n\t///   *group.get_mut(0).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 0b101_100_10);\n\t/// ```\n\t#[inline]\n\tpub fn splitn_mut<F>(&mut self, n: usize, pred: F) -> SplitNMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tSplitNMut::new(self.alias_mut(), pred, n)\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`\n\t/// limited to returining at most `n` items. This starts at the end of the\n\t/// slice and works backwards. The matched bit is not contained in the\n\t/// subslices.\n\t///\n\t/// The last item returned, if any, will contain the remainder of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rsplitn`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplitn)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0xA5u8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// for group in bits.rsplitn(2, |pos, _bit| pos % 3 == 2) {\n\t/// # #[cfg(feature = \"std\")] {\n\t///   println!(\"{}\", group.len());\n\t/// # }\n\t/// }\n\t/// //  2\n\t/// //  5\n\t/// # //  [10]\n\t/// # //  [00101]\n\t/// ```\n\t#[inline]\n\tpub fn rsplitn<F>(&self, n: usize, pred: F) -> RSplitN<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tRSplitN::new(self, pred, n)\n\t}\n\n\t/// Returns an iterator over subslices separated by bits that match `pred`\n\t/// limited to returning at most `n` items. This starts at the end of the\n\t/// slice and works backwards. The matched bit is not contained in the\n\t/// subslices.\n\t///\n\t/// The last item returned, if any, will contain the remainder of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rsplitn_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplitn_mut)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0b001_000_10u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// for group in bits.rsplitn_mut(2, |_pos, bit| *bit) {\n\t///   *group.get_mut(0).unwrap() = true;\n\t/// }\n\t/// assert_eq!(data, 0b101_000_11);\n\t/// ```\n\t#[inline]\n\tpub fn rsplitn_mut<F>(&mut self, n: usize, pred: F) -> RSplitNMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tRSplitNMut::new(self.alias_mut(), pred, n)\n\t}\n\n\t/// Returns `true` if the slice contains a subslice that matches the given\n\t/// span.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::contains`](https://doc.rust-lang.org/std/primitive.slice.html#method.contains)\n\t///\n\t/// # API Differences\n\t///\n\t/// This searches for a matching subslice (allowing different type\n\t/// parameters) rather than for a specific bit. Searching for a contained\n\t/// element with a given value is not as useful on a collection of `bool`.\n\t///\n\t/// Furthermore, `BitSlice` defines [`any`] and [`not_all`], which are\n\t/// optimized searchers for any `true` or `false` bit, respectively, in a\n\t/// sequence.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b0101_1010u8;\n\t/// let bits_msb = data.view_bits::<Msb0>();\n\t/// let bits_lsb = data.view_bits::<Lsb0>();\n\t/// assert!(bits_msb.contains(&bits_lsb[1 .. 5]));\n\t/// ```\n\t///\n\t/// This example uses a palindrome pattern to demonstrate that the slice\n\t/// being searched for does not need to have the same type parameters as the\n\t/// slice being searched.\n\t///\n\t/// [`any`]: #method.any\n\t/// [`not_all`]: #method.not_all\n\t#[inline]\n\tpub fn contains<O2, T2>(&self, x: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tlet len = x.len();\n\t\tif len > self.len() {\n\t\t\treturn false;\n\t\t};\n\t\tself.windows(len).any(|s| s == x)\n\t}\n\n\t/// Returns `true` if `needle` is a prefix of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::starts_with`](https://doc.rust-lang.org/std/primitive.slice.html#method.starts_with)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b0100_1011u8;\n\t/// let haystack = data.view_bits::<Msb0>();\n\t/// let needle = &data.view_bits::<Lsb0>()[2 .. 5];\n\t/// assert!(haystack.starts_with(&needle[.. 2]));\n\t/// assert!(haystack.starts_with(needle));\n\t/// assert!(!haystack.starts_with(&haystack[2 .. 4]));\n\t/// ```\n\t///\n\t/// Always returns `true` if `needle` is an empty slice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let empty = BitSlice::<Local, usize>::empty();\n\t/// assert!(0u8.view_bits::<Local>().starts_with(empty));\n\t/// assert!(empty.starts_with(empty));\n\t/// ```\n\t#[inline]\n\tpub fn starts_with<O2, T2>(&self, needle: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tlet len = needle.len();\n\t\tself.len() >= len && needle == unsafe { self.get_unchecked(.. len) }\n\t}\n\n\t/// Returns `true` if `needle` is a suffix of the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::ends_with`](https://doc.rust-lang.org/std/primitive.slice.html#method.ends_with)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0b0100_1011u8;\n\t/// let haystack = data.view_bits::<Lsb0>();\n\t/// let needle = &data.view_bits::<Msb0>()[3 .. 6];\n\t/// assert!(haystack.ends_with(&needle[1 ..]));\n\t/// assert!(haystack.ends_with(needle));\n\t/// assert!(!haystack.ends_with(&haystack[2 .. 4]));\n\t/// ```\n\t///\n\t/// Always returns `true` if `needle` is an empty slice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let empty = BitSlice::<Local, usize>::empty();\n\t/// assert!(0u8.view_bits::<Local>().ends_with(empty));\n\t/// assert!(empty.ends_with(empty));\n\t/// ```\n\t#[inline]\n\tpub fn ends_with<O2, T2>(&self, needle: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tlet nlen = needle.len();\n\t\tlet len = self.len();\n\t\tlen >= nlen && needle == unsafe { self.get_unchecked(len - nlen ..) }\n\t}\n\n\t/// Rotates the slice in-place such that the first `by` bits of the slice\n\t/// move to the end while the last `self.len() - by` bits move to the front.\n\t/// After calling `rotate_left`, the bit previously at index `by` will\n\t/// become the first bit in the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rotate_left`](https://doc.rust-lang.org/std/primitive.slice.html#rotate_left)\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if `by` is greater than the length of the\n\t/// slice. Note that `by == self.len()` does *not* panic and is a no-op\n\t/// rotation.\n\t///\n\t/// # Complexity\n\t///\n\t/// Takes linear (in `self.len()`) time.\n\t///\n\t/// # Performance\n\t///\n\t/// While this is faster than the equivalent rotation on `[bool]`, it is\n\t/// slower than a handcrafted partial-element rotation on `[T]`. Because of\n\t/// the support for custom orderings, and the lack of specialization, this\n\t/// method can only accelerate by reducing the number of loop iterations\n\t/// performed on the slice body, and cannot accelerate by using shift-mask\n\t/// instructions to move multiple bits in one operation.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t/// let mut data = 0xF0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits.rotate_left(2);\n\t/// assert_eq!(data, 0xC3);\n\t/// ```\n\t///\n\t/// Rotating a subslice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0xF0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits[1 .. 5].rotate_left(1);\n\t/// assert_eq!(data, 0b1_1101_000);\n\t/// ```\n\t#[inline]\n\tpub fn rotate_left(&mut self, mut by: usize) {\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tby <= len,\n\t\t\t\"Slices cannot be rotated by more than their length\"\n\t\t);\n\t\tif by == 0 || by == len {\n\t\t\treturn;\n\t\t}\n\t\t/* The standard one-element-at-a-time algorithm is necessary for `[T]`\n\t\trotation, because it must not allocate, but bit slices have an advantage\n\t\tin that placing a single element `T` on the stack as a temporary has\n\t\tsignificant logical acceleration.\n\n\t\tInstead, we can move `min(T::Mem::BITS, by)` bits from the front of the\n\t\tslice into the stack, then shunt the rest of the slice downwards, then\n\t\tinsert the stack bits into the now-open back, repeating until complete.\n\t\t*/\n\t\tlet mut tmp = 0usize;\n\t\tlet tmp_bits = BitSlice::<O, _>::from_element_mut(&mut tmp);\n\t\twhile by > 0 {\n\t\t\t//  Note: in theory, the \"head to tmp\" operation could be optimized\n\t\t\t//  to a single element copy of `head .. BITS`, at the cost of more\n\t\t\t//  loops.\n\t\t\tlet shamt = cmp::min(usize::BITS as usize, by);\n\t\t\tunsafe {\n\t\t\t\tlet tmp_bits = tmp_bits.get_unchecked_mut(.. shamt);\n\t\t\t\ttmp_bits.clone_from_bitslice(self.get_unchecked(.. shamt));\n\t\t\t\tself.copy_within_unchecked(shamt .., 0);\n\t\t\t\tself.get_unchecked_mut(len - shamt ..)\n\t\t\t\t\t.clone_from_bitslice(tmp_bits);\n\t\t\t}\n\t\t\tby -= shamt;\n\t\t}\n\t}\n\n\t/// Rotates the slice in-place such that the first `self.len() - by` bits of\n\t/// the slice move to the end while the last `by` bits move to the front.\n\t/// After calling `rotate_right`, the bit previously at index `self.len() -\n\t/// by` will become the first bit in the slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::rotate_right`](https://doc.rust-lang.org/std/primitive.slice.html#rotate_right)\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if `by` is greater than the length of the\n\t/// slice. Note that `by == self.len()` does *not* panic and is a no-op\n\t/// rotation.\n\t///\n\t/// # Complexity\n\t///\n\t/// Takes linear (in `self.len()`) time.\n\t///\n\t/// # Performance\n\t///\n\t/// While this is faster than the equivalent rotation on `[bool]`, it is\n\t/// slower than a handcrafted partial-element rotation on `[T]`. Because of\n\t/// the support for custom orderings, and the lack of specialization, this\n\t/// method can only accelerate by reducing the number of loop iterations\n\t/// performed on the slice body, and cannot accelerate by using shift-mask\n\t/// instructions to move multiple bits in one operation.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0xF0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits.rotate_right(2);\n\t/// assert_eq!(data, 0x3C);\n\t/// ```\n\t///\n\t/// Rotate a subslice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0xF0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits[1 .. 5].rotate_right(1);\n\t/// assert_eq!(data, 0b1_0111_000);\n\t/// ```\n\t#[inline]\n\tpub fn rotate_right(&mut self, mut by: usize) {\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tby <= len,\n\t\t\t\"Slices cannot be rotated by more than their length\"\n\t\t);\n\t\tif by == 0 || by == len {\n\t\t\treturn;\n\t\t}\n\t\tlet mut tmp = 0usize;\n\t\tlet tmp_bits = BitSlice::<O, _>::from_element_mut(&mut tmp);\n\t\twhile by > 0 {\n\t\t\tlet shamt = cmp::min(usize::BITS as usize, by);\n\t\t\tlet mid = len - shamt;\n\t\t\tunsafe {\n\t\t\t\tlet tmp_bits = tmp_bits.get_unchecked_mut(.. shamt);\n\t\t\t\ttmp_bits.clone_from_bitslice(self.get_unchecked(mid ..));\n\t\t\t\tself.copy_within_unchecked(.. mid, shamt);\n\t\t\t\tself.get_unchecked_mut(.. shamt)\n\t\t\t\t\t.clone_from_bitslice(tmp_bits);\n\t\t\t}\n\t\t\tby -= shamt;\n\t\t}\n\t}\n\n\t/// Copies the bits from `src` into `self`.\n\t///\n\t/// The length of `src` must be the same as `self`.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::clone_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.clone_from_slice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This method is renamed, as it takes a bit slice rather than an element\n\t/// slice.\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if the two slices have different lengths.\n\t///\n\t/// # Examples\n\t///\n\t/// Cloning two bits from a slice into another:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// let src = 0x0Fu16.view_bits::<Lsb0>();\n\t/// bits[.. 2].clone_from_bitslice(&src[2 .. 4]);\n\t/// assert_eq!(data, 0xC0);\n\t/// ```\n\t///\n\t/// Rust enforces that there can only be one mutable reference with no\n\t/// immutable references to a particular piece of data in a particular\n\t/// scope. Because of this, attempting to use `clone_from_bitslice` on a\n\t/// single slice will result in a compile failure:\n\t///\n\t/// ```rust,compile_fail\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 3u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// bits[.. 2].clone_from_bitslice(&bits[6 ..]);\n\t/// ```\n\t///\n\t/// To work around this, we can use [`split_at_mut`] to create two distinct\n\t/// sub-slices from a slice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 3u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t/// let (head, tail) = bits.split_at_mut(4);\n\t/// head.clone_from_bitslice(tail);\n\t/// assert_eq!(data, 0x33);\n\t/// ```\n\t///\n\t/// [`split_at_mut`]: #method.split_at_mut\n\t#[inline]\n\tpub fn clone_from_bitslice<O2, T2>(&mut self, src: &BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tlet len = self.len();\n\t\tassert_eq!(len, src.len(), \"Cloning from slice requires equal lengths\",);\n\t\tfor idx in 0 .. len {\n\t\t\tunsafe {\n\t\t\t\tself.set_unchecked(idx, *src.get_unchecked(idx));\n\t\t\t}\n\t\t}\n\t}\n\n\t#[inline]\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.clone_from_bitslice` to copy between bitslices\")]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn clone_from_slice<O2, T2>(&mut self, src: &BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tself.clone_from_bitslice(src)\n\t}\n\n\t/// Copies all bits from `src` into `self`.\n\t///\n\t/// The length of `src` must be the same as `self`.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::copy_from_slice`](https://doc.rust-lang.org/std/primitive.std.html#method.copy_from_slice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This method is renamed, as it takes a bit slice rather than an element\n\t/// slice.\n\t///\n\t/// This is unable to guarantee a strictly faster copy behavior than\n\t/// [`clone_from_bitslice`]. In the future, the implementation *may*\n\t/// specialize, as the language allows.\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if the two slices have different lengths.\n\t///\n\t/// # Examples\n\t///\n\t/// Copying two bits from a slice into another:\n\t///\n\t/// [`clone_from_bitslice`]: #method.clone_from_bitslice\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn copy_from_bitslice(&mut self, src: &Self) {\n\t\tself.clone_from_bitslice(src);\n\t}\n\n\t#[inline]\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.copy_from_bitslice` to copy between bitslices\")]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn copy_from_slice(&mut self, src: &Self) {\n\t\tself.copy_from_bitslice(src)\n\t}\n\n\t/// Copies bits from one part of the slice to another part of itself.\n\t///\n\t/// `src` is the range within `self` to copy from. `dest` is the starting\n\t/// index of the range within `self` to copy to, which will have the same\n\t/// length as `src`. The two ranges may overlap. The ends of the two ranges\n\t/// must be less than or equal to `self.len()`.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::copy_within`](https://doc.rust-lang.org/std/primitive.slice.html#method.copy_within)\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if either range exceeds the end of the slice,\n\t/// or if the end of `src` is before the start.\n\t///\n\t/// # Examples\n\t///\n\t/// Copying four bytes within a slice:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut data = 0x07u8;\n\t/// let bits = data.view_bits_mut::<Msb0>();\n\t///\n\t/// bits.copy_within(5 .., 0);\n\t///\n\t/// assert_eq!(data, 0xE7);\n\t/// ```\n\t#[inline]\n\tpub fn copy_within<R>(&mut self, src: R, dest: usize)\n\twhere R: RangeBounds<usize> {\n\t\tlet len = self.len();\n\t\tlet src = dvl::normalize_range(src, len);\n\t\t//  Check that the source range is within bounds,\n\t\tdvl::assert_range(src.clone(), len);\n\t\t//  And that the destination range is within bounds.\n\t\tdvl::assert_range(dest .. dest + (src.end - src.start), len);\n\t\tunsafe {\n\t\t\tself.copy_within_unchecked(src, dest);\n\t\t}\n\t}\n\n\t/// Swaps all bits in `self` with those in `other`.\n\t///\n\t/// The length of `other` must be the same as `self`.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::swap_with_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.swap_with_slice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This method is renamed, as it takes a bit slice rather than an element\n\t/// slice.\n\t///\n\t/// # Panics\n\t///\n\t/// This function will panic if the two slices have different lengths.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut one = [0xA5u8, 0x69];\n\t/// let mut two = 0x1234u16;\n\t/// let one_bits = one.view_bits_mut::<Msb0>();\n\t/// let two_bits = two.view_bits_mut::<Lsb0>();\n\t///\n\t/// one_bits.swap_with_bitslice(two_bits);\n\t///\n\t/// assert_eq!(one, [0x2C, 0x48]);\n\t/// # #[cfg(target_endian = \"little\")] {\n\t/// assert_eq!(two, 0x96A5);\n\t/// # }\n\t/// ```\n\t#[inline]\n\tpub fn swap_with_bitslice<O2, T2>(&mut self, other: &mut BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tlet len = self.len();\n\t\tassert_eq!(len, other.len());\n\t\tfor n in 0 .. len {\n\t\t\tunsafe {\n\t\t\t\tlet (this, that) =\n\t\t\t\t\t(*self.get_unchecked(n), *other.get_unchecked(n));\n\t\t\t\tself.set_unchecked(n, that);\n\t\t\t\tother.set_unchecked(n, this);\n\t\t\t}\n\t\t}\n\t}\n\n\t#[inline]\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.swap_with_bitslice` to swap between bitslices\")]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn swap_with_slice<O2, T2>(&mut self, other: &mut BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tself.swap_with_bitslice(other);\n\t}\n\n\t/// Transmute the bitslice to a bitslice of another type, ensuring alignment\n\t/// of the types is maintained.\n\t///\n\t/// This method splits the bitslice into three distinct bitslices: prefix,\n\t/// correctly aligned middle bitslice of a new type, and the suffix\n\t/// bitslice. The method may make the middle bitslice the greatest\n\t/// length possible for a given type and input bitslice, but only your\n\t/// algorithm's performance should depend on that, not its correctness. It\n\t/// is permissible for all of the input data to be returned as the prefix or\n\t/// suffix bitslice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::align_to`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to)\n\t///\n\t/// # API Differences\n\t///\n\t/// Type `U` is **required** to have the same type family as type `T`.\n\t/// Whatever `T` is of the fundamental integers, atomics, or `Cell`\n\t/// wrappers, `U` must be a different width in the same family. Changing the\n\t/// type family with this method is **unsound** and strictly forbidden.\n\t/// Unfortunately, it cannot be guaranteed by this function, so you are\n\t/// required to abide by this limitation.\n\t///\n\t/// # Safety\n\t///\n\t/// This method is essentially a `transmute` with respect to the elements in\n\t/// the returned middle bitslice, so all the usual caveats pertaining to\n\t/// `transmute::<T, U>` also apply here.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// unsafe {\n\t///   let bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n\t///   let bits = bytes.view_bits::<Local>();\n\t///   let (prefix, shorts, suffix) = bits.align_to::<u16>();\n\t///   match prefix.len() {\n\t///     0 => {\n\t///       assert_eq!(shorts, bits[.. 48]);\n\t///       assert_eq!(suffix, bits[48 ..]);\n\t///     },\n\t///     8 => {\n\t///       assert_eq!(prefix, bits[.. 8]);\n\t///       assert_eq!(shorts, bits[8 ..]);\n\t///     },\n\t///     _ => unreachable!(\"This case will not occur\")\n\t///   }\n\t/// }\n\t/// ```\n\t#[inline]\n\tpub unsafe fn align_to<U>(&self) -> (&Self, &BitSlice<O, U>, &Self)\n\twhere U: BitStore {\n\t\tlet bitptr = self.bitptr();\n\t\tlet bp_len = bitptr.len();\n\t\tlet (l, c, r) = bitptr.as_aliased_slice().align_to::<U::Alias>();\n\t\tlet l_start = bitptr.head().value() as usize;\n\t\tlet mut l = BitSlice::<O, T::Alias>::from_aliased_slice_unchecked(l);\n\t\tif l.len() > l_start {\n\t\t\tl = l.get_unchecked(l_start ..);\n\t\t}\n\t\tlet mut c = BitSlice::<O, U::Alias>::from_aliased_slice_unchecked(c);\n\t\tlet c_len = cmp::min(c.len(), bp_len - l.len());\n\t\tc = c.get_unchecked(.. c_len);\n\t\tlet mut r = BitSlice::<O, T::Alias>::from_aliased_slice_unchecked(r);\n\t\tlet r_len = bp_len - l.len() - c.len();\n\t\tif r.len() > r_len {\n\t\t\tr = r.get_unchecked(.. r_len);\n\t\t}\n\t\t(\n\t\t\tl.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<T>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t\tc.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<U>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t\tr.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<T>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t)\n\t}\n\n\t/// Transmute the bitslice to a bitslice of another type, ensuring alignment\n\t/// of the types is maintained.\n\t///\n\t/// This method splits the bitslice into three distinct bitslices: prefix,\n\t/// correctly aligned middle bitslice of a new type, and the suffix\n\t/// bitslice. The method may make the middle bitslice the greatest\n\t/// length possible for a given type and input bitslice, but only your\n\t/// algorithm's performance should depend on that, not its correctness. It\n\t/// is permissible for all of the input data to be returned as the prefix or\n\t/// suffix bitslice.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::align_to`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to)\n\t///\n\t/// # API Differences\n\t///\n\t/// Type `U` is **required** to have the same type family as type `T`.\n\t/// Whatever `T` is of the fundamental integers, atomics, or `Cell`\n\t/// wrappers, `U` must be a different width in the same family. Changing the\n\t/// type family with this method is **unsound** and strictly forbidden.\n\t/// Unfortunately, it cannot be guaranteed by this function, so you are\n\t/// required to abide by this limitation.\n\t///\n\t/// # Safety\n\t///\n\t/// This method is essentially a `transmute` with respect to the elements in\n\t/// the returned middle bitslice, so all the usual caveats pertaining to\n\t/// `transmute::<T, U>` also apply here.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// unsafe {\n\t///   let mut bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n\t///   let bits = bytes.view_bits_mut::<Local>();\n\t///   let (prefix, shorts, suffix) = bits.align_to_mut::<u16>();\n\t///   //  same access and behavior as in `align_to`\n\t/// }\n\t/// ```\n\t#[inline]\n\tpub unsafe fn align_to_mut<U>(\n\t\t&mut self,\n\t) -> (&mut Self, &mut BitSlice<O, U>, &mut Self)\n\twhere U: BitStore {\n\t\tlet (l, c, r) = self.align_to::<U>();\n\t\t(\n\t\t\tl.bitptr().to_bitslice_mut(),\n\t\t\tc.bitptr().to_bitslice_mut(),\n\t\t\tr.bitptr().to_bitslice_mut(),\n\t\t)\n\t}\n}","impl<O, T> BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// The inclusive maximum length of a `BitSlice<_, T>`.\n\t///\n\t/// As `BitSlice` is zero-indexed, the largest possible index is one less\n\t/// than this value.\n\t///\n\t/// |CPU word width|         Value         |\n\t/// |-------------:|----------------------:|\n\t/// |32 bits       |     `0x1fff_ffff`     |\n\t/// |64 bits       |`0x1fff_ffff_ffff_ffff`|\n\tpub const MAX_BITS: usize = BitPtr::<T>::REGION_MAX_BITS;\n\t/// The inclusive maximum length that a slice `[T]` can be for\n\t/// `BitSlice<_, T>` to cover it.\n\t///\n\t/// A `BitSlice<_, T>` that begins in the interior of an element and\n\t/// contains the maximum number of bits will extend one element past the\n\t/// cutoff that would occur if the slice began at the zeroth bit. Such a\n\t/// slice must be manually constructed, but will not otherwise fail.\n\t///\n\t/// |Type Bits|Max Elements (32-bit)| Max Elements (64-bit) |\n\t/// |--------:|--------------------:|----------------------:|\n\t/// |        8|    `0x0400_0001`    |`0x0400_0000_0000_0001`|\n\t/// |       16|    `0x0200_0001`    |`0x0200_0000_0000_0001`|\n\t/// |       32|    `0x0100_0001`    |`0x0100_0000_0000_0001`|\n\t/// |       64|    `0x0080_0001`    |`0x0080_0000_0000_0001`|\n\tpub const MAX_ELTS: usize = BitPtr::<T>::REGION_MAX_ELTS;\n}","impl<O, T> Debug for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tif fmt.alternate() {\n\t\t\tPointer::fmt(self, fmt)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tBinary::fmt(self, fmt)\n\t}\n}","impl<O, T> Display for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tBinary::fmt(self, fmt)\n\t}\n}","impl<O, T> Eq for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> Hash for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn hash<H>(&self, hasher: &mut H)\n\twhere H: Hasher {\n\t\tfor bit in self {\n\t\t\thasher.write_u8(*bit as u8);\n\t\t}\n\t}\n}","impl<O, T> Index<$t> for BitSlice<O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\ttype Output = Self;\n\n\t\t\tfn index(&self, index: $t) -> &Self::Output {\n\t\t\t\tindex.index(self)\n\t\t\t}\n\t\t}","impl<O, T> Index<usize> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Output = bool;\n\n\t/// Looks up a single bit by semantic index.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = bits![Msb0, u8; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0];\n\t/// assert!(!bits[7]); // --------------------------^  |  |\n\t/// assert!( bits[8]); // -----------------------------^  |\n\t/// assert!(!bits[9]); // --------------------------------^\n\t/// ```\n\t///\n\t/// If the index is greater than or equal to the length, indexing will\n\t/// panic.\n\t///\n\t/// The below test will panic when accessing index 1, as only index 0 is\n\t/// valid.\n\t///\n\t/// ```rust,should_panic\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = bits![0,  ];\n\t/// bits[1]; // --------^\n\t/// ```\n\tfn index(&self, index: usize) -> &Self::Output {\n\t\tindex.index(self)\n\t}\n}","impl<O, T> IndexMut<$t> for BitSlice<O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\tfn index_mut(&mut self, index: $t) -> &mut Self::Output {\n\t\t\t\tindex.index_mut(self)\n\t\t\t}\n\t\t}","impl<O, T> Ord for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn cmp(&self, rhs: &Self) -> cmp::Ordering {\n\t\tself.partial_cmp(rhs)\n\t\t\t.expect(\"BitSlice has a total ordering\")\n\t}\n}","impl<O, T> PartialOrd<BitBox<O, T>> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &BitBox<O, T>) -> Option<cmp::Ordering> {\n\t\tself.partial_cmp(other.as_bitslice())\n\t}\n}","impl<O, T> PartialOrd<BitVec<O, T>> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &BitVec<O, T>) -> Option<cmp::Ordering> {\n\t\tself.partial_cmp(other.as_bitslice())\n\t}\n}","impl<O, T> Pointer for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Slice\", Some(any::type_name::<O>()), None)\n\t}\n}","impl<O, T> ToOwned for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Owned = BitVec<O, T>;\n\n\t#[inline]\n\tfn to_owned(&self) -> Self::Owned {\n\t\tBitVec::from_bitslice(self)\n\t}\n}","impl<O, V, T> PartialEq<BitArray<O, V>> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn eq(&self, other: &BitArray<O, V>) -> bool {\n\t\tself == other.as_bitslice()\n\t}\n}","impl<O, V, T> PartialOrd<BitArray<O, V>> for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &BitArray<O, V>) -> Option<cmp::Ordering> {\n\t\tself.partial_cmp(other.as_bitslice())\n\t}\n}","impl<O1, O2, T1, T2> PartialEq<&BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn eq(&self, rhs: &&BitSlice<O2, T2>) -> bool {\n\t\t*self == **rhs\n\t}\n}","impl<O1, O2, T1, T2> PartialEq<&mut BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn eq(&self, rhs: &&mut BitSlice<O2, T2>) -> bool {\n\t\t*self == **rhs\n\t}\n}","impl<O1, O2, T1, T2> PartialEq<BitBox<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn eq(&self, other: &BitBox<O2, T2>) -> bool {\n\t\tself == other.as_bitslice()\n\t}\n}","impl<O1, O2, T1, T2> PartialEq<BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\tfn eq(&self, rhs: &BitSlice<O2, T2>) -> bool {\n\t\tself.len() == rhs.len()\n\t\t\t&& self.iter().zip(rhs.iter()).all(|(l, r)| l == r)\n\t}\n}","impl<O1, O2, T1, T2> PartialEq<BitVec<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn eq(&self, other: &BitVec<O2, T2>) -> bool {\n\t\tself == other.as_bitslice()\n\t}\n}","impl<O1, O2, T1, T2> PartialOrd<&BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn partial_cmp(&self, rhs: &&BitSlice<O2, T2>) -> Option<cmp::Ordering> {\n\t\t(*self).partial_cmp(&**rhs)\n\t}\n}","impl<O1, O2, T1, T2> PartialOrd<&mut BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\t#[inline]\n\tfn partial_cmp(&self, rhs: &&mut BitSlice<O2, T2>) -> Option<cmp::Ordering> {\n\t\t(*self).partial_cmp(&**rhs)\n\t}\n}","impl<O1, O2, T1, T2> PartialOrd<BitSlice<O2, T2>> for BitSlice<O1, T1>\nwhere\n\tO1: BitOrder,\n\tO2: BitOrder,\n\tT1: BitStore,\n\tT2: BitStore,\n{\n\tfn partial_cmp(&self, rhs: &BitSlice<O2, T2>) -> Option<cmp::Ordering> {\n\t\tfor (l, r) in self.iter().zip(rhs.iter()) {\n\t\t\tmatch (l, r) {\n\t\t\t\t(true, false) => return Some(cmp::Ordering::Greater),\n\t\t\t\t(false, true) => return Some(cmp::Ordering::Less),\n\t\t\t\t_ => continue,\n\t\t\t}\n\t\t}\n\t\tself.len().partial_cmp(&rhs.len())\n\t}\n}","impl<T> BitField for BitSlice<Lsb0, T>\nwhere T: BitStore\n{\n\t#[inline]\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\t//  In Lsb0, a `head` index counts distance from LSedge, and a\n\t\t\t//  `tail` index counts element width minus distance from MSedge.\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\t/* For multi-`T::Mem` domains, the most significant chunk is\n\t\t\t\tstored in the highest memory address, the tail. Each successive\n\t\t\t\tmemory address lower has a chunk of decreasing significance,\n\t\t\t\tuntil the least significant chunk is stored in the lowest memory\n\t\t\t\taddress, the head.\n\t\t\t\t*/\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum = get::<T, M>(elem, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().rev().copied() {\n\t\t\t\t\t/* Rust does not allow the use of shift instructions of\n\t\t\t\t\texactly a type width to clear a value. This loop only enters\n\t\t\t\t\twhen `M` is not narrower than `T::Mem`, and the shift is\n\t\t\t\t\tonly needed when `M` occupies *more than one* `T::Mem` slot.\n\t\t\t\t\tWhen `M` is exactly as wide as `T::Mem`, this loop either\n\t\t\t\t\tdoes not runs (head and tail only), or runs once (single\n\t\t\t\t\telement), and thus the shift is unnecessary.\n\n\t\t\t\t\tAs a const-expression, this branch folds at compile-time to\n\t\t\t\t\tconditionally remove or retain the instruction.\n\t\t\t\t\t*/\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tlet shamt = head.value();\n\t\t\t\t\taccum <<= T::Mem::BITS - shamt;\n\t\t\t\t\taccum |= get::<T, M>(elem, Lsb0::mask(head, None), shamt);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum =\n\t\t\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, None), head.value());\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum <<= tail.value();\n\t\t\t\t\taccum |= get::<T, M>(elem, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn store_le<M>(&mut self, mut value: M)\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tlet shamt = head.value();\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, None), shamt);\n\t\t\t\t\tvalue >>= T::Mem::BITS - shamt;\n\t\t\t\t}\n\n\t\t\t\tfor elem in body {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn store_be<M>(&mut self, mut value: M)\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(None, tail), 0);\n\t\t\t\t\tvalue >>= tail.value()\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut().rev() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tLsb0::mask(head, None),\n\t\t\t\t\t\thead.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}\n}","impl<T> BitField for BitSlice<Msb0, T>\nwhere T: BitStore\n{\n\t#[inline]\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => get::<T, M>(\n\t\t\t\telem,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum = get::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().rev().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum <<= T::Mem::BITS - head.value();\n\t\t\t\t\taccum |= get::<T, M>(elem, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => get::<T, M>(\n\t\t\t\telem,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum = get::<T, M>(elem, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tlet width = tail.value();\n\t\t\t\t\taccum <<= width;\n\t\t\t\t\taccum |= get::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - width,\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn store_le<M>(&mut self, mut value: M)\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => set::<T, M>(\n\t\t\t\telem,\n\t\t\t\tvalue,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(elem, value, Msb0::mask(head, None), 0);\n\t\t\t\t\tvalue >>= T::Mem::BITS - head.value();\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}\n\n\t#[inline]\n\tfn store_be<M>(&mut self, mut value: M)\n\twhere M: BitMemory {\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => set::<T, M>(\n\t\t\t\telem,\n\t\t\t\tvalue,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t\tvalue >>= tail.value();\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut().rev() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(elem, value, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}\n}","unsafe impl<O, T> Send for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tT::Threadsafe: Send,\n{\n}","unsafe impl<O, T> Sync for BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tT::Threadsafe: Sync,\n{\n}"],"slice::iter::Chunks":["Clone","Debug","impl<'a, O, T> $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self {\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::ChunksExact":["Clone","Debug","impl<'a, O, T> ChunksExact<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub(super) fn new(slice: &'a BitSlice<O, T>, width: usize) -> Self {\n\t\tlet len = slice.len();\n\t\tlet rem = len % width;\n\t\tlet (slice, extra) = unsafe { slice.split_at_unchecked(len - rem) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}\n\n\t/// Returns the remainder of the original bit slice that is not going to be\n\t/// returned by the iterator. The returned slice has at most `chunk_size-1`\n\t/// bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::ChunksExact::remainder`](https://doc.rust-lang.org/core/slice/struct.ChunksExact.html#method.remainder)\n\tpub fn remainder(&self) -> &'a BitSlice<O, T> {\n\t\tself.extra\n\t}\n}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::ChunksExactMut":["Debug","impl<'a, O, T> ChunksExactMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub(super) fn new(slice: &'a mut BitSlice<O, T>, width: usize) -> Self {\n\t\tlet len = slice.len();\n\t\tlet rem = len % width;\n\t\tlet (slice, extra) = unsafe { slice.split_at_unchecked_mut(len - rem) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}\n\n\t/// Returns the remainder of the original slice that is not going to be\n\t/// returned by the iterator. The returned slice has at most `chunk_size-1`\n\t/// bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::ChunksExactMut::into_remainder`](https://doc.rust-lang.org/core/slice/struct.ChunksExactMut.html#method.into_remainder)\n\t///\n\t/// # API Differences\n\t///\n\t/// The remainder slice, as with all slices yielded from this iterator, is\n\t/// marked as aliased.\n\t#[inline]\n\tpub fn into_remainder(self) -> &'a mut BitSlice<O, T::Alias> {\n\t\tself.extra\n\t}\n}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::ChunksMut":["Debug","impl<'a, O, T> $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self {\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::Iter":["Debug","impl<'a, O, T> $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// The canonical empty iterator.\n\t\t\tconst EMPTY: Self = Self {\n\t\t\t\tbase: NonNull::dangling(),\n\t\t\t\tlast: NonNull::dangling(),\n\t\t\t\thead: BitIdx::ZERO,\n\t\t\t\ttail: BitIdx::ZERO,\n\t\t\t\t_ref: PhantomData,\n\t\t\t};\n\n\t\t\t/// Tests whether the iterator is *any* empty iterator.\n\t\t\tpub(crate) fn inherent_is_empty(&self) -> bool {\n\t\t\t\tself.base == self.last && self.head == self.tail\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_back())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn nth_back(&mut self, n: usize) -> Option<Self::Item> {\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the tail cursors down by `n` bits before producing a\n\t\t\t\t//  bit.\n\t\t\t\tlet (elts, tail) = self.tail.offset(-(n as isize));\n\t\t\t\tself.last =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.last.as_ptr().offset(elts)) };\n\t\t\t\tself.tail = tail;\n\t\t\t\tSome(self.pop_back())\n\t\t\t}\n\t\t}","impl<'a, O, T> Iter<'a, O, T>\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Views the underlying data as a subslice of the original data.\n\t///\n\t/// This has the same lifetime as the original bit slice, and so the\n\t/// iterator can continue to be used while this exists.\n\t///\n\t/// # Original\n\t///\n\t/// [`Iter::as_slice`](https://doc.rust-lang.org/core/slice/struct.Iter.html#method.as_slice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This is renamed, as its return type is not an element slice `&[T]` or\n\t/// `&[bool]` but a bit slice.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t///\n\t/// // First, we declare a type which has the `iter` method to get the `Iter`\n\t/// // struct (&BitSlice here):\n\t/// let data = 129u8;\n\t/// let bits = BitSlice::<Msb0, _>::from_element(&data);\n\t///\n\t/// // Then, we get the iterator:\n\t/// let mut iter = bits.iter();\n\t/// // So if we print what `as_bitslice` returns here, we have \"[1, 0, 0, 0, 0, 0, 0, 1]\":\n\t/// println!(\"{:?}\", iter.as_bitslice());\n\t///\n\t/// // Next, we move to the second element of the slice:\n\t/// iter.next();\n\t/// // Now `as_bitslice` returns \"[0, 0, 0, 0, 0, 0, 1]\":\n\t/// println!(\"{:?}\", iter.as_bitslice());\n\t/// # }\n\t/// ```\n\t#[inline]\n\tpub fn as_bitslice(&self) -> &'a BitSlice<O, T> {\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(\n\t\t\t\tself.base.as_ptr() as *const T::Access as *const T,\n\t\t\t\tself.head,\n\t\t\t\tself.len(),\n\t\t\t)\n\t\t}\n\t\t.to_bitslice_ref()\n\t}\n\n\t/* Allow the standard-library name to resolve, but instruct the user to\n\trename.\n\n\tIt is important not to use the name `slice` to refer to any `BitSlice`\n\tregions, and to keep distinct the views of a `BitSlice` from the views of\n\tthe underlying `[T]` storage slice.\n\t*/\n\t#[inline]\n\t#[doc(hidden)]\n\t#[deprecated(\n\t\tnote = \"Use `.as_bitslice` on iterators to view the remaining data\"\n\t)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_slice(&self) -> &'a BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n\n\t/// Removes the bit at the front of the iterator.\n\tfn pop_front(&mut self) -> <Self as Iterator>::Item {\n\t\tlet out = unsafe { &*self.base.as_ptr() }.get_bit::<O>(self.head);\n\t\tlet (head, incr) = self.head.incr();\n\t\tself.base = unsafe {\n\t\t\tNonNull::new_unchecked(self.base.as_ptr().add(incr as usize))\n\t\t};\n\t\tself.head = head;\n\n\t\tif out { &true } else { &false }\n\t}\n\n\t/// Removes the bit at the back of the iterator.\n\tfn pop_back(&mut self) -> <Self as Iterator>::Item {\n\t\tlet (tail, offset) = self.tail.decr();\n\t\tself.last = unsafe {\n\t\t\tNonNull::new_unchecked(self.last.as_ptr().offset(-(offset as isize)))\n\t\t};\n\t\tself.tail = tail;\n\t\tif unsafe { &*self.last.as_ptr() }.get_bit::<O>(self.tail) {\n\t\t\t&true\n\t\t}\n\t\telse {\n\t\t\t&false\n\t\t}\n\t}\n}","impl<'a, O, T> Iterator for $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $i;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_front())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn nth(&mut self, n: usize) -> Option<Self::Item> {\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the head cursors up by `n` bits before producing a bit.\n\t\t\t\tlet (elts, head) = self.head.offset(n as isize);\n\t\t\t\tself.base =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.base.as_ptr().offset(elts)) };\n\t\t\t\tself.head = head;\n\t\t\t\tSome(self.pop_front())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> AsRef<BitSlice<O, T>> for Iter<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[cfg(not(tarpaulin_include))]\n\tfn as_ref(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> Clone for Iter<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\tfn clone(&self) -> Self {\n\t\t*self\n\t}\n}","impl<O, T> Copy for Iter<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> ExactSizeIterator for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\tfn len(&self) -> usize {\n\t\t\t\tlet (base, last) =\n\t\t\t\t\t(self.base.as_ptr() as usize, self.last.as_ptr() as usize);\n\t\t\t\t/* Get the total number of bits in the element range\n\t\t\t\t`self.base .. self.last`. Wrapping arithmetic is used because\n\t\t\t\t`last` is known to never be less than base, so we always want a\n\t\t\t\tbare `sub` instruction without any checks. We also know that the\n\t\t\t\tdifference between the two addresses can support a `shl`\n\t\t\t\tinstruction without overflow.\n\t\t\t\t*/\n\t\t\t\tlast.wrapping_sub(base)\n\t\t\t\t\t.wrapping_shl(T::Mem::INDX as u32)\n\t\t\t\t\t//  Now, add the live bits before `self.tail` in `*last`,\n\t\t\t\t\t.wrapping_add(self.tail.value() as usize)\n\t\t\t\t\t//  And remove the dead bits before `self.head` in `*base`.\n\t\t\t\t\t.wrapping_sub(self.head.value() as usize)\n\t\t\t}\n\t\t}","impl<O, T> core::iter::FusedIterator for $t <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t}","unsafe impl<O, T> Send for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}","unsafe impl<O, T> Sync for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::IterMut":["Debug","impl<'a, O, T> $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// The canonical empty iterator.\n\t\t\tconst EMPTY: Self = Self {\n\t\t\t\tbase: NonNull::dangling(),\n\t\t\t\tlast: NonNull::dangling(),\n\t\t\t\thead: BitIdx::ZERO,\n\t\t\t\ttail: BitIdx::ZERO,\n\t\t\t\t_ref: PhantomData,\n\t\t\t};\n\n\t\t\t/// Tests whether the iterator is *any* empty iterator.\n\t\t\tpub(crate) fn inherent_is_empty(&self) -> bool {\n\t\t\t\tself.base == self.last && self.head == self.tail\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_back())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn nth_back(&mut self, n: usize) -> Option<Self::Item> {\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the tail cursors down by `n` bits before producing a\n\t\t\t\t//  bit.\n\t\t\t\tlet (elts, tail) = self.tail.offset(-(n as isize));\n\t\t\t\tself.last =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.last.as_ptr().offset(elts)) };\n\t\t\t\tself.tail = tail;\n\t\t\t\tSome(self.pop_back())\n\t\t\t}\n\t\t}","impl<'a, O, T> IterMut<'a, O, T>\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Views the underlying data as a subslice of the original data.\n\t///\n\t/// To avoid creating `&mut` references that alias the same *bits*, this is\n\t/// forced to consume the iterator.\n\t///\n\t/// # Original\n\t///\n\t/// [`IterMut::into_bitslice`](https://doc.rust-lang.org/core/slice/struct.IterMut.html#method.into_bitslice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This is renamed, as its return type is not an element slice `&mut [T]`\n\t/// or `&mut [bool]` but a bit slice.\n\t///\n\t/// # Examples\n\t///\n\t/// Basic usage:\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t///\n\t/// // First, we declare a type which has `iter_mut` method to get the `IterMut`\n\t/// // struct (&BitSlice here):\n\t/// let mut data = 0u8;\n\t/// let bits = data.view_bits_mut::<Lsb0>();\n\t///\n\t/// {\n\t///   // Then, we get the iterator:\n\t///   let mut iter = bits.iter_mut();\n\t///   // We move to the next element:\n\t///   iter.next();\n\t///   // So if we print what `into_bitslice` method returns here, we have\n\t///   // \"[0, 0, 0, 0, 0, 0, 0]\":\n\t///   println!(\"{:?}\", iter.into_bitslice());\n\t/// }\n\t///\n\t/// // Now let's modify a value of the slice:\n\t/// {\n\t///   // First we get back the iterator:\n\t///   let mut iter = bits.iter_mut();\n\t///   // We change the value of the first bit of the slice returned by the `next` method:\n\t///   *iter.next().unwrap() = true;\n\t/// }\n\t/// // Now data is \"1\":\n\t/// assert_eq!(data, 1);\n\t/// # }\n\tpub fn into_bitslice(self) -> &'a mut BitSlice<O, T::Alias> {\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(\n\t\t\t\tself.base.as_ptr()\n\t\t\t\t\tas *const <<T as BitStore>::Alias as BitStore>::Access\n\t\t\t\t\tas *const <T as BitStore>::Alias,\n\t\t\t\tself.head,\n\t\t\t\tself.len(),\n\t\t\t)\n\t\t}\n\t\t.to_bitslice_mut()\n\t}\n\n\t/* Allow the standard-library name to resolve, but instruct the user to\n\trename.\n\n\tIt is important not to use the name `slice` to refer to any `BitSlice`\n\tregions, and to keep distinct the views of a `BitSlice` from the views of\n\tthe underlying `[T]` storage slice.\n\t*/\n\t#[inline]\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.into_bitslice` on mutable iterators to view \\\n\t                     the remaining data\")]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn into_slice(self) -> &'a mut BitSlice<O, T::Alias> {\n\t\tself.into_bitslice()\n\t}\n\n\t/// Removes the bit at the front of the iterator.\n\tfn pop_front(&mut self) -> <Self as Iterator>::Item {\n\t\tlet out =\n\t\t\tunsafe { BitMut::new_unchecked(self.base.as_ptr(), self.head) };\n\n\t\tlet (head, incr) = self.head.incr();\n\t\tself.base = unsafe {\n\t\t\tNonNull::new_unchecked(self.base.as_ptr().add(incr as usize))\n\t\t};\n\t\tself.head = head;\n\n\t\tout\n\t}\n\n\t/// Removes the bit at the back of the iterator.\n\tfn pop_back(&mut self) -> <Self as Iterator>::Item {\n\t\tlet (tail, decr) = self.tail.decr();\n\t\tself.last = unsafe {\n\t\t\tNonNull::new_unchecked(self.last.as_ptr().sub(decr as usize))\n\t\t};\n\t\tself.tail = tail;\n\n\t\tunsafe { BitMut::new_unchecked(self.last.as_ptr(), self.tail) }\n\t}\n}","impl<'a, O, T> Iterator for $t<'a, O, T>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $i;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_front())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn nth(&mut self, n: usize) -> Option<Self::Item> {\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the head cursors up by `n` bits before producing a bit.\n\t\t\t\tlet (elts, head) = self.head.offset(n as isize);\n\t\t\t\tself.base =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.base.as_ptr().offset(elts)) };\n\t\t\t\tself.head = head;\n\t\t\t\tSome(self.pop_front())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\tfn len(&self) -> usize {\n\t\t\t\tlet (base, last) =\n\t\t\t\t\t(self.base.as_ptr() as usize, self.last.as_ptr() as usize);\n\t\t\t\t/* Get the total number of bits in the element range\n\t\t\t\t`self.base .. self.last`. Wrapping arithmetic is used because\n\t\t\t\t`last` is known to never be less than base, so we always want a\n\t\t\t\tbare `sub` instruction without any checks. We also know that the\n\t\t\t\tdifference between the two addresses can support a `shl`\n\t\t\t\tinstruction without overflow.\n\t\t\t\t*/\n\t\t\t\tlast.wrapping_sub(base)\n\t\t\t\t\t.wrapping_shl(T::Mem::INDX as u32)\n\t\t\t\t\t//  Now, add the live bits before `self.tail` in `*last`,\n\t\t\t\t\t.wrapping_add(self.tail.value() as usize)\n\t\t\t\t\t//  And remove the dead bits before `self.head` in `*base`.\n\t\t\t\t\t.wrapping_sub(self.head.value() as usize)\n\t\t\t}\n\t\t}","impl<O, T> core::iter::FusedIterator for $t <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t}","unsafe impl<O, T> Send for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}","unsafe impl<O, T> Sync for $t<'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::RChunks":["Clone","Debug","impl<'a, O, T> $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self {\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::RChunksExact":["Clone","Debug","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<'a, O, T> RChunksExact<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub(super) fn new(slice: &'a BitSlice<O, T>, width: usize) -> Self {\n\t\tlet (extra, slice) =\n\t\t\tunsafe { slice.split_at_unchecked(slice.len() % width) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}\n\n\t/// Returns the remainder of the original slice that is not going to be\n\t/// returned by the iterator. The returned slice has at most `chunk_size-1`\n\t/// bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::RChunksExact::remainder`](https://doc.rust-lang.org/core/slice/struct.RChunksExact.html#method.remainder)\n\t#[inline]\n\tpub fn remainder(&self) -> &'a BitSlice<O, T> {\n\t\tself.extra\n\t}\n}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::RChunksExactMut":["Debug","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<'a, O, T> RChunksExactMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub(super) fn new(slice: &'a mut BitSlice<O, T>, width: usize) -> Self {\n\t\tlet (extra, slice) =\n\t\t\tunsafe { slice.split_at_unchecked_mut(slice.len() % width) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}\n\n\t/// Returns the remainder of the original slice that is not going to be\n\t/// returned by the iterator. The returned slice has at most `chunk_size-1`\n\t/// bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`slice::RChunksExactMut::into_remainder`](https://doc.rust-lang.org/core/slice/struct.RChunksExactMut.html#method.into_remainder)\n\t///\n\t/// # API Differences\n\t///\n\t/// The remainder slice, as with all slices yielded from this iterator, is\n\t/// marked as aliased.\n\t#[inline]\n\tpub fn into_remainder(self) -> &'a mut BitSlice<O, T::Alias> {\n\t\tself.extra\n\t}\n}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::RChunksMut":["Debug","impl<'a, O, T> $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self {\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::iter::RSplit":["Clone","impl<'a, O, T, P> $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tpub(super) fn new(slice: $item, pred: P) -> Self {\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> DoubleEndedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\t\t}","impl<'a, O, T, P> Iterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> SplitIter for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn finish(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> core::iter::FusedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t}","impl<O, T, P> Debug for $iter <'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}"],"slice::iter::RSplitMut":["impl<'a, O, T, P> $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tpub(super) fn new(slice: $item, pred: P) -> Self {\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> DoubleEndedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\t\t}","impl<'a, O, T, P> Iterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> SplitIter for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn finish(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> core::iter::FusedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t}","impl<O, T, P> Debug for $iter <'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}"],"slice::iter::RSplitN":["impl<'a, O, T, P> $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self\n\t\t\t{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}\n\t\t}","impl<'a, O, T, P> Iterator for $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t\ttype Item = <$inner <'a, O, T, P> as Iterator>::Item;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}\n\t\t}","impl<O, T, P> Debug for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}","impl<O, T, P> core::iter::FusedIterator for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t}"],"slice::iter::RSplitNMut":["impl<'a, O, T, P> $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self\n\t\t\t{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}\n\t\t}","impl<'a, O, T, P> Iterator for $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t\ttype Item = <$inner <'a, O, T, P> as Iterator>::Item;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}\n\t\t}","impl<O, T, P> Debug for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}","impl<O, T, P> core::iter::FusedIterator for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t}"],"slice::iter::Split":["Clone","impl<'a, O, T, P> $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tpub(super) fn new(slice: $item, pred: P) -> Self {\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> DoubleEndedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\t\t}","impl<'a, O, T, P> Iterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> SplitIter for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn finish(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> core::iter::FusedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t}","impl<O, T, P> Debug for $iter <'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}"],"slice::iter::SplitMut":["impl<'a, O, T, P> $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tpub(super) fn new(slice: $item, pred: P) -> Self {\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> DoubleEndedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\t\t}","impl<'a, O, T, P> Iterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> SplitIter for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\t#[inline]\n\t\t\tfn finish(&mut self) -> Option<Self::Item> {\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}\n\t\t}","impl<'a, O, T, P> core::iter::FusedIterator for $iter <'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t}","impl<O, T, P> Debug for $iter <'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}"],"slice::iter::SplitN":["impl<'a, O, T, P> $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self\n\t\t\t{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}\n\t\t}","impl<'a, O, T, P> Iterator for $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t\ttype Item = <$inner <'a, O, T, P> as Iterator>::Item;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}\n\t\t}","impl<O, T, P> Debug for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}","impl<O, T, P> core::iter::FusedIterator for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t}"],"slice::iter::SplitNMut":["impl<'a, O, T, P> $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t{\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self\n\t\t\t{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}\n\t\t}","impl<'a, O, T, P> Iterator for $outer<'a, O, T, P>\n\t\twhere\n\t\t\tO: 'a + BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t\ttype Item = <$inner <'a, O, T, P> as Iterator>::Item;\n\n\t\t\t#[inline]\n\t\t\tfn next(&mut self) -> Option<Self::Item> {\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}\n\t\t}","impl<O, T, P> Debug for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool\n\t\t{\n\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}\n\t\t}","impl<O, T, P> core::iter::FusedIterator for $outer<'_, O, T, P>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t\tP: FnMut(usize, &bool) -> bool,\n\t\t\t$( T::$alias: radium::Radium<<<T as BitStore>::Alias as BitStore>::Mem>, )?\n\t\t{\n\t\t}"],"slice::iter::Windows":["Clone","Debug","impl<'a, O, T> $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore\n\t\t{\n\t\t\t#[cfg_attr(not(tarpaulin), inline(always))]\n\t\t\tpub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self {\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}\n\t\t}","impl<'a, O, T> DoubleEndedIterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$next_back\n\n\t\t\t#[inline]\n\t\t\t$nth_back\n\t\t}","impl<'a, O, T> Iterator for $iter <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\ttype Item = $item;\n\n\t\t\t#[inline]\n\t\t\t$next\n\n\t\t\t#[inline]\n\t\t\t$nth\n\n\t\t\t#[inline]\n\t\t\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn count(self) -> usize {\n\t\t\t\tself.len()\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn last(mut self) -> Option<Self::Item> {\n\t\t\t\tself.next_back()\n\t\t\t}\n\t\t}","impl<O, T> ExactSizeIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t\t#[inline]\n\t\t\t$len\n\t\t}","impl<O, T> core::iter::FusedIterator for $iter <'_, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: BitStore,\n\t\t{\n\t\t}"],"slice::proxy::BitMut":["impl<O, T> BitMut<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Constructs a new proxy from provided element and bit addresses.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `addr`: The address of a memory element, correctly typed for access.\n\t/// - `head`: The index of a bit within `*addr`.\n\t///\n\t/// # Safety\n\t///\n\t/// The caller must produce `addr`’s value from a valid reference, and its\n\t/// type from the correct access requirements at time of construction.\n\t#[inline]\n\tpub(crate) unsafe fn new_unchecked(\n\t\taddr: *const T::Access,\n\t\thead: BitIdx<T::Mem>,\n\t) -> Self\n\t{\n\t\tSelf {\n\t\t\t_ref: PhantomData,\n\t\t\taddr: NonNull::new_unchecked(addr as *mut T::Access),\n\t\t\thead,\n\t\t\tdata: (&*addr).get_bit::<O>(head),\n\t\t}\n\t}\n\n\t/// Writes a bit into the proxied location without an intermediate copy.\n\t///\n\t/// This function writes `value` directly into the proxied location, and\n\t/// does not store `value` in the proxy’s internal cache. This should be\n\t/// equivalent to the behavior seen when using ordinary `DerefMut` proxying,\n\t/// but the latter depends on compiler optimization.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`: This destroys the proxy, as it becomes invalid when writing\n\t///   directly to the location without updating the cache.\n\t/// - `value`: The new bit to write into the proxied slot.\n\t#[inline]\n\tpub fn set(mut self, value: bool) {\n\t\tself.write(value);\n\t\tmem::forget(self);\n\t}\n\n\t/// Commits a bit into memory.\n\t///\n\t/// This is the internal function used to drive `.set()` and `.drop()`.\n\t#[inline]\n\tfn write(&mut self, value: bool) {\n\t\tunsafe { (&*self.addr.as_ptr()).write_bit::<O>(self.head, value) }\n\t}\n}","impl<O, T> Debug for BitMut<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\twrite!(fmt, \"BitMut<{}>\", core::any::type_name::<T::Mem>())?;\n\t\tfmt.debug_struct(\"\")\n\t\t\t.field(\"addr\", &self.addr.as_ptr().fmt_pointer())\n\t\t\t.field(\"head\", &self.head.fmt_binary())\n\t\t\t.field(\"data\", &self.data)\n\t\t\t.finish()\n\t}\n}","impl<O, T> Deref for BitMut<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Target = bool;\n\n\t#[inline]\n\tfn deref(&self) -> &Self::Target {\n\t\t&self.data\n\t}\n}","impl<O, T> DerefMut for BitMut<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn deref_mut(&mut self) -> &mut Self::Target {\n\t\t&mut self.data\n\t}\n}","impl<O, T> Drop for BitMut<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn drop(&mut self) {\n\t\tlet value = self.data;\n\t\tself.write(value);\n\t}\n}"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq":["impl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq":["impl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq":["impl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq":["impl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}"],"std::cell::Cell":["impl<M> BitStore for Cell<M>\nwhere\n\tSelf: Radium<M>,\n\tM: BitMemory + BitStore,\n{\n\ttype Access = Self;\n\ttype Alias = Self;\n\ttype Mem = M;\n\t/// Raw pointers are never threadsafe, so this prevents handles using\n\t/// `Cell<_>` type parameters from crossing thread boundaries.\n\t#[doc(hidden)]\n\ttype Threadsafe = *const Self;\n\n\t//  If these are true for `M: BitStore`, then they are true for `Cell<M>`.\n\n\t#[doc(hidden)]\n\tconst __ALIAS_WIDTH: [(); 0] = [];\n\t#[doc(hidden)]\n\tconst __ALIGNED_TO_SIZE: [(); 0] = [];\n}","impl<M> seal::Sealed for Cell<M> where M: BitMemory + BitStore\n{\n}"],"std::ops::Range":["impl<'a, O, T> BitSliceIndex<'a, O, T> for $r\n\t\twhere O: 'a + BitOrder, T: 'a + BitStore {\n\t\t\ttype Immut = &'a BitSlice<O, T>;\n\t\t\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t\t\t#[inline]\n\t\t\t$get\n\n\t\t\t#[inline]\n\t\t\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\t$unchecked\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\n\t\t\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\t\t}"],"std::ops::RangeFrom":["impl<'a, O, T> BitSliceIndex<'a, O, T> for $r\n\t\twhere O: 'a + BitOrder, T: 'a + BitStore {\n\t\t\ttype Immut = &'a BitSlice<O, T>;\n\t\t\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t\t\t#[inline]\n\t\t\t$get\n\n\t\t\t#[inline]\n\t\t\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\t$unchecked\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\n\t\t\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\t\t}"],"std::ops::RangeFull":["impl<'a, O, T> BitSliceIndex<'a, O, T> for RangeFull\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\ttype Immut = &'a BitSlice<O, T>;\n\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t#[inline]\n\tfn get(self, slice: Self::Immut) -> Option<Self::Immut> {\n\t\tSome(slice)\n\t}\n\n\t#[inline]\n\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\tSome(slice)\n\t}\n\n\t#[inline]\n\tunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut {\n\t\tslice\n\t}\n\n\t#[inline]\n\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\tslice\n\t}\n\n\t#[inline]\n\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\tslice\n\t}\n\n\t#[inline]\n\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\tslice\n\t}\n}"],"std::ops::RangeInclusive":["impl<'a, O, T> BitSliceIndex<'a, O, T> for $r\n\t\twhere O: 'a + BitOrder, T: 'a + BitStore {\n\t\t\ttype Immut = &'a BitSlice<O, T>;\n\t\t\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t\t\t#[inline]\n\t\t\tfn get(self, slice: Self::Immut) -> Option<Self::Immut> {\n\t\t\t\t$func(self).get(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\t\t\t$func(self).get_mut(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\t$func(self).get_unchecked(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\t$func(self).get_unchecked_mut(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\t$func(self).index(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\t$func(self).index_mut(slice)\n\t\t\t}\n\t\t}"],"std::ops::RangeTo":["impl<'a, O, T> BitSliceIndex<'a, O, T> for $r\n\t\twhere O: 'a + BitOrder, T: 'a + BitStore {\n\t\t\ttype Immut = &'a BitSlice<O, T>;\n\t\t\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t\t\t#[inline]\n\t\t\t$get\n\n\t\t\t#[inline]\n\t\t\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\t$unchecked\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\n\t\t\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}\n\t\t}"],"std::ops::RangeToInclusive":["impl<'a, O, T> BitSliceIndex<'a, O, T> for $r\n\t\twhere O: 'a + BitOrder, T: 'a + BitStore {\n\t\t\ttype Immut = &'a BitSlice<O, T>;\n\t\t\ttype Mut = &'a mut BitSlice<O, T>;\n\n\t\t\t#[inline]\n\t\t\tfn get(self, slice: Self::Immut) -> Option<Self::Immut> {\n\t\t\t\t$func(self).get(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut> {\n\t\t\t\t$func(self).get_mut(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\t$func(self).get_unchecked(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\t$func(self).get_unchecked_mut(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index(self, slice: Self::Immut) -> Self::Immut {\n\t\t\t\t$func(self).index(slice)\n\t\t\t}\n\n\t\t\t#[inline]\n\t\t\tfn index_mut(self, slice: Self::Mut) -> Self::Mut {\n\t\t\t\t$func(self).index_mut(slice)\n\t\t\t}\n\t\t}"],"std::sync::atomic::AtomicU16":["impl BitStore for $a {\n\t\t\ttype Access = Self;\n\n\t\t\ttype Alias = Self;\n\n\t\t\ttype Mem = $t;\n\n\t\t\t#[doc(hidden)]\n\t\t\ttype Threadsafe = Self;\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIGNED_TO_SIZE: [(); 0] = [(); mem::aligned_to_size::<Self>()];\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIAS_WIDTH: [(); 0] = [(); mem::cmp_layout::<Self::Mem, Self::Alias>()];\n\t\t}","impl seal::Sealed for $a {}"],"std::sync::atomic::AtomicU32":["impl BitStore for $a {\n\t\t\ttype Access = Self;\n\n\t\t\ttype Alias = Self;\n\n\t\t\ttype Mem = $t;\n\n\t\t\t#[doc(hidden)]\n\t\t\ttype Threadsafe = Self;\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIGNED_TO_SIZE: [(); 0] = [(); mem::aligned_to_size::<Self>()];\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIAS_WIDTH: [(); 0] = [(); mem::cmp_layout::<Self::Mem, Self::Alias>()];\n\t\t}","impl seal::Sealed for $a {}"],"std::sync::atomic::AtomicU64":["impl BitStore for $a {\n\t\t\ttype Access = Self;\n\n\t\t\ttype Alias = Self;\n\n\t\t\ttype Mem = $t;\n\n\t\t\t#[doc(hidden)]\n\t\t\ttype Threadsafe = Self;\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIGNED_TO_SIZE: [(); 0] = [(); mem::aligned_to_size::<Self>()];\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIAS_WIDTH: [(); 0] = [(); mem::cmp_layout::<Self::Mem, Self::Alias>()];\n\t\t}","impl seal::Sealed for $a {}"],"std::sync::atomic::AtomicU8":["impl BitStore for $a {\n\t\t\ttype Access = Self;\n\n\t\t\ttype Alias = Self;\n\n\t\t\ttype Mem = $t;\n\n\t\t\t#[doc(hidden)]\n\t\t\ttype Threadsafe = Self;\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIGNED_TO_SIZE: [(); 0] = [(); mem::aligned_to_size::<Self>()];\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIAS_WIDTH: [(); 0] = [(); mem::cmp_layout::<Self::Mem, Self::Alias>()];\n\t\t}","impl seal::Sealed for $a {}"],"std::sync::atomic::AtomicUsize":["impl BitStore for $a {\n\t\t\ttype Access = Self;\n\n\t\t\ttype Alias = Self;\n\n\t\t\ttype Mem = $t;\n\n\t\t\t#[doc(hidden)]\n\t\t\ttype Threadsafe = Self;\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIGNED_TO_SIZE: [(); 0] = [(); mem::aligned_to_size::<Self>()];\n\n\t\t\t#[doc(hidden)]\n\t\t\tconst __ALIAS_WIDTH: [(); 0] = [(); mem::cmp_layout::<Self::Mem, Self::Alias>()];\n\t\t}","impl seal::Sealed for $a {}"],"vec::BitVec":["impl<'a, O, T> Extend<&'a bool> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn extend<I>(&mut self, iter: I)\n\twhere I: IntoIterator<Item = &'a bool> {\n\t\tself.extend(iter.into_iter().copied());\n\t}\n}","impl<'a, O, T> From<&'a BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn from(slice: &'a BitSlice<O, T>) -> Self {\n\t\tslice.to_bitvec()\n\t}\n}","impl<'a, O, T> From<&'a mut BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn from(slice: &'a mut BitSlice<O, T>) -> Self {\n\t\tslice.to_bitvec()\n\t}\n}","impl<'a, O, T> FromIterator<&'a bool> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn from_iter<I>(iter: I) -> Self\n\twhere I: IntoIterator<Item = &'a bool> {\n\t\titer.into_iter().copied().pipe(Self::from_iter)\n\t}\n}","impl<O, T, Idx> Index<Idx> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: Index<Idx>,\n{\n\ttype Output = <BitSlice<O, T> as Index<Idx>>::Output;\n\n\t#[inline]\n\tfn index(&self, index: Idx) -> &Self::Output {\n\t\tself.as_bitslice().index(index)\n\t}\n}","impl<O, T, Idx> IndexMut<Idx> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: IndexMut<Idx>,\n{\n\t#[inline]\n\tfn index_mut(&mut self, index: Idx) -> &mut Self::Output {\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}\n}","impl<O, T, Rhs> BitAnd<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitAndAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitand(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitAndAssign<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitAndAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitand_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}\n}","impl<O, T, Rhs> BitOr<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitOrAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitOrAssign<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitOrAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}\n}","impl<O, T, Rhs> BitXor<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitXorAssign<Rhs>,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn bitxor(mut self, rhs: Rhs) -> Self::Output {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}\n}","impl<O, T, Rhs> BitXorAssign<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitXorAssign<Rhs>,\n{\n\t#[inline]\n\tfn bitxor_assign(&mut self, rhs: Rhs) {\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}\n}","impl<O, T, Rhs> PartialEq<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: ?Sized + PartialEq<BitSlice<O, T>>,\n{\n\t#[inline]\n\tfn eq(&self, other: &Rhs) -> bool {\n\t\tother == self.as_bitslice()\n\t}\n}","impl<O, T, Rhs> PartialOrd<Rhs> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tRhs: ?Sized + PartialOrd<BitSlice<O, T>>,\n{\n\t#[inline]\n\tfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering> {\n\t\tother.partial_cmp(self.as_bitslice())\n\t}\n}","impl<O, T> AsMut<BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn as_mut(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> AsRef<BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn as_ref(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> Binary for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> BitField for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T>: BitField,\n{\n\t#[inline]\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_le()\n\t}\n\n\t#[inline]\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory {\n\t\tself.as_bitslice().load_be()\n\t}\n\n\t#[inline]\n\tfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_le(value)\n\t}\n\n\t#[inline]\n\tfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\tself.as_mut_bitslice().store_be(value)\n\t}\n}","impl<O, T> BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Constructs a `BitVec` from a value repeated many times.\n\t///\n\t/// This function is equivalent to the `bitvec![O, T; bit; len]` macro call,\n\t/// and is in fact the implementation of that macro syntax.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `bit`: The bit value to which all `len` allocated bits will be set.\n\t/// - `len`: The number of live bits in the constructed `BitVec`.\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitVec` with `len` live bits, all set to `bit`.\n\t#[inline]\n\tpub fn repeat(bit: bool, len: usize) -> Self {\n\t\tlet mut out = Self::with_capacity(len);\n\t\tunsafe {\n\t\t\tout.set_len(len);\n\t\t}\n\t\tout.set_elements(if bit { T::Mem::ALL } else { T::Mem::ZERO });\n\t\tout\n\t}\n\n\t/// Clones a `&BitSlice` into a `BitVec`.\n\t///\n\t/// # Original\n\t///\n\t/// [`<Vec<T: Clone> as Clone>::clone`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#impl-Clone)\n\t///\n\t/// # Effects\n\t///\n\t/// This performs a direct element-wise copy from the source slice to the\n\t/// newly-allocated buffer, then sets the vector to have the same starting\n\t/// bit as the slice did. This allows for faster behavior. If you require\n\t/// that the vector start at the leading edge of the first element, use\n\t/// [`force_align`] to guarantee this.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bits = bits![0, 1, 0, 1, 1, 0, 1, 1];\n\t/// let bv = BitVec::from_bitslice(&bits[2 ..]);\n\t/// assert_eq!(bv, bits[2 ..]);\n\t/// ```\n\t///\n\t/// [`force_align`]: #method.force_align\n\t#[inline]\n\tpub fn from_bitslice(slice: &BitSlice<O, T>) -> Self {\n\t\tlet mut bitptr = slice.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_access(), bitptr.elements());\n\t\tlet source = unsafe { slice::from_raw_parts(base, elts) };\n\n\t\tlet mut vec = elts.pipe(Vec::with_capacity).pipe(ManuallyDrop::new);\n\n\t\tvec.extend(source.iter().map(BitAccess::load_value));\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(vec.as_ptr() as *const T);\n\t\t}\n\n\t\tlet capacity = vec.capacity();\n\t\tSelf {\n\t\t\tpointer: bitptr.to_nonnull(),\n\t\t\tcapacity,\n\t\t}\n\t}\n\n\t/// Converts a `Vec<T>` into a `BitVec<O, T>` without copying its buffer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `vec`: A vector to view as bits.\n\t///\n\t/// # Returns\n\t///\n\t/// A `BitVec` over the `vec` buffer.\n\t///\n\t/// # Panics\n\t///\n\t/// This panics if `vec` is too long to convert into a `BitVec`. See\n\t/// [`BitSlice::MAX_ELTS`].\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let vec = vec![0u8; 4];\n\t/// let bv = BitVec::<Local, _>::from_vec(vec);\n\t/// assert_eq!(bv, bits![0; 32]);\n\t/// ```\n\t///\n\t/// [`BitSlice::MAX_ELTS`]:\n\t/// ../slice/struct.BitSlice.html#associatedconstant.MAX_ELTS\n\t#[inline]\n\tpub fn from_vec(vec: Vec<T>) -> Self {\n\t\tSelf::try_from_vec(vec)\n\t\t\t.expect(\"Vector was too long to be converted into a `BitVec`\")\n\t}\n\n\t/// Converts a `Vec<T>` into a `BitVec<O, T>` without copying its buffer.\n\t///\n\t/// This method takes ownership of a memory buffer and enables it to be used\n\t/// as a bit-vector. Because `Vec` can be longer than `BitVec`s, this is a\n\t/// fallible method, and the original vector will be returned if it cannot\n\t/// be converted.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `vec`: Some vector of memory, to be viewed as bits.\n\t///\n\t/// # Returns\n\t///\n\t/// If `vec` is short enough to be viewed as a `BitVec`, then this returns\n\t/// a `BitVec` over the `vec` buffer. If `vec` is too long, then this\n\t/// returns `vec` unmodified.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let vec = vec![0u8; 4];\n\t/// let bv = BitVec::<Local, _>::try_from_vec(vec).unwrap();\n\t/// assert_eq!(bv, bits![0; 32]);\n\t/// ```\n\t///\n\t/// An example showing this function failing would require an allocation\n\t/// exceeding `!0usize >> 3` bytes in size, which is infeasible to produce.\n\t#[inline]\n\tpub fn try_from_vec(vec: Vec<T>) -> Result<Self, Vec<T>> {\n\t\tlet len = vec.len();\n\t\tif len > BitSlice::<O, T>::MAX_ELTS {\n\t\t\treturn Err(vec);\n\t\t}\n\n\t\tlet vec = ManuallyDrop::new(vec);\n\t\tlet (base, capacity) = (vec.as_ptr(), vec.capacity());\n\t\tOk(Self {\n\t\t\tpointer: unsafe {\n\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\tbase,\n\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\tlen * T::Mem::BITS as usize,\n\t\t\t\t)\n\t\t\t}\n\t\t\t.to_nonnull(),\n\t\t\tcapacity,\n\t\t})\n\t}\n\n\t/// Copies all bits in a `BitSlice` into the `BitVec`.\n\t///\n\t/// This is provided for API completeness; it has no performance benefits\n\t/// compared to use of the [`Extend`] implementation.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `other`: A `BitSlice` reference of the same type parameters as `self`.\n\t///\n\t/// # Behavior\n\t///\n\t/// `self` is extended by the length of `other`, and then the contents of\n\t/// `other` are copied into the newly-allocated end of `self`.\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1];\n\t/// bv.extend_from_bitslice(bits![1, 1, 0, 1]);\n\t///\n\t/// assert_eq!(bv, bits![0, 1, 1, 1, 0, 1]);\n\t/// ```\n\t///\n\t/// [`Extend`]: #impl-Extend<%26'a bool>\n\t/// [`.as_bitslice()`]: #method.as_bitslice()\n\t#[inline]\n\tpub fn extend_from_bitslice(&mut self, other: &BitSlice<O, T>) {\n\t\tlet len = self.len();\n\t\tlet olen = other.len();\n\t\tself.resize(len + olen, false);\n\t\tunsafe { self.get_unchecked_mut(len ..) }.clone_from_bitslice(other);\n\t}\n\n\t/// Converts the vector into [`BitBox<O, T>`].\n\t///\n\t/// Note that this will drop any excess capacity.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::into_boxed_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.into_boxed_slice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1; 50];\n\t/// let bb: BitBox = bv.into_boxed_bitslice();\n\t/// assert_eq!(bb, bits![1; 50]);\n\t/// ```\n\t///\n\t/// [`BitBox<O, T>`]: ../boxed/struct.BitBox.html\n\t#[inline]\n\tpub fn into_boxed_bitslice(self) -> BitBox<O, T> {\n\t\tlet mut bitptr = self.bitptr();\n\t\tlet boxed = self.into_boxed_slice().pipe(ManuallyDrop::new);\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(boxed.as_ptr());\n\t\t}\n\t\tunsafe { BitBox::from_raw(bitptr.to_bitslice_ptr_mut::<O>()) }\n\t}\n\n\t/// Converts the vector back into an ordinary vector of memory elements.\n\t///\n\t/// This does not affect the vector’s buffer, only the handle used to\n\t/// control it.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `self`\n\t///\n\t/// # Returns\n\t///\n\t/// An ordinary vector containing all of the bit-vector’s memory buffer.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0; 5];\n\t/// let vec = bv.into_vec();\n\t/// assert_eq!(vec, [0]);\n\t/// ```\n\t#[inline]\n\tpub fn into_vec(self) -> Vec<T> {\n\t\tlet mut this = ManuallyDrop::new(self);\n\t\tlet buf = this.as_mut_slice();\n\t\tunsafe {\n\t\t\tVec::from_raw_parts(\n\t\t\t\tbuf.as_mut_ptr() as *mut T,\n\t\t\t\tbuf.len(),\n\t\t\t\tthis.capacity,\n\t\t\t)\n\t\t}\n\t}\n\n\t/// Gets the number of elements `T` that contain live bits of the vector.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![Local, u16; 1; 50];\n\t/// assert_eq!(bv.elements(), 4);\n\t/// ```\n\t#[inline]\n\tpub fn elements(&self) -> usize {\n\t\tself.bitptr().elements()\n\t}\n\n\t/// Ensures that the live region of the vector’s contents begins at the\n\t/// leading edge of the buffer.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let data = 0x3Cu8;\n\t/// let bits = data.view_bits::<Msb0>();\n\t///\n\t/// let mut bv = bits[2 .. 6].to_bitvec();\n\t/// assert_eq!(bv, bits[2 .. 6]);\n\t/// assert_eq!(bv.as_slice()[0], data);\n\t///\n\t/// bv.force_align();\n\t/// assert_eq!(bv, bits[2 .. 6]);\n\t/// //  It is not specified what happens to bits that are no longer used.\n\t/// assert_eq!(bv.as_slice()[0] & 0xF0, 0xF0);\n\t/// ```\n\t#[inline]\n\tpub fn force_align(&mut self) {\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head().value() as usize;\n\t\tif head == 0 {\n\t\t\treturn;\n\t\t}\n\t\tlet last = bitptr.len() + head;\n\t\tunsafe {\n\t\t\tself.pointer =\n\t\t\t\tbitptr.tap_mut(|bp| bp.set_head(BitIdx::ZERO)).to_nonnull();\n\t\t\tself.copy_within_unchecked(head .. last, 0);\n\t\t}\n\t}\n\n\t/// Writes a value into every element that the vector considers live.\n\t///\n\t/// This unconditionally writes `element` into each live location in the\n\t/// backing buffer, without altering the `BitVec`’s length or capacity.\n\t///\n\t/// It is unspecified what effects this has on the allocated but dead\n\t/// elements in the buffer.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `element`: The value which will be written to each live location in\n\t///   the vector’s buffer.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![Local, u8; 0; 10];\n\t/// assert_eq!(bv.as_slice(), [0, 0]);\n\t/// bv.set_elements(0xA5);\n\t/// assert_eq!(bv.as_slice(), [0xA5, 0xA5]);\n\t/// ```\n\t#[inline]\n\tpub fn set_elements(&mut self, element: T::Mem) {\n\t\tself.as_mut_slice()\n\t\t\t.iter_mut()\n\t\t\t.for_each(|elt| *elt = element.into());\n\t}\n\n\t/// Views the buffer’s contents as a `BitSlice`.\n\t///\n\t/// This is equivalent to `&bv[..]`.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_slice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0, 1, 1, 0];\n\t/// let bits = bv.as_bitslice();\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitslice(&self) -> &BitSlice<O, T> {\n\t\tunsafe { &*self.pointer.as_ptr() }\n\t}\n\n\t/// Extracts a mutable bit-slice of the entire vector.\n\t///\n\t/// Equivalent to `&mut bv[..]`.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_slice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 0, 1];\n\t/// let bits = bv.as_mut_bitslice();\n\t/// bits.set(0, true);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T> {\n\t\tunsafe { &mut *self.pointer.as_ptr() }\n\t}\n\n\t/// Returns a raw pointer to the vector’s region.\n\t///\n\t/// The caller must ensure that the vector outlives the pointer this\n\t/// function returns, or else it will end up pointing to garbage. Modifying\n\t/// the vector may cause its buffer to be reallocated, which would also make\n\t/// any pointers to it invalid.\n\t///\n\t/// The caller must also ensure that the memory the pointer\n\t/// (non-transitively) points to is never written to (except inside an\n\t/// `UnsafeCell`) using this pointer or any pointer derived from it. If you\n\t/// need to mutate the contents of the region, use [`as_mut_bitptr`].\n\t///\n\t/// This pointer is an opaque crate-internal type. Its in-memory\n\t/// representation is unsafe to modify in any way. The only safe action to\n\t/// take with this pointer is to pass it, unchanged, back into a `bitvec`\n\t/// API.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0; 20];\n\t/// let ptr = bv.as_bitptr();\n\t///\n\t/// let bits = unsafe { &*ptr };\n\t/// assert_eq!(bv, bits);\n\t/// ```\n\t///\n\t/// [`as_mut_bitptr`]: #method.as_mut_bitptr\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitptr(&self) -> *const BitSlice<O, T> {\n\t\tself.pointer.as_ptr() as *const BitSlice<O, T>\n\t}\n\n\t/// Returns an unsafe mutable pointer to the vector’s region.\n\t///\n\t/// The caller must ensure that the vector outlives the pointer this\n\t/// function returns, or else it will end up pointing to garbage. Modifying\n\t/// the vector may cause its buffer to be reallocated, which would also make\n\t/// any pointers to it invalid.\n\t///\n\t/// This pointer is an opaque crate-internal type. Its in-memory\n\t/// representation is unsafe to modify in any way. The only safe action to\n\t/// take with this pointer is to pass it, unchanged, back into a `bitvec`\n\t/// API.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0; 20];\n\t/// let ptr = bv.as_mut_bitptr();\n\t///\n\t/// let bits = unsafe { &mut *ptr };\n\t/// assert_eq!(bv, bits);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_bitptr(&mut self) -> *mut BitSlice<O, T> {\n\t\tself.pointer.as_ptr()\n\t}\n\n\t#[inline]\n\tpub(crate) fn bitptr(&self) -> BitPtr<T> {\n\t\tself.pointer.as_ptr().pipe(BitPtr::from_bitslice_ptr_mut)\n\t}\n\n\t/// Permits a function to modify the `Vec<T>` backing storage of a\n\t/// `BitVec<_, T>`.\n\t///\n\t/// This produces a temporary `Vec<T::Mem>` structure governing the\n\t/// `BitVec`’s buffer and allows a function to view it mutably. After the\n\t/// callback returns, the `Vec` is written back into `self` and forgotten.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `F`: A function which operates on a mutable borrow of a `Vec<T::Mem>`\n\t///   buffer controller.\n\t/// - `R`: The return type of the `F` function.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `func`: A function which receives a mutable borrow of a `Vec<T::Mem>`\n\t///   controlling `self`’s buffer.\n\t///\n\t/// # Returns\n\t///\n\t/// The return value of `func`. `func` is forbidden from borrowing any part\n\t/// of the `Vec<T::Mem>` temporary view.\n\tfn with_vec<F, R>(&mut self, func: F) -> R\n\twhere F: FnOnce(&mut ManuallyDrop<Vec<T::Mem>>) -> R {\n\t\tlet cap = self.capacity;\n\t\tlet mut bitptr = self.bitptr();\n\t\tlet (base, elts) =\n\t\t\t(bitptr.pointer().to_mut() as *mut T::Mem, bitptr.elements());\n\n\t\tlet mut vec = unsafe { Vec::from_raw_parts(base, elts, cap) }\n\t\t\t.pipe(ManuallyDrop::new);\n\t\tlet out = func(&mut vec);\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(vec.as_ptr() as *mut T);\n\t\t}\n\t\tself.pointer = bitptr.to_nonnull();\n\t\tself.capacity = vec.capacity();\n\t\tout\n\t}\n}","impl<O, T> BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Constructs a new, empty `BitVec<O, T>`.\n\t///\n\t/// The vector will not allocate until bits are pushed into it.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::new`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.new)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = BitVec::<Local, usize>::new();\n\t/// ```\n\t#[inline]\n\tpub fn new() -> Self {\n\t\tSelf {\n\t\t\tpointer: BitPtr::<T>::EMPTY.to_nonnull(),\n\t\t\tcapacity: 0,\n\t\t}\n\t}\n\n\t/// Constructs a new, empty `BitVec<O, T>` with the specified capacity.\n\t///\n\t/// The vector will be able to hold at least `capacity` bits without\n\t/// reällocating. If `capacity` is 0, the vector will not allocate.\n\t///\n\t/// It is important to note that although the returned vector has the\n\t/// *capacity* specified, the vector will have a zero *length*. For an\n\t/// explanation of the difference between length and capacity, see\n\t/// *[Capacity and reällocation]*.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::with_capacity`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.with_capacity)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the requested capacity exceeds the vector’s limits.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = BitVec::<Local, usize>::with_capacity(10);\n\t///\n\t/// // The vector contains no items, even though it has capacity for more\n\t/// assert_eq!(bv.len(), 0);\n\t///\n\t/// // These are all done without reallocating...\n\t/// for i in 0..10 {\n\t///   bv.push(true);\n\t/// }\n\t///\n\t/// // ...but this may make the vector reallocate\n\t/// bv.push(false);\n\t/// ```\n\t///\n\t/// [Capacity and reällocation]: #capacity-and-reallocation\n\t#[inline]\n\tpub fn with_capacity(capacity: usize) -> Self {\n\t\tassert!(\n\t\t\tcapacity <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tcapacity,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet vec = capacity\n\t\t\t.pipe(crate::mem::elts::<T>)\n\t\t\t.pipe(Vec::<T>::with_capacity);\n\t\tlet (ptr, capacity) = (vec.as_ptr(), vec.capacity());\n\t\tmem::forget(vec);\n\t\tptr.pipe(BitPtr::uninhabited)\n\t\t\t.pipe(BitPtr::to_nonnull)\n\t\t\t.pipe(|pointer| Self { pointer, capacity })\n\t}\n\n\t/// Creates a `BitVec<O, T>` directly from the raw components of another\n\t/// bit-vector.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::from_raw_parts`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.from_raw_parts)\n\t///\n\t/// # API Differences\n\t///\n\t/// Ordinary vectors decompose into their buffer pointer and element length\n\t/// separately; bit vectors must keep these two components bundled into the\n\t/// `*BitSlice` region pointer. As such, this only accepts two components;\n\t/// the slice pointer and the buffer capacity.\n\t///\n\t/// `Vec` could define its raw parts as `*[T]` and `usize` also, but Rust\n\t/// does not make working with raw slice pointers easy.\n\t///\n\t/// # Panics\n\t///\n\t/// This function panics if `pointer` is the null pointer.\n\t///\n\t/// # Safety\n\t///\n\t/// This is highly unsafe, due to the number of invariants that aren’t\n\t/// checked:\n\t///\n\t/// - `pointer` needs to have been previously allocated via `BitVec<O, T>`\n\t///   (at least, it’s highly likely to be incorrect if it wasn’t).\n\t/// - `T` needs to have the same size and alignment as what `pointer` was\n\t///   allocated with. (`T` having a less strict alignment is not sufficient;\n\t///   the alignment really needs to be equal to satisfy the [`dealloc`]\n\t///   requirement that memory must be allocated and deällocated with the\n\t///   same layout.)\n\t/// - `capacity` needs to be the capacity that the pointer was allocated\n\t///   with.\n\t///\n\t/// In addition to the invariants inherited from `Vec::from_raw_parts`, the\n\t/// fact that this function takes a bit-slice pointer adds another one:\n\t///\n\t/// - **`pointer` MUST NOT have had its value modified in any way in the**\n\t/// **time when it was outside of a `bitvec` container type.**\n\t///\n\t/// Violating these *will* cause problems like corrupting the allocator’s\n\t/// internal data structures. For example it is **not** safe to build a\n\t/// `BitVec<_, u8>` from a pointer to a C `char` array with length `size_t`.\n\t/// It’s also not safe to build one from a `BitVec<_, u16>` and its length,\n\t/// becauset the allocator cares about the alignment, and these two types\n\t/// have different alignments. The buffer was allocated with alignment 2\n\t/// (for `u16`), but after turning it into a `BitVec<_, u8>`, it’ll be\n\t/// deällocated with alignment 1.\n\t///\n\t/// The ownership of `pointer` is effectively transferred to the `BitVec<O,\n\t/// T>` which may then deällocate, reällocate, or change the contents of\n\t/// memory pointed to by the pointer at will. Ensure that nothing else uses\n\t/// the pointer after calling this function.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # extern crate core;\n\t/// use bitvec::prelude::*;\n\t/// use bitvec as bv;\n\t/// use core::mem;\n\t///\n\t/// let bv = bitvec![0, 1, 0, 1];\n\t///\n\t/// // Prevent running `bv`’s destructor so we are in complete control\n\t/// // of the allocation.\n\t/// let mut bv = mem::ManuallyDrop::new(bv);\n\t///\n\t/// // Pull out the various important pieces of information about `bv`\n\t/// let p = bv.as_mut_ptr();\n\t/// let e = bv.elements();\n\t/// let cap = bv.capacity();\n\t///\n\t/// unsafe {\n\t///   let bits = bv::slice::from_raw_parts_mut::<Local, _>(p, e);\n\t///   let len = bits.len();\n\t///\n\t///   // Overwrite memory with a new pattern\n\t///   bits.iter_mut().for_each(|mut b| *b = true);\n\t///\n\t///   // Put everything back together into a BitVec\n\t///   let rebuilt = BitVec::from_raw_parts(bits as *mut _, cap);\n\t///   assert_eq!(rebuilt.len(), len);\n\t/// }\n\t/// ```\n\t#[inline]\n\tpub unsafe fn from_raw_parts(\n\t\tpointer: *mut BitSlice<O, T>,\n\t\tcapacity: usize,\n\t) -> Self\n\t{\n\t\tif (pointer as *mut [()]).is_null() {\n\t\t\tpanic!(\"Attempted to reconstruct a `BitVec` from a null pointer\");\n\t\t}\n\t\tpointer\n\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.to_nonnull()\n\t\t\t.pipe(|pointer| Self { pointer, capacity })\n\t}\n\n\t/// Returns the number of bits the vector can hold without reällocating.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::capacity`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.capacity)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv: BitVec<Local, usize> = BitVec::with_capacity(100);\n\t/// assert!(bv.capacity() >= 100);\n\t/// ```\n\t#[inline]\n\tpub fn capacity(&self) -> usize {\n\t\tself.capacity\n\t\t\t.checked_mul(T::Mem::BITS as usize)\n\t\t\t.expect(\"Vector capacity exceeded\")\n\t\t\t//  Don’t forget to subtract any dead bits in the front of the base!\n\t\t\t//  This has to be saturating, becase a non-zero head on a zero\n\t\t\t//  capacity underflows.\n\t\t\t.saturating_sub(self.bitptr().head().value() as usize)\n\t}\n\n\t/// Reserves capacity for at least `additional` more bits to be inserted in\n\t/// the given `BitVec<O, T>`. The collection may reserve more space to avoid\n\t/// frequent reällocations. After calling `reserve`, capacity will be\n\t/// greater than or equal to `self.len() + additional`. Does nothing if\n\t/// capacity is already sufficient.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::reserve`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.reserve)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the new capacity exceeds the vector’s limits.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1];\n\t/// bv.reserve(100);\n\t/// assert!(bv.capacity() >= 101);\n\t/// ```\n\t#[inline]\n\tpub fn reserve(&mut self, additional: usize) {\n\t\tlet new_len = self\n\t\t\t.len()\n\t\t\t.checked_add(additional)\n\t\t\t.expect(\"Vector capacity exceeded\");\n\t\tassert!(\n\t\t\tnew_len <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tnew_len,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head();\n\t\tlet elts = bitptr.elements();\n\t\t//  Only reserve if the request needs new elements.\n\t\tif let Some(extra) = head.span(new_len).0.checked_sub(elts) {\n\t\t\tself.with_vec(|v| v.reserve(extra));\n\t\t}\n\t}\n\n\t/// Reserves the minimum capacity for exactly `additional` more bits to be\n\t/// inserted in the given `BitVec<O, T>`. After calling `reserve_exact`,\n\t/// capacity will be greater than or equal to `self.len() + additional`.\n\t/// Does nothing if the capacity is already sufficient.\n\t///\n\t/// Note that the allocator may give the collection more space than it\n\t/// requests. Therefore, capacity can not be relied upon to be precisely\n\t/// minimal. Prefer `reserve` if future insertions are expected.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::reserve_exact`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.reserve_exact)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the new capacity exceeds the vector’s limits.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1];\n\t/// bv.reserve_exact(100);\n\t/// assert!(bv.capacity() >= 101);\n\t/// ```\n\t#[inline]\n\tpub fn reserve_exact(&mut self, additional: usize) {\n\t\tlet new_len = self\n\t\t\t.len()\n\t\t\t.checked_add(additional)\n\t\t\t.expect(\"Vector capacity exceeded\");\n\t\tassert!(\n\t\t\tnew_len <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tnew_len,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head();\n\t\tlet elts = bitptr.elements();\n\t\t//  Only reserve if the request needs new elements.\n\t\tif let Some(extra) = head.span(new_len).0.checked_sub(elts) {\n\t\t\tself.with_vec(|v| v.reserve_exact(extra));\n\t\t}\n\t}\n\n\t/// Shrinks the capacity of the vector as much as possible.\n\t///\n\t/// It will drop down as close as possible to the length but the allocator\n\t/// may still inform the vector that there is space for a few more bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::shrink_to_fit`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.shrink_to_fit)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = BitVec::<Local, usize>::with_capacity(100);\n\t/// bv.extend([false, true, false].iter().copied());\n\t/// assert!(bv.capacity() >= 100);\n\t/// bv.shrink_to_fit();\n\t/// assert!(bv.capacity() >= 3);\n\t/// ```\n\t#[inline]\n\tpub fn shrink_to_fit(&mut self) {\n\t\tself.with_vec(|v| v.shrink_to_fit());\n\t}\n\n\t/// Converts the vector into [`Box<[T]>`].\n\t///\n\t/// Note that this will drop any excess capacity.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::into_boxed_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.into_boxed_slice)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`into_boxed_bitslice`] for a `BitVec -> BitBox` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0, 1, 0];\n\t///\n\t/// let slice = bv.into_boxed_slice();\n\t/// assert_eq!(slice.len(), 1);\n\t/// ```\n\t///\n\t/// Any excess capacity is removed:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv: BitVec = BitVec::with_capacity(100);\n\t/// bv.extend([false, true, false].iter().copied());\n\t///\n\t/// assert!(bv.capacity() >= 100);\n\t/// let slice = bv.into_boxed_slice();\n\t/// assert_eq!(slice.into_vec().capacity(), 1);\n\t/// ```\n\t///\n\t/// [`Box<[T]>`]: https://doc.rust-lang.org/alloc/boxed/struct.Box.html\n\t/// [`into_boxed_bitslice`]: #method.into_boxed_bitslice\n\t#[inline]\n\tpub fn into_boxed_slice(self) -> Box<[T]> {\n\t\tself.into_vec().into_boxed_slice()\n\t}\n\n\t/// Shortens the vector, keeping the first `len` bits and dropping the rest.\n\t///\n\t/// If `len` is greater than the vector’s current length, this has no\n\t/// effect.\n\t///\n\t/// The [`drain`] method can emulate `truncate`, but causes the excess bits\n\t/// to be returned instead of dropped.\n\t///\n\t/// Note that this method has no effect on the allocated capacity of the\n\t/// vector.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::truncate`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.truncate)\n\t///\n\t/// # Examples\n\t///\n\t/// Truncating a five bit vector to two bits:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1; 5];\n\t/// bv.truncate(2);\n\t/// assert_eq!(bv.len(), 2);\n\t/// ```\n\t///\n\t/// No truncation occurs when `len` is greater than the vector’s current\n\t/// length:\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1; 3];\n\t/// bv.truncate(8);\n\t/// assert_eq!(bv.len(), 3);\n\t/// ```\n\t///\n\t/// Truncating when `len == 0` is equivalent to calling the [`clean`]\n\t/// method.\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0; 3];\n\t/// bv.truncate(0);\n\t/// assert!(bv.is_empty());\n\t/// ```\n\t///\n\t/// [`clear`]: #method.clear\n\t/// [`drain`]: #method.drain\n\t#[inline]\n\tpub fn truncate(&mut self, len: usize) {\n\t\tif len < self.len() {\n\t\t\tunsafe { self.set_len(len) }\n\t\t}\n\t}\n\n\t/// Extracts an element slice containing the entire vector.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_slice)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_bitslice`] for a `&BitVec -> &BitSlice` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t/// use std::io::{self, Write};\n\t/// let buffer = bitvec![Msb0, u8; 0, 1, 0, 1, 1, 0, 0, 0];\n\t/// io::sink().write(buffer.as_slice()).unwrap();\n\t/// # }\n\t/// ```\n\t///\n\t/// [`as_bitslice`]: #method.as_bitslice\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_slice(&self) -> &[T] {\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_const(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}\n\n\t/// Extracts a mutable slice of the entire vector.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_slice)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_mut_bitslice`] for a `&mut BitVec -> &mut BitSlice` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// # #[cfg(feature = \"std\")] {\n\t/// use bitvec::prelude::*;\n\t/// use std::io::{self, Read};\n\t/// let mut buffer = bitvec![Msb0, u8; 0; 24];\n\t/// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();\n\t/// # }\n\t/// ```\n\t///\n\t/// [`as_mut_bitslice`]: #method.as_mut_bitslice\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_slice(&mut self) -> &mut [T] {\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_mut(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts_mut(base, elts) }\n\t}\n\n\t/// Returns a raw pointer to the vector’s buffer.\n\t///\n\t/// The caller must ensure that the vector outlives the pointer this\n\t/// function returns, or else it will end up pointing to garbage. Modifying\n\t/// the vector may cause its buffer to be reällocated, which would also make\n\t/// any pointers to it invalid.\n\t///\n\t/// The caller must also ensure that the memory the pointer\n\t/// (non-transitively) points to is never written to (except inside an\n\t/// `UnsafeCell`) using this pointer or any pointer derived from it. If you\n\t/// need to mutate the contents of the slice, use [`as_mut_ptr`].\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_ptr`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_ptr)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_bitptr`] for a `&BitVec -> *const BitSlice` transform.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![Lsb0; 0, 1, 0, 1];\n\t/// let bv_ptr = bv.as_ptr();\n\t///\n\t/// unsafe {\n\t///   assert_eq!(*bv_ptr, 0b1010);\n\t/// }\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_ptr(&self) -> *const T {\n\t\tself.bitptr().pointer().to_const()\n\t}\n\n\t/// Returns an unsafe mutable pointer to the vector’s buffer.\n\t///\n\t/// The caller must ensure that the vector outlives the pointer this\n\t/// function returns, or else it will end up pointing to garbage. Modifying\n\t/// the vector may cause its buffer to be reällocated, which would also make\n\t/// any pointers to it invalid.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::as_mut_ptr`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_ptr)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`as_mut_bitptr`] for a `&mut BitVec -> *mut BitSlice` transform.\n\t///\n\t/// # Eaxmples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let size = 4;\n\t/// let mut bv: BitVec<Msb0, usize> = BitVec::with_capacity(size);\n\t/// let bv_ptr = bv.as_mut_ptr();\n\t///\n\t/// unsafe {\n\t///   *bv_ptr = !0;\n\t///   bv.set_len(size);\n\t/// }\n\t/// assert_eq!(bv.len(), 4);\n\t/// assert!(bv.all());\n\t/// ```\n\t///\n\t/// [`as_mut_bitptr`]: #method.as_mut_bitptr\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_ptr(&mut self) -> *mut T {\n\t\tself.bitptr().pointer().to_mut()\n\t}\n\n\t/// Forces the length of the vector to `new_len`.\n\t///\n\t/// This is a low-level operation that maintains none of the normal\n\t/// invariants of the type. Normally changing the length of a vector is done\n\t/// using one of the safe operations instead, such as [`truncate`],\n\t/// [`resize`], [`extend`], or [`clear`].\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::set_len`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.set_len)\n\t///\n\t/// # Safety\n\t///\n\t/// - `new_len` must be less than or equal to [`capacity()`].\n\t///\n\t/// # Examples\n\t///\n\t/// This method can be useful for situations in which the vector is serving\n\t/// as a buffer for other code, particularly over FFI:\n\t///\n\t/// ```rust\n\t/// # #![allow(dead_code)]\n\t/// # #![allow(improper_ctypes)]\n\t/// # const ERL_OK: i32 = 0;\n\t/// # extern \"C\" {\n\t/// #   fn erl_read_bits(\n\t/// #     bv: *mut BitVec<Msb0, u8>,\n\t/// #     bits_reqd: usize,\n\t/// #     bits_read: *mut usize,\n\t/// #   ) -> i32;\n\t/// # }\n\t/// use bitvec::prelude::*;\n\t///\n\t/// // `bitvec` could pair with `rustler` for a better bitstream\n\t/// type ErlBitstring = BitVec<Msb0, u8>;\n\t/// # pub fn _test() {\n\t/// let mut bits_read = 0;\n\t/// // An imaginary Erlang function wants a large bit buffer.\n\t/// let mut buf = ErlBitstring::with_capacity(32_768);\n\t/// // SAFETY: When `erl_read_bits` returns `ERL_OK`, it holds that:\n\t/// // 1. `bits_read` bits were initialized.\n\t/// // 2. `bits_read` <= the capacity (32_768)\n\t/// // which makes `set_len` safe to call.\n\t/// unsafe {\n\t///   // Make the FFI call...\n\t///   let status = erl_read_bits(&mut buf, 10, &mut bits_read);\n\t///   if status == ERL_OK {\n\t///     // ...and update the length to what was read in.\n\t///     buf.set_len(bits_read);\n\t///   }\n\t/// }\n\t/// # }\n\t/// ```\n\t///\n\t/// [`capacity()`]: #method.capacity\n\t/// [`clear`]: #method.clear\n\t/// [`extend`]: #method.extend\n\t/// [`resize`]: #method.resize\n\t/// [`truncate`]: #method.truncate\n\t#[inline]\n\tpub unsafe fn set_len(&mut self, new_len: usize) {\n\t\tassert!(\n\t\t\tnew_len <= BitPtr::<T>::REGION_MAX_BITS,\n\t\t\t\"Capacity exceeded: {} exceeds maximum length {}\",\n\t\t\tnew_len,\n\t\t\tBitPtr::<T>::REGION_MAX_BITS,\n\t\t);\n\t\tlet cap = self.capacity();\n\t\tassert!(\n\t\t\tnew_len <= cap,\n\t\t\t\"Capacity exceeded: {} exceeds allocation size {}\",\n\t\t\tnew_len,\n\t\t\tcap,\n\t\t);\n\t\tself.pointer = self\n\t\t\t.pointer\n\t\t\t.as_ptr()\n\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.tap_mut(|bp| bp.set_len(new_len))\n\t\t\t.to_nonnull()\n\t}\n\n\t/// Removes a bit from the vector and returns it.\n\t///\n\t/// The removed bit is replaced by the last bit of the vector.\n\t///\n\t/// This does not preserve ordering, but is O(1).\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::swap_remove`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.swap_remove)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `index` is out of bounds.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 0, 1, 0, 1];\n\t/// assert!(!bv.swap_remove(1));\n\t/// assert_eq!(bv, bits![0, 1, 1, 0]);\n\t///\n\t/// assert!(!bv.swap_remove(0));\n\t/// assert_eq!(bv, bits![0, 1, 1]);\n\t/// ```\n\t#[inline]\n\tpub fn swap_remove(&mut self, index: usize) -> bool {\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index {} out of bounds: {}\", index, len);\n\t\tlet last = len - 1;\n\t\t//  TODO(myrrlyn): Implement `BitSlice::xchg`?\n\t\tunsafe {\n\t\t\tself.swap_unchecked(index, last);\n\t\t\tself.set_len(last);\n\t\t\t*self.get_unchecked(last)\n\t\t}\n\t}\n\n\t/// Inserts a bit at position `index` within the vector, shifting all bits\n\t/// after it to the right.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::insert`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.insert)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `index > len`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0; 5];\n\t/// bv.insert(4, true);\n\t/// assert_eq!(bv, bits![0, 0, 0, 0, 1, 0]);\n\t/// bv.insert(2, true);\n\t/// assert_eq!(bv, bits![0, 0, 1, 0, 0, 1, 0]);\n\t/// ```\n\t#[inline]\n\tpub fn insert(&mut self, index: usize, value: bool) {\n\t\tlet len = self.len();\n\t\tassert!(index <= len, \"Index {} out of bounds: {}\", index, len);\n\t\tself.push(value);\n\t\tunsafe { self.get_unchecked_mut(index ..) }.rotate_right(1);\n\t}\n\n\t/// Removes and returns the bit at position `index` within the vector,\n\t/// shifting all bits after it to the left.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::remove`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.remove)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `index` is out of bounds.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 0];\n\t/// assert!(bv.remove(1));\n\t/// assert_eq!(bv, bits![0, 0]);\n\t/// ```\n\t#[inline]\n\tpub fn remove(&mut self, index: usize) -> bool {\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index {} out of bounds: {}\", index, len);\n\t\tlet last = len - 1;\n\t\tunsafe {\n\t\t\tself.get_unchecked_mut(index ..).rotate_left(1);\n\t\t\tself.set_len(last);\n\t\t\t*self.get_unchecked(last)\n\t\t}\n\t}\n\n\t/// Retains only the bits specified by the predicate.\n\t///\n\t/// In other words, remove all bits `b` such that `func(idx(b), &b)` returns\n\t/// `false`. This method operates in place, visiting each bit exactly once\n\t/// in the original order, and preserves the order of the retained bits.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::retain`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.retain)\n\t///\n\t/// # API Differences\n\t///\n\t/// In order to allow more than one bit of information for the split\n\t/// decision, the predicate receives the index of each bit, as well as its\n\t/// value.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 1, 0, 0, 1];\n\t/// bv.retain(|i, b| (i % 2 == 0) ^ b);\n\t/// assert_eq!(bv, bits![0, 1, 0, 1]);\n\t/// ```\n\t#[inline]\n\tpub fn retain<F>(&mut self, mut func: F)\n\twhere F: FnMut(usize, &bool) -> bool {\n\t\tfor n in (0 .. self.len()).rev() {\n\t\t\tif !func(n, unsafe { self.get_unchecked(n) }) {\n\t\t\t\tself.remove(n);\n\t\t\t}\n\t\t}\n\t}\n\n\t/// Appends a bit to the back of a collection.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::push`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.push)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the number of bits in the vector exceeds the maximum vector\n\t/// capacity.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 0];\n\t/// bv.push(true);\n\t/// assert_eq!(bv.count_ones(), 1);\n\t/// ```\n\t#[inline]\n\tpub fn push(&mut self, value: bool) {\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tlen <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Exceeded capacity: {} >= {}\",\n\t\t\tlen,\n\t\t\tBitSlice::<O, T>::MAX_BITS,\n\t\t);\n\t\tif self.is_empty() || self.bitptr().tail().value() == T::Mem::BITS {\n\t\t\tself.with_vec(|v| v.push(T::Mem::ZERO));\n\t\t}\n\t\tunsafe {\n\t\t\tself.pointer = self\n\t\t\t\t.pointer\n\t\t\t\t.as_ptr()\n\t\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t\t.tap_mut(|bp| bp.set_len(len + 1))\n\t\t\t\t.to_nonnull();\n\t\t\tself.set_unchecked(len, value);\n\t\t}\n\t}\n\n\t/// Removes the last bit from a vector and returns it, or [`None`] if it is\n\t/// empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::pop`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.pop)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 0, 1];\n\t/// assert_eq!(bv.pop(), Some(true));\n\t/// assert!(bv.not_any());\n\t/// ```\n\t///\n\t/// [`None`]: https://doc.rust-lang.org/core/option/enum.Option.html#variant.None\n\t#[inline]\n\tpub fn pop(&mut self) -> Option<bool> {\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tn => unsafe {\n\t\t\t\tlet m = n - 1;\n\t\t\t\t(*self.get_unchecked(m)).tap(|_| self.set_len(m)).pipe(Some)\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Moves all the bits of `other` into `self`, leaving `other` empty.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::append`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.append)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the number of bits overflows the maximum vector capacity.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv1 = bitvec![0; 10];\n\t/// let mut bv2 = bitvec![1; 10];\n\t///\n\t/// bv1.append(&mut bv2);\n\t///\n\t/// assert_eq!(bv1.count_ones(), 10);\n\t/// assert!(bv2.is_empty());\n\t/// ```\n\t#[inline]\n\tpub fn append<O2, T2>(&mut self, other: &mut BitVec<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,\n\t{\n\t\tself.extend(other.iter().copied());\n\t\tother.clear();\n\t}\n\n\t/// Creates a draining iterator that removes the specified range in the\n\t/// vector and yields the removed items.\n\t///\n\t/// Note 1: The bit range is removed even if the iterator is only partially\n\t/// consumed or not consumed at all.\n\t///\n\t/// Note 2: It is unspecified how many bits are removed from the vector if\n\t/// the `Drain` value is leaked.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::drain`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.drain)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if the starting point is greater than the end point or if the end\n\t/// point is greater than the length of the vector.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 1];\n\t/// let bv2: BitVec = bv.drain(1 ..).collect();\n\t/// assert_eq!(bv, bits![0]);\n\t/// assert_eq!(bv2, bits![1, 1]);\n\t///\n\t/// // A full range clears the vector\n\t/// bv.drain(..);\n\t/// assert_eq!(bv, bits![]);\n\t/// ```\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn drain<R>(&mut self, range: R) -> Drain<O, T>\n\twhere R: RangeBounds<usize> {\n\t\tDrain::new(self, range)\n\t}\n\n\t/// Clears the vector, removing all values.\n\t///\n\t/// Note that this method has no effect on the allocated capacity of the\n\t/// vector.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::clear`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.clear)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 0, 1];\n\t///\n\t/// bv.clear();\n\t///\n\t/// assert!(bv.is_empty());\n\t/// ```\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn clear(&mut self) {\n\t\tunsafe {\n\t\t\tself.set_len(0);\n\t\t}\n\t}\n\n\t/// Splits the collection into two at the given index.\n\t///\n\t/// Returns a newly allocated vector containing the elements in range `[at,\n\t/// len)`. After the call, the original vector will be left containing the\n\t/// bits `[0, at)` with its previous capacity unchanged.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::split_off`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.split_off)\n\t///\n\t/// # Panics\n\t///\n\t/// Panics if `at > len`.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 0, 1];\n\t/// let bv2 = bv.split_off(1);\n\t/// assert_eq!(bv, bits![0]);\n\t/// assert_eq!(bv2, bits![0, 1]);\n\t/// ```\n\t#[inline]\n\tpub fn split_off(&mut self, at: usize) -> Self {\n\t\tlet len = self.len();\n\t\tassert!(at <= len, \"Index {} out of bounds: {}\", at, len);\n\t\tmatch at {\n\t\t\t0 => mem::replace(self, Self::with_capacity(self.capacity())),\n\t\t\tn if n == len => Self::new(),\n\t\t\t_ => unsafe {\n\t\t\t\tself.set_len(at);\n\t\t\t\tself.get_unchecked(at .. len).to_owned()\n\t\t\t},\n\t\t}\n\t}\n\n\t/// Resizes the `BitVec` in-place so that `len` is equal to `new_len`.\n\t///\n\t/// If `new_len` is greater than `len`, the `BitVec` is extended by the\n\t/// difference, with each additional slot filled with the result of calling\n\t/// the closure `func`. The return values from `func` will end up in the\n\t/// `BitVec` in the order they have been generated.\n\t///\n\t/// If `new_len` is less than `len`, the `Vec` is simply truncated.\n\t///\n\t/// This method uses a closure to create new values on every push. If you’d\n\t/// rather [`Clone`] a given bit, use [`resize`]. If you want to use the\n\t/// [`Default`] trait to generate values, you can pass [`Default::default`]\n\t/// as the second argument.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::resize_with`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.resize_with)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1; 3];\n\t/// bv.resize_with(5, Default::default);\n\t/// assert_eq!(bv, bits![1, 1, 1, 0, 0]);\n\t///\n\t/// let mut bv = bitvec![];\n\t/// let mut p = 0;\n\t/// bv.resize_with(4, || { p += 1; p % 2 == 0 });\n\t/// assert_eq!(bv, bits![0, 1, 0, 1]);\n\t/// ```\n\t///\n\t/// [`Clone`]: https://doc.rust-lang.org/std/clone/trait.Clone.html\n\t/// [`Default`]: https://doc.rust-lang.org/std/default/trait.Default.html\n\t/// [`Default::default`]: https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default\n\t/// [`resize`]: #method.resize\n\t#[inline]\n\tpub fn resize_with<F>(&mut self, new_len: usize, mut func: F)\n\twhere F: FnMut() -> bool {\n\t\tlet len = self.len();\n\t\tif new_len > len {\n\t\t\tlet ext = new_len - len;\n\t\t\tself.reserve(ext);\n\t\t\tunsafe {\n\t\t\t\tself.get_unchecked_mut(len .. new_len)\n\t\t\t\t\t.for_each(|_, _| func());\n\t\t\t}\n\t\t}\n\t\tunsafe {\n\t\t\tself.set_len(new_len);\n\t\t}\n\t}\n\n\t/// Resizes the `BitVec` in-place so that `len` is equal to `new_len`.\n\t///\n\t/// If `new_len` is greater than `len`, the `BitVec` is extended by the\n\t/// difference, with each additional slot filled with `value`. If `new_len`\n\t/// is less than `len`, the `BitVec` is simply truncated.\n\t///\n\t/// This method requires a single `bool` value. If you need more\n\t/// flexibility, use [`resize_with`].\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::resize`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.resize)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![1];\n\t/// bv.resize(3, false);\n\t/// assert_eq!(bv, bits![1, 0, 0]);\n\t///\n\t/// let mut bv = bitvec![1; 4];\n\t/// bv.resize(2, false);\n\t/// assert_eq!(bv, bits![1; 2]);\n\t/// ```\n\t///\n\t/// [`resize_with`]: #method.resize_with\n\t#[inline]\n\tpub fn resize(&mut self, new_len: usize, value: bool) {\n\t\tlet len = self.len();\n\t\tif new_len > len {\n\t\t\tlet ext = new_len - len;\n\t\t\tself.reserve(ext);\n\t\t\t/* Initialize all of the newly-allocated memory, not just the bits\n\t\t\tthat will become live. This is a requirement for correctness.\n\n\t\t\t*Strictly speaking*, only `len .. ⌈new_len / bit_width⌉` needs to be\n\t\t\tinitialized, but computing the correct boundary is probably not\n\t\t\tsufficiently less effort than just initializing the complete\n\t\t\tallocation to be worth the instructions. If users complain about\n\t\t\tperformance on this method, revisit this decision, but if they don’t\n\t\t\tthen the naïve solution is fine.\n\t\t\t*/\n\t\t\tlet capa = self.capacity();\n\t\t\tunsafe {\n\t\t\t\tself.get_unchecked_mut(len .. capa).set_all(value);\n\t\t\t}\n\t\t}\n\t\tunsafe {\n\t\t\tself.set_len(new_len);\n\t\t}\n\t}\n\n\t/// Clones and appends all `bool`s in a slice to the `BitVec`.\n\t///\n\t/// Iterates over the slice `other`, clones each `bool`, and then appends it\n\t/// to the `BitVec`. The `other` slice is traversed in-order.\n\t///\n\t/// Prefer the [`Extend`] implementation; this method is retained only for\n\t/// API compatibility, and offers no performance benefit.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::extend_from_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.extend_from_slice)\n\t///\n\t/// # Analogue\n\t///\n\t/// See [`extend_from_bitslice`] for the method to append a bit-slice of the\n\t/// same type parameters to a bit-vector.\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0];\n\t/// bv.extend_from_slice(&[true]);\n\t/// assert_eq!(bv, bits![0, 1]);\n\t/// ```\n\t///\n\t/// [`extend`]: #impl-Extend<%26'a bool>\n\t/// [`extend_from_bitslice`]: #method.extend_from_bitslice\n\t#[cfg_attr(not(tarpaulin), inline(always))]\n\tpub fn extend_from_slice(&mut self, other: &[bool]) {\n\t\tself.extend(other)\n\t}\n\n\t/// Creates a splicing iterator that replaces the specified range in the\n\t/// vector with the given `replace_with` iterator and yields the removed\n\t/// items. `replace_with` does not need to be the same length as `range`.\n\t///\n\t/// The element range is removed even if the iterator is not consumed until\n\t/// the end.\n\t///\n\t/// It is unspecified how many bits are removed from the vector if the\n\t/// `Splice` value is leaked.\n\t///\n\t/// The input iterator `replace_with` is only consumed when the `Splice`\n\t/// value is dropped.\n\t///\n\t/// This is optimal if:\n\t///\n\t/// - the tail (bits in the vector after `range`) is empty\n\t/// - or `replace_with` yields fewer bits than `range`’s length\n\t/// - or the lower bound of its `size_hint()` is exact\n\t///\n\t/// Otherwise, a temporary vector is allocated and the tail is moved twice.\n\t///\n\t/// # Original\n\t///\n\t/// [`Vec::splice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.splice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let mut bv = bitvec![0, 1, 0];\n\t/// let new = bits![1, 0];\n\t/// let old: BitVec = bv.splice(.. 2, new.iter().copied()).collect();\n\t/// assert_eq!(bv, bits![1, 0, 0]);\n\t/// assert_eq!(old, bits![0, 1]);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn splice<R, I>(\n\t\t&mut self,\n\t\trange: R,\n\t\treplace_with: I,\n\t) -> Splice<O, T, I::IntoIter>\n\twhere\n\t\tR: RangeBounds<usize>,\n\t\tI: IntoIterator<Item = bool>,\n\t{\n\t\tSplice::new(self.drain(range), replace_with)\n\t}\n}","impl<O, T> Borrow<BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn borrow(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> BorrowMut<BitSlice<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn borrow_mut(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> Clone for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn clone(&self) -> Self {\n\t\tself.as_bitslice().pipe(Self::from_bitslice)\n\t}\n\n\t#[inline]\n\tfn clone_from(&mut self, other: &Self) {\n\t\tself.clear();\n\t\tself.reserve(other.len());\n\t\tself.with_vec(|v| {\n\t\t\tv.extend(\n\t\t\t\tother\n\t\t\t\t\t.as_slice()\n\t\t\t\t\t.iter()\n\t\t\t\t\t.map(dvl::accessor)\n\t\t\t\t\t.map(BitAccess::load_value),\n\t\t\t)\n\t\t});\n\t\tunsafe {\n\t\t\tself.set_len(other.len());\n\t\t}\n\t\tself.pointer = self\n\t\t\t.bitptr()\n\t\t\t.tap_mut(|bp| unsafe { bp.set_head(other.bitptr().head()) })\n\t\t\t.to_nonnull();\n\t}\n}","impl<O, T> Debug for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tif fmt.alternate() {\n\t\t\tPointer::fmt(self, fmt)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Default for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn default() -> Self {\n\t\tSelf::new()\n\t}\n}","impl<O, T> Deref for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Target = BitSlice<O, T>;\n\n\t#[inline(always)]\n\tfn deref(&self) -> &Self::Target {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> DerefMut for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn deref_mut(&mut self) -> &mut Self::Target {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> Display for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Drop for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn drop(&mut self) {\n\t\t//  The buffer elements do not have destructors.\n\t\tself.clear();\n\t\t//  Run the `Vec` destructor to deällocate the buffer.\n\t\tself.with_vec(|vec| unsafe { ManuallyDrop::drop(vec) });\n\t}\n}","impl<O, T> Eq for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> Extend<bool> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn extend<I>(&mut self, iter: I)\n\twhere I: IntoIterator<Item = bool> {\n\t\tlet mut iter = iter.into_iter();\n\t\tmatch iter.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => {\n\t\t\t\t// This body exists to try to accelerate the push-per-bit loop.\n\t\t\t\tself.reserve(n);\n\t\t\t\tlet len = self.len();\n\t\t\t\tlet new_len = len + n;\n\t\t\t\tlet new = unsafe { self.get_unchecked_mut(len .. new_len) };\n\t\t\t\tlet mut pulled = 0;\n\t\t\t\tfor (slot, bit) in new.iter_mut().zip(iter.by_ref()) {\n\t\t\t\t\tslot.set(bit);\n\t\t\t\t\tpulled += 1;\n\t\t\t\t}\n\t\t\t\tunsafe {\n\t\t\t\t\tself.set_len(len + pulled);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t\titer.for_each(|bit| self.push(bit));\n\t}\n}","impl<O, T> From<BitBox<O, T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn from(boxed: BitBox<O, T>) -> Self {\n\t\tboxed.into_bitvec()\n\t}\n}","impl<O, T> FromIterator<bool> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn from_iter<I>(iter: I) -> Self\n\twhere I: IntoIterator<Item = bool> {\n\t\tlet iter = iter.into_iter();\n\t\tlet mut out = match iter.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => Self::with_capacity(n),\n\t\t};\n\t\tout.extend(iter);\n\t\tout\n\t}\n}","impl<O, T> Hash for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn hash<H>(&self, state: &mut H)\n\twhere H: Hasher {\n\t\tself.as_bitslice().hash(state)\n\t}\n}","impl<O, T> Into<Vec<T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn into(self) -> Vec<T> {\n\t\tself.into_vec()\n\t}\n}","impl<O, T> IntoIterator for BitVec<O, T>\nwhere\n\tO: 'static + BitOrder,\n\tT: 'static + BitStore,\n{\n\ttype IntoIter = IntoIter<O, T>;\n\ttype Item = bool;\n\n\t#[inline]\n\tfn into_iter(self) -> Self::IntoIter {\n\t\tIntoIter {\n\t\t\titer: self.as_bitslice().bitptr().to_bitslice_ref().iter(),\n\t\t\t_bv: self,\n\t\t}\n\t}\n}","impl<O, T> LowerHex for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Not for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Output = Self;\n\n\t#[inline]\n\tfn not(mut self) -> Self::Output {\n\t\tfor elem in self.as_mut_slice().iter_mut().map(dvl::mem_mut) {\n\t\t\t*elem = !*elem;\n\t\t}\n\t\tself\n\t}\n}","impl<O, T> Octal for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Ord for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn cmp(&self, other: &Self) -> cmp::Ordering {\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}\n}","impl<O, T> Pointer for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Vec\", Some(any::type_name::<O>()), &[(\n\t\t\t\t\"capacity\",\n\t\t\t\t&self.capacity() as &dyn Debug,\n\t\t\t)])\n\t}\n}","impl<O, T> TryFrom<Vec<T>> for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Error = Vec<T>;\n\n\t#[inline(always)]\n\tfn try_from(vec: Vec<T>) -> Result<Self, Self::Error> {\n\t\tSelf::try_from_vec(vec)\n\t}\n}","impl<O, T> Unpin for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> UpperHex for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}\n}","impl<O, T> Write for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tBitSlice<O, T::Alias>: BitField,\n{\n\t#[inline]\n\tfn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n\t\tlet len = self.len();\n\t\tself.resize(len + buf.len() * 8, false);\n\t\tunsafe { self.get_unchecked_mut(len ..) }.write(buf)\n\t}\n\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tfn flush(&mut self) -> io::Result<()> {\n\t\tOk(())\n\t}\n}","unsafe impl<O, T> Send for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","unsafe impl<O, T> Sync for BitVec<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}"],"vec::iter::Drain":["impl<'a, O, T> Debug for Drain<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[inline]\n\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\tfmt.debug_tuple(\"Drain\")\n\t\t\t.field(&self.drain.as_bitslice())\n\t\t\t.finish()\n\t}\n}","impl<'a, O, T> Drain<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t#[inline]\n\tpub(super) fn new<R>(source: &'a mut BitVec<O, T>, range: R) -> Self\n\twhere R: RangeBounds<usize> {\n\t\t//  Hold the current vector size for bounds comparison.\n\t\tlet len = source.len();\n\t\t//  Normalize the input range and assert that it is within bounds.\n\t\tlet drain = dvl::normalize_range(range, len);\n\t\tdvl::assert_range(drain.clone(), len);\n\n\t\t//  The tail region is everything after the drain, before the real end.\n\t\tlet tail = drain.end .. len;\n\t\t//  The drain span is an iterator over the provided range.\n\t\tlet drain = unsafe {\n\t\t\t//  Set the source vector to end before the drain.\n\t\t\tsource.set_len(drain.start);\n\t\t\t//  Grab the drain range and produce an iterator over it.\n\t\t\tsource\n\t\t\t\t.as_bitslice()\n\t\t\t\t.get_unchecked(drain)\n\t\t\t\t//  Detach the region from the `source` borrow.\n\t\t\t\t.bitptr()\n\t\t\t\t.to_bitslice_ref()\n\t\t\t\t.iter()\n\t\t};\n\t\tlet source = source.into();\n\t\tSelf {\n\t\t\tsource,\n\t\t\tdrain,\n\t\t\ttail,\n\t\t}\n\t}\n\n\t/// Returns the remaining bits of this iterator as a bit-slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`Drain::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Drain.html#method.as_slice)\n\t///\n\t/// # API Differences\n\t///\n\t/// This method is renamed, as it operates on a bit-slice rather than an\n\t/// element slice.\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitslice(&self) -> &'a BitSlice<O, T> {\n\t\tself.drain.as_bitslice()\n\t}\n\n\t/// Attempts to overwrite the drained region with another iterator.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `I`: Some source of `bool`s.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `iter`: A source of `bool`s with which to overwrite the drained span.\n\t///\n\t/// # Returns\n\t///\n\t/// Whether the drained span was completely filled, or if the replacement\n\t/// source `iter`ator was exhausted first.\n\t///\n\t/// # Effects\n\t///\n\t/// The source vector is extended to include all bits filled in from the\n\t/// replacement `iter`ator, but is *not* extended to include the tail, even\n\t/// if drained region is completely filled. This work is done in the\n\t/// destructor.\n\t#[inline]\n\tfn fill<I>(&mut self, iter: &mut I) -> FillStatus\n\twhere I: Iterator<Item = bool> {\n\t\tlet bitvec = unsafe { self.source.as_mut() };\n\t\t//  Get the length of the source vector. This will be grown as `iter`\n\t\t//  writes into the drain span.\n\t\tlet mut len = bitvec.len();\n\t\t//  Get the drain span as a bit-slice.\n\t\tlet span = unsafe { bitvec.get_unchecked_mut(len .. self.tail.start) };\n\n\t\t//  Set the exit flag to assume completion.\n\t\tlet mut out = FillStatus::FullSpan;\n\t\t//  Write the `iter` bits into the drain `span`.\n\t\tfor slot in span {\n\t\t\t//  While the `iter` is not exhausted, write it into the span and\n\t\t\t//  increase the vector length counter.\n\t\t\tif let Some(bit) = iter.next() {\n\t\t\t\tslot.set(bit);\n\t\t\t\tlen += 1;\n\t\t\t}\n\t\t\t//  If the `iter` exhausts before the drain `span` is filled, set\n\t\t\t//  the exit flag accordingly.\n\t\t\telse {\n\t\t\t\tout = FillStatus::EmptyInput;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t//  Update the vector length counter to include the bits written by\n\t\t//  `iter`.\n\t\tunsafe {\n\t\t\tbitvec.set_len(len);\n\t\t}\n\t\tout\n\t}\n\n\t/// Inserts `additional` capacity between the vector and the tail.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`\n\t/// - `additional`: The amount of new bits to reserve between the head and\n\t///   tail sections of the vector.\n\t///\n\t/// # Effects\n\t///\n\t/// This is permitted to reällocate the buffer in order to grow capacity.\n\t/// After completion, the tail segment will be relocated to begin\n\t/// `additional` bits after the head segment ends. The drain iteration\n\t/// cursor will not be modified.\n\t#[inline]\n\tunsafe fn move_tail(&mut self, additional: usize) {\n\t\tlet bitvec = self.source.as_mut();\n\t\tlet tail_len = self.tail.end - self.tail.start;\n\n\t\t//  Reserve allocation capacity for `additional` and the tail.\n\t\t//  `.reserve()` begins from the `bitvec.len()`, so the tail length must\n\t\t//  still be included.\n\t\tlet full_len = additional + tail_len;\n\t\tbitvec.reserve(full_len);\n\t\tlet new_tail_start = additional + self.tail.start;\n\t\tlet orig_tail = mem::replace(\n\t\t\t&mut self.tail,\n\t\t\tnew_tail_start .. new_tail_start + tail_len,\n\t\t);\n\t\t//  Temporarily resize the vector to include the full buffer. This is\n\t\t//  necessary until `copy_within_unchecked` stops using `.len()`\n\t\t//  internally.\n\t\tlet len = bitvec.len();\n\t\tbitvec.set_len(full_len);\n\t\tbitvec.copy_within_unchecked(orig_tail, new_tail_start);\n\t\tbitvec.set_len(len);\n\t}\n}","impl<O, T> AsRef<BitSlice<O, T>> for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn as_ref(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n}","impl<O, T> DoubleEndedIterator for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\tself.drain.next_back().copied()\n\t}\n\n\t#[inline(always)]\n\tfn nth_back(&mut self, n: usize) -> Option<Self::Item> {\n\t\tself.drain.nth_back(n).copied()\n\t}\n}","impl<O, T> Drop for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline]\n\tfn drop(&mut self) {\n\t\t//  Grab the tail range descriptor\n\t\tlet tail = self.tail.clone();\n\t\t//  And compute its length.\n\t\tlet tail_len = tail.end - tail.start;\n\t\t//  If the tail region is empty, then there is no cleanup work to do.\n\t\tif tail_len == 0 {\n\t\t\treturn;\n\t\t}\n\t\t//  Otherwise, access the source vector,\n\t\tlet bitvec = unsafe { self.source.as_mut() };\n\t\t//  And grab its current end.\n\t\tlet old_len = bitvec.len();\n\t\tlet new_len = old_len + tail_len;\n\t\tunsafe {\n\t\t\t//  Expand the vector to include where the tail bits will be.\n\t\t\tbitvec.set_len(new_len);\n\t\t\t//  Then move the tail bits into the new location.\n\t\t\tbitvec.copy_within_unchecked(tail, old_len);\n\t\t\t//  This ordering is important! `copy_within_unchecked` uses the\n\t\t\t//  `len` boundary.\n\t\t}\n\t}\n}","impl<O, T> ExactSizeIterator for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[inline(always)]\n\tfn len(&self) -> usize {\n\t\tself.drain.len()\n\t}\n}","impl<O, T> FusedIterator for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> Iterator for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Item = bool;\n\n\t#[inline(always)]\n\tfn next(&mut self) -> Option<Self::Item> {\n\t\tself.drain.next().copied()\n\t}\n\n\t#[inline(always)]\n\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\tself.drain.size_hint()\n\t}\n\n\t#[inline(always)]\n\tfn count(self) -> usize {\n\t\tself.len()\n\t}\n\n\t#[inline(always)]\n\tfn nth(&mut self, n: usize) -> Option<Self::Item> {\n\t\tself.drain.nth(n).copied()\n\t}\n\n\t#[inline(always)]\n\tfn last(mut self) -> Option<Self::Item> {\n\t\tself.next_back()\n\t}\n}","unsafe impl<O, T> Send for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","unsafe impl<O, T> Sync for Drain<'_, O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}"],"vec::iter::FillStatus":["Clone","Copy","Debug","Eq","Ord","PartialEq","PartialOrd"],"vec::iter::IntoIter":["Clone","Debug","impl<O, T> DoubleEndedIterator for IntoIter<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\tself.iter.next_back().copied()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn nth_back(&mut self, n: usize) -> Option<Self::Item> {\n\t\tself.iter.nth_back(n).copied()\n\t}\n}","impl<O, T> ExactSizeIterator for IntoIter<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn len(&self) -> usize {\n\t\tself.iter.len()\n\t}\n}","impl<O, T> FusedIterator for IntoIter<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n}","impl<O, T> IntoIter<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Returns the remaining bits of this iterator as a bitslice.\n\t///\n\t/// # Original\n\t///\n\t/// [`vec::IntoIter::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.IntoIter.html#method.as_slice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0, 1, 0, 1];\n\t/// let mut into_iter = bv.into_iter();\n\t/// assert_eq!(into_iter.as_bitslice(), bits![0, 1, 0, 1]);\n\t/// let _ = into_iter.next().unwrap();\n\t/// assert_eq!(into_iter.as_bitslice(), bits![1, 0, 1]);\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_bitslice(&self) -> &BitSlice<O, T> {\n\t\tself.iter.as_bitslice()\n\t}\n\n\t#[doc(hidden)]\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\t#[deprecated(\n\t\tnote = \"Use `.as_bitslice()` on iterators to view the remaining data.\"\n\t)]\n\tpub fn as_slice(&self) -> &BitSlice<O, T> {\n\t\tself.as_bitslice()\n\t}\n\n\t/// Returns the remaining bits of this iterator as a mutable slice.\n\t///\n\t/// # Original\n\t///\n\t/// [`vec::IntoIter::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.IntoIter.html#method.as_mut_slice)\n\t///\n\t/// # Examples\n\t///\n\t/// ```rust\n\t/// use bitvec::prelude::*;\n\t///\n\t/// let bv = bitvec![0, 1, 0, 1];\n\t/// let mut into_iter = bv.into_iter();\n\t/// assert_eq!(into_iter.as_bitslice(), bits![0, 1, 0, 1]);\n\t/// into_iter.as_mut_bitslice().set(2, true);\n\t/// assert!(!into_iter.next().unwrap());\n\t/// assert!(into_iter.next().unwrap());\n\t/// assert!(into_iter.next().unwrap());\n\t/// ```\n\t#[inline]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.iter.as_bitslice().bitptr().to_bitslice_mut()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\t#[doc(hidden)]\n\t#[deprecated(note = \"Use `.as_mut_bitslice()` on iterators to view the \\\n\t                     remaining data.\")]\n\t#[cfg(not(tarpaulin_include))]\n\tpub fn as_mut_slice(&mut self) -> &mut BitSlice<O, T> {\n\t\tself.as_mut_bitslice()\n\t}\n}","impl<O, T> Iterator for IntoIter<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\ttype Item = bool;\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn next(&mut self) -> Option<Self::Item> {\n\t\tself.iter.next().copied()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\tself.iter.size_hint()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn count(self) -> usize {\n\t\tself.len()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn nth(&mut self, n: usize) -> Option<Self::Item> {\n\t\tself.iter.nth(n).copied()\n\t}\n\n\t#[cfg_attr(not(tarpaulin_include), inline(always))]\n\tfn last(mut self) -> Option<Self::Item> {\n\t\tself.next_back()\n\t}\n}"],"vec::iter::Splice":["Debug","impl<'a, O, T, I> Splice<'a, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tI: Iterator<Item = bool>,\n{\n\t/// Constructs a splice out of a drain and a replacement.\n\tpub(super) fn new<II>(drain: Drain<'a, O, T>, splice: II) -> Self\n\twhere II: IntoIterator<IntoIter = I, Item = bool> {\n\t\tlet splice = splice.into_iter();\n\t\tSelf { drain, splice }\n\t}\n}","impl<O, T, I> DoubleEndedIterator for Splice<'_, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tI: Iterator<Item = bool>,\n{\n\t#[inline(always)]\n\tfn next_back(&mut self) -> Option<Self::Item> {\n\t\tself.drain.next_back()\n\t}\n\n\t#[inline(always)]\n\tfn nth_back(&mut self, n: usize) -> Option<Self::Item> {\n\t\tself.drain.nth_back(n)\n\t}\n}","impl<O, T, I> Drop for Splice<'_, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tI: Iterator<Item = bool>,\n{\n\t#[inline]\n\tfn drop(&mut self) {\n\t\tlet tail = self.drain.tail.clone();\n\t\tlet tail_len = tail.end - tail.start;\n\t\tlet bitvec = unsafe { self.drain.source.as_mut() };\n\n\t\t//  If the `drain` has no tail span, then extend the vector with the\n\t\t//  splice and exit.\n\t\tif tail_len == 0 {\n\t\t\tbitvec.extend(self.splice.by_ref());\n\t\t\treturn;\n\t\t}\n\n\t\t//  Fill the drained range first. If the `splice` exhausts, then the\n\t\t//  `Drain` destructor will handle relocating the vector tail segment.\n\t\tif let FillStatus::EmptyInput = self.drain.fill(&mut self.splice) {\n\t\t\treturn;\n\t\t}\n\n\t\t//  If the `splice` has not yet exhausted, then the `Drain` needs to\n\t\t//  adjust to receive its contents.\n\t\tlet len = match self.splice.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => n,\n\t\t};\n\t\tunsafe {\n\t\t\tself.drain.move_tail(len);\n\t\t}\n\t\t//  Now that the tail has been relocated, fill the `splice` into it. If\n\t\t//  this exhausts the `splice`, exit.\n\t\tif let FillStatus::EmptyInput = self.drain.fill(&mut self.splice) {\n\t\t\treturn;\n\t\t}\n\n\t\t//  If the `splice` *still* has bits to provide, then its `.size_hint()`\n\t\t//  is untrustworthy. Collect the `splice` into a vector, then insert\n\t\t//  the vector into the spliced region.\n\t\tlet mut collected = self.splice.by_ref().collect::<BitVec>().into_iter();\n\t\tlet len = collected.len();\n\t\tif len > 0 {\n\t\t\tunsafe {\n\t\t\t\tself.drain.move_tail(len);\n\t\t\t}\n\t\t\tlet filled = self.drain.fill(&mut collected);\n\t\t\tdebug_assert_eq!(filled, FillStatus::EmptyInput);\n\t\t\tdebug_assert_eq!(collected.len(), 0);\n\t\t}\n\t}\n}","impl<O, T, I> ExactSizeIterator for Splice<'_, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tI: Iterator<Item = bool>,\n{\n\t#[inline(always)]\n\tfn len(&self) -> usize {\n\t\tself.drain.len()\n\t}\n}","impl<O, T, I> FusedIterator for Splice<'_, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tI: Iterator<Item = bool>,\n{\n}","impl<O, T, I> Iterator for Splice<'_, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tI: Iterator<Item = bool>,\n{\n\ttype Item = bool;\n\n\t#[inline]\n\tfn next(&mut self) -> Option<Self::Item> {\n\t\tself.drain.next().tap_some(|_| {\n\t\t\t/* Attempt to write a bit into the now-vacated slot at the front of\n\t\t\tthe `Drain`. If the `splice` stream produces a bit, then it is\n\t\t\twritten into the end of the `Drain`’s buffer, extending it by one.\n\t\t\tThis works because `Drain` always truncates its vector to the front\n\t\t\tedge of the drain region, so `bv.len()` is always the first bit of\n\t\t\tthe `Drain` region if the `Drain` is willing to yield a bit.\n\t\t\t*/\n\t\t\tif let Some(bit) = self.splice.next() {\n\t\t\t\tunsafe {\n\t\t\t\t\tlet bv = self.drain.source.as_mut();\n\t\t\t\t\tlet len = bv.len();\n\t\t\t\t\t/* TODO(myrrlyn): Investigate adding functionality to `Iter`\n\t\t\t\t\tthat permits an exchange behavior, rather than separated\n\t\t\t\t\tcomputations of the pointer for read and write access.\n\t\t\t\t\t*/\n\t\t\t\t\tbv.set_unchecked(len, bit);\n\t\t\t\t\tbv.set_len(len + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\n\t#[inline(always)]\n\tfn size_hint(&self) -> (usize, Option<usize>) {\n\t\tself.drain.size_hint()\n\t}\n\n\t#[inline(always)]\n\tfn count(self) -> usize {\n\t\tself.drain.len()\n\t}\n}"]},"single_path_import":{"array::BitArray":"prelude::types::BitArray","boxed::BitBox":"prelude::types::BitBox","domain::BitDomain":"prelude::types::BitDomain","domain::BitDomainMut":"prelude::types::BitDomainMut","field::BitField":"prelude::trait_methods::BitField","macros::bitarr":"prelude::macros::bitarr","macros::bitbox":"prelude::macros::bitbox","macros::bits":"prelude::macros::bits","macros::bitvec":"prelude::macros::bitvec","macros::internal::u8_from_le_bits":"macros::internal::u8_from_le_bits","mem::BitMemory":"prelude::traits::BitMemory","order::BitOrder":"prelude::traits::BitOrder","order::Local":"prelude::types::Local","order::Lsb0":"prelude::types::Lsb0","order::Msb0":"prelude::types::Msb0","slice::BitSlice":"prelude::types::BitSlice","slice::api::BitSliceIndex":"slice::BitSliceIndex","slice::api::from_mut":"slice::from_mut","slice::api::from_raw_parts":"slice::from_raw_parts","slice::api::from_raw_parts_mut":"slice::from_raw_parts_mut","slice::api::from_ref":"slice::from_ref","slice::iter::Chunks":"slice::Chunks","slice::iter::ChunksExact":"slice::ChunksExact","slice::iter::ChunksExactMut":"slice::ChunksExactMut","slice::iter::ChunksMut":"slice::ChunksMut","slice::iter::Iter":"slice::Iter","slice::iter::IterMut":"slice::IterMut","slice::iter::RChunks":"slice::RChunks","slice::iter::RChunksExact":"slice::RChunksExact","slice::iter::RChunksExactMut":"slice::RChunksExactMut","slice::iter::RChunksMut":"slice::RChunksMut","slice::iter::RSplit":"slice::RSplit","slice::iter::RSplitMut":"slice::RSplitMut","slice::iter::RSplitN":"slice::RSplitN","slice::iter::RSplitNMut":"slice::RSplitNMut","slice::iter::Split":"slice::Split","slice::iter::SplitMut":"slice::SplitMut","slice::iter::SplitN":"slice::SplitN","slice::iter::SplitNMut":"slice::SplitNMut","slice::iter::Windows":"slice::Windows","slice::proxy::BitMut":"slice::BitMut","store::BitStore":"prelude::traits::BitStore","vec::BitVec":"prelude::types::BitVec","vec::iter::Drain":"vec::Drain","vec::iter::IntoIter":"vec::IntoIter","vec::iter::Splice":"vec::Splice","view::BitView":"prelude::trait_methods::BitView"},"srcs":{"<A as view::AsBits<T>>::as_bits":["#[inline]\nfn as_bits<O>(&self) -> &BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tself.as_ref().view_bits::<O>()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<A as view::AsBitsMut<T>>::as_bits_mut":["#[inline]\nfn as_bits_mut<O>(&mut self) -> &mut BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tself.as_mut().view_bits_mut::<O>()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<T as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t1\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<T as view::BitView>::view_bits":["#[inline(always)]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::from_element(self)\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<T as view::BitView>::view_bits_mut":["#[inline(always)]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::from_element_mut(self)\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 0] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t0\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 0] as view::BitView>::view_bits":["#[inline(always)]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::empty()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 0] as view::BitView>::view_bits_mut":["#[inline(always)]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::empty_mut()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 10] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 10] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 10] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 11] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 11] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 11] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 12] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 12] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 12] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 13] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 13] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 13] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 14] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 14] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 14] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 15] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 15] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 15] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 16] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 16] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 16] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 17] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 17] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 17] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 18] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 18] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 18] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 19] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 19] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 19] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 1] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 1] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 1] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 20] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 20] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 20] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 21] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 21] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 21] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 22] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 22] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 22] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 23] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 23] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 23] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 24] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 24] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 24] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 25] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 25] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 25] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 26] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 26] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 26] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 27] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 27] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 27] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 28] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 28] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 28] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 29] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 29] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 29] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 2] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 2] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 2] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 30] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 30] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 30] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 31] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 31] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 31] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 32] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 32] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 32] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 33] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 33] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 33] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 34] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 34] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 34] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 35] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 35] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 35] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 36] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 36] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 36] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 37] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 37] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 37] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 38] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 38] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 38] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 39] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 39] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 39] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 3] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 3] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 3] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 40] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 40] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 40] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 41] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 41] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 41] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 42] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 42] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 42] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 43] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 43] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 43] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 44] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 44] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 44] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 45] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 45] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 45] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 46] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 46] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 46] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 47] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 47] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 47] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 48] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 48] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 48] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 49] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 49] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 49] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 4] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 4] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 4] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 50] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 50] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 50] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 51] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 51] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 51] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 52] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 52] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 52] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 53] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 53] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 53] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 54] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 54] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 54] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 55] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 55] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 55] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 56] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 56] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 56] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 57] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 57] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 57] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 58] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 58] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 58] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 59] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 59] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 59] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 5] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 5] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 5] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 60] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 60] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 60] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 61] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 61] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 61] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 62] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 62] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 62] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 63] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 63] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 63] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 64] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 64] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 64] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 6] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 6] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 6] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 7] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 7] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 7] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 8] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 8] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 8] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 9] as view::BitView>::const_elts":["#[doc(hidden)]\n#[inline(always)]\nfn const_elts() -> usize{\n\t\t\t\t$n\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 9] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_ref()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T; 9] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\t\t\twhere O: BitOrder{\n\t\t\t\tunsafe {\n\t\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\t\tself.as_ptr(),\n\t\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\t\t$n * T::Mem::BITS as usize,\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\t.to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T] as view::BitView>::const_elts":["/// Slices cannot implement this function.\n#[cold]\n#[doc(hidden)]\n#[inline(never)]\nfn const_elts() -> usize{\n\t\tunreachable!(\"This cannot be called on unsized slices\")\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T] as view::BitView>::view_bits":["#[inline]\nfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::from_slice(self).expect(\"slice was too long to view as bits\")\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<[T] as view::BitView>::view_bits_mut":["#[inline]\nfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tBitSlice::from_slice_mut(self)\n\t\t\t.expect(\"slice was too long to view as bits\")\n\t}","Real(LocalPath(\"src/view.rs\"))"],"<array::BitArray<O, V> as field::BitField>::load_be":["#[inline]\nfn load_be<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_be()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<array::BitArray<O, V> as field::BitField>::load_le":["#[inline]\nfn load_le<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_le()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<array::BitArray<O, V> as field::BitField>::store_be":["#[inline]\nfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_be(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<array::BitArray<O, V> as field::BitField>::store_le":["#[inline]\nfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_le(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<array::traits::TryFromBitSliceError as std::fmt::Display>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tfmt.write_str(\"could not convert bitslice to bitarray\")\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"<boxed::BitBox<O, T> as field::BitField>::load_be":["#[inline]\nfn load_be<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_be()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<boxed::BitBox<O, T> as field::BitField>::load_le":["#[inline]\nfn load_le<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_le()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<boxed::BitBox<O, T> as field::BitField>::store_be":["#[inline]\nfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_be(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<boxed::BitBox<O, T> as field::BitField>::store_le":["#[inline]\nfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_le(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<domain::BitDomain<'_, O, T> as std::clone::Clone>::clone":["#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn clone(&self) -> Self{\n\t\t*self\n\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::clone::Clone>::clone":["#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn clone(&self) -> Self{\n\t\t*self\n\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::fmt::Binary>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_list()\n\t\t\t\t\t.entries(self.into_iter().map(FmtForward::$fwd))\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::fmt::LowerHex>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_list()\n\t\t\t\t\t.entries(self.into_iter().map(FmtForward::$fwd))\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::fmt::Octal>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_list()\n\t\t\t\t\t.entries(self.into_iter().map(FmtForward::$fwd))\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::fmt::UpperHex>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_list()\n\t\t\t\t\t.entries(self.into_iter().map(FmtForward::$fwd))\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'_, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tmatch self {\n\t\t\tSelf::Enclave { .. } => 1,\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\thead.is_some() as usize + body.len() + tail.is_some() as usize\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'a, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tmatch self {\n\t\t\tSelf::Enclave { elem, .. } => (*elem)\n\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t.pipe(Some)\n\t\t\t\t.tap(|_| *self = Self::empty()),\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, _)) = *tail {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *tail = None);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, rest)) = body.split_last() {\n\t\t\t\t\t*body = rest;\n\t\t\t\t\treturn Some(*elem);\n\t\t\t\t}\n\t\t\t\tif let Some((_, elem)) = *head {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *head = None);\n\t\t\t\t}\n\t\t\t\tNone\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/domain.rs\"))"],"<domain::Domain<'a, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tmatch self {\n\t\t\tSelf::Enclave { elem, .. } => (*elem)\n\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t.pipe(Some)\n\t\t\t\t.tap(|_| *self = Self::empty()),\n\t\t\tSelf::Region { head, body, tail } => {\n\t\t\t\tif let Some((_, elem)) = *head {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *head = None);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, rest)) = body.split_first() {\n\t\t\t\t\t*body = rest;\n\t\t\t\t\treturn Some(*elem);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, _)) = *tail {\n\t\t\t\t\treturn elem\n\t\t\t\t\t\t.pipe(dvl::load_aliased_local::<T>)\n\t\t\t\t\t\t.pipe(Some)\n\t\t\t\t\t\t.tap(|_| *tail = None);\n\t\t\t\t}\n\t\t\t\tNone\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/domain.rs\"))"],"<index::BitIdx<M> as std::fmt::Binary>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"{:0>1$b}\", self.idx, M::INDX as usize)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitIdx<M> as std::fmt::Debug>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitIdx<{}>({})\", type_name::<M>(), self.idx)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitIdx<M> as std::fmt::Display>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tDisplay::fmt(&self.idx, fmt)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitMask<{}>(\", type_name::<M>())?;\n\t\tDisplay::fmt(&self, fmt)?;\n\t\tfmt.write_str(\")\")\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::fmt::Display>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"{:0>1$b}\", self.mask, M::BITS as usize)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::iter::Sum<index::BitSel<M>>>::sum":["fn sum<I>(iter: I) -> Self\n\twhere I: Iterator<Item = BitSel<M>>{\n\t\titer.fold(Self::ZERO, Self::combine)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::ops::BitAnd<M>>::bitand":["fn bitand(self, rhs: M) -> Self{\n\t\tmake!(mask self.mask & rhs)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::ops::BitOr<M>>::bitor":["fn bitor(self, rhs: M) -> Self{\n\t\tmake!(mask self.mask | rhs)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitMask<M> as std::ops::Not>::not":["fn not(self) -> Self::Output{\n\t\tmake!(mask !self.mask)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitPos<M> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitPos<{}>({})\", type_name::<M>(), self.pos)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitSel<M> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitSel<{}>(\", type_name::<M>())?;\n\t\tDisplay::fmt(&self, fmt)?;\n\t\tfmt.write_str(\")\")\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitSel<M> as std::fmt::Display>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"{:0>1$b}\", self.sel, M::BITS as usize)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitTail<M> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitTail<{}>({})\", type_name::<M>(), self.end)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<index::BitTail<M> as std::fmt::Display>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tDisplay::fmt(&self.end, fmt)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"<order::Lsb0 as order::BitOrder>::at":["inline(always)\nfn at<M>(index: BitIdx<M>) -> BitPos<M>\n\twhere M: BitMemory{\n\t\tunsafe { BitPos::new_unchecked(index.value()) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<order::Lsb0 as order::BitOrder>::mask":["fn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,{\n\t\tlet from = from.into().unwrap_or(BitIdx::ZERO).value();\n\t\tlet upto = upto.into().unwrap_or(BitTail::END).value();\n\t\tdebug_assert!(upto >= from, \"Ranges must run from low index to high\");\n\t\tlet ct = upto - from;\n\t\tif ct == M::BITS {\n\t\t\treturn BitMask::ALL;\n\t\t}\n\t\t//  1. Set all bits high.\n\t\t//  2. Shift left by the number of bits in the mask. These are now low.\n\t\t//  3. Invert. The mask bits are high, the rest are low, but at LSedge.\n\t\t//  4. Shift left by the distance from LSedge.\n\t\tunsafe { BitMask::new(!(M::ALL << ct) << from) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<order::Lsb0 as order::BitOrder>::select":["inline(always)\nfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory{\n\t\tunsafe { BitSel::new_unchecked(M::ONE << index.value()) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<order::Msb0 as order::BitOrder>::at":["#[inline]\nfn at<M>(index: BitIdx<M>) -> BitPos<M>\n\twhere M: BitMemory{\n\t\tunsafe { BitPos::new_unchecked(M::MASK - index.value()) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<order::Msb0 as order::BitOrder>::mask":["fn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,{\n\t\tlet from = from.into().unwrap_or(BitIdx::ZERO).value();\n\t\tlet upto = upto.into().unwrap_or(BitTail::END).value();\n\t\tdebug_assert!(upto >= from, \"Ranges must run from low index to high\");\n\t\tlet ct = upto - from;\n\t\tif ct == M::BITS {\n\t\t\treturn BitMask::ALL;\n\t\t}\n\t\t//  1. Set all bits high\n\t\t//  2. Shift right by the number of bits in the mask. These are now low.\n\t\t//  3. Invert. The mask bits are high, the rest are low, but at MSedge.\n\t\t//  4. Shift right by the distance from MSedge.\n\t\tunsafe { BitMask::new(!(M::ALL >> ct) >> from) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<order::Msb0 as order::BitOrder>::select":["#[inline]\nfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory{\n\t\t/* Set the MSbit, then shift it down. The left expr is const-folded.\n\t\tNote: this is not equivalent to `1 << (mask - index)`, because that\n\t\trequires a runtime subtraction, but the expression below is only a\n\t\tsingle right-shift.\n\t\t*/\n\t\tunsafe { BitSel::new_unchecked((M::ONE << M::MASK) >> index.value()) }\n\t}","Real(LocalPath(\"src/order.rs\"))"],"<pointer::Address<T> as std::clone::Clone>::clone":["#[inline(always)]\nfn clone(&self) -> Self{\n\t\tSelf { ..*self }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::convert::From<&T>>::from":["#[inline(always)]\nfn from(addr: &T) -> Self{\n\t\t(addr as *const T).into()\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::convert::From<&mut T>>::from":["#[inline(always)]\nfn from(addr: &mut T) -> Self{\n\t\t(addr as *mut T).into()\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::convert::From<*const T>>::from":["#[inline(always)]\nfn from(addr: *const T) -> Self{\n\t\tSelf::new((addr) as usize)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::convert::From<*mut T>>::from":["#[inline(always)]\nfn from(addr: *mut T) -> Self{\n\t\tSelf::new(addr as usize)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::fmt::Debug>::fmt":["#[inline(always)]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t<Self as Pointer>::fmt(&self, fmt)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::Address<T> as std::fmt::Pointer>::fmt":["#[inline(always)]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tPointer::fmt(&self.to_const(), fmt)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::BitPtr<T> as std::clone::Clone>::clone":["fn clone(&self) -> Self{\n\t\tSelf { ..*self }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::BitPtr<T> as std::cmp::PartialEq<pointer::BitPtr<U>>>::eq":["fn eq(&self, other: &BitPtr<U>) -> bool{\n\t\tlet (addr_a, head_a, bits_a) = self.raw_parts();\n\t\tlet (addr_b, head_b, bits_b) = other.raw_parts();\n\t\t//  Since ::BITS is an associated const, the compiler will automatically\n\t\t//  replace the entire function with `false` when the types don’t match.\n\t\tT::Mem::BITS == U::Mem::BITS\n\t\t\t&& addr_a.value() == addr_b.value()\n\t\t\t&& head_a.value() == head_b.value()\n\t\t\t&& bits_a == bits_b\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::BitPtr<T> as std::default::Default>::default":["#[inline(always)]\nfn default() -> Self{\n\t\tSelf::EMPTY\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::BitPtr<T> as std::fmt::Debug>::fmt":["#[inline(always)]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tPointer::fmt(self, fmt)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<pointer::BitPtr<T> as std::fmt::Pointer>::fmt":["#[inline(always)]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tself.render(fmt, \"Ptr\", None, None)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_be":["#[inline]\nfn load_be<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum =\n\t\t\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, None), head.value());\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum <<= tail.value();\n\t\t\t\t\taccum |= get::<T, M>(elem, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_le":["#[inline]\nfn load_le<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\t//  In Lsb0, a `head` index counts distance from LSedge, and a\n\t\t\t//  `tail` index counts element width minus distance from MSedge.\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tget::<T, M>(elem, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\t/* For multi-`T::Mem` domains, the most significant chunk is\n\t\t\t\tstored in the highest memory address, the tail. Each successive\n\t\t\t\tmemory address lower has a chunk of decreasing significance,\n\t\t\t\tuntil the least significant chunk is stored in the lowest memory\n\t\t\t\taddress, the head.\n\t\t\t\t*/\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum = get::<T, M>(elem, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().rev().copied() {\n\t\t\t\t\t/* Rust does not allow the use of shift instructions of\n\t\t\t\t\texactly a type width to clear a value. This loop only enters\n\t\t\t\t\twhen `M` is not narrower than `T::Mem`, and the shift is\n\t\t\t\t\tonly needed when `M` occupies *more than one* `T::Mem` slot.\n\t\t\t\t\tWhen `M` is exactly as wide as `T::Mem`, this loop either\n\t\t\t\t\tdoes not runs (head and tail only), or runs once (single\n\t\t\t\t\telement), and thus the shift is unnecessary.\n\n\t\t\t\t\tAs a const-expression, this branch folds at compile-time to\n\t\t\t\t\tconditionally remove or retain the instruction.\n\t\t\t\t\t*/\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tlet shamt = head.value();\n\t\t\t\t\taccum <<= T::Mem::BITS - shamt;\n\t\t\t\t\taccum |= get::<T, M>(elem, Lsb0::mask(head, None), shamt);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_be":["#[inline]\nfn store_be<M>(&mut self, mut value: M)\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(None, tail), 0);\n\t\t\t\t\tvalue >>= tail.value()\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut().rev() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tLsb0::mask(head, None),\n\t\t\t\t\t\thead.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_le":["#[inline]\nfn store_le<M>(&mut self, mut value: M)\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, tail), head.value())\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tlet shamt = head.value();\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(head, None), shamt);\n\t\t\t\t\tvalue >>= T::Mem::BITS - shamt;\n\t\t\t\t}\n\n\t\t\t\tfor elem in body {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(elem, value, Lsb0::mask(None, tail), 0);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_be":["#[inline]\nfn load_be<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => get::<T, M>(\n\t\t\t\telem,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum = get::<T, M>(elem, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tlet width = tail.value();\n\t\t\t\t\taccum <<= width;\n\t\t\t\t\taccum |= get::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - width,\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_le":["#[inline]\nfn load_le<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"load\", len, M::BITS);\n\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => get::<T, M>(\n\t\t\t\telem,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\tlet mut accum = M::ZERO;\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\taccum = get::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter().rev().copied() {\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\taccum <<= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t\taccum |= resize::<T::Mem, M>(elem);\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\taccum <<= T::Mem::BITS - head.value();\n\t\t\t\t\taccum |= get::<T, M>(elem, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\n\t\t\t\taccum\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_be":["#[inline]\nfn store_be<M>(&mut self, mut value: M)\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => set::<T, M>(\n\t\t\t\telem,\n\t\t\t\tvalue,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t\tvalue >>= tail.value();\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut().rev() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(elem, value, Msb0::mask(head, None), 0);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_le":["#[inline]\nfn store_le<M>(&mut self, mut value: M)\n\twhere M: BitMemory{\n\t\tlet len = self.len();\n\t\tcheck(\"store\", len, M::BITS);\n\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => set::<T, M>(\n\t\t\t\telem,\n\t\t\t\tvalue,\n\t\t\t\tMsb0::mask(head, tail),\n\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t),\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tset::<T, M>(elem, value, Msb0::mask(head, None), 0);\n\t\t\t\t\tvalue >>= T::Mem::BITS - head.value();\n\t\t\t\t}\n\n\t\t\t\tfor elem in body.iter_mut() {\n\t\t\t\t\t*elem = resize(value);\n\t\t\t\t\tif M::BITS > T::Mem::BITS {\n\t\t\t\t\t\tvalue >>= T::Mem::BITS;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tset::<T, M>(\n\t\t\t\t\t\telem,\n\t\t\t\t\t\tvalue,\n\t\t\t\t\t\tMsb0::mask(None, tail),\n\t\t\t\t\t\tT::Mem::BITS - tail.value(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<slice::iter::Chunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tmatch self.slice.len() {\n\t\t\t0 => 0,\n\t\t\tlen => {\n\t\t\t\t//  an explicit `div_mod` would be nice here\n\t\t\t\tlet (n, r) = (len / self.width, len % self.width);\n\t\t\t\tn + (r > 0) as usize\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tmatch self.slice.len() {\n\t\t\t0 => None,\n\t\t\tlen => {\n\t\t\t\t//  Determine if the back chunk is a remnant or a whole chunk.\n\t\t\t\tlet rem = len % self.width;\n\t\t\t\tlet size = if rem == 0 { self.width } else { rem };\n\t\t\t\tlet (rest, out) =\n\t\t\t\t\tunsafe { self.slice.split_at_unchecked(len - size) };\n\t\t\t\tself.slice = rest;\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tif n >= len {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet start = (len - 1 - n) * self.width;\n\t\tlet width = cmp::min(start + self.width, self.slice.len());\n\t\tlet (rest, out) = unsafe {\n\t\t\tself.slice\n\t\t\t\t//  Truncate to the end of the returned chunk,\n\t\t\t\t.get_unchecked(.. start + width)\n\t\t\t\t//  then split at the start of the returned chunk.\n\t\t\t\t.split_at_unchecked(start)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tif len == 0 {\n\t\t\treturn None;\n\t\t}\n\t\tlet mid = cmp::min(len, self.width);\n\t\tlet (out, rest) = unsafe { self.slice.split_at_unchecked(mid) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start >= len || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe {\n\t\t\tself.slice\n\t\t\t\t//  Discard the skipped front chunks,\n\t\t\t\t.get_unchecked(start ..)\n\t\t\t\t//  then split at the chunk width, or remnant length.\n\t\t\t\t.split_at_unchecked(cmp::min(len, self.width))\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tself.slice.len() / self.width\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tif len < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (rest, out) =\n\t\t\tunsafe { self.slice.split_at_unchecked(len - self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tif n >= len {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet end = (len - n) * self.width;\n\t\tlet (rest, out) = unsafe {\n\t\t\tself.slice\n\t\t\t\t.get_unchecked(.. end)\n\t\t\t\t.split_at_unchecked(end - self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tif self.slice.len() < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe { self.slice.split_at_unchecked(self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start + self.width >= self.slice.len() || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe {\n\t\t\tself.slice\n\t\t\t\t.get_unchecked(start ..)\n\t\t\t\t.split_at_unchecked(self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tself.slice.len() / self.width\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tif len < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (rest, out) =\n\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(len - self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tif n >= len {\n\t\t\treturn None;\n\t\t}\n\t\tlet end = (len - n) * self.width;\n\t\tlet (rest, out) = unsafe {\n\t\t\tslice.get_unchecked_mut(.. end)\n\t\t\t\t.split_at_aliased_unchecked_mut(end - self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tif slice.len() < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) =\n\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start + self.width >= slice.len() || ovf {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe {\n\t\t\tslice.get_unchecked_mut(start ..)\n\t\t\t\t.split_at_aliased_unchecked_mut(self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tmatch self.slice.len() {\n\t\t\t0 => 0,\n\t\t\tlen => {\n\t\t\t\t//  an explicit `div_mod` would be nice here\n\t\t\t\tlet (n, r) = (len / self.width, len % self.width);\n\t\t\t\tn + (r > 0) as usize\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tmatch slice.len() {\n\t\t\t0 => None,\n\t\t\tlen => {\n\t\t\t\t//  Determine if the back chunk is a remnant or a whole chunk.\n\t\t\t\tlet rem = len % self.width;\n\t\t\t\tlet size = if rem == 0 { self.width } else { rem };\n\t\t\t\tlet (rest, out) =\n\t\t\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(len - size) };\n\t\t\t\tself.slice = rest;\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tif n >= len {\n\t\t\treturn None;\n\t\t}\n\t\tlet start = (len - 1 - n) * self.width;\n\t\tlet width = cmp::min(start + self.width, slice.len());\n\t\tlet (rest, out) = unsafe {\n\t\t\tslice\n\t\t\t\t//  Truncate to the end of the returned chunk,\n\t\t\t\t.get_unchecked_mut(.. start + width)\n\t\t\t\t//  then split at the start of the returned chunk.\n\t\t\t\t.split_at_aliased_unchecked_mut(start)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tif len == 0 {\n\t\t\treturn None;\n\t\t}\n\t\tlet mid = cmp::min(len, self.width);\n\t\tlet (out, rest) = unsafe { slice.split_at_aliased_unchecked_mut(mid) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start >= len || ovf {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe {\n\t\t\tslice\n\t\t\t\t//  Discard the skipped front chunks,\n\t\t\t\t.get_unchecked_mut(start ..)\n\t\t\t\t//  then split at the chunk width, or remnant length.\n\t\t\t\t.split_at_aliased_unchecked_mut(cmp::min(len, self.width))\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'_, O, T> as std::clone::Clone>::clone":["fn clone(&self) -> Self{\n\t\t*self\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["#[cfg(not(tarpaulin_include))]\nfn as_ref(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'_, O, T> as std::iter::ExactSizeIterator>::len":["fn len(&self) -> usize{\n\t\t\t\tlet (base, last) =\n\t\t\t\t\t(self.base.as_ptr() as usize, self.last.as_ptr() as usize);\n\t\t\t\t/* Get the total number of bits in the element range\n\t\t\t\t`self.base .. self.last`. Wrapping arithmetic is used because\n\t\t\t\t`last` is known to never be less than base, so we always want a\n\t\t\t\tbare `sub` instruction without any checks. We also know that the\n\t\t\t\tdifference between the two addresses can support a `shl`\n\t\t\t\tinstruction without overflow.\n\t\t\t\t*/\n\t\t\t\tlast.wrapping_sub(base)\n\t\t\t\t\t.wrapping_shl(T::Mem::INDX as u32)\n\t\t\t\t\t//  Now, add the live bits before `self.tail` in `*last`,\n\t\t\t\t\t.wrapping_add(self.tail.value() as usize)\n\t\t\t\t\t//  And remove the dead bits before `self.head` in `*base`.\n\t\t\t\t\t.wrapping_sub(self.head.value() as usize)\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_back())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the tail cursors down by `n` bits before producing a\n\t\t\t\t//  bit.\n\t\t\t\tlet (elts, tail) = self.tail.offset(-(n as isize));\n\t\t\t\tself.last =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.last.as_ptr().offset(elts)) };\n\t\t\t\tself.tail = tail;\n\t\t\t\tSome(self.pop_back())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_front())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the head cursors up by `n` bits before producing a bit.\n\t\t\t\tlet (elts, head) = self.head.offset(n as isize);\n\t\t\t\tself.base =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.base.as_ptr().offset(elts)) };\n\t\t\t\tself.head = head;\n\t\t\t\tSome(self.pop_front())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["fn len(&self) -> usize{\n\t\t\t\tlet (base, last) =\n\t\t\t\t\t(self.base.as_ptr() as usize, self.last.as_ptr() as usize);\n\t\t\t\t/* Get the total number of bits in the element range\n\t\t\t\t`self.base .. self.last`. Wrapping arithmetic is used because\n\t\t\t\t`last` is known to never be less than base, so we always want a\n\t\t\t\tbare `sub` instruction without any checks. We also know that the\n\t\t\t\tdifference between the two addresses can support a `shl`\n\t\t\t\tinstruction without overflow.\n\t\t\t\t*/\n\t\t\t\tlast.wrapping_sub(base)\n\t\t\t\t\t.wrapping_shl(T::Mem::INDX as u32)\n\t\t\t\t\t//  Now, add the live bits before `self.tail` in `*last`,\n\t\t\t\t\t.wrapping_add(self.tail.value() as usize)\n\t\t\t\t\t//  And remove the dead bits before `self.head` in `*base`.\n\t\t\t\t\t.wrapping_sub(self.head.value() as usize)\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_back())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the tail cursors down by `n` bits before producing a\n\t\t\t\t//  bit.\n\t\t\t\tlet (elts, tail) = self.tail.offset(-(n as isize));\n\t\t\t\tself.last =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.last.as_ptr().offset(elts)) };\n\t\t\t\tself.tail = tail;\n\t\t\t\tSome(self.pop_back())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.inherent_is_empty() {\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\t\t\t\tSome(self.pop_front())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\t\t\tif n >= self.len() {\n\t\t\t\t\t*self = Self::EMPTY;\n\t\t\t\t\treturn None;\n\t\t\t\t}\n\n\t\t\t\t//  Move the head cursors up by `n` bits before producing a bit.\n\t\t\t\tlet (elts, head) = self.head.offset(n as isize);\n\t\t\t\tself.base =\n\t\t\t\t\tunsafe { NonNull::new_unchecked(self.base.as_ptr().offset(elts)) };\n\t\t\t\tself.head = head;\n\t\t\t\tSome(self.pop_front())\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tmatch self.slice.len() {\n\t\t\t0 => 0,\n\t\t\tlen => {\n\t\t\t\tlet (n, r) = (len / self.width, len % self.width);\n\t\t\t\tn + (r > 0) as usize\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tmatch self.slice.len() {\n\t\t\t0 => None,\n\t\t\tn => {\n\t\t\t\tlet rem = n % self.width;\n\t\t\t\tlet len = if rem == 0 { self.width } else { rem };\n\t\t\t\tlet (out, rest) = unsafe { self.slice.split_at_unchecked(len) };\n\t\t\t\tself.slice = rest;\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tif n >= len {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\t/* Taking from the back of a reverse iterator means taking from the\n\t\tfront of the slice.\n\n\t\t`len` gives us the total number of subslices remaining. In order to find\n\t\tthe partition point, we need to subtract `n - 1` full subslices from\n\t\tthat count (because the back slice of the iteration might not be full),\n\t\tcompute their bit width, and offset *that* from the end of the memory\n\t\tregion. This gives us the zero-based index of the partition point\n\t\tbetween what is returned and what is retained.\n\n\t\tThe `part ..` section of the slice is retained, and the very end of the\n\t\t`.. part` section is returned. The head section is split at no less than\n\t\t`self.width` bits below the end marker (this could be the partial\n\t\tsection, so a wrapping subtraction cannot be used), and `.. start` is\n\t\tdiscarded.\n\n\t\tSource:\n\t\thttps://doc.rust-lang.org/1.43.0/src/core/slice/mod.rs.html#5141-5156\n\t\t*/\n\t\tlet from_end = (len - 1 - n) * self.width;\n\t\tlet end = self.slice.len() - from_end;\n\t\tlet start = end.saturating_sub(self.width);\n\t\tlet (out, rest) = unsafe { self.slice.split_at_unchecked(end) };\n\t\tself.slice = rest;\n\t\tSome(unsafe { out.get_unchecked(start ..) })\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tif len == 0 {\n\t\t\treturn None;\n\t\t}\n\t\tlet mid = len - cmp::min(len, self.width);\n\t\tlet (rest, out) = unsafe { self.slice.split_at_unchecked(mid) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tlet (num, ovf) = n.overflowing_mul(self.width);\n\t\tif num >= len || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet end = len - num;\n\t\t//  Find the partition between `[.. retain]` and `[return ..][..w]`\n\t\tlet mid = end.saturating_sub(self.width);\n\t\tlet (rest, out) = unsafe {\n\t\t\tself.slice\n\t\t\t\t.get_unchecked(.. end)\n\t\t\t\t.split_at_unchecked(mid)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tself.slice.len() / self.width\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tif self.slice.len() < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) = unsafe { self.slice.split_at_unchecked(self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start >= len || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\t//  At this point, `start` is at least `self.width` less than `len`.\n\t\tlet (out, rest) = unsafe {\n\t\t\tself.slice.get_unchecked(start ..).split_at_unchecked(self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tif len < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (rest, out) =\n\t\t\tunsafe { self.slice.split_at_unchecked(len - self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tlet (split, ovf) = n.overflowing_mul(self.width);\n\t\tif split >= len || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tlet end = len - split;\n\t\tlet (rest, out) = unsafe {\n\t\t\tself.slice\n\t\t\t\t.get_unchecked(.. end)\n\t\t\t\t.split_at_unchecked(end - self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tself.slice.len() / self.width\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tif slice.len() < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (out, rest) =\n\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tlet (start, ovf) = n.overflowing_mul(self.width);\n\t\tif start >= len || ovf {\n\t\t\treturn None;\n\t\t}\n\t\t//  At this point, `start` is at least `self.width` less than `len`.\n\t\tlet (out, rest) = unsafe {\n\t\t\tslice.get_unchecked_mut(start ..)\n\t\t\t\t.split_at_aliased_unchecked_mut(self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tif len < self.width {\n\t\t\treturn None;\n\t\t}\n\t\tlet (rest, out) =\n\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(len - self.width) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tlet (split, ovf) = n.overflowing_mul(self.width);\n\t\tif split >= len || ovf {\n\t\t\treturn None;\n\t\t}\n\t\tlet end = len - split;\n\t\tlet (rest, out) = unsafe {\n\t\t\tslice.get_unchecked_mut(.. end)\n\t\t\t\t.split_at_aliased_unchecked_mut(end - self.width)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tmatch self.slice.len() {\n\t\t\t0 => 0,\n\t\t\tlen => {\n\t\t\t\tlet (n, r) = (len / self.width, len % self.width);\n\t\t\t\tn + (r > 0) as usize\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tmatch slice.len() {\n\t\t\t0 => None,\n\t\t\tn => {\n\t\t\t\tlet rem = n % self.width;\n\t\t\t\tlet len = if rem == 0 { self.width } else { rem };\n\t\t\t\tlet (out, rest) =\n\t\t\t\t\tunsafe { slice.split_at_aliased_unchecked_mut(len) };\n\t\t\t\tself.slice = rest;\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet len = self.len();\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tif n >= len {\n\t\t\treturn None;\n\t\t}\n\t\tlet from_end = (len - 1 - n) * self.width;\n\t\tlet end = slice.len() - from_end;\n\t\tlet start = end.saturating_sub(self.width);\n\t\tlet (out, rest) = unsafe { slice.split_at_aliased_unchecked_mut(end) };\n\t\tself.slice = rest;\n\t\tSome(unsafe { out.get_unchecked_mut(start ..) })\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tif len == 0 {\n\t\t\treturn None;\n\t\t}\n\t\tlet mid = len - cmp::min(len, self.width);\n\t\tlet (rest, out) = unsafe { slice.split_at_aliased_unchecked_mut(mid) };\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet slice = mem::take(&mut self.slice);\n\t\tlet len = slice.len();\n\t\tlet (num, ovf) = n.overflowing_mul(self.width);\n\t\tif num >= len || ovf {\n\t\t\treturn None;\n\t\t}\n\t\tlet end = len - num;\n\t\t//  Find the partition between `[.. retain]` and `[return ..][..w]`\n\t\tlet mid = end.saturating_sub(self.width);\n\t\tlet (rest, out) = unsafe {\n\t\t\tslice.get_unchecked_mut(.. end)\n\t\t\t\t.split_at_aliased_unchecked_mut(mid)\n\t\t};\n\t\tself.slice = rest;\n\t\tSome(out)\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplit<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplit<'a, O, T, P> as slice::iter::SplitIter>::finish":["#[inline]\nfn finish(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet mut split = Split::<'a, O, T, &mut P> {\n\t\t\tslice: mem::take(&mut self.slice),\n\t\t\tpred: &mut self.pred,\n\t\t\tdone: self.done,\n\t\t};\n\t\tlet out = split.next();\n\t\tself.slice = mem::take(&mut split.slice);\n\t\tself.done = split.done;\n\t\tout\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet mut split = Split::<'a, O, T, &mut P> {\n\t\t\tslice: mem::take(&mut self.slice),\n\t\t\tpred: &mut self.pred,\n\t\t\tdone: self.done,\n\t\t};\n\t\tlet out = split.next_back();\n\t\tself.slice = mem::take(&mut split.slice);\n\t\tself.done = split.done;\n\t\tout\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["#[inline]\nfn finish(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet mut split = SplitMut::<'a, O, T, &mut P> {\n\t\t\tslice: mem::take(&mut self.slice),\n\t\t\tpred: &mut self.pred,\n\t\t\tdone: self.done,\n\t\t};\n\t\tlet out = split.next();\n\t\tself.slice = mem::take(&mut split.slice);\n\t\tself.done = split.done;\n\t\tout\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tlet mut split = SplitMut::<'a, O, T, &mut P> {\n\t\t\tslice: mem::take(&mut self.slice),\n\t\t\tpred: &mut self.pred,\n\t\t\tdone: self.done,\n\t\t};\n\t\tlet out = split.next_back();\n\t\tself.slice = mem::take(&mut split.slice);\n\t\tself.done = split.done;\n\t\tout\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Split<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Split<'a, O, T, P> as slice::iter::SplitIter>::finish":["#[inline]\nfn finish(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Split<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tif self.done {\n\t\t\treturn None;\n\t\t}\n\t\tmatch self.slice\n\t\t\t.iter()\n\t\t\t.enumerate()\n\t\t\t.rposition(|(idx, bit)| (self.pred)(idx, bit))\n\t\t{\n\t\t\tNone => self.finish(),\n\t\t\tSome(idx) => unsafe {\n\t\t\t\tlet out = self.slice.get_unchecked(idx + 1 ..);\n\t\t\t\tself.slice = self.slice.get_unchecked(.. idx);\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tif self.done {\n\t\t\treturn None;\n\t\t}\n\t\tmatch self.slice\n\t\t\t.iter()\n\t\t\t.enumerate()\n\t\t\t.position(|(idx, bit)| (self.pred)(idx, bit))\n\t\t{\n\t\t\tNone => self.finish(),\n\t\t\tSome(idx) => unsafe {\n\t\t\t\tlet out = self.slice.get_unchecked(.. idx);\n\t\t\t\tself.slice = self.slice.get_unchecked(idx + 1 ..);\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($iter))\n\t\t\t\t\t.field(\"slice\", &self.slice)\n\t\t\t\t\t.field(\"done\", &self.done)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["#[inline]\nfn finish(&mut self) -> Option<Self::Item>{\n\t\t\t\tif self.done {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tself.done = true;\n\t\t\t\t\tSome(mem::take(&mut self.slice))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tif self.done {\n\t\t\treturn None;\n\t\t}\n\t\tlet idx_opt = {\n\t\t\tlet pred = &mut self.pred;\n\t\t\tself.slice\n\t\t\t\t.iter()\n\t\t\t\t.enumerate()\n\t\t\t\t.rposition(|(idx, bit)| (pred)(idx, bit))\n\t\t};\n\t\tmatch idx_opt\n\t\t{\n\t\t\tNone => self.finish(),\n\t\t\tSome(idx) => unsafe {\n\t\t\t\tlet slice = mem::take(&mut self.slice);\n\t\t\t\tlet (rest, out) = slice.split_at_aliased_unchecked_mut(idx);\n\t\t\t\tself.slice = rest;\n\t\t\t\tSome(out.get_unchecked_mut(1 ..))\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tif self.done {\n\t\t\treturn None;\n\t\t}\n\t\tlet idx_opt = {\n\t\t\tlet pred = &mut self.pred;\n\t\t\tself.slice\n\t\t\t\t.iter()\n\t\t\t\t.enumerate()\n\t\t\t\t.position(|(idx, bit)| (pred)(idx, bit))\n\t\t};\n\t\tmatch idx_opt\n\t\t{\n\t\t\tNone => self.finish(),\n\t\t\tSome(idx) => unsafe {\n\t\t\t\tlet slice = mem::take(&mut self.slice);\n\t\t\t\tlet (out, rest) = slice.split_at_aliased_unchecked_mut(idx);\n\t\t\t\tself.slice = rest.get_unchecked_mut(1 ..);\n\t\t\t\tSome(out)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tif self.done {\n\t\t\t\t\t(0, Some(0))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t(1, Some(self.slice.len() + 1))\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\tfmt.debug_struct(stringify!($outer))\n\t\t\t\t\t.field(\"slice\", &self.inner.slice)\n\t\t\t\t\t.field(\"count\", &self.count)\n\t\t\t\t\t.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\t\t\tmatch self.count {\n\t\t\t\t\t0 => None,\n\t\t\t\t\t1 => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.finish()\n\t\t\t\t\t},\n\t\t\t\t\t_ => {\n\t\t\t\t\t\tself.count -= 1;\n\t\t\t\t\t\tself.inner.next()\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet (low, hi) = self.inner.size_hint();\n\t\t\t\t(low, hi.map(|h| cmp::min(self.count, h)))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline]\nfn len(&self) -> usize{\n\t\tlet len = self.slice.len();\n\t\tif self.width > len {\n\t\t\treturn 0;\n\t\t}\n\t\tlen - self.width + 1\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tlet len = self.slice.len();\n\t\tif self.width > len {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tunsafe {\n\t\t\tlet out = self.slice.get_unchecked(len - self.width ..);\n\t\t\tself.slice = self.slice.get_unchecked(.. len - 1);\n\t\t\tSome(out)\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet (end, ovf) = self.slice.len().overflowing_sub(n);\n\t\tif end < self.width || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tunsafe {\n\t\t\tlet out = self.slice.get_unchecked(end - self.width .. end);\n\t\t\tself.slice = self.slice.get_unchecked(.. end - 1);\n\t\t\tSome(out)\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::count":["#[inline]\nfn count(self) -> usize{\n\t\t\t\tself.len()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::last":["#[inline]\nfn last(mut self) -> Option<Self::Item>{\n\t\t\t\tself.next_back()\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tif self.width > self.slice.len() {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tunsafe {\n\t\t\tlet out = self.slice.get_unchecked(.. self.width);\n\t\t\tself.slice = self.slice.get_unchecked(1 ..);\n\t\t\tSome(out)\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::nth":["#[inline]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tlet (end, ovf) = self.width.overflowing_add(n);\n\t\tif end > self.slice.len() || ovf {\n\t\t\tself.slice = Default::default();\n\t\t\treturn None;\n\t\t}\n\t\tunsafe {\n\t\t\tlet out = self.slice.get_unchecked(n .. end);\n\t\t\tself.slice = self.slice.get_unchecked(n + 1 ..);\n\t\t\tSome(out)\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::size_hint":["#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\t\t\tlet len = self.len();\n\t\t\t\t(len, Some(len))\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"<slice::proxy::BitMut<'_, O, T> as std::fmt::Debug>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\twrite!(fmt, \"BitMut<{}>\", core::any::type_name::<T::Mem>())?;\n\t\tfmt.debug_struct(\"\")\n\t\t\t.field(\"addr\", &self.addr.as_ptr().fmt_pointer())\n\t\t\t.field(\"head\", &self.head.fmt_binary())\n\t\t\t.field(\"data\", &self.data)\n\t\t\t.finish()\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Deref>::deref":["#[inline]\nfn deref(&self) -> &Self::Target{\n\t\t&self.data\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"<slice::proxy::BitMut<'_, O, T> as std::ops::DerefMut>::deref_mut":["#[inline]\nfn deref_mut(&mut self) -> &mut Self::Target{\n\t\t&mut self.data\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Drop>::drop":["#[inline(always)]\nfn drop(&mut self){\n\t\tlet value = self.data;\n\t\tself.write(value);\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"<slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"<slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"<slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"<slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\tlet len = slice.len();\n\n\t\tif self.start > len || self.end > len || self.start > self.end {\n\t\t\treturn None;\n\t\t}\n\n\t\tSome(unsafe { (self.start .. self.end).get_unchecked(slice) })\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\tlet (addr, head, _) = slice.bitptr().raw_parts();\n\n\t\tlet (skip, new_head) = head.offset(self.start as isize);\n\n\t\tBitPtr::new_unchecked(\n\t\t\taddr.to_const().offset(skip),\n\t\t\tnew_head,\n\t\t\tself.end - self.start,\n\t\t).to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["fn index(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\tlet len = slice.len();\n\t\tif self.start <= len {\n\t\t\tSome(unsafe { (self.start ..).get_unchecked(slice) })\n\t\t}\n\t\telse {\n\t\t\tNone\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\tlet (addr, head, bits) = slice.bitptr().raw_parts();\n\n\t\tlet (skip, new_head) = head.offset(self.start as isize);\n\n\t\tBitPtr::new_unchecked(\n\t\t\taddr.to_const().offset(skip),\n\t\t\tnew_head,\n\t\t\tbits - self.start,\n\t\t).to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["fn index(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\tSome(slice)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\tSome(slice)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\tslice\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\tslice\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index":["#[inline]\nfn index(self, slice: Self::Immut) -> Self::Immut{\n\t\tslice\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\tslice\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\t\t\t$func(self).get(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\t\t\t$func(self).get_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\t$func(self).get_unchecked(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\t$func(self).get_unchecked_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["#[inline]\nfn index(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\t$func(self).index(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\t$func(self).index_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\tlet len = slice.len();\n\t\tif self.end <= len {\n\t\t\tSome(unsafe { (.. self.end).get_unchecked(slice) })\n\t\t}\n\t\telse {\n\t\t\tNone\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\t\t\tself.get(slice).map(|s| s.bitptr().to_bitslice_mut())\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\tlet mut bp = slice.bitptr();\n\t\tbp.set_len(self.end);\n\t\tbp.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.get_unchecked(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["fn index(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\tlet r = self.clone();\n\t\t\t\tlet l = slice.len();\n\t\t\t\tself.get(slice)\n\t\t\t\t\t.unwrap_or_else(|| {\n\t\t\t\t\t\tpanic!(\"Range {:?} out of bounds: {}\", r, l)\n\t\t\t\t\t})\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\tself.index(slice).bitptr().to_bitslice_mut()\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: Self::Immut) -> Option<Self::Immut>{\n\t\t\t\t$func(self).get(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: Self::Mut) -> Option<Self::Mut>{\n\t\t\t\t$func(self).get_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\t$func(self).get_unchecked(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\t$func(self).get_unchecked_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["#[inline]\nfn index(self, slice: Self::Immut) -> Self::Immut{\n\t\t\t\t$func(self).index(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: Self::Mut) -> Self::Mut{\n\t\t\t\t$func(self).index_mut(slice)\n\t\t\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get":["#[inline]\nfn get(self, slice: &'a BitSlice<O, T>) -> Option<Self::Immut>{\n\t\tif self < slice.len() {\n\t\t\tSome(unsafe { self.get_unchecked(slice) })\n\t\t}\n\t\telse {\n\t\t\tNone\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["#[inline]\nfn get_mut(self, slice: &'a mut BitSlice<O, T>) -> Option<Self::Mut>{\n\t\tif self < slice.len() {\n\t\t\tSome(unsafe { self.get_unchecked_mut(slice) })\n\t\t}\n\t\telse {\n\t\t\tNone\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["#[inline]\nunsafe fn get_unchecked(self, slice: &'a BitSlice<O, T>) -> Self::Immut{\n\t\tif slice.bitptr().read::<O>(self) {\n\t\t\t&true\n\t\t}\n\t\telse {\n\t\t\t&false\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["#[inline]\nunsafe fn get_unchecked_mut(\n\t\tself,\n\t\tslice: &'a mut BitSlice<O, T>,\n\t) -> Self::Mut{\n\t\tlet bitptr = slice.bitptr();\n\t\tlet (elt, bit) = bitptr.head().offset(self as isize);\n\t\tlet addr = bitptr.pointer().to_access().offset(elt);\n\t\tBitMut::new_unchecked(addr, bit)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index":["#[inline]\nfn index(self, slice: &'a BitSlice<O, T>) -> Self::Immut{\n\t\tself.get(slice).unwrap_or_else(|| {\n\t\t\tpanic!(\"Index {} out of bounds: {}\", self, slice.len())\n\t\t})\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["#[inline]\nfn index_mut(self, slice: &'a mut BitSlice<O, T>) -> Self::Mut{\n\t\tlet len = slice.len();\n\t\tself.get_mut(slice)\n\t\t\t.unwrap_or_else(|| panic!(\"Index {} out of bounds: {}\", self, len))\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"<vec::BitVec<O, T> as field::BitField>::load_be":["#[inline]\nfn load_be<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_be()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<vec::BitVec<O, T> as field::BitField>::load_le":["#[inline]\nfn load_le<M>(&self) -> M\n\twhere M: BitMemory{\n\t\tself.as_bitslice().load_le()\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<vec::BitVec<O, T> as field::BitField>::store_be":["#[inline]\nfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_be(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<vec::BitVec<O, T> as field::BitField>::store_le":["#[inline]\nfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\tself.as_mut_bitslice().store_le(value)\n\t}","Real(LocalPath(\"src/field.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["#[inline(always)]\nfn as_ref(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::next_back":["#[inline(always)]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tself.drain.next_back().copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::nth_back":["#[inline(always)]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tself.drain.nth_back(n).copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::ExactSizeIterator>::len":["#[inline(always)]\nfn len(&self) -> usize{\n\t\tself.drain.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::count":["#[inline(always)]\nfn count(self) -> usize{\n\t\tself.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::last":["#[inline(always)]\nfn last(mut self) -> Option<Self::Item>{\n\t\tself.next_back()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::next":["#[inline(always)]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tself.drain.next().copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::nth":["#[inline(always)]\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tself.drain.nth(n).copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::size_hint":["#[inline(always)]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\tself.drain.size_hint()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'_, O, T> as std::ops::Drop>::drop":["#[inline]\nfn drop(&mut self){\n\t\t//  Grab the tail range descriptor\n\t\tlet tail = self.tail.clone();\n\t\t//  And compute its length.\n\t\tlet tail_len = tail.end - tail.start;\n\t\t//  If the tail region is empty, then there is no cleanup work to do.\n\t\tif tail_len == 0 {\n\t\t\treturn;\n\t\t}\n\t\t//  Otherwise, access the source vector,\n\t\tlet bitvec = unsafe { self.source.as_mut() };\n\t\t//  And grab its current end.\n\t\tlet old_len = bitvec.len();\n\t\tlet new_len = old_len + tail_len;\n\t\tunsafe {\n\t\t\t//  Expand the vector to include where the tail bits will be.\n\t\t\tbitvec.set_len(new_len);\n\t\t\t//  Then move the tail bits into the new location.\n\t\t\tbitvec.copy_within_unchecked(tail, old_len);\n\t\t\t//  This ordering is important! `copy_within_unchecked` uses the\n\t\t\t//  `len` boundary.\n\t\t}\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Drain<'a, O, T> as std::fmt::Debug>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tfmt.debug_tuple(\"Drain\")\n\t\t\t.field(&self.drain.as_bitslice())\n\t\t\t.finish()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::next_back":["inline(always)\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tself.iter.next_back().copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::nth_back":["inline(always)\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tself.iter.nth_back(n).copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::ExactSizeIterator>::len":["inline(always)\nfn len(&self) -> usize{\n\t\tself.iter.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::count":["inline(always)\nfn count(self) -> usize{\n\t\tself.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::last":["inline(always)\nfn last(mut self) -> Option<Self::Item>{\n\t\tself.next_back()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::next":["inline(always)\nfn next(&mut self) -> Option<Self::Item>{\n\t\tself.iter.next().copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::nth":["inline(always)\nfn nth(&mut self, n: usize) -> Option<Self::Item>{\n\t\tself.iter.nth(n).copied()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::size_hint":["inline(always)\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\tself.iter.size_hint()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::next_back":["#[inline(always)]\nfn next_back(&mut self) -> Option<Self::Item>{\n\t\tself.drain.next_back()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::nth_back":["#[inline(always)]\nfn nth_back(&mut self, n: usize) -> Option<Self::Item>{\n\t\tself.drain.nth_back(n)\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::ExactSizeIterator>::len":["#[inline(always)]\nfn len(&self) -> usize{\n\t\tself.drain.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::count":["#[inline(always)]\nfn count(self) -> usize{\n\t\tself.drain.len()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::next":["#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n\t\tself.drain.next().tap_some(|_| {\n\t\t\t/* Attempt to write a bit into the now-vacated slot at the front of\n\t\t\tthe `Drain`. If the `splice` stream produces a bit, then it is\n\t\t\twritten into the end of the `Drain`’s buffer, extending it by one.\n\t\t\tThis works because `Drain` always truncates its vector to the front\n\t\t\tedge of the drain region, so `bv.len()` is always the first bit of\n\t\t\tthe `Drain` region if the `Drain` is willing to yield a bit.\n\t\t\t*/\n\t\t\tif let Some(bit) = self.splice.next() {\n\t\t\t\tunsafe {\n\t\t\t\t\tlet bv = self.drain.source.as_mut();\n\t\t\t\t\tlet len = bv.len();\n\t\t\t\t\t/* TODO(myrrlyn): Investigate adding functionality to `Iter`\n\t\t\t\t\tthat permits an exchange behavior, rather than separated\n\t\t\t\t\tcomputations of the pointer for read and write access.\n\t\t\t\t\t*/\n\t\t\t\t\tbv.set_unchecked(len, bit);\n\t\t\t\t\tbv.set_len(len + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::size_hint":["#[inline(always)]\nfn size_hint(&self) -> (usize, Option<usize>){\n\t\tself.drain.size_hint()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"<vec::iter::Splice<'_, O, T, I> as std::ops::Drop>::drop":["#[inline]\nfn drop(&mut self){\n\t\tlet tail = self.drain.tail.clone();\n\t\tlet tail_len = tail.end - tail.start;\n\t\tlet bitvec = unsafe { self.drain.source.as_mut() };\n\n\t\t//  If the `drain` has no tail span, then extend the vector with the\n\t\t//  splice and exit.\n\t\tif tail_len == 0 {\n\t\t\tbitvec.extend(self.splice.by_ref());\n\t\t\treturn;\n\t\t}\n\n\t\t//  Fill the drained range first. If the `splice` exhausts, then the\n\t\t//  `Drain` destructor will handle relocating the vector tail segment.\n\t\tif let FillStatus::EmptyInput = self.drain.fill(&mut self.splice) {\n\t\t\treturn;\n\t\t}\n\n\t\t//  If the `splice` has not yet exhausted, then the `Drain` needs to\n\t\t//  adjust to receive its contents.\n\t\tlet len = match self.splice.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => n,\n\t\t};\n\t\tunsafe {\n\t\t\tself.drain.move_tail(len);\n\t\t}\n\t\t//  Now that the tail has been relocated, fill the `splice` into it. If\n\t\t//  this exhausts the `splice`, exit.\n\t\tif let FillStatus::EmptyInput = self.drain.fill(&mut self.splice) {\n\t\t\treturn;\n\t\t}\n\n\t\t//  If the `splice` *still* has bits to provide, then its `.size_hint()`\n\t\t//  is untrustworthy. Collect the `splice` into a vector, then insert\n\t\t//  the vector into the spliced region.\n\t\tlet mut collected = self.splice.by_ref().collect::<BitVec>().into_iter();\n\t\tlet len = collected.len();\n\t\tif len > 0 {\n\t\t\tunsafe {\n\t\t\t\tself.drain.move_tail(len);\n\t\t\t}\n\t\t\tlet filled = self.drain.fill(&mut collected);\n\t\t\tdebug_assert_eq!(filled, FillStatus::EmptyInput);\n\t\t\tdebug_assert_eq!(collected.len(), 0);\n\t\t}\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"access::BitAccess":["/** Access interface to memory locations.\n\nThis trait abstracts over the specific instructions used to perform accesses to\nmemory locations, so that use sites elsewhere in the crate can select their\nrequired behavior without changing the interface.\n\nThis is automatically implemented for all types that permit shared/mutable\nmemory access to register types through the `radium` crate. Its use is\nconstrained in the `store` module.\n**/\npub trait BitAccess<M>: Debug + Radium<M> + Sized\nwhere M: BitMemory\n{\n\t/// Sets one bit in a memory element to `0`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The semantic index of the bit in `*self` to be erased.\n\t///\n\t/// # Effects\n\t///\n\t/// The memory element at `*self` has the bit corresponding to `index` set\n\t/// to `0`, and all other bits are unchanged.\n\t#[inline]\n\tfn clear_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder {\n\t\tself.fetch_and(!index.select::<O>().value(), Ordering::Relaxed);\n\t}\n\n\t/// Set any number of bits in a memory element to `0`.\n\t///\n\t/// The mask provided to this method must be constructed from indices that\n\t/// are valid in the caller’s context. As the mask is already computed by\n\t/// the caller, this does not take an ordering type parameter.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n\t///   to modify.\n\t///\n\t/// # Effects\n\t///\n\t/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n\t/// to `0`, and all bits in `*self` that are not selected (set to `0`) in\n\t/// `mask` will be unchanged.\n\t///\n\t/// Do not invert the mask prior to calling this function in order to save\n\t/// the unselected bits and erase the selected bits. `BitMask` is a\n\t/// selection type, not a bitwise-operation argument.\n\t#[inline]\n\tfn clear_bits(&self, mask: BitMask<M>) {\n\t\tself.fetch_and(!mask.value(), Ordering::Relaxed);\n\t}\n\n\t/// Sets one bit in a memory element to `1`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The semantic index of the bit in `*self` to be written.\n\t///\n\t/// # Effects\n\t///\n\t/// The memory element at `*self` has the bit corresponding to `index` set\n\t/// to `1`, and all other bits are unchanged.\n\t#[inline]\n\tfn set_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder {\n\t\tself.fetch_or(index.select::<O>().value(), Ordering::Relaxed);\n\t}\n\n\t/// Sets any number of bits in a memory element to `1`.\n\t///\n\t/// The mask provided to this method must be constructed from indices that\n\t/// are valid in the caller’s context. As the mask is already computed by\n\t/// the caller, this does not need to take an ordering type parameter.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n\t///   to modify.\n\t///\n\t/// # Effects\n\t///\n\t/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n\t/// to `1`, and all bits in `*self` that are not selected (set to `0`) in\n\t/// `mask` will be unchanged.\n\t#[inline]\n\tfn set_bits(&self, mask: BitMask<M>) {\n\t\tself.fetch_or(mask.value(), Ordering::Relaxed);\n\t}\n\n\t/// Inverts the value of one bit in a memory element.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The semantic index of the bit in `*self` to be inverted.\n\t///\n\t/// # Effects\n\t///\n\t/// The memory element at `*self` has the bit corresponding to `index` set\n\t/// to the opposite of its current value. All other bits are unchanged.\n\t#[inline]\n\tfn invert_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder {\n\t\tself.fetch_xor(index.select::<O>().value(), Ordering::Relaxed);\n\t}\n\n\t/// Invert any number of bits in a memory element.\n\t///\n\t/// The mask provided to this method must be constructed from indices that\n\t/// are valid in the caller’s context. As the mask is already computed by\n\t/// the caller, this does not take an ordering type parameter.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n\t///   to modify.\n\t///\n\t/// # Effects\n\t///\n\t/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n\t/// to the opposite of their current value, and all bits in `*self` that are\n\t/// not selected (set to `0`) in `mask` will be unchanged.\n\t#[inline]\n\tfn invert_bits(&self, mask: BitMask<M>) {\n\t\tself.fetch_xor(mask.value(), Ordering::Relaxed);\n\t}\n\n\t/// Fetches the value of one bit in a memory element.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The semantic index of the bit in `*self` to read.\n\t///\n\t/// # Returns\n\t///\n\t/// The value of the bit in `*self` corresponding to `index`.\n\t#[inline]\n\tfn get_bit<O>(&self, index: BitIdx<M>) -> bool\n\twhere O: BitOrder {\n\t\tunsafe { BitMask::new(self.load_value()) }.test(index.select::<O>())\n\t}\n\n\t/// Fetches any number of bits from a memory element.\n\t///\n\t/// The mask provided to this method must be constructed from indices that\n\t/// are valid in the caller’s context. As the mask is already computed by\n\t/// the caller, this does not take an ordering type parameter.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n\t///   to read.\n\t///\n\t/// # Returns\n\t///\n\t/// A copy of the memory element at `*self`, with all bits not selected (set\n\t/// to `0`) in `mask` erased and all bits selected (set to `1`) in `mask`\n\t/// preserved.\n\t#[inline]\n\tfn get_bits(&self, mask: BitMask<M>) -> M {\n\t\tself.load_value() & mask.value()\n\t}\n\n\t/// Writes a bit to an index within the `self` element.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `index`: The semantic index of the bit in `*self` to be written.\n\t/// - `value`: The bit value to write into `*self` at `index`.\n\t///\n\t/// # Effects\n\t///\n\t/// The bit in `*self` at `index` is set to the `value` bit.\n\t#[inline]\n\tfn write_bit<O>(&self, index: BitIdx<M>, value: bool)\n\twhere O: BitOrder {\n\t\tif value {\n\t\t\tself.set_bit::<O>(index);\n\t\t}\n\t\telse {\n\t\t\tself.clear_bit::<O>(index);\n\t\t}\n\t}\n\n\t/// Writes a bit value to any number of bits within the `self` element.\n\t///\n\t/// The mask provided to this method must be constructed from indices that\n\t/// are valid in the caller’s context. As the mask is already computed by\n\t/// the caller, this does not need to take an ordering type parameter.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n\t///   to modify.\n\t///\n\t/// # Effects\n\t///\n\t/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n\t/// to `value`, and all bits in `*self` that are not selected (set to `0`)\n\t/// in `mask` will be unchanged.\n\t#[inline]\n\tfn write_bits(&self, mask: BitMask<M>, value: bool) {\n\t\tif value {\n\t\t\tself.set_bits(mask);\n\t\t}\n\t\telse {\n\t\t\tself.clear_bits(mask);\n\t\t}\n\t}\n\n\t/// Gets the function that writes `value` to an index.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: A bit ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `value`: The bit that will be directly written by the returned\n\t///   function.\n\t///\n\t/// # Returns\n\t///\n\t/// A function which, when applied to a reference and an index, will write\n\t/// `value` into memory. If `value` is `false`, then this produces\n\t/// [`clear_bit`]; if it is `true`, then this produces [`set_bit`].\n\t///\n\t/// [`clear_bit`]: #method.clear_bit\n\t/// [`set_bit`]: #method.set_bit\n\t#[inline]\n\tfn get_writer<O>(value: bool) -> for<'a> fn(&'a Self, BitIdx<M>)\n\twhere O: BitOrder {\n\t\t[Self::clear_bit::<O>, Self::set_bit::<O>][value as usize]\n\t}\n\n\t/// Gets the function that writes `value` into all bits under a mask.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `value`: The bit that will be directly written by the returned\n\t///   function.\n\t///\n\t/// # Returns\n\t///\n\t/// A function which, when applied to a reference and a mask, will write\n\t/// `value` into memory. If `value` is `false`, then this produces\n\t/// [`clear_bits`]; if it is `true`, then this produces [`set_bits`].\n\t///\n\t/// [`clear_bits`]: #method.clear_bits\n\t/// [`set_bits`]: #method.set_bits\n\t#[inline]\n\tfn get_writers(value: bool) -> for<'a> fn(&'a Self, BitMask<M>) {\n\t\t[Self::clear_bits, Self::set_bits][value as usize]\n\t}\n\n\t/// Copies a memory element into the caller’s local context.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t///\n\t/// # Returns\n\t///\n\t/// A copy of the value at `*self`.\n\t#[inline]\n\tfn load_value(&self) -> M {\n\t\tself.load(Ordering::Relaxed)\n\t}\n\n\t/// Unconditionally writes a value into a memory location.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`\n\t/// - `value`: The new value to write into `*self`.\n\t///\n\t/// # Effects\n\t///\n\t/// The current value at `*self` is replaced with `value`.\n\t///\n\t/// # Safety\n\t///\n\t/// The calling context must either have write permissions to the entire\n\t/// memory element at `*self`, or construct a `value` that does not modify\n\t/// the bits of `*self` that the caller does not currently own.\n\t///\n\t/// As this directly permits the modification of memory outside the logical\n\t/// ownership of the caller, this method risks behavior that violates the\n\t/// Rust memory model, even if it may not be technically undefined.\n\t#[inline]\n\tunsafe fn store_value(&self, value: M) {\n\t\tself.store(value, Ordering::Relaxed)\n\t}\n}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::clear_bit":["/// Sets one bit in a memory element to `0`.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The semantic index of the bit in `*self` to be erased.\n///\n/// # Effects\n///\n/// The memory element at `*self` has the bit corresponding to `index` set\n/// to `0`, and all other bits are unchanged.\n#[inline]\nfn clear_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder{\n\t\tself.fetch_and(!index.select::<O>().value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::clear_bits":["/// Set any number of bits in a memory element to `0`.\n///\n/// The mask provided to this method must be constructed from indices that\n/// are valid in the caller’s context. As the mask is already computed by\n/// the caller, this does not take an ordering type parameter.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n///   to modify.\n///\n/// # Effects\n///\n/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n/// to `0`, and all bits in `*self` that are not selected (set to `0`) in\n/// `mask` will be unchanged.\n///\n/// Do not invert the mask prior to calling this function in order to save\n/// the unselected bits and erase the selected bits. `BitMask` is a\n/// selection type, not a bitwise-operation argument.\n#[inline]\nfn clear_bits(&self, mask: BitMask<M>){\n\t\tself.fetch_and(!mask.value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::get_bit":["/// Fetches the value of one bit in a memory element.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The semantic index of the bit in `*self` to read.\n///\n/// # Returns\n///\n/// The value of the bit in `*self` corresponding to `index`.\n#[inline]\nfn get_bit<O>(&self, index: BitIdx<M>) -> bool\n\twhere O: BitOrder{\n\t\tunsafe { BitMask::new(self.load_value()) }.test(index.select::<O>())\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::get_bits":["/// Fetches any number of bits from a memory element.\n///\n/// The mask provided to this method must be constructed from indices that\n/// are valid in the caller’s context. As the mask is already computed by\n/// the caller, this does not take an ordering type parameter.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n///   to read.\n///\n/// # Returns\n///\n/// A copy of the memory element at `*self`, with all bits not selected (set\n/// to `0`) in `mask` erased and all bits selected (set to `1`) in `mask`\n/// preserved.\n#[inline]\nfn get_bits(&self, mask: BitMask<M>) -> M{\n\t\tself.load_value() & mask.value()\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::get_writer":["/// Gets the function that writes `value` to an index.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `value`: The bit that will be directly written by the returned\n///   function.\n///\n/// # Returns\n///\n/// A function which, when applied to a reference and an index, will write\n/// `value` into memory. If `value` is `false`, then this produces\n/// [`clear_bit`]; if it is `true`, then this produces [`set_bit`].\n///\n/// [`clear_bit`]: #method.clear_bit\n/// [`set_bit`]: #method.set_bit\n#[inline]\nfn get_writer<O>(value: bool) -> for<'a> fn(&'a Self, BitIdx<M>)\n\twhere O: BitOrder{\n\t\t[Self::clear_bit::<O>, Self::set_bit::<O>][value as usize]\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::get_writers":["/// Gets the function that writes `value` into all bits under a mask.\n///\n/// # Parameters\n///\n/// - `value`: The bit that will be directly written by the returned\n///   function.\n///\n/// # Returns\n///\n/// A function which, when applied to a reference and a mask, will write\n/// `value` into memory. If `value` is `false`, then this produces\n/// [`clear_bits`]; if it is `true`, then this produces [`set_bits`].\n///\n/// [`clear_bits`]: #method.clear_bits\n/// [`set_bits`]: #method.set_bits\n#[inline]\nfn get_writers(value: bool) -> for<'a> fn(&'a Self, BitMask<M>){\n\t\t[Self::clear_bits, Self::set_bits][value as usize]\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::invert_bit":["/// Inverts the value of one bit in a memory element.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The semantic index of the bit in `*self` to be inverted.\n///\n/// # Effects\n///\n/// The memory element at `*self` has the bit corresponding to `index` set\n/// to the opposite of its current value. All other bits are unchanged.\n#[inline]\nfn invert_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder{\n\t\tself.fetch_xor(index.select::<O>().value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::invert_bits":["/// Invert any number of bits in a memory element.\n///\n/// The mask provided to this method must be constructed from indices that\n/// are valid in the caller’s context. As the mask is already computed by\n/// the caller, this does not take an ordering type parameter.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n///   to modify.\n///\n/// # Effects\n///\n/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n/// to the opposite of their current value, and all bits in `*self` that are\n/// not selected (set to `0`) in `mask` will be unchanged.\n#[inline]\nfn invert_bits(&self, mask: BitMask<M>){\n\t\tself.fetch_xor(mask.value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::load_value":["/// Copies a memory element into the caller’s local context.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A copy of the value at `*self`.\n#[inline]\nfn load_value(&self) -> M{\n\t\tself.load(Ordering::Relaxed)\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::set_bit":["/// Sets one bit in a memory element to `1`.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The semantic index of the bit in `*self` to be written.\n///\n/// # Effects\n///\n/// The memory element at `*self` has the bit corresponding to `index` set\n/// to `1`, and all other bits are unchanged.\n#[inline]\nfn set_bit<O>(&self, index: BitIdx<M>)\n\twhere O: BitOrder{\n\t\tself.fetch_or(index.select::<O>().value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::set_bits":["/// Sets any number of bits in a memory element to `1`.\n///\n/// The mask provided to this method must be constructed from indices that\n/// are valid in the caller’s context. As the mask is already computed by\n/// the caller, this does not need to take an ordering type parameter.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n///   to modify.\n///\n/// # Effects\n///\n/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n/// to `1`, and all bits in `*self` that are not selected (set to `0`) in\n/// `mask` will be unchanged.\n#[inline]\nfn set_bits(&self, mask: BitMask<M>){\n\t\tself.fetch_or(mask.value(), Ordering::Relaxed);\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::store_value":["/// Unconditionally writes a value into a memory location.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `value`: The new value to write into `*self`.\n///\n/// # Effects\n///\n/// The current value at `*self` is replaced with `value`.\n///\n/// # Safety\n///\n/// The calling context must either have write permissions to the entire\n/// memory element at `*self`, or construct a `value` that does not modify\n/// the bits of `*self` that the caller does not currently own.\n///\n/// As this directly permits the modification of memory outside the logical\n/// ownership of the caller, this method risks behavior that violates the\n/// Rust memory model, even if it may not be technically undefined.\n#[inline]\nunsafe fn store_value(&self, value: M){\n\t\tself.store(value, Ordering::Relaxed)\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::write_bit":["/// Writes a bit to an index within the `self` element.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The semantic index of the bit in `*self` to be written.\n/// - `value`: The bit value to write into `*self` at `index`.\n///\n/// # Effects\n///\n/// The bit in `*self` at `index` is set to the `value` bit.\n#[inline]\nfn write_bit<O>(&self, index: BitIdx<M>, value: bool)\n\twhere O: BitOrder{\n\t\tif value {\n\t\t\tself.set_bit::<O>(index);\n\t\t}\n\t\telse {\n\t\t\tself.clear_bit::<O>(index);\n\t\t}\n\t}","Real(LocalPath(\"src/access.rs\"))"],"access::BitAccess::write_bits":["/// Writes a bit value to any number of bits within the `self` element.\n///\n/// The mask provided to this method must be constructed from indices that\n/// are valid in the caller’s context. As the mask is already computed by\n/// the caller, this does not need to take an ordering type parameter.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mask`: A mask of any number of bits. This is a selection mask of bits\n///   to modify.\n///\n/// # Effects\n///\n/// All bits in `*self` that are selected (set to `1`) in `mask` will be set\n/// to `value`, and all bits in `*self` that are not selected (set to `0`)\n/// in `mask` will be unchanged.\n#[inline]\nfn write_bits(&self, mask: BitMask<M>, value: bool){\n\t\tif value {\n\t\t\tself.set_bits(mask);\n\t\t}\n\t\telse {\n\t\t\tself.clear_bits(mask);\n\t\t}\n\t}","Real(LocalPath(\"src/access.rs\"))"],"array::BitArray":["/** An array of individual bits, able to be held by value on the stack.\n\nThis type is generic over all `Sized` implementors of the `BitView` trait. Due\nto limitations in the Rust language’s const-generics implementation (it is both\nunstable and incomplete), this must take an array type parameter, rather than a\nbit-count integer parameter, making it inconvenient to use. The [`bitarr!`]\nmacro is capable of constructing both values and specific types of `BitArray`,\nand this macro should be preferred for most use.\n\nThe advantage of using this wrapper is that it implements `Deref`/`Mut` to\n`BitSlice`, as well as implementing all of `BitSlice`’s traits by forwarding to\nthe bit-slice view of its contained data. This allows it to have `BitSlice`\nbehavior by itself, without requiring explicit `.as_bitslice()` calls in user\ncode.\n\n> Note: Not all traits may be implemented for forwarding, as a matter of effort\n> and perceived need. Please file an issue for any additional traits that you\n> need to be forwarded.\n\n# Limitations\n\nThis always produces a bit-slice that fully spans its data; you cannot produce,\nfor example, an array of twelve bits.\n\n# Type Parameters\n\n- `O`: The ordering of bits within memory elements.\n- `V`: Some amount of memory which can be used as the basis for a `BitSlice`\n  view. This will usually be an array `[T: BitStore; N]`.\n\n# Examples\n\nThis type is useful for marking that some value is always to be used as a\nbit-slice.\n\n**/\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// struct HasBitfields {\n///   header: u32,\n///   //  creates a type declaration\n///   fields: bitarr!(for 20, in Msb0, u8),\n/// }\n///\n/// impl HasBitfields {\n///   pub fn new() -> Self {\n///     Self {\n///       header: 0,\n///       //  creates a value object. the type paramaters must be repeated.\n///       fields: bitarr![Msb0, u8; 0; 20],\n///     }\n///   }\n///\n///   /// Access a bit region directly\n///   pub fn get_subfield(&self) -> &BitSlice<Msb0, u8> {\n///     &self.fields[.. 4]\n///   }\n///\n///   /// Read a 12-bit value out of a region\n///   pub fn read_value(&self) -> u16 {\n///     self.fields[4 .. 16].load()\n///   }\n///\n///   /// Write a 12-bit value into a region\n///   pub fn set_value(&mut self, value: u16) {\n///     self.fields[4 .. 16].store(value);\n///   }\n/// }\n/// ```\n/**\n# Eventual Obsolescence\n\nWhen const-generics stabilize, this will be modified to have a signature more\nlike `BitArray<O, T: BitStore, const N: usize>([T; elts::<T>(N)]);`, to mirror\nthe behavior of ordinary arrays `[T; N]` as they stand today.\n\n[`bitarr!`]: ../../macro.bitarr.html\n**/\n#[repr(transparent)]\npub struct BitArray<O, V>\nwhere\n\tO: BitOrder,\n\tV: BitView + Sized,\n{\n\t/// Bit ordering when viewed as a bitslice.\n\t_ord: PhantomData<O>,\n\t/// The wrapped data store.\n\tdata: V,\n}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_bitslice":["/// Views the array as a bit-slice.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitslice(&self) -> &BitSlice<O, V::Store>{\n\t\tself.data.view_bits::<O>()\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_mut_bitslice":["/// Views the array as a mutable bit-slice.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, V::Store>{\n\t\tself.data.view_bits_mut::<O>()\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_mut_slice":["/// Views the array as a mutable slice of its underlying elements.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_slice(&mut self) -> &mut [V::Store]{\n\t\tunsafe {\n\t\t\tslice::from_raw_parts_mut(\n\t\t\t\t&mut self.data as *mut V as *mut V::Store,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_raw_mut_slice":["/// Views the array as a mutable slice of its raw underlying memory type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_raw_mut_slice(&mut self) -> &mut [V::Mem]{\n\t\tunsafe {\n\t\t\tslice::from_raw_parts_mut(\n\t\t\t\t&mut self.data as *mut V as *mut V::Mem,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_raw_slice":["/// Views the array as a slice of its raw underlying memory type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_raw_slice(&self) -> &[V::Mem]{\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(\n\t\t\t\t&self.data as *const V as *const V::Mem,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::as_slice":["/// Views the array as a slice of its underlying elements.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_slice(&self) -> &[V::Store]{\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(\n\t\t\t\t&self.data as *const V as *const V::Store,\n\t\t\t\tV::const_elts(),\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::new":["/// Constructs a new `BitArray` from a data store.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n/// ```\ninline(always)\npub fn new(data: V) -> Self{\n\t\tSelf {\n\t\t\t_ord: PhantomData,\n\t\t\tdata,\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::unwrap":["/// Removes the bit-array wrapper, returning the contained data.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bitarr: BitArray<Local, [usize; 1]> = bitarr![0; 30];\n/// let native: [usize; 1] = bitarr.unwrap();\n/// ```\ninline(always)\npub fn unwrap(self) -> V{\n\t\tself.data\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::BitArray::<O, V>::zeroed":["/// Constructs a new `BitArray` with zeroed memory.\ninline(always)\npub fn zeroed() -> Self{\n\t\tSelf {\n\t\t\t_ord: PhantomData,\n\t\t\tdata: unsafe { MaybeUninit::zeroed().assume_init() },\n\t\t}\n\t}","Real(LocalPath(\"src/array.rs\"))"],"array::ops::<impl std::ops::BitAnd<Rhs> for array::BitArray<O, V>>::bitand":["#[inline]\nfn bitand(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::BitAndAssign<Rhs> for array::BitArray<O, V>>::bitand_assign":["#[inline]\nfn bitand_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::BitOr<Rhs> for array::BitArray<O, V>>::bitor":["#[inline]\nfn bitor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::BitOrAssign<Rhs> for array::BitArray<O, V>>::bitor_assign":["#[inline]\nfn bitor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::BitXor<Rhs> for array::BitArray<O, V>>::bitxor":["#[inline]\nfn bitxor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::BitXorAssign<Rhs> for array::BitArray<O, V>>::bitxor_assign":["#[inline]\nfn bitxor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::Deref for array::BitArray<O, V>>::deref":["#[inline(always)]\nfn deref(&self) -> &Self::Target{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::DerefMut for array::BitArray<O, V>>::deref_mut":["#[inline(always)]\nfn deref_mut(&mut self) -> &mut Self::Target{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::Index<Idx> for array::BitArray<O, V>>::index":["#[inline]\nfn index(&self, index: Idx) -> &Self::Output{\n\t\tself.as_bitslice().index(index)\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::IndexMut<Idx> for array::BitArray<O, V>>::index_mut":["#[inline]\nfn index_mut(&mut self, index: Idx) -> &mut Self::Output{\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::ops::<impl std::ops::Not for array::BitArray<O, V>>::not":["#[inline]\nfn not(mut self) -> Self::Output{\n\t\tlet _ = !self.as_mut_bitslice();\n\t\tself\n\t}","Real(LocalPath(\"src/array/ops.rs\"))"],"array::traits::<impl std::borrow::Borrow<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow":["#[inline(always)]\nfn borrow(&self) -> &BitSlice<O, V::Store>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow_mut":["#[inline(always)]\nfn borrow_mut(&mut self) -> &mut BitSlice<O, V::Store>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::cmp::Ord for array::BitArray<O, V>>::cmp":["#[inline]\nfn cmp(&self, other: &Self) -> cmp::Ordering{\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::cmp::PartialEq<Rhs> for array::BitArray<O, V>>::eq":["#[inline]\n#[cfg(not(tarpaulin_include))]\nfn eq(&self, other: &Rhs) -> bool{\n\t\tself.as_bitslice() == other\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::cmp::PartialEq<array::BitArray<O, V>> for slice::BitSlice<O, T>>::eq":["#[inline]\nfn eq(&self, other: &BitArray<O, V>) -> bool{\n\t\tself == other.as_bitslice()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::cmp::PartialOrd<Rhs> for array::BitArray<O, V>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering>{\n\t\tself.as_bitslice().partial_cmp(other)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::cmp::PartialOrd<array::BitArray<O, V>> for slice::BitSlice<O, T>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &BitArray<O, V>) -> Option<cmp::Ordering>{\n\t\tself.partial_cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::AsMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_mut":["#[inline(always)]\nfn as_mut(&mut self) -> &mut BitSlice<O, V::Store>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::AsRef<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_ref":["#[inline(always)]\nfn as_ref(&self) -> &BitSlice<O, V::Store>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::From<V> for array::BitArray<O, V>>::from":["#[inline(always)]\nfn from(data: V) -> Self{\n\t\tSelf::new(data)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::TryFrom<&'a mut slice::BitSlice<O, <V as view::BitView>::Store>> for &'a mut array::BitArray<O, V>>::try_from":["#[inline]\nfn try_from(\n\t\tsrc: &'a mut BitSlice<O, V::Store>,\n\t) -> Result<Self, Self::Error>{\n\t\tlet bitptr = src.bitptr();\n\t\tif src.len() != V::const_bits() || bitptr.head().value() != 0 {\n\t\t\treturn Self::Error::err();\n\t\t}\n\t\tOk(unsafe { &mut *(bitptr.pointer().to_mut() as *mut BitArray<O, V>) })\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::TryFrom<&'a slice::BitSlice<O, <V as view::BitView>::Store>> for &'a array::BitArray<O, V>>::try_from":["#[inline]\nfn try_from(src: &'a BitSlice<O, V::Store>) -> Result<Self, Self::Error>{\n\t\tlet bitptr = src.bitptr();\n\t\t//  This pointer cast can only happen if the slice is exactly as long\n\t\t//  as the array, and is aligned to the front of the element.\n\t\tif src.len() != V::const_bits() || bitptr.head().value() != 0 {\n\t\t\treturn Self::Error::err();\n\t\t}\n\t\tOk(unsafe { &*(bitptr.pointer().to_const() as *const BitArray<O, V>) })\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::convert::TryFrom<&slice::BitSlice<O2, T>> for array::BitArray<O, V>>::try_from":["#[inline]\nfn try_from(src: &BitSlice<O2, T>) -> Result<Self, Self::Error>{\n\t\tlet mut out = Self::zeroed();\n\t\tif src.len() != out.len() {\n\t\t\treturn Self::Error::err();\n\t\t}\n\t\tout.clone_from_bitslice(src);\n\t\tOk(out)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::default::Default for array::BitArray<O, V>>::default":["#[inline(always)]\nfn default() -> Self{\n\t\tSelf::zeroed()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::Binary for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::Debug for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tif fmt.alternate() {\n\t\t\tself.bitptr().render(\n\t\t\t\tfmt,\n\t\t\t\t\"Array\",\n\t\t\t\tSome(core::any::type_name::<O>()),\n\t\t\t\tNone,\n\t\t\t)?;\n\t\t}\n\t\tBinary::fmt(self, fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::Display for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::LowerHex for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::Octal for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::fmt::UpperHex for array::BitArray<O, V>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::hash::Hash for array::BitArray<O, V>>::hash":["#[inline]\nfn hash<H>(&self, hasher: &mut H)\n\twhere H: Hasher{\n\t\tself.as_bitslice().hash(hasher)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::iter::IntoIterator for &'a array::BitArray<O, V>>::into_iter":["#[inline]\nfn into_iter(self) -> Self::IntoIter{\n\t\tself.as_bitslice().into_iter()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::<impl std::iter::IntoIterator for &'a mut array::BitArray<O, V>>::into_iter":["#[inline]\nfn into_iter(self) -> Self::IntoIter{\n\t\tself.as_mut_bitslice().into_iter()\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::TryFromBitSliceError":["/// The error type returned when a conversion from a bitslice to a bitarray\n/// fails.\npub struct TryFromBitSliceError;","Real(LocalPath(\"src/array/traits.rs\"))"],"array::traits::TryFromBitSliceError::err":["#[inline]\nfn err<T>() -> Result<T, Self>{\n\t\tErr(Self)\n\t}","Real(LocalPath(\"src/array/traits.rs\"))"],"boxed::BitBox":["/** A frozen heap-allocated buffer of individual bits.\n\nThis is essentially a [`BitVec`] that has frozen its allocation, and given up\nthe ability to change size. It is analagous to `Box<[bool]>`, and is written to\nbe as close as possible to drop-in replacable for it. This type contains almost\nno interesting behavior in its own right; it dereferences to [`BitSlice`] to\nmanipulate its contents, and it converts to and from `BitVec` for allocation\ncontrol.\n\nIf you know the length of your bit sequence at compile-time, and it is\nexpressible within the limits of [`BitArray`], you should prefer that type\ninstead. Large `BitArray`s can be `Box`ed normally as desired.\n\n# Documentation\n\nAll APIs that mirror something in the standard library will have an `Original`\nsection linking to the corresponding item. All APIs that have a different\nsignature or behavior than the original will have an `API Differences` section\nexplaining what has changed, and how to adapt your existing code to the change.\n\nThese sections look like this:\n\n# Original\n\n[`Box<[T]>`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html)\n\n# API Differences\n\nThe buffer type `Box<[bool]>` has no type parameters. `BitBox<O, T>` has the\nsame two type parameters as `BitSlice<O, T>`. Otherwise, `BitBox` is able to\nimplement the full API surface of `Box<[bool]>`.\n\n# Behavior\n\nBecause `BitBox` is a fully-owned buffer, it is able to operate on its memory\nwithout concern for any other views that may alias. This enables it to\nspecialize some `BitSlice` behavior to be faster or more efficient.\n\n# Type Parameters\n\nThis takes the same two type parameters, `O: BitOrder` and `T: BitStore`, as\n`BitSlice`.\n\n# Safety\n\nLike `BitSlice`, `BitBox` is exactly equal in size to `Box<[bool]>`, and is also\nabsolutely representation-incompatible with it. You must never attempt to\ntype-cast between `Box<[bool]>` and `BitBox` in any way, nor attempt to modify\nthe memory value of a `BitBox` handle. Doing so will cause allocator and memory\nerrors in your program, likely inducing a panic.\n\nEverything in the `BitBox` public API, even the `unsafe` parts, are guaranteed\nto have no more unsafety than their equivalent items in the standard library.\nAll `unsafe` APIs will have documentation explicitly detailing what the API\nrequires you to uphold in order for it to function safely and correctly. All\nsafe APIs will do so themselves.\n\n# Performance\n\nIteration over the buffer is governed by the `BitSlice` characteristics on the\ntype parameter. You are generally better off using larger types when your buffer\nis a data collection rather than a specific I/O protocol buffer.\n\n# Macro Construction\n\nHeap allocation can only occur at runtime, but the [`bitbox!`] macro will\nconstruct an appropriate `BitSlice` buffer at compile-time, and at run-time,\nonly copy the buffer into a heap allocation.\n\n[`BitArray`]: ../array/struct.BitArray.html\n[`BitSlice`]: ../slice/struct.BitSlice.html\n[`BitVec`]: ../vec/struct.BitVec.html\n[`bitbox!`]: ../macro.bitbox.html\n**/\n#[repr(transparent)]\npub struct BitBox<O = Local, T = usize>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\tpointer: NonNull<BitSlice<O, T>>,\n}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::as_bitslice":["/// Views the buffer’s contents as a `BitSlice`.\n///\n/// This is equivalent to `&bb[..]`.\n///\n/// # Original\n///\n/// [`<Box<[T]> as AsRef<[T]>>::as_ref`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsRef%3CT%3E)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bb = bitbox![0, 1, 1, 0];\n/// let bits = bb.as_bitslice();\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitslice(&self) -> &BitSlice<O, T>{\n\t\tself.bitptr().to_bitslice_ref()\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::as_mut_bitslice":["/// Extracts a mutable bit-slice of the entire vector.\n///\n/// Equivalent to `&mut bv[..]`.\n///\n/// # Original\n///\n/// [`<Box<[T]> as AsMut<[T]>>::as_mut`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsMut%3CT%3E)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 0, 1];\n/// let bits = bv.as_mut_bitslice();\n/// bits.set(0, true);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.bitptr().to_bitslice_mut()\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::as_mut_slice":["/// Extracts a mutable slice of the entire box.\n///\n/// # Original\n///\n/// [`<Box<[T]> as AsMut<[T]>>::as_mut`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsMut%3CT%3E)\n///\n/// # Analogue\n///\n/// See [`as_mut_bitslice`] for a `&mut BitBox -> &mut BitSlice` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n/// use std::io::{self, Read};\n/// let mut buffer = bitbox![Msb0, u8; 0; 24];\n/// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();\n/// # }\n/// ```\n///\n/// [`as_mut_bitslice`]: #method.as_mut_bitslice\n#[inline]\npub fn as_mut_slice(&mut self) -> &mut [T]{\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_mut(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts_mut(base, elts) }\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::as_slice":["/// Extracts an element slice containing the entire box.\n///\n/// # Original\n///\n/// [`<Box<[T]> as AsRef<[T]>>::as_ref`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-AsRef%3CT%3E)\n///\n/// # Analogue\n///\n/// See [`as_bitslice`] for a `&BitBox -> &BitSlice` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n/// use std::io::{self, Write};\n/// let buffer = bitbox![Msb0, u8; 0, 1, 0, 1, 1, 0, 0, 0];\n/// io::sink().write(buffer.as_slice()).unwrap();\n/// # }\n/// ```\n///\n/// [`as_bitslice`]: #method.as_bitslice\n#[inline]\npub fn as_slice(&self) -> &[T]{\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_const(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::bitptr":["#[inline]\npub(crate) fn bitptr(&self) -> BitPtr<T>{\n\t\tself.pointer.as_ptr().pipe(BitPtr::from_bitslice_ptr_mut)\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::from_bitslice":["/// Clones a `&BitSlice` into a `BitVec`.\n///\n/// # Original\n///\n/// [`<Box<T: Clone> as Clone>::clone`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#impl-Clone)\n///\n/// # Effects\n///\n/// This performs a direct element-wise copy from the source slice to the\n/// newly-allocated buffer, then sets the box to have the same starting bit\n/// as the slice did. This allows for faster behavior.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = bits![0, 1, 0, 1, 1, 0, 1, 1];\n/// let bb = BitBox::from_bitslice(&bits[2 ..]);\n/// assert_eq!(bb, bits[2 ..]);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn from_bitslice(slice: &BitSlice<O, T>) -> Self{\n\t\tslice.to_bitvec().into_boxed_bitslice()\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::from_boxed_slice":["/// Converts a `Box<[T]>` into a `BitBox`<O, T>` without copying its buffer.\n///\n/// # Parameters\n///\n/// - `boxed`: A boxed slice to view as bits.\n///\n/// # Returns\n///\n/// A `BitBox` over the `boxed` buffer.\n///\n/// # Panics\n///\n/// This panics if `boxed` is too long to convert into a `BitBox`. See\n/// [`BitSlice::MAX_ELTS`].\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let boxed: Box<[u8]> = Box::new([0; 4]);\n/// let bb = BitBox::<Local, _>::from_boxed_slice(boxed);\n/// assert_eq!(bb, bits![0; 32]);\n/// ```\n///\n/// [`BitSlice::MAX_ELTS`]:\n/// ../slice/struct.BitSlice.html#associatedconstant.MAX_ELTS\n#[inline]\npub fn from_boxed_slice(boxed: Box<[T]>) -> Self{\n\t\tSelf::try_from_boxed_slice(boxed)\n\t\t\t.expect(\"Slice was too long to be converted into a `BitBox`\")\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::into_boxed_slice":["/// Converts the slice back into an ordinary slice of memory elements.\n///\n/// This does not affect the slice’s buffer, only the handle used to control\n/// it.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// An ordinary boxed slice containing all of the bit-slice’s memory buffer.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bb = bitbox![0; 5];\n/// let boxed = bb.into_boxed_slice();\n/// assert_eq!(boxed[..], [0][..]);\n/// ```\n#[inline]\npub fn into_boxed_slice(self) -> Box<[T]>{\n\t\tlet mut this = ManuallyDrop::new(self);\n\t\tunsafe { Box::from_raw(this.as_mut_slice()) }\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::try_from_boxed_slice":["/// Converts a `Box<[T]>` into a `BitBox<O, T>` without copying its buffer.\n///\n/// This method takes ownership of a memory buffer and enables it to be used\n/// as a bit-box. Because `Box<[T]>` can be longer than `BitBox`es, this is\n/// a fallible method, and the original box will be returned if it cannot be\n/// converted.\n///\n/// # Parameters\n///\n/// - `boxed`: Some boxed slice of memory, to be viewed as bits.\n///\n/// # Returns\n///\n/// If `boxed` is short enough to be viewed as a `BitBox`, then this returns\n/// a `BitBox` over the `boxed` buffer. If `boxed` is too long, then this\n/// returns `boxed` unmodified.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let boxed: Box<[u8]> = Box::new([0; 4]);\n/// let bb = BitBox::<Local, _>::try_from_boxed_slice(boxed).unwrap();\n/// assert_eq!(bb[..], bits![0; 32]);\n/// ```\n#[inline]\npub fn try_from_boxed_slice(boxed: Box<[T]>) -> Result<Self, Box<[T]>>{\n\t\tlet len = boxed.len();\n\t\tif len > BitSlice::<O, T>::MAX_ELTS {\n\t\t\treturn Err(boxed);\n\t\t}\n\n\t\tlet boxed = ManuallyDrop::new(boxed);\n\t\tlet base = boxed.as_ptr();\n\t\tOk(Self {\n\t\t\tpointer: unsafe {\n\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\tbase,\n\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\tlen * T::Mem::BITS as usize,\n\t\t\t\t)\n\t\t\t}\n\t\t\t.to_nonnull(),\n\t\t})\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::BitBox::<O, T>::with_box":["/// Permits a function to modify the `Box<[T]>` backing storage of a\n/// `BitBox<_, T>`.\n///\n/// This produces a temporary `Box<[T::Mem]>` structure governing the\n/// `BitBox`’s buffer and allows a function to view it mutably. After the\n/// callback returns, the `Box` is written back into `self` and forgotten.\n///\n/// # Type Parameters\n///\n/// - `F`: A function which operates on a mutable borrow of a\n///   `Box<[T::Mem]>` buffer controller.\n/// - `R`: The return type of the `F` function.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `func`: A function which receives a mutable borrow of a\n///   `Box<[T::Mem]>` controlling `self`’s buffer.\n///\n/// # Returns\n///\n/// The return value of `func`. `func` is forbidden from borrowing any part\n/// of the `Box<[T::Mem]>` temporary view.\nfn with_box<F, R>(&mut self, func: F) -> R\n\twhere F: FnOnce(&mut ManuallyDrop<Box<[T::Mem]>>) -> R{\n\t\tlet mut bitptr = self.bitptr();\n\n\t\tlet mut boxed = self\n\t\t\t.as_mut_slice()\n\t\t\t.pipe(|s| s as *mut [T] as *mut [T::Mem])\n\t\t\t.pipe(|raw| unsafe { Box::from_raw(raw) })\n\t\t\t.pipe(ManuallyDrop::new);\n\t\tlet out = func(&mut boxed);\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(boxed.as_ptr() as *mut T);\n\t\t}\n\t\tself.pointer = bitptr.to_nonnull();\n\t\tout\n\t}","Real(LocalPath(\"src/boxed.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::from_raw":["/// Constructs a box from a raw pointer.\n///\n/// After calling this function, the raw pointer is owned by the\n/// resulting `BitBox`. Specifically, the `Box` destructor will free the\n/// allocated memory. For this to be safe, the memory must have been\n/// allocated in accordance with the [memory layout] used by `Box` .\n///\n/// # Original\n///\n/// [`Box::from_raw`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.from_raw)\n///\n/// # Safety\n///\n/// This function is unsafe because improper use may lead to\n/// memory problems. For example, a double-free may occur if the\n/// function is called twice on the same raw pointer.\n///\n/// # Examples\n///\n/// Recreate a `BitBox` which was previously converted to a raw pointer\n/// using [`BitBox::into_raw`]:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let x = bitbox![0; 10];\n/// let ptr = BitBox::into_raw(x);\n/// let x = unsafe { BitBox::from_raw(ptr) };\n/// ```\n///\n/// [memory layout]: https://doc.rust-lang.org/alloc/boxed/index.html#memory-layout\n/// [`Layout`]: https://doc.rust-lang.org/alloc/struct.Layout.html\n/// [`BitBox::into_raw`]: #method.into_raw\n#[inline]\npub unsafe fn from_raw(raw: *mut BitSlice<O, T>) -> Self{\n\t\traw.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.to_nonnull()\n\t\t\t.pipe(|pointer| Self { pointer })\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::into_bitvec":["/// Converts `self` into a vector without clones or allocation.\n///\n/// The resulting vector can be converted back into a box via `BitVec<O,\n/// T>`’s `into_boxed_bitslice` method.\n///\n/// # Original\n///\n/// [`slice::into_vec`](https://doc.rust-lang.org/std/primitive.slice.html#method.into_vec)\n///\n/// Despite taking a `Box<[T]>` receiver, this function is written in an\n/// `impl<T> [T]` block.\n///\n/// Rust does not allow the text\n///\n/// ```rust,ignore\n/// impl<O, T> BitSlice<O, T> {\n///   fn into_bitvec(self: BitBox<O, T>);\n/// }\n/// ```\n///\n/// to be written, so this function must be implemented directly on `BitBox`\n/// rather than on `BitSlice` with a boxed receiver.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bb = bitbox![0, 1, 0, 1];\n/// let bv = bb.into_bitvec();\n///\n/// assert_eq!(bv, bitvec![0, 1, 0, 1]);\n/// ```\n#[inline]\npub fn into_bitvec(self) -> BitVec<O, T>{\n\t\tlet bitptr = self.bitptr();\n\t\tlet raw = self\n\t\t\t//  Disarm the `self` destructor\n\t\t\t.pipe(ManuallyDrop::new)\n\t\t\t//  Extract the `Box<[T]>` handle, invalidating `self`\n\t\t\t.with_box(|b| unsafe { ManuallyDrop::take(b) })\n\t\t\t//  The distribution guarantees this to be correct and in-place.\n\t\t\t.into_vec()\n\t\t\t//  Disarm the `Vec<T>` destructor *also*.\n\t\t\t.pipe(ManuallyDrop::new);\n\t\t/* The distribution claims that `[T]::into_vec(Box<[T]>) -> Vec<T>` does\n\t\tnot alter the address of the heap allocation, and only modifies the\n\t\tbuffer handle. Since the address does not change, the `BitPtr` does not\n\t\tneed to be updated; the only change is that buffer capacity is now\n\t\tcarried locally, rather than frozen in the allocator’s state.\n\n\t\tInspection of the distribution’s implementation shows that the\n\t\tconversion from `(buf, len)` to `(buf, cap, len)` is done by using the\n\t\tslice length as the buffer capacity. However, this is *not* a behavior\n\t\tguaranteed by the distribution, and so the pipeline above must remain in\n\t\tplace in the event that this behavior ever changes. It should compile\n\t\taway to nothing, as it is almost entirely typesystem manipulation.\n\t\t*/\n\t\tunsafe {\n\t\t\tBitVec::from_raw_parts(bitptr.to_bitslice_ptr_mut(), raw.capacity())\n\t\t}\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::into_raw":["/// Consumes the `BitBox`, returning a wrapped raw pointer.\n///\n/// The pointer will be properly aligned and non-null.\n///\n/// After calling this function, the caller is responsible for the memory\n/// previously managed by the `BitBox`. In particular, the caller should\n/// properly release the memory by converting the pointer back into a\n/// `BitBox` with the [`BitBox::from_raw`] function, allowing the `BitBox`\n/// destructor to perform the cleanup.\n///\n/// Note: this is an associated function, which means that you have to call\n/// it as `BitBox::into_raw(b)` instead of `b.into_raw()`. This is to match\n/// layout with the standard library’s `Box` API; there will never be a name\n/// conflict with `BitSlice`.\n///\n/// # Original\n///\n/// [`Box::into_raw`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.into_raw)\n///\n/// # Examples\n///\n/// Converting the raw pointer back into a `BitBox` with\n/// [`BitBox::from_raw`] for automatic cleanup:\n///\n/// ```rust\n/// # use bitvec::prelude::*;\n/// let b = BitBox::new(bits![Msb0, u32; 0; 32]);\n/// let ptr = BitBox::into_raw(b);\n/// let b = unsafe { BitBox::<Msb0, _>::from_raw(ptr) };\n/// ```\n///\n/// [`BitBox::from_raw`]: #method.from_raw\ninline(always)\npub fn into_raw(b: Self) -> *mut BitSlice<O, T>{\n\t\tSelf::leak(b)\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::leak":["/// Consumes and leaks the `BitBox`, returning a mutable reference,\n/// `&'a mut BitSlice<O, T>`. Note that the memory region `[T]` must outlive\n/// the chosen lifetime `'a`.\n///\n/// This function is mainly useful for bit regions that live for the\n/// remainder of the program’s life. Dropping the returned reference will\n/// cause a memory leak. If this is not acceptable, the reference should\n/// first be wrapped with the [`BitBox::from_raw`] function, producing a\n/// `BitBox`. This `BitBox` can then be dropped which will properly\n/// deallocate the memory.\n///\n/// Note: this is an associated function, which means that you have to call\n/// it as `BitBox::leak(b)` instead of `b.leak()`. This is to match layout\n/// with the standard library’s `Box` API; there will never be a name\n/// conflict with `BitSlice`.\n///\n/// # Original\n///\n/// [`Box::leak`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.leak)\n///\n/// # Examples\n///\n/// Simple usage:\n///\n/// ```rust\n/// # use bitvec::prelude::*;\n/// let b = BitBox::new(bits![Local, u32; 0; 32]);\n/// let static_ref: &'static mut BitSlice<Local, u32> = BitBox::leak(b);\n/// static_ref.set(0, true);\n/// assert_eq!(static_ref.count_ones(), 1);\n/// ```\n///\n/// [`BitBox::from_raw`]: #method.from_raw\n#[inline]\npub fn leak<'a>(b: Self) -> &'a mut BitSlice<O, T>\n\twhere T: 'a{\n\t\tb.pipe(ManuallyDrop::new).bitptr().to_bitslice_mut()\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::new":["/// Allocates memory on the heap and copies `x` into it.\n///\n/// This doesn’t actually allocate if `x` is zero-length.\n///\n/// # Original\n///\n/// [`Box::new`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.new)\n///\n/// # API Differences\n///\n/// `Box::<[T]>::new` does not exist, because `new` cannot take unsized\n/// types by value. Instead, this takes a slice reference, and boxes the\n/// referent slice.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let boxed = BitBox::new(bits![0; 5]);\n/// ```\ninline(always)\n#[deprecated(since = \"0.18.0\", note = \"Prefer `::from_bitslice`\")]\npub fn new(x: &BitSlice<O, T>) -> Self{\n\t\tSelf::from_bitslice(x)\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::api::<impl boxed::BitBox<O, T>>::pin":["/// Constructs a new `Pin<BitBox<O, T>>`.\n///\n/// `BitSlice` is always `Unpin`, so this has no actual immobility effect.\n///\n/// # Original\n///\n/// [`Box::pin`](https://doc.rust-lang.org/alloc/boxed/struct.Box.html#method.pin)\n///\n/// # API Differences\n///\n/// As with `::new`, this only exists on `Box` when `T` is not unsized. This\n/// takes a slice reference, and pins the referent slice.\n#[inline]\npub fn pin(x: &BitSlice<O, T>) -> Pin<Self>\n\twhere\n\t\tO: Unpin,\n\t\tT: Unpin,{\n\t\tx.pipe(Self::from_bitslice).pipe(Pin::new)\n\t}","Real(LocalPath(\"src/boxed/api.rs\"))"],"boxed::ops::<impl std::ops::BitAnd<Rhs> for boxed::BitBox<O, T>>::bitand":["#[inline]\nfn bitand(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::BitAndAssign<Rhs> for boxed::BitBox<O, T>>::bitand_assign":["#[inline]\nfn bitand_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::BitOr<Rhs> for boxed::BitBox<O, T>>::bitor":["#[inline]\nfn bitor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::BitOrAssign<Rhs> for boxed::BitBox<O, T>>::bitor_assign":["#[inline]\nfn bitor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::BitXor<Rhs> for boxed::BitBox<O, T>>::bitxor":["#[inline]\nfn bitxor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::BitXorAssign<Rhs> for boxed::BitBox<O, T>>::bitxor_assign":["#[inline]\nfn bitxor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::Deref for boxed::BitBox<O, T>>::deref":["#[inline(always)]\nfn deref(&self) -> &Self::Target{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::DerefMut for boxed::BitBox<O, T>>::deref_mut":["#[inline(always)]\nfn deref_mut(&mut self) -> &mut Self::Target{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::Drop for boxed::BitBox<O, T>>::drop":["#[inline]\nfn drop(&mut self){\n\t\t//  Run the `Box` destructor to deällocate the buffer.\n\t\tself.with_box(|boxed| unsafe { ManuallyDrop::drop(boxed) });\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::Index<Idx> for boxed::BitBox<O, T>>::index":["#[inline]\nfn index(&self, index: Idx) -> &Self::Output{\n\t\tself.as_bitslice().index(index)\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::IndexMut<Idx> for boxed::BitBox<O, T>>::index_mut":["#[inline]\nfn index_mut(&mut self, index: Idx) -> &mut Self::Output{\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::ops::<impl std::ops::Not for boxed::BitBox<O, T>>::not":["#[inline]\nfn not(mut self) -> Self::Output{\n\t\tfor elem in self.as_mut_slice().iter_mut().map(dvl::mem_mut) {\n\t\t\t*elem = !*elem;\n\t\t}\n\t\tself\n\t}","Real(LocalPath(\"src/boxed/ops.rs\"))"],"boxed::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow":["#[inline(always)]\nfn borrow(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow_mut":["#[inline(always)]\nfn borrow_mut(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::clone::Clone for boxed::BitBox<O, T>>::clone":["#[inline]\nfn clone(&self) -> Self{\n\t\tself.as_bitslice().pipe(Self::from_bitslice)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::Ord for boxed::BitBox<O, T>>::cmp":["#[inline]\nfn cmp(&self, other: &Self) -> cmp::Ordering{\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialEq<Rhs> for boxed::BitBox<O, T>>::eq":["#[inline]\nfn eq(&self, other: &Rhs) -> bool{\n\t\tother == self.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitBox<O2, T2>) -> bool{\n\t\t**self == other.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitBox<O2, T2>) -> bool{\n\t\t*self == other.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitBox<O2, T2>) -> bool{\n\t\tself == other.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialOrd<Rhs> for boxed::BitBox<O, T>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering>{\n\t\tother.partial_cmp(self.as_bitslice())\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::cmp::PartialOrd<boxed::BitBox<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &BitBox<O, T>) -> Option<cmp::Ordering>{\n\t\tself.partial_cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_mut":["#[inline(always)]\nfn as_mut(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_ref":["#[inline(always)]\nfn as_ref(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::from":["#[inline(always)]\nfn from(slice: &'a BitSlice<O, T>) -> Self{\n\t\tSelf::from_bitslice(slice)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::From<vec::BitVec<O, T>> for boxed::BitBox<O, T>>::from":["#[inline(always)]\nfn from(bv: BitVec<O, T>) -> Self{\n\t\tbv.into_boxed_bitslice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::Into<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::into":["#[inline(always)]\nfn into(self) -> Box<[T]>{\n\t\tself.into_boxed_slice()\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::convert::TryFrom<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::try_from":["#[inline(always)]\nfn try_from(boxed: Box<[T]>) -> Result<Self, Self::Error>{\n\t\tSelf::try_from_boxed_slice(boxed)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::default::Default for boxed::BitBox<O, T>>::default":["#[inline(always)]\nfn default() -> Self{\n\t\tSelf {\n\t\t\tpointer: BitPtr::EMPTY.to_nonnull(),\n\t\t}\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::Binary for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::Debug for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tif fmt.alternate() {\n\t\t\tself.bitptr().render(\n\t\t\t\tfmt,\n\t\t\t\t\"Box\",\n\t\t\t\tSome(any::type_name::<O>()),\n\t\t\t\tNone,\n\t\t\t)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::Display for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::LowerHex for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::Octal for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::Pointer for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Box\", Some(any::type_name::<O>()), None)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::fmt::UpperHex for boxed::BitBox<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"boxed::traits::<impl std::hash::Hash for boxed::BitBox<O, T>>::hash":["#[inline]\nfn hash<H>(&self, state: &mut H)\n\twhere H: Hasher{\n\t\tself.as_bitslice().hash(state)\n\t}","Real(LocalPath(\"src/boxed/traits.rs\"))"],"devel::accessor":["/// Views a `BitStore` reference as its accessor.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn accessor<T>(x: &T) -> &T::Access\nwhere T: BitStore{\n\tunsafe { &*(x as *const T as *const T::Access) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::alias_mask":["/// Inserts an `::Alias` marker into a `BitMask`’s type parameter.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn alias_mask<T>(\n\tx: BitMask<T::Mem>,\n) -> BitMask<<T::Alias as BitStore>::Mem>\nwhere T: BitStore{\n\tunsafe { *(&x as *const _ as *const _) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::alias_mem":["/// Inserts an `::Alias` marker into a `T::Mem` value’s type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn alias_mem<T>(x: T::Mem) -> <T::Alias as BitStore>::Mem\nwhere T: BitStore{\n\tunsafe { *(&x as *const _ as *const _) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::assert_range":["/** Asserts that a range satisfies bounds constraints.\n\nThis requires that the range start be not greater than the range end, and the\nrange end be not greater than the ending marker (if provided).\n\n# Parameters\n\n- `range`: The range to validate\n- `end`: An optional maximal value that the range cannot exceed\n\n# Panics\n\nThis panics if the range fails a requirement.\n**/\n#[inline]\npub fn assert_range(range: Range<usize>, end: impl Into<Option<usize>>){\n\tif range.start > range.end {\n\t\tpanic!(\n\t\t\t\"Malformed range: `{} .. {}` must run from lower to higher\",\n\t\t\trange.start, range.end\n\t\t);\n\t}\n\tif let Some(end) = end.into() {\n\t\tif range.end > end {\n\t\t\tpanic!(\n\t\t\t\t\"Range out of bounds: `{} .. {}` must not exceed `{}`\",\n\t\t\t\trange.start, range.end, end\n\t\t\t);\n\t\t}\n\t}\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::load_aliased_local":["/// Loads through an aliased reference into an unmarked local.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn load_aliased_local<T>(x: &T::Alias) -> T::Mem\nwhere T: BitStore{\n\tx.pipe(accessor::<T::Alias>)\n\t\t.pipe(BitAccess::load_value)\n\t\t.pipe(remove_alias::<T>)\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::mem_mut":["/// Converts a mutable reference into its memory register type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn mem_mut<T>(x: &mut T) -> &mut T::Mem\nwhere T: BitStore{\n\tunsafe { &mut *(x as *mut _ as *mut _) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::nonnull_slice_to_base":["/// Gets a `NonNull<T>` base pointer from a `NonNull<[T]>` slice pointer.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn nonnull_slice_to_base<T>(mut nn_slice: NonNull<[T]>) -> NonNull<T>{\n\tunsafe { nn_slice.as_mut() }\n\t\t.pipe(<[T]>::as_mut_ptr)\n\t\t.pipe(|p| unsafe { NonNull::new_unchecked(p) })\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::normalize_range":["/** Normalizes any range into a basic `Range`.\n\nThis unpacks any range type into an ordinary `Range`, returning the start and\nexclusive end markers. If the start marker is not provided, it is assumed to be\nzero; if the end marker is not provided, then it is assumed to be `end`.\n\nThe end marker, if provided, may be greater than `end`. This is not checked in\nthe function, and must be inspected by the caller.\n\n# Type Parameters\n\n- `R`: A range of some kind\n\n# Parameters\n\n- `bounds`: A range of some kind\n- `end`: The value to use as the exclusive end, if the range does not have an\n  end.\n\n# Returns\n\n`bounds` normalized to an ordinary `Range`, optionally clamped to `end`.\n**/\n#[inline]\npub fn normalize_range<R>(bounds: R, end: usize) -> Range<usize>\nwhere R: RangeBounds<usize>{\n\tlet min = match bounds.start_bound() {\n\t\tBound::Included(&n) => n,\n\t\tBound::Excluded(&n) => n + 1,\n\t\tBound::Unbounded => 0,\n\t};\n\tlet max = match bounds.end_bound() {\n\t\tBound::Included(&n) => n + 1,\n\t\tBound::Excluded(&n) => n,\n\t\tBound::Unbounded => end,\n\t};\n\tmin .. max\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::remove_alias":["/// Removes the `::Alias` marker from a register value’s type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn remove_alias<T>(x: <<T as BitStore>::Alias as BitStore>::Mem) -> T::Mem\nwhere T: BitStore{\n\tunsafe { *(&x as *const _ as *const _) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::remove_bitptr_alias":["/// Removes the `::Alias` marker from a `BitPtr`’s referent type.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn remove_bitptr_alias<T>(x: BitPtr<T::Alias>) -> BitPtr<T>\nwhere T: BitStore{\n\tunsafe { *(&x as *const _ as *const _) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"devel::remove_mem":["/// Removes the `::Mem` marker from a memory value.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn remove_mem<T>(x: T::Mem) -> T\nwhere T: BitStore{\n\tunsafe { ptr::read(&x as *const T::Mem as *const T) }\n}","Real(LocalPath(\"src/devel.rs\"))"],"domain::BitDomain":["/// Granular representation of the memory region containing a\n/// `BitSlice`.\n///\n/// `BitSlice` regions can be described in terms of edge and center\n/// elements, where the edge elements retain the aliasing status of the\n/// source `BitSlice` handle, and the center elements are known to be\n/// completely unaliased by any other view. This property allows any\n/// `BitSlice` handle to be decomposed into smaller regions, and safely\n/// remove any aliasing markers from the subregion of memory that no\n/// longer requires them for correct access.\n///\n/// This enum acts like the `.split*` methods in that it only subdivides\n/// the source `BitSlice` into smaller `BitSlices`, and makes\n/// appropriate modifications to the aliasing markers. It does not\n/// provide references to the underlying memory elements. If you need\n/// such access directly, use the [`Domain`] or [`DomainMut`] enums.\n///\n/// # Lifetimes\n///\n/// - `'a`: The lifetime of the referent storage region.\n///\n/// # Type Parameters\n///\n/// - `O`: The ordering type of the source `BitSlice` handle.\n/// - `T`: The element type of the source `BitSlice` handle, including\n///   aliasing markers.\n///\n/// [`Domain`]: enum.Domain.html\n/// [`DomainMut`]: enum.DomainMut.html\npub enum $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore\n\t\t{\n\t\t\t/// Indicates that a `BitSlice` is contained entirely in the\n\t\t\t/// interior indices of a single memory element.\n\t\t\tEnclave {\n\t\t\t\t/// The start index of the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is not likely to be useful information, but is retained\n\t\t\t\t/// for structural similarity with the rest of the module.\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\t/// The original `BitSlice` used to create this bit-domain view.\n\t\t\t\tbody: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/// The end index of the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is not likely to be useful information, but is retained\n\t\t\t\t/// for structural similarity with the rest of the module.\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t},\n\t\t\t/// Indicates that a `BitSlice` region touches at least one edge\n\t\t\t/// index of any number of elements.\n\t\t\t///\n\t\t\t/// This contains two bitslices representing the partially-occupied\n\t\t\t/// edge elements, with their original aliasing marker, and one\n\t\t\t/// bitslice representing the fully-occupied interior elements,\n\t\t\t/// marked as unaliased.\n\t\t\tRegion {\n\t\t\t\t/// Any bits that partially-fill the base element of the slice\n\t\t\t\t/// region.\n\t\t\t\t///\n\t\t\t\t/// This does not modify its aliasing status, as it will already\n\t\t\t\t/// be appropriately marked before constructing this view.\n\t\t\t\thead: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/// Any bits inside elements that the source bitslice completely\n\t\t\t\t/// covers.\n\t\t\t\t///\n\t\t\t\t/// This is marked as unaliased, because it is statically\n\t\t\t\t/// impossible for any other handle to have write access to the\n\t\t\t\t/// region it covers. As such, a bitslice that was marked as\n\t\t\t\t/// entirely aliased, but contains interior unaliased elements,\n\t\t\t\t/// can safely remove its aliasing protections.\n\t\t\t\t///\n\t\t\t\t/// # Safety Exception\n\t\t\t\t///\n\t\t\t\t/// `&BitSlice<O, T::Alias>` references have access to a\n\t\t\t\t/// `.set_aliased` method, which represents the only means in\n\t\t\t\t/// `bitvec` of writing to memory without an exclusive `&mut `\n\t\t\t\t/// reference.\n\t\t\t\t///\n\t\t\t\t/// Construction of two such shared, aliasing, references over\n\t\t\t\t/// the same data, then construction of a bit-domain view over\n\t\t\t\t/// one of them and simultaneous writing through the other to\n\t\t\t\t/// interior elements marked as unaliased, will cause the\n\t\t\t\t/// bit-domain view to be undefined behavior. Do not combine\n\t\t\t\t/// bit-domain views and `.set_aliased` calls.\n\t\t\t\tbody: &'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t/// Any bits that partially fill the last element of the slice\n\t\t\t\t/// region.\n\t\t\t\t///\n\t\t\t\t/// This does not modify its aliasing status, as it will already\n\t\t\t\t/// be appropriately marked before constructing this view.\n\t\t\t\ttail: &'a $($m)? BitSlice<O, T>,\n\t\t\t},\n\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::empty":["#[inline]\nfn empty() -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: Default::default(),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::enclave":["/// Attempts to view the domain as an enclave variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n/// enclave fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Enclave`]: #variant.Enclave\n#[inline]\npub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)>{\n\t\t\t\tif let Self::Enclave { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::major":["#[inline]\nfn major(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = bit_domain!(split $($m)?\n\t\t\t\t\trest,\n\t\t\t\t\trest.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: bit_domain!(retype $($m)? head),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? body),\n\t\t\t\t\ttail: bit_domain!(retype $($m)? tail),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::minor":["#[inline]\nfn minor(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\tbody: slice,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::new":["/// Constructs a bit-domain view from a bitslice.\n///\n/// # Parameters\n///\n/// - `slice`: The source bitslice for which the view is constructed\n///\n/// # Returns\n///\n/// A bit-domain view over the source slice.\n#[inline]\npub(crate) fn new(slice: &'a $($m)? BitSlice<O, T>) -> Self{\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet h = bitptr.head();\n\t\t\t\tlet (e, t) = h.span(bitptr.len());\n\t\t\t\tlet w = T::Mem::BITS;\n\n\t\t\t\tmatch (h.value(), e, t.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == w => Self::spanning(slice),\n\t\t\t\t\t(_, _, t) if t == w => Self::partial_head(slice, h),\n\t\t\t\t\t(0, ..) => Self::partial_tail(slice, h, t),\n\t\t\t\t\t(_, 1, _) => Self::minor(slice, h, t),\n\t\t\t\t\t_ => Self::major(slice, h, t),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::partial_head":["#[inline]\nfn partial_head(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (head, body) = (\n\t\t\t\t\tbit_domain!(retype $($m)? head),\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::partial_tail":["#[inline]\nfn partial_tail(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/* This discarded head argument makes all constructor functions\n\t\t\t\thave the same register layout for the call, allowing the `::new`\n\t\t\t\tfunction to establish the arguments ahead of time, then select a\n\t\t\t\tconstructor function to jump into.\n\t\t\t\t*/\n\t\t\t\t_head: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (rest, tail) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\tslice.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = (\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t\tbit_domain!(retype $($m)? tail),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::region":["/// Attempts to view the domain as a region variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Region`] variant, this returns `Some` of the\n/// region fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Region`]: #variant.Region\n#[inline]\npub fn region(self) -> Option<(\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\t&'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t)>{\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomain::<'a, O, T>::spanning":["#[inline]\nfn spanning(slice: &'a $($m)? BitSlice<O, T>) -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? slice),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut":["/// Granular representation of the memory region containing a\n/// `BitSlice`.\n///\n/// `BitSlice` regions can be described in terms of edge and center\n/// elements, where the edge elements retain the aliasing status of the\n/// source `BitSlice` handle, and the center elements are known to be\n/// completely unaliased by any other view. This property allows any\n/// `BitSlice` handle to be decomposed into smaller regions, and safely\n/// remove any aliasing markers from the subregion of memory that no\n/// longer requires them for correct access.\n///\n/// This enum acts like the `.split*` methods in that it only subdivides\n/// the source `BitSlice` into smaller `BitSlices`, and makes\n/// appropriate modifications to the aliasing markers. It does not\n/// provide references to the underlying memory elements. If you need\n/// such access directly, use the [`Domain`] or [`DomainMut`] enums.\n///\n/// # Lifetimes\n///\n/// - `'a`: The lifetime of the referent storage region.\n///\n/// # Type Parameters\n///\n/// - `O`: The ordering type of the source `BitSlice` handle.\n/// - `T`: The element type of the source `BitSlice` handle, including\n///   aliasing markers.\n///\n/// [`Domain`]: enum.Domain.html\n/// [`DomainMut`]: enum.DomainMut.html\npub enum $t <'a, O, T>\n\t\twhere\n\t\t\tO: BitOrder,\n\t\t\tT: 'a + BitStore\n\t\t{\n\t\t\t/// Indicates that a `BitSlice` is contained entirely in the\n\t\t\t/// interior indices of a single memory element.\n\t\t\tEnclave {\n\t\t\t\t/// The start index of the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is not likely to be useful information, but is retained\n\t\t\t\t/// for structural similarity with the rest of the module.\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\t/// The original `BitSlice` used to create this bit-domain view.\n\t\t\t\tbody: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/// The end index of the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is not likely to be useful information, but is retained\n\t\t\t\t/// for structural similarity with the rest of the module.\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t},\n\t\t\t/// Indicates that a `BitSlice` region touches at least one edge\n\t\t\t/// index of any number of elements.\n\t\t\t///\n\t\t\t/// This contains two bitslices representing the partially-occupied\n\t\t\t/// edge elements, with their original aliasing marker, and one\n\t\t\t/// bitslice representing the fully-occupied interior elements,\n\t\t\t/// marked as unaliased.\n\t\t\tRegion {\n\t\t\t\t/// Any bits that partially-fill the base element of the slice\n\t\t\t\t/// region.\n\t\t\t\t///\n\t\t\t\t/// This does not modify its aliasing status, as it will already\n\t\t\t\t/// be appropriately marked before constructing this view.\n\t\t\t\thead: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/// Any bits inside elements that the source bitslice completely\n\t\t\t\t/// covers.\n\t\t\t\t///\n\t\t\t\t/// This is marked as unaliased, because it is statically\n\t\t\t\t/// impossible for any other handle to have write access to the\n\t\t\t\t/// region it covers. As such, a bitslice that was marked as\n\t\t\t\t/// entirely aliased, but contains interior unaliased elements,\n\t\t\t\t/// can safely remove its aliasing protections.\n\t\t\t\t///\n\t\t\t\t/// # Safety Exception\n\t\t\t\t///\n\t\t\t\t/// `&BitSlice<O, T::Alias>` references have access to a\n\t\t\t\t/// `.set_aliased` method, which represents the only means in\n\t\t\t\t/// `bitvec` of writing to memory without an exclusive `&mut `\n\t\t\t\t/// reference.\n\t\t\t\t///\n\t\t\t\t/// Construction of two such shared, aliasing, references over\n\t\t\t\t/// the same data, then construction of a bit-domain view over\n\t\t\t\t/// one of them and simultaneous writing through the other to\n\t\t\t\t/// interior elements marked as unaliased, will cause the\n\t\t\t\t/// bit-domain view to be undefined behavior. Do not combine\n\t\t\t\t/// bit-domain views and `.set_aliased` calls.\n\t\t\t\tbody: &'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t/// Any bits that partially fill the last element of the slice\n\t\t\t\t/// region.\n\t\t\t\t///\n\t\t\t\t/// This does not modify its aliasing status, as it will already\n\t\t\t\t/// be appropriately marked before constructing this view.\n\t\t\t\ttail: &'a $($m)? BitSlice<O, T>,\n\t\t\t},\n\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::empty":["#[inline]\nfn empty() -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: Default::default(),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::enclave":["/// Attempts to view the domain as an enclave variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n/// enclave fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Enclave`]: #variant.Enclave\n#[inline]\npub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)>{\n\t\t\t\tif let Self::Enclave { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::major":["#[inline]\nfn major(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = bit_domain!(split $($m)?\n\t\t\t\t\trest,\n\t\t\t\t\trest.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: bit_domain!(retype $($m)? head),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? body),\n\t\t\t\t\ttail: bit_domain!(retype $($m)? tail),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::minor":["#[inline]\nfn minor(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\tbody: slice,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::new":["/// Constructs a bit-domain view from a bitslice.\n///\n/// # Parameters\n///\n/// - `slice`: The source bitslice for which the view is constructed\n///\n/// # Returns\n///\n/// A bit-domain view over the source slice.\n#[inline]\npub(crate) fn new(slice: &'a $($m)? BitSlice<O, T>) -> Self{\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet h = bitptr.head();\n\t\t\t\tlet (e, t) = h.span(bitptr.len());\n\t\t\t\tlet w = T::Mem::BITS;\n\n\t\t\t\tmatch (h.value(), e, t.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == w => Self::spanning(slice),\n\t\t\t\t\t(_, _, t) if t == w => Self::partial_head(slice, h),\n\t\t\t\t\t(0, ..) => Self::partial_tail(slice, h, t),\n\t\t\t\t\t(_, 1, _) => Self::minor(slice, h, t),\n\t\t\t\t\t_ => Self::major(slice, h, t),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::partial_head":["#[inline]\nfn partial_head(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (head, rest) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\t(T::Mem::BITS - head.value()) as usize,\n\t\t\t\t);\n\t\t\t\tlet (head, body) = (\n\t\t\t\t\tbit_domain!(retype $($m)? head),\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::partial_tail":["#[inline]\nfn partial_tail(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\t/* This discarded head argument makes all constructor functions\n\t\t\t\thave the same register layout for the call, allowing the `::new`\n\t\t\t\tfunction to establish the arguments ahead of time, then select a\n\t\t\t\tconstructor function to jump into.\n\t\t\t\t*/\n\t\t\t\t_head: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet (rest, tail) = bit_domain!(split $($m)?\n\t\t\t\t\tslice,\n\t\t\t\t\tslice.len() - (tail.value() as usize),\n\t\t\t\t);\n\t\t\t\tlet (body, tail) = (\n\t\t\t\t\tbit_domain!(retype $($m)? rest),\n\t\t\t\t\tbit_domain!(retype $($m)? tail),\n\t\t\t\t);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::region":["/// Attempts to view the domain as a region variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Region`] variant, this returns `Some` of the\n/// region fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Region`]: #variant.Region\n#[inline]\npub fn region(self) -> Option<(\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t\t&'a $($m)? BitSlice<O, T::Mem>,\n\t\t\t\t&'a $($m)? BitSlice<O, T>,\n\t\t\t)>{\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head, body, tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::BitDomainMut::<'a, O, T>::spanning":["#[inline]\nfn spanning(slice: &'a $($m)? BitSlice<O, T>) -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Default::default(),\n\t\t\t\t\tbody: bit_domain!(retype $($m)? slice),\n\t\t\t\t\ttail: Default::default(),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain":["/// Granular representation of the memory region containing a\n/// `BitSlice`.\n///\n/// `BitSlice` regions can be described in terms of edge and center\n/// elements, where the edge elements retain the aliasing status of the\n/// source `BitSlice` handle, and the center elements are known to be\n/// completely unaliased by any other view. This property allows any\n/// `BitSlice` handle to be decomposed into smaller regions, and safely\n/// remove any aliasing markers from the subregion of memory that no\n/// longer requires them for correct access.\n///\n/// This enum splits the element region backing a `BitSlice` into\n/// maybe-aliased and known-unaliased subslices. If you do not need to\n/// work directly with the memory elements, and only need to firmly\n/// specify the aliasing status of a `BitSlice`, see the [`BitDomain`]\n/// and [`BitDomainMut`] enums.\n///\n/// # Lifetimes\n///\n/// - `'a`: The lifetime of the referent storage region.\n///\n/// # Type Parameters\n///\n/// - `T`: The element type of the source `BitSlice` handle, including\n///   aliasing markers.\n///\n/// [`BitDomain`]: enum.BitDomain.html\n/// [`BitDomainMut`]: enum.BitDomainMut.html\npub enum $t <'a, T>\n\t\twhere\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Indicates that a `BitSlice` is contained entirely in the\n\t\t\t/// interior indices of a single memory element.\n\t\t\tEnclave {\n\t\t\t\t/// The start index of the `BitSlice`.\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\t/// An aliased view of the element containing the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is necessary even on immutable views, because other\n\t\t\t\t/// views to the referent element may be permitted to modify it.\n\t\t\t\telem: &'a T::Alias,\n\t\t\t\t/// The end index of the `BitSlice`.\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t},\n\t\t\t/// Indicates that a `BitSlice` region touches at least one edge\n\t\t\t/// index of any number of elements.\n\t\t\t///\n\t\t\t/// This contains two optional references to the aliased edges, and\n\t\t\t/// one reference to the unaliased middle. Each can be queried and\n\t\t\t/// used individually.\n\t\t\tRegion {\n\t\t\t\t/// If the `BitSlice` started in the interior of its first\n\t\t\t\t/// element, this contains the starting index and the base\n\t\t\t\t/// address.\n\t\t\t\thead: Option<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t/// All fully-spanned, unaliased, elements.\n\t\t\t\t///\n\t\t\t\t/// This is marked as bare memory without any access\n\t\t\t\t/// protections, because it is statically impossible for any\n\t\t\t\t/// other handle to have write access to the region it covers.\n\t\t\t\t/// As such, a bitslice that was marked as entirely aliased, but\n\t\t\t\t/// contains interior unaliased elements, can safely remove its\n\t\t\t\t/// aliasing protections.\n\t\t\t\t///\n\t\t\t\t/// # Safety Exception\n\t\t\t\t///\n\t\t\t\t/// `&BitSlice<O, T::Alias>` references have access to a\n\t\t\t\t/// `.set_aliased` method, which represents the only means in\n\t\t\t\t/// `bitvec` of writing to memory without an exclusive `&mut `\n\t\t\t\t/// reference.\n\t\t\t\t///\n\t\t\t\t/// Construction of two such shared, aliasing, references over\n\t\t\t\t/// the same data, then construction of a domain view over one\n\t\t\t\t/// of them and simultaneous writing through the other to\n\t\t\t\t/// interior elements marked as unaliased, will cause the domain\n\t\t\t\t/// view to be undefined behavior. Do not combine domain views\n\t\t\t\t/// and `.set_aliased` calls.\n\t\t\t\tbody: &'a $($m)? [T::Mem],\n\t\t\t\t/// If the `BitSlice` ended in the interior of its last element,\n\t\t\t\t/// this contains the ending index and the last address.\n\t\t\t\ttail: Option<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t}\n\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::empty":["#[inline]\nfn empty() -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: & $($m)? [],\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::enclave":["/// Attempts to view the domain as an enclave variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n/// enclave fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Enclave`]: #variant.Enclave\n#[inline]\npub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a T::Alias,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)>{\n\t\t\t\tif let Self::Enclave { head, elem, tail } = self {\n\t\t\t\t\tSome((head, elem, tail))\n\t\t\t\t} else {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::major":["#[inline]\nfn major(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 2);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::minor":["#[inline]\nfn minor(\n\t\t\t\taddr: *const T::Alias,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\telem: unsafe { &*addr },\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::new":["#[inline]\npub(crate) fn new<O>(slice: &'a $($m)? BitSlice<O, T>) -> Self\n\t\t\twhere O: BitOrder{\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet head = bitptr.head();\n\t\t\t\tlet elts = bitptr.elements();\n\t\t\t\tlet tail = bitptr.tail();\n\t\t\t\tlet bits = T::Mem::BITS;\n\t\t\t\tlet base = bitptr.pointer().to_alias();\n\t\t\t\tmatch (head.value(), elts, tail.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == bits => Self::spanning(base, elts),\n\t\t\t\t\t(_, _, t) if t == bits => Self::partial_head(base, elts, head),\n\t\t\t\t\t(0, ..) => Self::partial_tail(base, elts, tail),\n\t\t\t\t\t(_, 1, _) => Self::minor(base, head, tail),\n\t\t\t\t\t_ => Self::major(base, elts, head, tail),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::partial_head":["#[inline]\nfn partial_head(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::partial_tail":["#[inline]\nfn partial_tail(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base, elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::region":["/// Attempts to view the domain as the region variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Region`] variant, this returns `Some` of the\n/// region fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Region`]: #variant.Region\n#[inline]\npub fn region(self) -> Option<(\n\t\t\t\tOption<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t&'a $($m)? [T::Mem],\n\t\t\t\tOption<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t)>{\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head,body,tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::Domain::<'a, T>::spanning":["#[inline]\nfn spanning(base: *const T::Alias, elts: usize) -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: domain!(slice $($m)? base, elts),\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut":["/// Granular representation of the memory region containing a\n/// `BitSlice`.\n///\n/// `BitSlice` regions can be described in terms of edge and center\n/// elements, where the edge elements retain the aliasing status of the\n/// source `BitSlice` handle, and the center elements are known to be\n/// completely unaliased by any other view. This property allows any\n/// `BitSlice` handle to be decomposed into smaller regions, and safely\n/// remove any aliasing markers from the subregion of memory that no\n/// longer requires them for correct access.\n///\n/// This enum splits the element region backing a `BitSlice` into\n/// maybe-aliased and known-unaliased subslices. If you do not need to\n/// work directly with the memory elements, and only need to firmly\n/// specify the aliasing status of a `BitSlice`, see the [`BitDomain`]\n/// and [`BitDomainMut`] enums.\n///\n/// # Lifetimes\n///\n/// - `'a`: The lifetime of the referent storage region.\n///\n/// # Type Parameters\n///\n/// - `T`: The element type of the source `BitSlice` handle, including\n///   aliasing markers.\n///\n/// [`BitDomain`]: enum.BitDomain.html\n/// [`BitDomainMut`]: enum.BitDomainMut.html\npub enum $t <'a, T>\n\t\twhere\n\t\t\tT: 'a + BitStore,\n\t\t{\n\t\t\t/// Indicates that a `BitSlice` is contained entirely in the\n\t\t\t/// interior indices of a single memory element.\n\t\t\tEnclave {\n\t\t\t\t/// The start index of the `BitSlice`.\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\t/// An aliased view of the element containing the `BitSlice`.\n\t\t\t\t///\n\t\t\t\t/// This is necessary even on immutable views, because other\n\t\t\t\t/// views to the referent element may be permitted to modify it.\n\t\t\t\telem: &'a T::Alias,\n\t\t\t\t/// The end index of the `BitSlice`.\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t},\n\t\t\t/// Indicates that a `BitSlice` region touches at least one edge\n\t\t\t/// index of any number of elements.\n\t\t\t///\n\t\t\t/// This contains two optional references to the aliased edges, and\n\t\t\t/// one reference to the unaliased middle. Each can be queried and\n\t\t\t/// used individually.\n\t\t\tRegion {\n\t\t\t\t/// If the `BitSlice` started in the interior of its first\n\t\t\t\t/// element, this contains the starting index and the base\n\t\t\t\t/// address.\n\t\t\t\thead: Option<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t/// All fully-spanned, unaliased, elements.\n\t\t\t\t///\n\t\t\t\t/// This is marked as bare memory without any access\n\t\t\t\t/// protections, because it is statically impossible for any\n\t\t\t\t/// other handle to have write access to the region it covers.\n\t\t\t\t/// As such, a bitslice that was marked as entirely aliased, but\n\t\t\t\t/// contains interior unaliased elements, can safely remove its\n\t\t\t\t/// aliasing protections.\n\t\t\t\t///\n\t\t\t\t/// # Safety Exception\n\t\t\t\t///\n\t\t\t\t/// `&BitSlice<O, T::Alias>` references have access to a\n\t\t\t\t/// `.set_aliased` method, which represents the only means in\n\t\t\t\t/// `bitvec` of writing to memory without an exclusive `&mut `\n\t\t\t\t/// reference.\n\t\t\t\t///\n\t\t\t\t/// Construction of two such shared, aliasing, references over\n\t\t\t\t/// the same data, then construction of a domain view over one\n\t\t\t\t/// of them and simultaneous writing through the other to\n\t\t\t\t/// interior elements marked as unaliased, will cause the domain\n\t\t\t\t/// view to be undefined behavior. Do not combine domain views\n\t\t\t\t/// and `.set_aliased` calls.\n\t\t\t\tbody: &'a $($m)? [T::Mem],\n\t\t\t\t/// If the `BitSlice` ended in the interior of its last element,\n\t\t\t\t/// this contains the ending index and the last address.\n\t\t\t\ttail: Option<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t}\n\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::empty":["#[inline]\nfn empty() -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: & $($m)? [],\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::enclave":["/// Attempts to view the domain as an enclave variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Enclave`] variant, this returns `Some` of the\n/// enclave fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Enclave`]: #variant.Enclave\n#[inline]\npub fn enclave(self) -> Option<(\n\t\t\t\tBitIdx<T::Mem>,\n\t\t\t\t&'a T::Alias,\n\t\t\t\tBitTail<T::Mem>,\n\t\t\t)>{\n\t\t\t\tif let Self::Enclave { head, elem, tail } = self {\n\t\t\t\t\tSome((head, elem, tail))\n\t\t\t\t} else {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::major":["#[inline]\nfn major(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 2);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::minor":["#[inline]\nfn minor(\n\t\t\t\taddr: *const T::Alias,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tSelf::Enclave {\n\t\t\t\t\thead,\n\t\t\t\t\telem: unsafe { &*addr },\n\t\t\t\t\ttail,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::new":["#[inline]\npub(crate) fn new<O>(slice: &'a $($m)? BitSlice<O, T>) -> Self\n\t\t\twhere O: BitOrder{\n\t\t\t\tlet bitptr = slice.bitptr();\n\t\t\t\tlet head = bitptr.head();\n\t\t\t\tlet elts = bitptr.elements();\n\t\t\t\tlet tail = bitptr.tail();\n\t\t\t\tlet bits = T::Mem::BITS;\n\t\t\t\tlet base = bitptr.pointer().to_alias();\n\t\t\t\tmatch (head.value(), elts, tail.value()) {\n\t\t\t\t\t(_, 0, _) => Self::empty(),\n\t\t\t\t\t(0, _, t) if t == bits => Self::spanning(base, elts),\n\t\t\t\t\t(_, _, t) if t == bits => Self::partial_head(base, elts, head),\n\t\t\t\t\t(0, ..) => Self::partial_tail(base, elts, tail),\n\t\t\t\t\t(_, 1, _) => Self::minor(base, head, tail),\n\t\t\t\t\t_ => Self::major(base, elts, head, tail),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::partial_head":["#[inline]\nfn partial_head(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\thead: BitIdx<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet h = unsafe { &*base };\n\t\t\t\tlet body = domain!(slice $($m)? base.add(1), elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: Some((head, h)),\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::partial_tail":["#[inline]\nfn partial_tail(\n\t\t\t\tbase: *const T::Alias,\n\t\t\t\telts: usize,\n\t\t\t\ttail: BitTail<T::Mem>,\n\t\t\t) -> Self{\n\t\t\t\tlet t = unsafe { &*base.add(elts - 1) };\n\t\t\t\tlet body = domain!(slice $($m)? base, elts - 1);\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody,\n\t\t\t\t\ttail: Some((t, tail)),\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::region":["/// Attempts to view the domain as the region variant.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// If `self` is the [`Region`] variant, this returns `Some` of the\n/// region fields, as a tuple. Otherwise, it returns `None`.\n///\n/// [`Region`]: #variant.Region\n#[inline]\npub fn region(self) -> Option<(\n\t\t\t\tOption<(BitIdx<T::Mem>, &'a T::Alias)>,\n\t\t\t\t&'a $($m)? [T::Mem],\n\t\t\t\tOption<(&'a T::Alias, BitTail<T::Mem>)>,\n\t\t\t)>{\n\t\t\t\tif let Self::Region { head, body, tail } = self {\n\t\t\t\t\tSome((head,body,tail))\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tNone\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"domain::DomainMut::<'a, T>::spanning":["#[inline]\nfn spanning(base: *const T::Alias, elts: usize) -> Self{\n\t\t\t\tSelf::Region {\n\t\t\t\t\thead: None,\n\t\t\t\t\tbody: domain!(slice $($m)? base, elts),\n\t\t\t\t\ttail: None,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/domain.rs\"))"],"field::BitField":["/** Performs C-style bitfield access through a `BitSlice`.\n\nBit orderings that permit batched access to regions of memory are enabled to\nload data from, and store data to, a `BitStore` with faster behavior than the\ndefault bit-by-bit traversal.\n\nThis trait transfers data between a `BitSlice` and a local element. The trait\nfunctions always place the live bit region of the slice against the least\nsignificant bit edge of the local element (return value of `load`, argument of\n`store`).\n\nImplementations are encouraged to preserve in-memory bit ordering within a\nmemory element, so that call sites can provide a value pattern that the user can\nclearly see matches what they expect for memory ordering. These methods should\nonly move data between locations, without modifying the data itself.\n\nMethods should be called as `bits[start .. end].load_or_store()`, where the\nrange subslice selects no mor than the `M::BITS` element width being\ntransferred.\n**/\npub trait BitField {\n\t/// Loads the bits in the `self` region into a local value.\n\t///\n\t/// This can load into any of the unsigned integers which implement\n\t/// `BitMemory`. Any further transformation must be done by the user.\n\t///\n\t/// The default implementation of this function calls [`load_le`] on\n\t/// little-endian byte-ordered CPUs, and [`load_be`] on big-endian\n\t/// byte-ordered CPUs.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: A read reference to some bits in memory. This slice must be\n\t///   trimmed to have a width no more than the `M::BITS` width of the type\n\t///   being loaded. This can be accomplished with range indexing on a larger\n\t///   slice.\n\t///\n\t/// # Returns\n\t///\n\t/// A value `M` whose least `self.len()` significant bits are filled with\n\t/// the bits of `self`.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\t///\n\t/// [`load_be`]: #tymethod.load_be\n\t/// [`load_le`]: #tymethod.load_le\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tfn load<M>(&self) -> M\n\twhere M: BitMemory {\n\t\t#[cfg(target_endian = \"little\")]\n\t\treturn self.load_le::<M>();\n\n\t\t#[cfg(target_endian = \"big\")]\n\t\treturn self.load_be::<M>();\n\t}\n\n\t/// Stores a sequence of bits from the user into the domain of `self`.\n\t///\n\t/// This can store any of the unsigned integers which implement\n\t/// `BitMemory`. Any other types must first be transformed by the user.\n\t///\n\t/// The default implementation of this function calls [`store_le`] on\n\t/// little-endian byte-ordered CPUs, and [`store_be`] on big-endian\n\t/// byte-ordered CPUs.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`: A write reference to some bits in memory. This slice must\n\t///   be trimmed to have a width no more than the `M::BITS` width of the\n\t///   type being stored. This can be accomplished with range indexing on a\n\t///   larger slice.\n\t/// - `value`: A value, whose `self.len()` least significant bits will be\n\t///   stored into `self`.\n\t///\n\t/// # Behavior\n\t///\n\t/// The `self.len()` least significant bits of `value` are written into the\n\t/// domain of `self`.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\t///\n\t/// [`store_be`]: #tymethod.store_be\n\t/// [`store_le`]: #tymethod.store_le\n\t#[inline(always)]\n\t#[cfg(not(tarpaulin_include))]\n\tfn store<M>(&mut self, value: M)\n\twhere M: BitMemory {\n\t\t#[cfg(target_endian = \"little\")]\n\t\tself.store_le(value);\n\n\t\t#[cfg(target_endian = \"big\")]\n\t\tself.store_be(value);\n\t}\n\n\t/// Loads from `self`, using little-endian element `T` ordering.\n\t///\n\t/// This function interprets a multi-element slice as having its least\n\t/// significant chunk in the low memory address, and its most significant\n\t/// chunk in the high memory address. Each element `T` is still interpreted\n\t/// from individual bytes according to the local CPU ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: A read reference to some bits in memory. This slice must be\n\t///   trimmed to have a width no more than the `M::BITS` width of the type\n\t///   being loaded. This can be accomplished with range indexing on a larger\n\t///   slice.\n\t///\n\t/// # Returns\n\t///\n\t/// A value `M` whose least `self.len()` significant bits are filled with\n\t/// the bits of `self`. If `self` spans multiple elements `T`, then the\n\t/// lowest-address `T` is interpreted as containing the least significant\n\t/// bits of the return value `M`, and the highest-address `T` is interpreted\n\t/// as containing its most significant bits.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\tfn load_le<M>(&self) -> M\n\twhere M: BitMemory;\n\n\t/// Loads from `self`, using big-endian element `T` ordering.\n\t///\n\t/// This function interprets a multi-element slice as having its most\n\t/// significant chunk in the low memory address, and its least significant\n\t/// chunk in the high memory address. Each element `T` is still interpreted\n\t/// from individual bytes according to the local CPU ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: A read reference to some bits in memory. This slice must be\n\t///   trimmed to have a width no more than the `M::BITS` width of the type\n\t///   being loaded. This can be accomplished with range indexing on a larger\n\t///   slice.\n\t///\n\t/// # Returns\n\t///\n\t/// A value `M` whose least `self.len()` significant bits are filled with\n\t/// the bits of `self`. If `self` spans multiple elements `T`, then the\n\t/// lowest-address `T` is interpreted as containing the most significant\n\t/// bits of the return value `M`, and the highest-address `T` is interpreted\n\t/// as containing its least significant bits.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\tfn load_be<M>(&self) -> M\n\twhere M: BitMemory;\n\n\t/// Stores into `self`, using little-endian element ordering.\n\t///\n\t/// This function interprets a multi-element slice as having its least\n\t/// significant chunk in the low memory address, and its most significant\n\t/// chunk in the high memory address. Each element `T` is still interpreted\n\t/// from individual bytes according to the local CPU ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`: A write reference to some bits in memory. This slice must\n\t///   be trimmed to have a width no more than the `M::BITS` width of the\n\t///   type being stored. This can be accomplished with range indexing on a\n\t///   larger slice.\n\t/// - `value`: A value, whose `self.len()` least significant bits will be\n\t///   stored into `self`.\n\t///\n\t/// # Behavior\n\t///\n\t/// The `self.len()` least significant bits of `value` are written into the\n\t/// domain of `self`. If `self` spans multiple elements `T`, then the\n\t/// lowest-address `T` is interpreted as containing the least significant\n\t/// bits of the `M` return value, and the highest-address `T` is interpreted\n\t/// as containing its most significant bits.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\tfn store_le<M>(&mut self, value: M)\n\twhere M: BitMemory;\n\n\t/// Stores into `self`, using big-endian element ordering.\n\t///\n\t/// This function interprets a multi-element slice as having its most\n\t/// significant chunk in the low memory address, and its least significant\n\t/// chunk in the high memory address. Each element `T` is still interpreted\n\t/// from individual bytes according to the local CPU ordering.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`: A write reference to some bits in memory. This slice must\n\t///   be trimmed to have a width no more than the `M::BITS` width of the\n\t///   type being stored. This can be accomplished with range indexing on a\n\t///   larger slice.\n\t/// - `value`: A value, whose `self.len()` least significant bits will be\n\t///   stored into `self`.\n\t///\n\t/// # Behavior\n\t///\n\t/// The `self.len()` least significant bits of `value` are written into the\n\t/// domain of `self`. If `self` spans multiple elements `T`, then the\n\t/// lowest-address `T` is interpreted as containing the most significant\n\t/// bits of the `M` return value, and the highest-address `T` is interpreted\n\t/// as containing its least significant bits.\n\t///\n\t/// # Panics\n\t///\n\t/// This method is encouraged to panic if `self` is empty, or wider than a\n\t/// single element `M`.\n\tfn store_be<M>(&mut self, value: M)\n\twhere M: BitMemory;\n}","Real(LocalPath(\"src/field.rs\"))"],"field::BitField::load":["/// Loads the bits in the `self` region into a local value.\n///\n/// This can load into any of the unsigned integers which implement\n/// `BitMemory`. Any further transformation must be done by the user.\n///\n/// The default implementation of this function calls [`load_le`] on\n/// little-endian byte-ordered CPUs, and [`load_be`] on big-endian\n/// byte-ordered CPUs.\n///\n/// # Parameters\n///\n/// - `&self`: A read reference to some bits in memory. This slice must be\n///   trimmed to have a width no more than the `M::BITS` width of the type\n///   being loaded. This can be accomplished with range indexing on a larger\n///   slice.\n///\n/// # Returns\n///\n/// A value `M` whose least `self.len()` significant bits are filled with\n/// the bits of `self`.\n///\n/// # Panics\n///\n/// This method is encouraged to panic if `self` is empty, or wider than a\n/// single element `M`.\n///\n/// [`load_be`]: #tymethod.load_be\n/// [`load_le`]: #tymethod.load_le\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn load<M>(&self) -> M\n\twhere M: BitMemory{\n\t\t#[cfg(target_endian = \"little\")]\n\t\treturn self.load_le::<M>();\n\n\t\t#[cfg(target_endian = \"big\")]\n\t\treturn self.load_be::<M>();\n\t}","Real(LocalPath(\"src/field.rs\"))"],"field::BitField::store":["/// Stores a sequence of bits from the user into the domain of `self`.\n///\n/// This can store any of the unsigned integers which implement\n/// `BitMemory`. Any other types must first be transformed by the user.\n///\n/// The default implementation of this function calls [`store_le`] on\n/// little-endian byte-ordered CPUs, and [`store_be`] on big-endian\n/// byte-ordered CPUs.\n///\n/// # Parameters\n///\n/// - `&mut self`: A write reference to some bits in memory. This slice must\n///   be trimmed to have a width no more than the `M::BITS` width of the\n///   type being stored. This can be accomplished with range indexing on a\n///   larger slice.\n/// - `value`: A value, whose `self.len()` least significant bits will be\n///   stored into `self`.\n///\n/// # Behavior\n///\n/// The `self.len()` least significant bits of `value` are written into the\n/// domain of `self`.\n///\n/// # Panics\n///\n/// This method is encouraged to panic if `self` is empty, or wider than a\n/// single element `M`.\n///\n/// [`store_be`]: #tymethod.store_be\n/// [`store_le`]: #tymethod.store_le\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn store<M>(&mut self, value: M)\n\twhere M: BitMemory{\n\t\t#[cfg(target_endian = \"little\")]\n\t\tself.store_le(value);\n\n\t\t#[cfg(target_endian = \"big\")]\n\t\tself.store_be(value);\n\t}","Real(LocalPath(\"src/field.rs\"))"],"field::check":["/// Asserts that a slice length is within a memory element width.\n#[inline]\nfn check(action: &'static str, len: usize, width: u8){\n\tif !(1 ..= width as usize).contains(&len) {\n\t\tpanic!(\"Cannot {} {} bits from a {}-bit region\", action, width, len);\n\t}\n}","Real(LocalPath(\"src/field.rs\"))"],"field::get":["/** Reads a value out of a section of a memory element.\n\nThis function is used to extract a portion of an `M` value from a portion of a\n`T` value. The `BitField` implementations call it as they assemble a complete\n`M`. It performs the following steps:\n\n1. the referent value of the `elem` pointer is copied into local memory,\n2. `mask`ed to discard the portions of `*elem` that are not live,\n3. shifted to the LSedge of the `T::Mem` temporary,\n4. then `resize`d into an `M` value.\n\nThis is the exact inverse of `set`.\n\n# Type Parameters\n\n- `T`: The `BitStore` type of a `BitSlice` that is the source of a read event.\n- `M`: The local type of the data contained in that `BitSlice`.\n\n# Parameters\n\n- `elem`: An aliased reference to a single element of a `BitSlice` storage. This\n  is required to remain aliased, as other write-capable references to the\n  location may exist.\n- `mask`: A `BitMask` of the live region of the value at `*elem` to be used as\n  the contents of the returned value.\n- `shamt`: The distance of the least significant bit of the mask region from the\n  least significant edge of the `T::Mem` fetched value.\n\n# Returns\n\n`resize((*elem & mask) >> shamt)`\n**/\n#[inline]\nfn get<T, M>(elem: &T::Alias, mask: BitMask<T::Mem>, shamt: u8) -> M\nwhere\n\tT: BitStore,\n\tM: BitMemory,{\n\telem.pipe(dvl::load_aliased_local::<T>)\n\t\t.pipe(|val| mask & val)\n\t\t.value()\n\t\t.pipe(|val| Shr::<u8>::shr(val, shamt))\n\t\t.pipe(resize::<T::Mem, M>)\n}","Real(LocalPath(\"src/field.rs\"))"],"field::io::<impl std::io::Read for &'a slice::BitSlice<O, T>>::read":["#[inline]\nfn read(&mut self, buf: &mut [u8]) -> io::Result<usize>{\n\t\tlet mut idx = 0;\n\t\tfor (byte, slot) in self.chunks_exact(8).zip(buf.iter_mut()) {\n\t\t\t*slot = byte.load();\n\t\t\tidx += 1;\n\t\t}\n\t\t*self = unsafe { self.get_unchecked(idx * 8 ..) };\n\t\tOk(idx)\n\t}","Real(LocalPath(\"src/field/io.rs\"))"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::flush":["#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn flush(&mut self) -> io::Result<()>{\n\t\tOk(())\n\t}","Real(LocalPath(\"src/field/io.rs\"))"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::write":["#[inline]\nfn write(&mut self, buf: &[u8]) -> io::Result<usize>{\n\t\tlet mut idx = 0;\n\t\tfor (slot, byte) in self.chunks_exact_mut(8).zip(buf.iter().copied()) {\n\t\t\tslot.store(byte);\n\t\t\tidx += 1;\n\t\t}\n\t\t*self = unsafe { mem::take(self).get_unchecked_mut(idx * 8 ..) };\n\t\tOk(idx)\n\t}","Real(LocalPath(\"src/field/io.rs\"))"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::flush":["#[inline(always)]\n#[cfg(not(tarpaulin_include))]\nfn flush(&mut self) -> io::Result<()>{\n\t\tOk(())\n\t}","Real(LocalPath(\"src/field/io.rs\"))"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::write":["#[inline]\nfn write(&mut self, buf: &[u8]) -> io::Result<usize>{\n\t\tlet len = self.len();\n\t\tself.resize(len + buf.len() * 8, false);\n\t\tunsafe { self.get_unchecked_mut(len ..) }.write(buf)\n\t}","Real(LocalPath(\"src/field/io.rs\"))"],"field::resize":["/** Resizes a value from one register width to another\n\nThis zero-extends or truncates its source value in order to fit in the target\ntype.\n\n# Type Parameters\n\n- `T`: The initial register type of the value to resize.\n- `U`: The final register type of the resized value.\n\n# Parameters\n\n- `value`: Any register value\n\n# Returns\n\n`value`, either zero-extended if `U` is wider than `T` or truncated if `U` is\nnarrower than `T`.\n**/\n#[inline]\nfn resize<T, U>(value: T) -> U\nwhere\n\tT: BitMemory,\n\tU: BitMemory,{\n\tlet mut out = U::ZERO;\n\tlet size_t = mem::size_of::<T>();\n\tlet size_u = mem::size_of::<U>();\n\n\tunsafe {\n\t\tresize_inner::<T, U>(&value, &mut out, size_t, size_u);\n\t}\n\n\tout\n}","Real(LocalPath(\"src/field.rs\"))"],"field::resize_inner":["/// Performs little-endian byte-order register resizing.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\n#[cfg(target_endian = \"little\")]\nunsafe fn resize_inner<T, U>(\n\tsrc: &T,\n\tdst: &mut U,\n\tsize_t: usize,\n\tsize_u: usize,\n){\n\t//  In LE, the least significant byte is the base address, so resizing is\n\t//  just a memcpy into a zeroed slot, taking only the smaller width.\n\tptr::copy_nonoverlapping(\n\t\tsrc as *const T as *const u8,\n\t\tdst as *mut U as *mut u8,\n\t\tcore::cmp::min(size_t, size_u),\n\t);\n}","Real(LocalPath(\"src/field.rs\"))"],"field::set":["/** Writes a value into a section of a memory element.\n\nThis function is used to emplace a portion of an `M` value into a portion of a\n`T` value. The `BitField` implementations call it as they disassemble a complete\n`M`. It performs the following steps:\n\n1. the provided `value` is `resize`d from `M` to `T::Mem`,\n2. then shifted from the LSedge of the `T::Mem` temporary by `shamt`,\n3. `mask`ed to discard the portions of `value` that are not live,\n4. then written into the `mask`ed portion of `*elem`.\n\nThis is the exact inverse of `get`.\n\n# Type Parameters\n\n- `T`: The `BitStore` type of a `BitSlice` that is the sink of a write event.\n- `M`: The local type of the data being written into that `BitSlice`.\n\n# Parameters\n\n- `elem`: An aliased reference to a single element of a `BitSlice` storage.\n- `value`: The value whose least-significant bits will be written into the\n  subsection of `*elt` covered by `mask`.\n- `mask`: A `BitMask` of the live region of the value at `*elem` to be used as\n  a filter on the provided value.\n- `shamt`: The distance of the least significant bit of the mask region from the\n  least significant edge of the `T::Mem` destination value.\n\n# Effects\n\n`*elem &= !mask; *elem |= (resize(value) << shamt) & mask;`\n**/\n#[inline]\nfn set<T, M>(elem: &T::Alias, value: M, mask: BitMask<T::Mem>, shamt: u8)\nwhere\n\tT: BitStore,\n\tM: BitMemory,{\n\t//  Convert the aliasing reference into its accessing type.\n\tlet elem = dvl::accessor(elem);\n\t//  Mark the mask as aliased, to fit into the accessor reference.\n\tlet mask = dvl::alias_mask::<T>(mask);\n\t//  Modify `value` to fit the accessor reference, by:\n\tlet value = value\n\t\t//  resizing from `M` to `T::Mem`,\n\t\t.pipe(resize::<M, T::Mem>)\n\t\t//  marking it as `T::Alias::Mem`,\n\t\t.pipe(dvl::alias_mem::<T>)\n\t\t//  and shifting it left by `shamt` to be in the mask region,\n\t\t.pipe(|val| Shl::<u8>::shl(val, shamt))\n\t\t//  then masking it.\n\t\t.pipe(|val| mask & val);\n\n\telem.clear_bits(mask);\n\telem.set_bits(value);\n}","Real(LocalPath(\"src/field.rs\"))"],"index::BitIdx":["/** A semantic index of a single bit within a memory element `M`.\n\nThis type is a counter in the range `0 .. M::BITS`, and marks the semantic\nposition of a bit according to some [`BitOrder`] implementation. As an abstract\ncounter, it can be used in arithmetic without having to go through `BitOrder`\ntranslation to an electrical position.\n\n# Type Parameters\n\n- `M`: The register type that values of this type govern.\n\n# Validity\n\nValues of this type are required to be in the range `0 .. M::BITS`. Any value\noutside this range will cause the program state to become invalid, and the\nlibrary’s behavior is unspecified. The library will never produce such an\ninvalid value.\n\n# Construction\n\nThis type cannot be constructed outside the `bitvec` crate. `bitvec` will\nconstruct safe values of this type, and allows users to view them and use them\nto construct other index types from them. All values of this type constructed by\n`bitvec` are known to be correct based on user input to the crate.\n**/\n#[repr(transparent)]\npub struct BitIdx<M>\nwhere M: BitMemory\n{\n\t/// Semantic index counter within an element, constrained to `0 .. M::BITS`.\n\tidx: u8,\n\t/// Marker for the indexed type.\n\t_ty: PhantomData<M>,\n}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::decr":["/// Decrements an index counter, wrapping at the front edge of the element.\n///\n/// # Parameters\n///\n/// - `self`: The inedx to decrement.\n///\n/// # Returns\n///\n/// - `.0`: The previous index before `self`.\n/// - `.1`: Indicates that the new index is in the previous memory element.\n#[inline]\npub(crate) fn decr(self) -> (Self, bool){\n\t\tlet next = self.idx.wrapping_sub(1);\n\t\t(make!(idx next & M::MASK), self.idx == 0)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::incr":["/// Increments an index counter, wrapping at the back edge of the element.\n///\n/// # Parameters\n///\n/// - `self`: The index to increment.\n///\n/// # Returns\n///\n/// - `.0`: The next index after `self`.\n/// - `.1`: Indicates that the new index is in the next memory element.\n#[inline]\npub(crate) fn incr(self) -> (Self, bool){\n\t\tlet next = self.idx + 1;\n\t\t(make!(idx next & M::MASK), next == M::BITS)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::mask":["/// Computes the bit selector for `self` as an accessor mask.\n///\n/// This is a type-cast over `Self::select`. It is one of the few public,\n/// safe, constructors of a multi-bit mask.\n#[inline]\npub fn mask<O>(self) -> BitMask<M>\n\twhere O: BitOrder{\n\t\tself.select::<O>().mask()\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::new":["/// Wraps a counter value as a known-good index into an `M` element.\n///\n/// # Parameters\n///\n/// - `idx`: A semantic index of a bit within an `M` element.\n///\n/// # Returns\n///\n/// If `idx` is outside the valid range `0 .. M::BITS`, this returns `None`;\n/// otherwise, it returns a `BitIdx` wrapping the `idx` value.\n#[inline]\npub(crate) fn new(idx: u8) -> Option<Self>{\n\t\tif idx >= M::BITS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(idx idx))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::new_unchecked":["/// Wraps a counter value as an assumed-good index into an `M` element.\n///\n/// # Parameters\n///\n/// - `idx`: A semantic index of a bit within an `M` element.\n///\n/// # Returns\n///\n/// `idx` wrapped in a `BitIdx`.\n///\n/// # Safety\n///\n/// `idx` **must** be within the valid range `0 .. M::BITS`. In debug\n/// builds, invalid `idx` values cause a panic; release builds do not check\n/// the input.\n#[inline]\npub(crate) unsafe fn new_unchecked(idx: u8) -> Self{\n\t\tdebug_assert!(\n\t\t\tidx < M::BITS,\n\t\t\t\"Bit index {} cannot exceed type width {}\",\n\t\t\tidx,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(idx idx)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::offset":["/// Computes the the jump distance for a number of bits away from a start.\n///\n/// This produces the number of elements to move from the starting point,\n/// and then the bit index of the destination bit in the destination\n/// element.\n///\n/// # Parameters\n///\n/// - `self`: A bit index in some memory element, used as the starting\n///   position for the offset calculation.\n/// - `by`: The number of bits by which to move. Negative values go towards\n///   the zero bit index and element address; positive values go towards the\n///   maximal bit index and element address.\n///\n/// # Returns\n///\n/// - `.0`: The number of elements by which to offset the caller’s element\n///   address. This value can be passed directly into [`ptr::offset`].\n/// - `.1`: The bit index of the destination bit in the element selected by\n///   applying the `.0` pointer offset.\n///\n/// [`ptr::offset`]: https://doc.rust-lang.org/std/primitive.pointer.html#method.offset\npub(crate) fn offset(self, by: isize) -> (isize, Self){\n\t\tlet val = self.value();\n\n\t\t/* Signed-add `*self` and the jump distance. Overflowing is the unlikely\n\t\tbranch. The result is a bit index, and an overflow marker. `far` is\n\t\tpermitted to be negative; this means that it is lower in memory than the\n\t\torigin bit. The number line has its origin at the front edge of the\n\t\torigin element, so `-1` is the *last* bit of the prior memory element.\n\t\t*/\n\t\tlet (far, ovf) = by.overflowing_add(val as isize);\n\t\t//  If the `isize` addition does not overflow, then the sum can be used\n\t\t//  directly.\n\t\tif !ovf {\n\t\t\t//  If `far` is in the origin element, then the jump moves zero\n\t\t\t//  elements and produces `far` as an absolute index directly.\n\t\t\tif (0 .. M::BITS as isize).contains(&far) {\n\t\t\t\t(0, make!(idx far as u8))\n\t\t\t}\n\t\t\t/* Otherwise, downshift the bit distance to compute the number of\n\t\t\telements moved in either direction, and mask to compute the absolute\n\t\t\tbit index in the destination element.\n\t\t\t*/\n\t\t\telse {\n\t\t\t\t(far >> M::INDX, make!(idx far as u8 & M::MASK))\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t/* Overflowing `isize` addition happens to produce ordinary `usize`\n\t\t\taddition. In point of fact, `isize` addition and `usize` addition\n\t\t\tare the same machine instruction to perform the sum; it is merely\n\t\t\tthe signed interpretation of the sum that differs. The sum can be\n\t\t\trecast back to `usize` without issue.\n\t\t\t*/\n\t\t\tlet far = far as usize;\n\t\t\t//  This is really only needed in order to prevent sign-extension of\n\t\t\t//  the downshift; once shifted, the value can be safely re-signed.\n\t\t\t((far >> M::INDX) as isize, make!(idx far as u8 & M::MASK))\n\t\t}\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::position":["/// Computes the bit position corresponding to `self` under some ordering.\n///\n/// This forwards to `O::at::<M>`, and is the only public, safe, constructor\n/// for a position counter.\n#[inline]\npub fn position<O>(self) -> BitPos<M>\n\twhere O: BitOrder{\n\t\tO::at::<M>(self)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::range":["/// Constructs a range over all indices between a start and end point.\n///\n/// Because implementation details of the `RangeOps` family are not yet\n/// stable, and heterogenous ranges are not supported, this must be an\n/// opaque iterator rather than a direct `Range<BitIdx<M>>`.\n///\n/// # Parameters\n///\n/// - `from`: The inclusive low bound of the range. This will be the first\n///   index produced by the iterator.\n/// - `upto`: The exclusive high bound of the range. The iterator will halt\n///   before yielding an index of this value.\n///\n/// # Returns\n///\n/// An opaque iterator that is equivalent to the range `from .. upto`.\n///\n/// # Requirements\n///\n/// `from` must be no greater than `upto`.\npub fn range(\n\t\tfrom: Self,\n\t\tupto: BitTail<M>,\n\t) -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator{\n\t\tdebug_assert!(\n\t\t\tfrom.value() <= upto.value(),\n\t\t\t\"Ranges must run from low to high\"\n\t\t);\n\t\t(from.value() .. upto.value()).map(|val| make!(idx val))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::range_all":["/// Ranges over all possible index values.\npub(crate) fn range_all() -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator{\n\t\t(Self::ZERO.idx ..= Self::LAST.idx).map(|val| make!(idx val))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::select":["/// Computes the bit selector corresponding to `self` under an ordering.\n///\n/// This forwards to `O::select::<M>`, and is the only public, safe,\n/// constructor for a bit selector.\n#[inline]\npub fn select<O>(self) -> BitSel<M>\n\twhere O: BitOrder{\n\t\tO::select::<M>(self)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::span":["/// Computes the span information for a region beginning at `self` for `len`\n/// bits.\n///\n/// The span information is the number of elements in the region that hold\n/// live bits, and the position of the tail marker after the live bits.\n///\n/// This forwards to [`BitTail::span`], as the computation is identical for\n/// the two types. Beginning a span at any `Idx` is equivalent to beginning\n/// it at the tail of a previous span.\n///\n/// # Parameters\n///\n/// - `self`: The start bit of the span.\n/// - `len`: The number of bits in the span.\n///\n/// # Returns\n///\n/// - `.0`: The number of elements, starting in the element that contains\n///   `self`, that contain live bits of the span.\n/// - `.1`: The tail counter of the span’s end point.\npub(crate) fn span(self, len: usize) -> (usize, BitTail<M>){\n\t\tmake!(tail self.value()).span(len)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitIdx::<M>::value":["/// Views the internal index value.\n#[inline]\npub fn value(self) -> u8{\n\t\tself.idx\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask":["/** A multi-bit selection mask.\n\nUnlike [`BitSel`], which enforces a strict one-hot mask encoding, this mask type\npermits any number of bits to be set or unset. This is used to accumulate\nselections for a batch operation on a register.\n\n# Construction\n\nIt is only constructed by accumulating `BitSel` values. The chain of custody for\nsafe construction in this module and in `order` ensures that all masks that are\napplied to register values can be trusted to not cause memory unsafety.\n**/\n#[repr(transparent)]\npub struct BitMask<M>\nwhere M: BitMemory\n{\n\t/// A mask of any number of bits to select.\n\tmask: M,\n}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask::<M>::combine":["/// Creates a new mask with a selector bit activated.\n///\n/// # Parameters\n///\n/// - `self`\n/// - `sel`: The selector bit to activate in the new mask.\n///\n/// # Returns\n///\n/// A copy of `self`, with the selector at `sel` activated.\n#[inline]\npub fn combine(mut self, sel: BitSel<M>) -> Self{\n\t\tself.insert(sel);\n\t\tself\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask::<M>::insert":["/// Inserts a selector into an existing mask.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `sel`: The selector bit to insert into the mask.\n///\n/// # Effects\n///\n/// The selector’s bit in the `self` mask is activated.\n#[inline]\npub fn insert(&mut self, sel: BitSel<M>){\n\t\tself.mask |= sel.sel;\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask::<M>::new":["/// Wraps any `M` value as a bit-mask.\n///\n/// This constructor is provided to explicitly declare that an operation is\n/// discarding the numeric value of an integer and reading it only as a\n/// bit-mask.\n///\n/// # Parameters\n///\n/// - `mask`: Some integer value\n///\n/// # Returns\n///\n/// `mask` wrapped as a bit-mask, with its numeric context discarded.\n///\n/// # Safety\n///\n/// This function must only be called within a `BitOrder::mask`\n/// implementation which is verified to be correct.\n///\n/// Prefer accumulating `BitSel` values using the `Sum` implementation.\n#[inline]\npub unsafe fn new(mask: M) -> Self{\n\t\tmake!(mask mask)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask::<M>::test":["/// Tests whether a mask contains a given selector bit.\n///\n/// # Paramters\n///\n/// - `self`\n/// - `sel`: The selector bit to test in the `self` mask.\n///\n/// # Returns\n///\n/// Whether `self` has set the bit at `sel`.\n#[inline]\npub fn test(self, sel: BitSel<M>) -> bool{\n\t\tself.mask & sel.sel != M::ZERO\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitMask::<M>::value":["/// Views the internal mask value.\n#[inline]\npub fn value(self) -> M{\n\t\tself.mask\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos":["/** An electrical position of a single bit within a memory element `M`.\n\nThis type is used as the shift distance in the expression `1 << shamt`. It is\nonly produced by the translation of a semantic `BitIdx<M>` according to some\n[`BitOrder`] implementation using `BitOrder::at`. It can only be used for the\nconstruction of bit masks used to manipulate a register value during memory\naccess, and serves no other purpose.\n\n# Type Parameters\n\n- `M`: The register type that values of this type govern.\n\n# Validity\n\nValues of this type are required to be in the range `0 .. M::BITS`. Any value\noutside this range will cause the program state to become invalid, and the\nlibrary’s behavior is unspecified. The library will never produce such an\ninvalid value, and users are required to do the same.\n\n# Construction\n\nThis type offers public unsafe constructors. `bitvec` does not offer any public\nAPIs that take values of this type directly; it always routes through `BitOrder`\nimplementations. As `BitIdx` will only be constructed from safe, correct,\nvalues, and `BitOrder::at` is the only `BitIdx -> BitPos` transform function,\nall constructed `BitPos` values are known to be memory-correct.\n**/\n#[repr(transparent)]\npub struct BitPos<M>\nwhere M: BitMemory\n{\n\t/// Electrical position within an element, constrained to `0 .. M::BITS`.\n\tpos: u8,\n\t/// Marker for the positioned type.\n\t_ty: PhantomData<M>,\n}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos::<M>::mask":["/// Constructs an untyped bitmask from the position counter.\n///\n/// This removes the one-hot requirement from the selection mask.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// A mask for `M` selecting only the bit specified by `self`.\n#[inline]\npub fn mask(self) -> BitMask<M>{\n\t\tmake!(mask self.select().sel)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos::<M>::new":["/// Wraps a value as a known-good position within an `M` element.\n///\n/// # Parameters\n///\n/// - `pos`: An electrical position of a bit within an `M` element.\n///\n/// # Returns\n///\n/// If `pos` is outside the valid range `0 .. M::BITS`, this returns `None`;\n/// otherwise, it returns a `BitPos` wrapping the `pos` value.\n///\n/// # Safety\n///\n/// This function must only be called within a `BitOrder::at` implementation\n/// which is verified to be correct.\n#[inline]\npub unsafe fn new(pos: u8) -> Option<Self>{\n\t\t//  Reject a position value that is not within the range `0 .. M::BITS`.\n\t\tif pos >= M::BITS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(pos pos))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos::<M>::new_unchecked":["/// Wraps a value as an assumed-good position within an `M` element.\n///\n/// # Parameters\n///\n/// - `pos`: An electrical position within an `M` element.\n///\n/// # Returns\n///\n/// `pos` wrapped in a `BitPos`.\n///\n/// # Safety\n///\n/// `pos` **must** be within the valid range `0 .. M::BITS`. In debug\n/// builds, invalid `pos` values cause a panic; release builds do not check\n/// the input.\n///\n/// This function must only be called in a correct `BitOrder::at`\n/// implementation.\n#[inline]\npub unsafe fn new_unchecked(pos: u8) -> Self{\n\t\tdebug_assert!(\n\t\t\tpos < M::BITS,\n\t\t\t\"Bit position {} cannot exceed type width {}\",\n\t\t\tpos,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(pos pos)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos::<M>::select":["/// Constructs a one-hot selection mask from the position counter.\n///\n/// This is a well-typed `1 << pos`.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// A one-hot mask for `M` selecting the bit specified by `self`.\n#[inline]\npub fn select(self) -> BitSel<M>{\n\t\tmake!(sel M::ONE << self.pos)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitPos::<M>::value":["/// Views the internal position value.\n#[inline]\npub fn value(self) -> u8{\n\t\tself.pos\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel":["/** A one-hot selection mask, to be applied to a memory element `M`.\n\nThis type selects exactly one bit, and is produced by the conversion of a\nsemantic [`BitIdx`] to a [`BitPos`] through a [`BitOrder`] implementation, and\nthen applying `1 << pos`. Values of this type are used to select only the bit\nspecified by a `BitIdx` when performing memory operations.\n\n# Type Parameters\n\n- `M`: The register type that values of this type govern.\n\n# Validity\n\nValues of this type are required to have exactly one bit set to `1` and all\nother bits set to `0`.\n\n# Construction\n\nThis type is only constructed from `BitPos` values, which are themselves only\nconstructed by a chain of known-good `BitIdx` values passed into known-correct\n`BitOrder` implementations. As such, `bitvec` can use `BitSel` values with full\nconfidence that they are correct in the surrounding context.\n**/\n#[repr(transparent)]\npub struct BitSel<M>\nwhere M: BitMemory\n{\n\t/// The one-hot selector mask.\n\tsel: M,\n}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel::<M>::mask":["/// Converts the selector into a bit mask.\n///\n/// This is a type-cast.\n#[inline]\npub fn mask(self) -> BitMask<M>\n\twhere M: BitMemory{\n\t\tmake!(mask self.sel)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel::<M>::new":["/// Wraps a selector value as a known-good selection of an `M` element.\n///\n/// # Parameters\n///\n/// - `sel`: A one-hot selection mask of a bit in an `M` element.\n///\n/// # Returns\n///\n/// If `sel` does not have exactly one bit set, this returns `None`;\n/// otherwise, it returns a `BitSel` wrapping the `sel` value.\n///\n/// # Safety\n///\n/// This function must only be called within a `BitOrder::select`\n/// implementation that is verified to be correct.\n#[inline]\npub unsafe fn new(sel: M) -> Option<Self>{\n\t\tif sel.count_ones() != 1 {\n\t\t\treturn None;\n\t\t}\n\t\tSome(make!(sel sel))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel::<M>::new_unchecked":["/// Wraps a selector value as an assumed-good selection of an `M` element.\n///\n/// # Parameters\n///\n/// - `sel`: A one-hot selection mask of a bit in an `M` element.\n///\n/// # Returns\n///\n/// `sel` wrapped in a `BitSel`.\n///\n/// # Safety\n///\n/// `sel` **must** have exactly one bit set high and all others low. In\n/// debug builds, invalid `sel` values cause a panic; release builds do not\n/// check the input.\n///\n/// This function must only be called in a correct `BitOrder::select`\n/// implementation.\n#[inline]\npub unsafe fn new_unchecked(sel: M) -> Self{\n\t\tdebug_assert!(\n\t\t\tsel.count_ones() == 1,\n\t\t\t\"Selections are required to have exactly one set bit: {:0>1$b}\",\n\t\t\tsel,\n\t\t\tM::BITS as usize\n\t\t);\n\t\tmake!(sel sel)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel::<M>::range_all":["/// Ranges over all possible selector values.\npub fn range_all() -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator{\n\t\tBitIdx::<M>::range_all().map(|i| make!(pos i.idx).select())\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitSel::<M>::value":["/// Views the internal selector value.\n#[inline]\npub fn value(self) -> M{\n\t\tself.sel\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitTail":["/** Semantic index of a dead bit *after* a live region.\n\nLike `BitIdx<M>`, this type indicates a semantic counter within a memory element\n`M`. However, it marks the position of a *dead* bit *after* a live range. This\nmeans that it is permitted to have the value of `M::BITS`, to indicate that a\nlive region touches the semantic back edge of the element `M`.\n\nInstances of this type will only contain the value `0` when the span that\ncreated them is empty. Otherwise, they will have the range `1 ..= M::BITS`.\n\nThis type cannot be used for indexing into an element `M`, and does not\ntranslate to a `BitPos<M>`. It has no behavior other than viewing its internal\ncounter for region arithmetic.\n\n# Type Parameters\n\n- `M`: The register type that values of this type govern.\n\n# Validity\n\nValues of this type are required to be in the range `0 ..= M::BITS`. Any value\noutside this range will cause the program state to become invalid, and the\nlibrary’s behavior is unspecified. The library will never produce such an\ninvalid value.\n\n# Construction\n\nThis type cannot be directly constructed outside the `bitvec` crate. `bitvec`\nwill construct safe values of this type, and allows users to view them and use\nthem for region computation. All values of this type constructed by `bitvec` are\nknown to be correct based on user input to the crate.\n**/\n#[repr(transparent)]\npub struct BitTail<M>\nwhere M: BitMemory\n{\n\t/// Semantic tail counter of an element, constrained to `0 ..= M::BITS`.\n\tend: u8,\n\t/// Marker for the tailed type.\n\t_ty: PhantomData<M>,\n}","Real(LocalPath(\"src/index.rs\"))"],"index::BitTail::<M>::new_unchecked":["/// Wraps a counter value as an assumed-good tail of an `M` element.\n///\n/// # Parameters\n///\n/// - `end`: A semantic index of a dead bit in or after an `M` element.\n///\n/// # Returns\n///\n/// `end` wrapped in a `BitTail`.\n///\n/// # Safety\n///\n/// `end` **must** be within the valid range `0 ..= M::BITS`. In debug\n/// builds, invalid `end` values cause a panic; release builds do not check\n/// the input.\n#[inline]\npub(crate) unsafe fn new_unchecked(end: u8) -> Self{\n\t\tdebug_assert!(\n\t\t\tend <= M::BITS,\n\t\t\t\"Bit tail {} cannot exceed type width {}\",\n\t\t\tend,\n\t\t\tM::BITS\n\t\t);\n\t\tmake!(tail end)\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitTail::<M>::range_from":["/// Ranges over all valid tails for a starting index.\n#[inline]\npub(crate) fn range_from(\n\t\tstart: BitIdx<M>,\n\t) -> impl Iterator<Item = Self>\n\t+ DoubleEndedIterator\n\t+ ExactSizeIterator\n\t+ FusedIterator{\n\t\t(start.idx ..= Self::END.end).map(|val| make!(tail val))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitTail::<M>::span":["/// Computes span information for a region beginning immediately after a\n/// preceding region.\n///\n/// The computed region of `len` bits has its start at the *live* bit that\n/// corresponds to the `self` dead tail. The return value is the number of\n/// memory elements containing live bits of the computed span and its tail\n/// marker.\n///\n/// # Parameters\n///\n/// - `self`\n/// - `len`: The number of live bits in the span starting after `self`.\n///\n/// # Returns\n///\n/// - `.0`: The number of elements `M` that contain live bits in the\n///   computed region.\n/// - `.1`: The tail counter of the first dead bit after the new span.\n///\n/// # Behavior\n///\n/// If `len` is `0`, this returns `(0, self)`, as the span has no live bits.\n/// If `self` is `BitTail::END`, then the new region starts at\n/// `BitIdx::ZERO` in the next element.\npub(crate) fn span(self, len: usize) -> (usize, Self){\n\t\tif len == 0 {\n\t\t\treturn (0, self);\n\t\t}\n\n\t\tlet val = self.end;\n\n\t\tlet head = val & M::MASK;\n\t\tlet bits_in_head = (M::BITS - head) as usize;\n\n\t\tif len <= bits_in_head {\n\t\t\treturn (1, make!(tail head + len as u8));\n\t\t}\n\n\t\tlet bits_after_head = len - bits_in_head;\n\t\tlet elts = bits_after_head >> M::INDX;\n\t\tlet tail = bits_after_head as u8 & M::MASK;\n\n\t\tlet is_zero = (tail == 0) as u8;\n\t\tlet edges = 2 - is_zero as usize;\n\t\t(elts + edges, make!(tail(is_zero << M::INDX) | tail))\n\t}","Real(LocalPath(\"src/index.rs\"))"],"index::BitTail::<M>::value":["/// Views the internal tail value.\n#[inline]\npub fn value(self) -> u8{\n\t\tself.end\n\t}","Real(LocalPath(\"src/index.rs\"))"],"macros::internal::u8_from_be_bits":["/// Construct a `u8` from bits applied in Msb0-order.\n#[allow(clippy::many_single_char_names)]\n#[allow(clippy::too_many_arguments)]\npub const fn u8_from_be_bits(\n\ta: bool,\n\tb: bool,\n\tc: bool,\n\td: bool,\n\te: bool,\n\tf: bool,\n\tg: bool,\n\th: bool,\n) -> u8{\n\t(h as u8)\n\t\t| ((g as u8) << 1)\n\t\t| ((f as u8) << 2)\n\t\t| ((e as u8) << 3)\n\t\t| ((d as u8) << 4)\n\t\t| ((c as u8) << 5)\n\t\t| ((b as u8) << 6)\n\t\t| ((a as u8) << 7)\n}","Real(LocalPath(\"src/macros/internal.rs\"))"],"macros::internal::u8_from_le_bits":["/// Construct a `u8` from bits applied in Lsb0-order.\n#[allow(clippy::many_single_char_names)]\n#[allow(clippy::too_many_arguments)]\npub const fn u8_from_le_bits(\n\ta: bool,\n\tb: bool,\n\tc: bool,\n\td: bool,\n\te: bool,\n\tf: bool,\n\tg: bool,\n\th: bool,\n) -> u8{\n\t(a as u8)\n\t\t| ((b as u8) << 1)\n\t\t| ((c as u8) << 2)\n\t\t| ((d as u8) << 3)\n\t\t| ((e as u8) << 4)\n\t\t| ((f as u8) << 5)\n\t\t| ((g as u8) << 6)\n\t\t| ((h as u8) << 7)\n}","Real(LocalPath(\"src/macros/internal.rs\"))"],"mem::BitMemory":["/** Description of a register type.\n\nThis trait provides information used for the manipulation of values in processor\nregisters, and the computation of the state of system memory. It has no bearing\non the behavior used to perform loads or stores between the processor and the\nmemory bus.\n\nThis trait cannot be implemented outside this crate.\n**/\npub trait BitMemory: IsUnsigned + BitOps + seal::Sealed {\n\t/// The bit width of the register element.\n\t///\n\t/// `mem::size_of` returns the size in bytes, and bytes are always eight\n\t/// bits on architectures Rust targets.\n\tconst BITS: u8 = mem::size_of::<Self>() as u8 * 8;\n\t/// The number of bits required to store an index in the range `0 .. BITS`.\n\tconst INDX: u8 = Self::BITS.trailing_zeros() as u8;\n\t/// A mask over all bits that can be used as an index within the element.\n\tconst MASK: u8 = Self::BITS - 1;\n\n\t/// The value with only its least significant bit set to `1`.\n\tconst ONE: Self;\n\t/// The value with all of its bits set to `1`.\n\tconst ALL: Self;\n}","Real(LocalPath(\"src/mem.rs\"))"],"mem::aligned_to_size":["/** Tests that a type is aligned to its size.\n\nThis property is not necessarily true for all integers; for instance, `u64` on\n32-bit x86 is permitted to be 4-byte-aligned. `bitvec` requires this property to\nhold for the pointer representation to correctly function.\n\n# Type Parameters\n\n- `T`: A type whose alignment and size are to be compared\n\n# Returns\n\n`0` if the alignment matches the size; `1` if they differ\n**/\n#[doc(hidden)]\npub(crate) const fn aligned_to_size<T>() -> usize{\n\t(mem::align_of::<T>() != mem::size_of::<T>()) as usize\n}","Real(LocalPath(\"src/mem.rs\"))"],"mem::cmp_layout":["#[doc(hidden)]\npub(crate) const fn cmp_layout<A, B>() -> usize{\n\t(mem::align_of::<A>() != mem::align_of::<B>()) as usize\n\t\t+ (mem::size_of::<A>() != mem::size_of::<B>()) as usize\n}","Real(LocalPath(\"src/mem.rs\"))"],"mem::elts":["/** Computes the number of elements required to store some number of bits.\n\n# Parameters\n\n- `bits`: The number of bits to store in a `[T]` array.\n\n# Returns\n\nThe number of elements `T` required to store `bits`.\n\nAs this is a const function, when `bits` is a constant expression, this can be\nused to compute the size of an array type `[T; elts(bits)]`.\n**/\n#[doc(hidden)]\npub const fn elts<T>(bits: usize) -> usize{\n\tlet width = mem::size_of::<T>() * 8;\n\tbits / width + (bits % width != 0) as usize\n}","Real(LocalPath(\"src/mem.rs\"))"],"mem::seal::Sealed":["#[doc(hidden)]\npub trait Sealed {}","Real(LocalPath(\"src/mem.rs\"))"],"order::BitOrder":["/** An ordering over an element.\n\n# Usage\n\n`bitvec` structures store and operate on semantic counts, not bit positions. The\n`BitOrder::at` function takes a semantic ordering, `BitIdx`, and produces an\nelectrical position, `BitPos`.\n\n# Safety\n\nIf your implementation violates any of the requirements on these functions, then\nthe program will become incorrect and have unspecified behavior. The best-case\nscenario is that operations relying on your implementation will crash the\nprogram; the worst-case is that memory access will silently become corrupt.\n\nYou are responsible for adhering to the requirements of these functions. In the\nfuture, a verification function may be provided for your test suite; however, it\nis not yet possible to verify your implementation at compile-time.\n\nThis is an `unsafe trait` to implement, because you are responsible for\nupholding the state requirements. The types you manipulate have `unsafe fn`\nconstructors, because they require you to maintain correct and consistent\nprocesses in order for the rest of the library to use them.\n\nThe implementations of `BitOrder` are trusted to drive safe code, and once data\nleaves a `BitOrder` implementation, it is considered safe to use as the basis\nfor interaction with memory.\n\n# Verification\n\nRust currently lacks Zig’s compile-time computation capability. This means that\n`bitvec` cannot fail a compile if it detects that a `BitOrder` implementation is\ninvalid and breaks the stated requirements. `bitvec` does offer a function,\n[`verify`], which ensures the correctness of an implementation. When Rust gains\nthe capability to run this function in generic `const` contexts, `bitvec` will\nuse it to prevent at compile-time the construction of data structures that use\nincorrect ordering implementations.\n\nThe verifier function panics when it detects invalid behavior, with an error\nmessage intended to clearly indicate the broken requirement.\n\n```rust\nuse bitvec::index::{BitIdx, BitPos};\nuse bitvec::mem::BitMemory;\nuse bitvec::order::{BitOrder, verify};\n# use bitvec::{index::*, order::Lsb0};\n\npub struct Custom;\nunsafe impl BitOrder for Custom {\n  fn at<M: BitMemory>(idx: BitIdx<M>) -> BitPos<M> {\n  // impl\n  # return Lsb0::at::<M>(idx);\n  }\n}\n\n#[cfg(test)]\n#[test]\nfn prove_custom() {\n  verify::<Custom>();\n}\n```\n\n[`verify`]: fn.verify.html\n**/\npub unsafe trait BitOrder {\n\t/// Converts a semantic bit index into an electrical bit position.\n\t///\n\t/// This function is the basis of the trait, and must adhere to a number of\n\t/// requirements in order for an implementation to be considered correct.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `index`: The semantic index of a bit within an element `M`.\n\t///\n\t/// # Returns\n\t///\n\t/// The electrical position of the indexed bit within an element `M`. See\n\t/// the `BitPos` documentation for what electrical positions are considered\n\t/// to mean.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `M`: The element type which the index and position describe.\n\t///\n\t/// # Requirements\n\t///\n\t/// This function must satisfy the following requirements for all possible\n\t/// input and output values for all possible type parameters:\n\t///\n\t/// ## Totality\n\t///\n\t/// This function must be able to accept every input in the `BitIdx<M>`\n\t/// value range, and produce a corresponding `BitPos<M>`. It must not abort\n\t/// the program or return an invalid `BitPos<M>` for any input value in the\n\t/// `BitIdx<M>` range.\n\t///\n\t/// ## Bijection\n\t///\n\t/// There must be an exactly one-to-one correspondence between input value\n\t/// and output value. No input index may select from a set of more than one\n\t/// output position, and no output position may be produced by more than one\n\t/// input index.\n\t///\n\t/// ## Purity\n\t///\n\t/// The translation from index to position must be consistent for the\n\t/// lifetime of the program. This function *may* refer to global state, but\n\t/// that state **must** be immutable for the program lifetime, and must not\n\t/// be used to violate the totality or bijection requirements.\n\t///\n\t/// ## Output Validity\n\t///\n\t/// The produced `BitPos<M>` must be within the valid range of that type.\n\t/// Call sites of this function will not take any steps to constrain the\n\t/// output value. If you use `unsafe` code to produce an invalid\n\t/// `BitPos<M>`, the program is permanently incorrect, and will likely\n\t/// crash.\n\t///\n\t/// # Usage\n\t///\n\t/// This function will only ever be called with input values in the valid\n\t/// `BitIdx<M>` range. Implementors are not required to consider any values\n\t/// outside this range in their function body.\n\tfn at<M>(index: BitIdx<M>) -> BitPos<M>\n\twhere M: BitMemory;\n\n\t/// Converts a semantic bit index into a one-hot selector mask.\n\t///\n\t/// This is an optional function; a default implementation is provided for\n\t/// you.\n\t///\n\t/// The default implementation of this function calls `Self::at` to produce\n\t/// an electrical position, then turns that into a selector mask by setting\n\t/// the `n`th bit more significant than the least significant bit of the\n\t/// element. `BitOrder` implementations may choose to provide a faster mask\n\t/// production here, but they must satisfy the requirements listed below.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `index`: The semantic index of a bit within an element `M`.\n\t///\n\t/// # Returns\n\t///\n\t/// A one-hot selector mask for the bit indicated by the index value.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `M`: The storage type for which the mask will be calculated. The mask\n\t///   must also be this type, as it will be applied to an element of `M` in\n\t///   order to set, clear, or test a single bit.\n\t///\n\t/// # Requirements\n\t///\n\t/// A one-hot encoding means that there is exactly one bit set in the\n\t/// produced value. It must be equivalent to `1 << Self::at::<M>(place)`.\n\t///\n\t/// As with `at`, this function must produce a unique mapping from each\n\t/// legal index in the `M` domain to a one-hot value of `M`.\n\t#[inline]\n\tfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory {\n\t\tSelf::at::<M>(index).select()\n\t}\n\n\t/// Constructs a multi-bit selector mask for batch operations on a single\n\t/// memory element `M`.\n\t///\n\t/// The default implementation of this function traverses the index range,\n\t/// converting each index into a single-bit selector with `Self::select` and\n\t/// accumulating into a combined register value.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `from`: The inclusive starting index for the mask.\n\t/// - `upto`: The exclusive ending index for the mask.\n\t///\n\t/// # Returns\n\t///\n\t/// A bit-mask with all bits corresponding to the input index range set high\n\t/// and all others set low.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `M`: The storage type for which the mask will be calculated. The mask\n\t///   must also be this type, as it will be applied to an element of `M` in\n\t///   order to set, clear, or test all the selected bits.\n\t///\n\t/// # Requirements\n\t///\n\t/// This function must always be equivalent to\n\t///\n\t/// ```rust,ignore\n\t/// (from .. upto)\n\t///   .map(1 << Self::at::<M>)\n\t///   .fold(0, |mask, sel| mask | sel)\n\t/// ```\n\tfn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,\n\t{\n\t\tlet (from, upto) = match (from.into(), upto.into()) {\n\t\t\t(None, None) => return BitMask::ALL,\n\t\t\t(Some(from), None) => (from, BitTail::<M>::END),\n\t\t\t(None, Some(upto)) => (BitIdx::<M>::ZERO, upto),\n\t\t\t(Some(from), Some(upto)) => (from, upto),\n\t\t};\n\t\tBitIdx::<M>::range(from, upto).map(Self::select::<M>).sum()\n\t}\n}","Real(LocalPath(\"src/order.rs\"))"],"order::BitOrder::mask":["/// Constructs a multi-bit selector mask for batch operations on a single\n/// memory element `M`.\n///\n/// The default implementation of this function traverses the index range,\n/// converting each index into a single-bit selector with `Self::select` and\n/// accumulating into a combined register value.\n///\n/// # Parameters\n///\n/// - `from`: The inclusive starting index for the mask.\n/// - `upto`: The exclusive ending index for the mask.\n///\n/// # Returns\n///\n/// A bit-mask with all bits corresponding to the input index range set high\n/// and all others set low.\n///\n/// # Type Parameters\n///\n/// - `M`: The storage type for which the mask will be calculated. The mask\n///   must also be this type, as it will be applied to an element of `M` in\n///   order to set, clear, or test all the selected bits.\n///\n/// # Requirements\n///\n/// This function must always be equivalent to\n///\n/// ```rust,ignore\n/// (from .. upto)\n///   .map(1 << Self::at::<M>)\n///   .fold(0, |mask, sel| mask | sel)\n/// ```\nfn mask<M>(\n\t\tfrom: impl Into<Option<BitIdx<M>>>,\n\t\tupto: impl Into<Option<BitTail<M>>>,\n\t) -> BitMask<M>\n\twhere\n\t\tM: BitMemory,{\n\t\tlet (from, upto) = match (from.into(), upto.into()) {\n\t\t\t(None, None) => return BitMask::ALL,\n\t\t\t(Some(from), None) => (from, BitTail::<M>::END),\n\t\t\t(None, Some(upto)) => (BitIdx::<M>::ZERO, upto),\n\t\t\t(Some(from), Some(upto)) => (from, upto),\n\t\t};\n\t\tBitIdx::<M>::range(from, upto).map(Self::select::<M>).sum()\n\t}","Real(LocalPath(\"src/order.rs\"))"],"order::BitOrder::select":["/// Converts a semantic bit index into a one-hot selector mask.\n///\n/// This is an optional function; a default implementation is provided for\n/// you.\n///\n/// The default implementation of this function calls `Self::at` to produce\n/// an electrical position, then turns that into a selector mask by setting\n/// the `n`th bit more significant than the least significant bit of the\n/// element. `BitOrder` implementations may choose to provide a faster mask\n/// production here, but they must satisfy the requirements listed below.\n///\n/// # Parameters\n///\n/// - `index`: The semantic index of a bit within an element `M`.\n///\n/// # Returns\n///\n/// A one-hot selector mask for the bit indicated by the index value.\n///\n/// # Type Parameters\n///\n/// - `M`: The storage type for which the mask will be calculated. The mask\n///   must also be this type, as it will be applied to an element of `M` in\n///   order to set, clear, or test a single bit.\n///\n/// # Requirements\n///\n/// A one-hot encoding means that there is exactly one bit set in the\n/// produced value. It must be equivalent to `1 << Self::at::<M>(place)`.\n///\n/// As with `at`, this function must produce a unique mapping from each\n/// legal index in the `M` domain to a one-hot value of `M`.\n#[inline]\nfn select<M>(index: BitIdx<M>) -> BitSel<M>\n\twhere M: BitMemory{\n\t\tSelf::at::<M>(index).select()\n\t}","Real(LocalPath(\"src/order.rs\"))"],"order::Lsb0":["/// Traverses an element from `LSbit` to `MSbit`.\npub struct Lsb0;","Real(LocalPath(\"src/order.rs\"))"],"order::Msb0":["/// Traverses an element from `MSbit` to `LSbit`.\npub struct Msb0;","Real(LocalPath(\"src/order.rs\"))"],"order::verify":["/** Verifies a `BitOrder` implementation’s adherence to the stated rules.\n\nThis function checks some `BitOrder` implementation’s behavior on each of the\n`BitMemory` types it must handle, and reports any violation of the rules that it\ndetects.\n\n# Type Parameters\n\n- `O`: The `BitOrder` implementation to test.\n\n# Parameters\n\n- `verbose`: Sets whether the test should print diagnostic information to\n  `stdout`.\n\n# Panics\n\nThis panics if it detects any violation of the `BitOrder` implementation rules\nfor `O`.\n**/\npub fn verify<O>(verbose: bool)\nwhere O: BitOrder{\n\tverify_for_type::<O, u8>(verbose);\n\tverify_for_type::<O, u16>(verbose);\n\tverify_for_type::<O, u32>(verbose);\n\tverify_for_type::<O, usize>(verbose);\n\n\t#[cfg(target_pointer_width = \"64\")]\n\tverify_for_type::<O, u64>(verbose);\n}","Real(LocalPath(\"src/order.rs\"))"],"order::verify_for_type":["/** Verifies a `BitOrder` implementation’s adherence to the stated rules, for\none register type.\n\nThis function checks some `BitOrder` implementation against only one of the\n`BitMemory` types that it will encounter. This is useful if you are implementing\nan ordering that only needs to be concerned with a subset of the types, and you\nknow that you will never use it with the types it does not support.\n\n# Type Parameters\n\n- `O`: The `BitOrder` implementation to test.\n- `M`: The `BitMemory` type  for which to test `O`.\n\n# Parameters\n\n- `verbose`: Sets whether the test should print diagnostic information to\n  `stdout`.\n\n# Panics\n\nThis panics if it detects any violation of the `BitOrder` implementation rules\nfor the combination of input types and index values.\n**/\npub fn verify_for_type<O, M>(verbose: bool)\nwhere\n\tO: BitOrder,\n\tM: BitMemory,{\n\tuse core::any::type_name;\n\tlet mut accum = BitMask::<M>::ZERO;\n\n\tlet oname = type_name::<O>();\n\tlet mname = type_name::<M>();\n\n\tfor n in 0 .. M::BITS {\n\t\t//  Wrap the counter as an index.\n\t\tlet idx = unsafe { BitIdx::<M>::new_unchecked(n) };\n\n\t\t//  Compute the bit position for the index.\n\t\tlet pos = O::at::<M>(idx);\n\t\tif verbose {\n\t\t\t#[cfg(feature = \"std\")]\n\t\t\tprintln!(\n\t\t\t\t\"`<{} as BitOrder>::at::<{}>({})` produces {}\",\n\t\t\t\toname,\n\t\t\t\tmname,\n\t\t\t\tn,\n\t\t\t\tpos.value(),\n\t\t\t);\n\t\t}\n\n\t\t//  If the computed position exceeds the valid range, fail.\n\t\tassert!(\n\t\t\tpos.value() < M::BITS,\n\t\t\t\"Error when verifying the implementation of `BitOrder` for `{}`: \\\n\t\t\t Index {} produces a bit position ({}) that exceeds the type width \\\n\t\t\t {}\",\n\t\t\toname,\n\t\t\tn,\n\t\t\tpos.value(),\n\t\t\tM::BITS,\n\t\t);\n\n\t\t//  Check `O`’s implementation of `select`\n\t\tlet sel = O::select::<M>(idx);\n\t\tif verbose {\n\t\t\t#[cfg(feature = \"std\")]\n\t\t\tprintln!(\n\t\t\t\t\"`<{} as BitOrder>::select::<{}>({})` produces {}\",\n\t\t\t\toname, mname, n, sel,\n\t\t\t);\n\t\t}\n\n\t\t//  If the selector bit is not one-hot, fail.\n\t\tassert_eq!(\n\t\t\tsel.value().count_ones(),\n\t\t\t1,\n\t\t\t\"Error when verifying the implementation of `BitOrder` for `{}`: \\\n\t\t\t Index {} produces a bit selector ({}) that is not a one-hot mask\",\n\t\t\toname,\n\t\t\tn,\n\t\t\tsel,\n\t\t);\n\n\t\t//  Check that the selection computed from the index matches the\n\t\t//  selection computed from the position.\n\t\tlet shl = pos.select();\n\t\t//  If `O::select(idx)` does not produce `1 << pos`, fail.\n\t\tassert_eq!(\n\t\t\tsel,\n\t\t\tshl,\n\t\t\t\"Error when verifying the implementation of `BitOrder` for `{}`: \\\n\t\t\t Index {} produces a bit selector ({}) that is not equal to `1 << \\\n\t\t\t {}` ({})\",\n\t\t\toname,\n\t\t\tn,\n\t\t\tsel,\n\t\t\tpos.value(),\n\t\t\tshl,\n\t\t);\n\n\t\t//  Check that the produced selector bit has not already been added to\n\t\t//  the accumulator.\n\t\tassert!(\n\t\t\t!accum.test(sel),\n\t\t\t\"Error when verifying the implementation of `BitOrder` for `{}`: \\\n\t\t\t Index {} produces a bit position ({}) that has already been \\\n\t\t\t produced by a prior index\",\n\t\t\toname,\n\t\t\tn,\n\t\t\tpos.value(),\n\t\t);\n\t\taccum.insert(sel);\n\t\tif verbose {\n\t\t\t#[cfg(feature = \"std\")]\n\t\t\tprintln!(\n\t\t\t\t\"`<{} as BitOrder>::at::<{}>({})` accumulates  {}\",\n\t\t\t\toname, mname, n, accum,\n\t\t\t);\n\t\t}\n\t}\n\n\t//  Check that all indices produced all positions.\n\tassert_eq!(\n\t\taccum,\n\t\tBitMask::ALL,\n\t\t\"Error when verifying the implementation of `BitOrder` for `{}`: The \\\n\t\t bit positions marked with a `0` here were never produced from an \\\n\t\t index, despite all possible indices being passed in for translation: \\\n\t\t {}\",\n\t\toname,\n\t\taccum,\n\t);\n\n\t//  Check that `O::mask` is correct for all range combinations.\n\tfor from in BitIdx::<M>::range_all() {\n\t\tfor upto in BitTail::<M>::range_from(from) {\n\t\t\tlet mask = O::mask(from, upto);\n\t\t\tlet check = BitIdx::<M>::range(from, upto)\n\t\t\t\t.map(O::at::<M>)\n\t\t\t\t.map(BitPos::<M>::select)\n\t\t\t\t.sum::<BitMask<M>>();\n\t\t\tassert_eq!(\n\t\t\t\tmask,\n\t\t\t\tcheck,\n\t\t\t\t\"Error when verifying the implementation of `BitOrder` for \\\n\t\t\t\t `{o}`: `{o}::mask::<{m}>({f}, {u})` produced {bad}, but \\\n\t\t\t\t expected {good}\",\n\t\t\t\to = oname,\n\t\t\t\tm = mname,\n\t\t\t\tf = from,\n\t\t\t\tu = upto,\n\t\t\t\tbad = mask,\n\t\t\t\tgood = check,\n\t\t\t);\n\t\t}\n\t}\n}","Real(LocalPath(\"src/order.rs\"))"],"pointer::Address":["/** Pointer to memory with limited typecasting support.\n\n# Type Parameters\n\n- `T`: The referent data type.\n**/\n#[doc(hidden)]\npub struct Address<T>\nwhere T: BitStore\n{\n\t/// The numeric value of the address.\n\taddr: usize,\n\t/// The referent type of data at the address.\n\t_ty: PhantomData<T>,\n}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::new":["/// Views a numeric address as a typed data address.\n#[inline(always)]\npub(crate) fn new(addr: usize) -> Self{\n\t\tSelf {\n\t\t\taddr,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::to_access":["/// Views the memory address as an access pointer.\n#[inline(always)]\npub(crate) fn to_access(self) -> *const T::Access{\n\t\tself.addr as *const T::Access\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::to_alias":["/// Views the memory address as an alias pointer.\n#[inline(always)]\npub(crate) fn to_alias(self) -> *const T::Alias{\n\t\tself.addr as *const T::Alias\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::to_const":["/// Views the memory address as an immutable pointer.\n#[inline(always)]\npub(crate) fn to_const(self) -> *const T{\n\t\tself.addr as *const T\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::to_mut":["/// Views the memory address as a mutable pointer.\n#[inline(always)]\n#[allow(clippy::wrong_self_convention)]\npub(crate) fn to_mut(self) -> *mut T{\n\t\tself.addr as *mut T\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::Address::<T>::value":["/// Gets the numeric value of the address.\n#[inline(always)]\npub(crate) fn value(self) -> usize{\n\t\tself.addr\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr":["/** Bit-precision slice pointer encoding.\n\nRust slices use a pointer/length encoding to represent regions of memory.\nReferences to slices of data, `&[T]`, have the ABI layout `(*const T, usize)`.\n\n`BitPtr` encodes a base address, a first-bit index, and a length counter, into\nthe Rust slice reference layout using this structure, permitting `bitvec` to use\nan opaque reference type in its implementation of Rust interfaces that require\nreferences, rather than immediate value types.\n\n# Layout\n\nThis structure is a more complex version of the `*const T`/`usize` tuple that\nRust uses to represent slices throughout the language. It breaks the pointer and\ncounter fundamentals into sub-field components. Rust does not have bitfield\nsyntax, so the below description of the structure layout is in C++.\n\n```cpp\ntemplate <typename T>\nstruct BitPtr {\n  uintptr_t ptr_head : __builtin_ctzll(alignof(T));\n  uintptr_t ptr_addr : sizeof(uintptr_T) * 8 - __builtin_ctzll(alignof(T));\n\n  size_t len_head : 3;\n  size_t len_bits : sizeof(size_t) * 8 - 3;\n};\n```\n\nThis means that the `BitPtr<T>` has three *logical* fields, stored in four\nsegments across the two *structural* fields of the type. The widths and\nplacements of each segment are functions of the size of `*const T` and `usize`,\nand of the alignment of the `T` referent buffer element type.\n\n# Fields\n\nThis section describes the purpose, semantic meaning, and layout of the three\nlogical fields.\n\n## Base Address\n\nThe address of the base element in a memory region is stored in all but the\nlowest bits of the `ptr` field. An aligned pointer to `T` will always have its\nlowest log<sub>2</sub>(byte width) bits zeroed, so those bits can be used to\nstore other information, as long as they are erased before dereferencing the\naddress as a pointer to `T`.\n\n## Head Bit Index\n\nFor any referent element type `T`, the selection of a single bit within the\nelement requires log<sub>2</sub>(byte width) bits to select a byte within the\nelement `T`, and another three bits to select a bit within the selected byte.\n\n|Type |Alignment|Trailing Zeros|Count Bits|\n|:----|--------:|-------------:|---------:|\n|`u8` |        1|             0|         3|\n|`u16`|        2|             1|         4|\n|`u32`|        4|             2|         5|\n|`u64`|        8|             3|         6|\n\nThe index of the first live bit in the base element is split to have its three\nleast significant bits stored in the least significant edge of the `len` field,\nand its remaining bits stored in the least significant edge of the `ptr` field.\n\n## Length Counter\n\nAll but the lowest three bits of the `len` field are used to store a counter of\nlive bits in the referent region. When this is zero, the region is empty.\nBecause it is missing three bits, a `BitPtr` has only ⅛ of the index space of\na `usize` value.\n\n# Significant Values\n\nThe following values represent significant instances of the `BitPtr` type.\n\n## Null Slice\n\nThe fully-zeroed slot is not a valid member of the `BitPtr<T>` type; it is\nreserved as the sentinel value for `Option::<BitPtr<T>>::None`.\n\n## Canonical Empty Slice\n\nAll pointers with a `bits: 0` logical field are empty. Pointers used to maintain\nownership of heap buffers are not permitted to erase their `addr` field, but\nunowning pointers may do so. When an unowning pointer becomes empty, it may\nreplace its `addr` with the `NonNull::<T>::dangling()` value.\n\nAll empty pointers are equivalent to each other.\n\n### Uninhabited Slices\n\nAny empty pointer with a non-`dangling()` base address is considered to be an\nuninhabited region.\n\n# Type Parameters\n\n- `T`: The memory type of the referent region. `BitPtr<T>` is a refined `*[T]`\n  slice pointer, and operates on memory in terms of the `T` type for access and\n  pointer calculation.\n\n# Safety\n\nA `BitPtr` must never be constructed such that the element addressed by\n`self.pointer().to_const().offset(self.elements())` causes an addition overflow.\nThis will be checked in `new()`.\n\nIt is difficult to cause an arithmetic overflow with pointer offsets, as most\ntargets divide the address space such that programs see a highest address of\n`0x7FFF…`. This restriction is inherited from restrictions in the distribution\ncollection libraries, which have studied these problems extensively and are\nreasonable sources of trustworthy plagiarism.\n\n# Undefined Behavior\n\nValues of this type are incompatible with slice pointers. Transmutation of these\nvalues into any other type will result in an incorrect program, and permit the\nprogram to begin illegal or undefined behaviors. This type may never be\nmanipulated in any way by user code outside of the APIs it offers to this crate;\nit certainly may not be seen or observed by other crates.\n**/\n#[repr(C)]\npub struct BitPtr<T>\nwhere T: BitStore\n{\n\t/// Two-element bitfield structure, holding pointer and head information.\n\t///\n\t/// This stores a pointer to the zeroth element of the slice, and the high\n\t/// bits of the head bit cursor. It is typed as a `NonNull<u8>` in order to\n\t/// provide null-value optimizations to `Option<BitPtr<T>>`, and because the\n\t/// presence of head-bit cursor information in the lowest bits means the\n\t/// bit pattern will not uphold alignment properties assumed by\n\t/// `NonNull<T>`.\n\t///\n\t/// This field cannot be treated as an address of the zeroth byte of the\n\t/// slice domain, because the owning handle’s [`BitOrder`] implementation\n\t/// governs the bit pattern of the head cursor.\n\t///\n\t/// [`BitOrder`]: ../order/trait.BitOrder.html\n\tptr: NonNull<u8>,\n\t/// Two-element bitfield structure, holding bit-count and head-index\n\t/// information.\n\t///\n\t/// This stores the bit count in its highest bits and the low three bits of\n\t/// the head `BitIdx` in the lowest three bits.\n\t///\n\t/// [`BitIdx`]: ../struct.BitIdx.html\n\tlen: usize,\n\t_ty: PhantomData<*mut T>,\n}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::as_aliased_slice":["/// Views the referent memory region as a slice of aliased elements.\n///\n/// This view will cause UB if it is used simultaneously with views of the\n/// referent region that assume full immutability of referent data.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A slice handle over all memory elements this pointer describes.\n///\n/// # Safety\n///\n/// `T` will be marked as `::Alias` where necessary by `BitSlice`, and so\n/// this pointer already contains the aliasing information it needs to be\n/// safe.\n#[inline]\npub(crate) fn as_aliased_slice<'a>(&self) -> &'a [T::Alias]{\n\t\tunsafe {\n\t\t\tslice::from_raw_parts(self.pointer().to_alias(), self.elements())\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::elements":["/// Computes the number of elements, starting at `self.pointer()`, that the\n/// region touches.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// The count of all elements, starting at `self.pointer()`, that contain\n/// live bits included in the referent region.\npub(crate) fn elements(&self) -> usize{\n\t\t//  Find the distance of the last bit from the base address.\n\t\tlet total = self.len() + self.head().value() as usize;\n\t\t//  The element count is always the bit count divided by the bit width,\n\t\tlet base = total >> T::Mem::INDX;\n\t\t//  plus whether any fractional element exists after the division.\n\t\tlet tail = total as u8 & T::Mem::MASK;\n\t\tbase + (tail != 0) as usize\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::from_bitslice_ptr":["/// Typecasts a raw region pointer into a pointer structure.\n#[inline]\npub(crate) fn from_bitslice_ptr<O>(raw: *const BitSlice<O, T>) -> Self\n\twhere O: BitOrder{\n\t\tlet slice_nn = match NonNull::new(raw as *const [()] as *mut [()]) {\n\t\t\tSome(r) => r,\n\t\t\tNone => return Self::EMPTY,\n\t\t};\n\t\tlet ptr = dvl::nonnull_slice_to_base(slice_nn).cast::<u8>();\n\t\tlet len = unsafe { slice_nn.as_ref() }.len();\n\t\tSelf {\n\t\t\tptr,\n\t\t\tlen,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::from_bitslice_ptr_mut":["/// Typecasts a raw region pointer into a pointer structure.\n#[inline(always)]\n#[cfg(feature = \"alloc\")]\npub(crate) fn from_bitslice_ptr_mut<O>(raw: *mut BitSlice<O, T>) -> Self\n\twhere O: BitOrder{\n\t\tSelf::from_bitslice_ptr(raw as *const BitSlice<O, T>)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::head":["/// Gets the starting bit index of the referent region.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A `BitIdx` of the first live bit in the element at the `self.pointer()`\n/// address.\npub(crate) fn head(&self) -> BitIdx<T::Mem>{\n\t\t//  Get the high part of the head counter out of the pointer.\n\t\tlet ptr = self.ptr.as_ptr() as usize;\n\t\tlet ptr_head = (ptr & Self::PTR_HEAD_MASK) << Self::LEN_HEAD_BITS;\n\t\t//  Get the low part of the head counter out of the length.\n\t\tlet len_head = self.len & Self::LEN_HEAD_MASK;\n\t\t//  Combine and mark as an index.\n\t\tunsafe { BitIdx::new_unchecked((ptr_head | len_head) as u8) }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::incr_head":["/// Increments the `.head` logical field, rolling over into `.addr`.\n///\n/// # Parameters\n///\n/// - `&mut self`\n///\n/// # Effects\n///\n/// Increments `.head` by one. If the increment resulted in a rollover to\n/// `0`, then the `.addr` field is increased to the next `T::Mem` stepping.\n#[inline]\npub(crate) unsafe fn incr_head(&mut self){\n\t\t//  Increment the cursor, permitting rollover to `T::Mem::BITS`.\n\t\tlet head = self.head().value() as usize + 1;\n\n\t\t//  Write the low bits into the `.len` field, then discard them.\n\t\tself.len &= !Self::LEN_HEAD_MASK;\n\t\tself.len |= head & Self::LEN_HEAD_MASK;\n\t\tlet head = head >> Self::LEN_HEAD_BITS;\n\n\t\t//  Erase the high bits of `.head` from `.ptr`,\n\t\tlet mut ptr = self.ptr.as_ptr() as usize;\n\t\tptr &= Self::PTR_ADDR_MASK;\n\t\t/* Then numerically add the high bits of `.head` into the low bits of\n\t\t`.ptr`. If the head increment rolled over into a new element, this will\n\t\thave the effect of raising the `.addr` logical field to the next element\n\t\taddress, in one instruction.\n\t\t*/\n\t\tptr += head;\n\t\tself.ptr = NonNull::new_unchecked(ptr as *mut u8);\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::len":["/// Gets the number of live bits in the referent region.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A count of how many live bits the region pointer describes.\n#[inline]\npub(crate) fn len(&self) -> usize{\n\t\tself.len >> Self::LEN_HEAD_BITS\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::new":["/// Constructs a new `BitPtr` from its components.\n///\n/// # Parameters\n///\n/// - `addr`: A well-aligned pointer to a storage element.\n/// - `head`: The bit index of the first live bit in the element under\n///   `*addr`.\n/// - `bits`: The number of live bits in the region the produced `BitPtr<T>`\n///   describes.\n///\n/// # Returns\n///\n/// This returns `None` in the following cases:\n///\n/// - `addr` is the null pointer, or is not adequately aligned for `T`.\n/// - `bits` is greater than `Self::REGION_MAX_BITS`, and cannot be encoded\n///   into a `BitPtr`.\n/// - addr` is so high in the address space that the element slice wraps\n///   around the address space boundary.\n///\n/// # Safety\n///\n/// The caller must provide an `addr` pointer and a `bits` counter which\n/// describe a `[T]` region which is correctly aligned and validly allocated\n/// in the caller’s memory space. The caller is responsible for ensuring\n/// that the slice of memory the produced `BitPtr<T>` describes is all\n/// governable in the caller’s context.\npub(crate) fn new(\n\t\taddr: impl Into<Address<T>>,\n\t\thead: BitIdx<T::Mem>,\n\t\tbits: usize,\n\t) -> Option<Self>{\n\t\tlet addr = addr.into();\n\n\t\tif addr.to_const().is_null() {\n\t\t\treturn None;\n\t\t}\n\n\t\tif (addr.value().trailing_zeros() as usize) < Self::PTR_HEAD_BITS {\n\t\t\treturn None;\n\t\t}\n\n\t\tif bits > Self::REGION_MAX_BITS {\n\t\t\treturn None;\n\t\t}\n\n\t\tlet elts = head.span(bits).0;\n\t\tlet last = addr.to_const().wrapping_add(elts);\n\t\tif last < addr.to_const() {\n\t\t\treturn None;\n\t\t}\n\n\t\tSome(unsafe { Self::new_unchecked(addr, head, bits) })\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::new_unchecked":["/// Creates a new `BitPtr<T>` from its components, without any validity\n/// checks.\n///\n/// # Safety\n///\n/// ***ABSOLUTELY NONE.*** This function *only* packs its arguments into the\n/// bit pattern of the `BitPtr<T>` type. It should only be used in contexts\n/// where a previously extant `BitPtr<T>` was constructed with ancestry\n/// known to have survived [`::new`], and any manipulations of its raw\n/// components are known to be valid for reconstruction.\n///\n/// # Parameters\n///\n/// See [`::new`].\n///\n/// # Returns\n///\n/// See [`::new`].\n///\n/// [`::new`]: #method.new\n#[inline]\npub(crate) unsafe fn new_unchecked(\n\t\taddr: impl Into<Address<T>>,\n\t\thead: BitIdx<T::Mem>,\n\t\tbits: usize,\n\t) -> Self{\n\t\tlet (addr, head) = (addr.into(), head.value() as usize);\n\n\t\tlet ptr_data = addr.value() & Self::PTR_ADDR_MASK;\n\t\tlet ptr_head = head >> Self::LEN_HEAD_BITS;\n\n\t\tlet len_head = head & Self::LEN_HEAD_MASK;\n\t\tlet len_bits = bits << Self::LEN_HEAD_BITS;\n\n\t\tlet ptr = Address::new(ptr_data | ptr_head);\n\n\t\tSelf {\n\t\t\tptr: NonNull::new_unchecked(ptr.to_mut()),\n\t\t\tlen: len_bits | len_head,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::pointer":["/// Gets the base element address of the referent region.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// The address of the starting element of the memory region. This address\n/// is weakly typed so that it can be cast by call sites to the most useful\n/// access type.\n#[inline]\npub(crate) fn pointer(&self) -> Address<T>{\n\t\tAddress::new(self.ptr.as_ptr() as usize & Self::PTR_ADDR_MASK)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::raw_parts":["/// Gets the three logical components of the pointer.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// - `.0`: The base address of the referent memory region.\n/// - `.1`: The index of the first live bit in the first element of the\n///   region.\n/// - `.2`: The number of live bits in the region.\n#[inline]\npub(crate) fn raw_parts(&self) -> (Address<T>, BitIdx<T::Mem>, usize){\n\t\t(self.pointer(), self.head(), self.len())\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::read":["/// Reads a bit some distance away from `self`.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `index`: The bit distance away from `self` at which to read.\n///\n/// # Returns\n///\n/// The value of the bit `index` bits away from `self.head()`, according to\n/// the `O` ordering.\n#[inline]\npub(crate) unsafe fn read<O>(&self, index: usize) -> bool\n\twhere O: BitOrder{\n\t\tlet (elt, bit) = self.head().offset(index as isize);\n\t\tlet base = self.pointer().to_access();\n\t\t(&*base.offset(elt)).get_bit::<O>(bit)\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::render":["/// Renders the pointer structure into a formatter for use during\n/// higher-level type `Debug` implementations.\n///\n/// # Parameters\n///\n/// - `self`\n/// - `fmt`: The formatter into which the pointer is written.\n/// - `name`: The suffix of the higher-level object rendering its pointer.\n///   The `Bit` prefix is applied to the object type name in this format.\n/// - `ord`: The name of a `BitOrder` type parameter, if any.\n/// - `fields`: Any additional fields in the object’s debuginfo to be\n///   rendered.\n///\n/// # Returns\n///\n/// The result of formatting the pointer into the receiver.\n///\n/// # Behavior\n///\n/// This function writes `Bit{name}<[{ord}, ]T> {{ {fields} }}` into the\n/// `fmt` formatter, where `{fields}` includes the address, head index, and\n/// bit count of the pointer, as well as any additional fields provided by\n/// the caller.\n///\n/// Higher types in the crate should use this function to drive their\n/// `Debug` implementations, and then use `BitSlice`’s list formatters to\n/// display their contents if appropriate.\npub(crate) fn render<'a>(\n\t\t&'a self,\n\t\tfmt: &'a mut Formatter,\n\t\tname: &'a str,\n\t\tord: Option<&'a str>,\n\t\tfields: impl IntoIterator<Item = &'a (&'static str, &'a dyn Debug)>,\n\t) -> fmt::Result{\n\t\twrite!(fmt, \"Bit{}<\", name)?;\n\t\tif let Some(ord) = ord {\n\t\t\twrite!(fmt, \"{}, \", ord)?;\n\t\t}\n\t\twrite!(fmt, \"{}>\", any::type_name::<T::Mem>())?;\n\t\tlet mut builder = fmt.debug_struct(\"\");\n\t\tbuilder\n\t\t\t.field(\"addr\", &self.pointer().fmt_pointer())\n\t\t\t.field(\"head\", &self.head().fmt_binary())\n\t\t\t.field(\"bits\", &self.len());\n\t\tfor (name, value) in fields {\n\t\t\tbuilder.field(name, value);\n\t\t}\n\t\tbuilder.finish()\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::set_head":["/// Write a new `head` value into the pointer, with no other effects.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `head`: A new starting index.\n///\n/// # Effects\n///\n/// `head` is written into the `.head` logical field, without affecting\n/// `.addr` or `.bits`.\n#[cfg(feature = \"alloc\")]\npub(crate) unsafe fn set_head(&mut self, head: BitIdx<T::Mem>){\n\t\tlet head = head.value() as usize;\n\t\tlet mut ptr = self.ptr.as_ptr() as usize;\n\n\t\tptr &= Self::PTR_ADDR_MASK;\n\t\tptr |= head >> Self::LEN_HEAD_BITS;\n\t\tself.ptr = NonNull::new_unchecked(ptr as *mut u8);\n\n\t\tself.len &= !Self::LEN_HEAD_MASK;\n\t\tself.len |= head & Self::LEN_HEAD_MASK;\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::set_len":["/// Sets the `.bits` logical member to a new value.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `len`: A new bit length. This must not be greater than\n///   `Self::REGION_MAX_BITS`.\n///\n/// # Effects\n///\n/// The `new_len` value is written directly into the `.bits` logical field.\n#[inline]\npub(crate) unsafe fn set_len(&mut self, new_len: usize){\n\t\tdebug_assert!(\n\t\t\tnew_len <= Self::REGION_MAX_BITS,\n\t\t\t\"Length {} out of range\",\n\t\t\tnew_len,\n\t\t);\n\t\tself.len &= Self::LEN_HEAD_MASK;\n\t\tself.len |= new_len << Self::LEN_HEAD_BITS;\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::set_pointer":["/// Overwrites the data pointer with a new address. This method does not\n/// perform safety checks on the new pointer.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `ptr`: The new address of the `BitPtr<T>`’s domain.\n///\n/// # Safety\n///\n/// None. The invariants of `::new` must be checked at the caller.\n#[inline]\n#[cfg(feature = \"alloc\")]\npub(crate) unsafe fn set_pointer(&mut self, addr: impl Into<Address<T>>){\n\t\tlet mut addr = addr.into();\n\t\tif addr.to_const().is_null() {\n\t\t\t*self = Self::EMPTY;\n\t\t\treturn;\n\t\t}\n\t\taddr.addr &= Self::PTR_ADDR_MASK;\n\t\taddr.addr |= self.ptr.as_ptr() as usize & Self::PTR_HEAD_MASK;\n\t\tself.ptr = NonNull::new_unchecked(addr.to_mut() as *mut u8);\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::tail":["/// Computes the tail index for the first dead bit after the live bits.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A `BitTail` that is the index of the first dead bit after the last live\n/// bit in the last element. This will almost always be in the range `1 ..=\n/// T::Mem::BITS`.\n///\n/// It will be zero only when `self` is empty.\n#[inline]\npub(crate) fn tail(&self) -> BitTail<T::Mem>{\n\t\tlet (head, len) = (self.head(), self.len());\n\n\t\tif head.value() == 0 && len == 0 {\n\t\t\treturn BitTail::ZERO;\n\t\t}\n\n\t\t//  Compute the in-element tail index as the head plus the length,\n\t\t//  modulated by the element width.\n\t\tlet tail = (head.value() as usize + len) & T::Mem::MASK as usize;\n\t\t/* If the tail is zero, wrap it to `T::Mem::BITS` as the maximal. This\n\t\tupshifts `1` (tail is zero) or `0` (tail is not), then sets the upshift\n\t\ton the rest of the tail, producing something in the range\n\t\t`1 ..= T::Mem::BITS`.\n\t\t*/\n\t\tunsafe {\n\t\t\tBitTail::new_unchecked(\n\t\t\t\t(((tail == 0) as u8) << T::Mem::INDX) | tail as u8,\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::to_bitslice_mut":["/// Typecasts the pointer structure into a mutable-region reference.\n///\n/// # Safety\n///\n/// This must only be used when the pointer refers to a region that is\n/// correctly initialized *and uniquely mutable* in the caller’s context.\n/// There must be no other references of any kind to the referent region.\n///\n/// # Lifetimes\n///\n/// - `'a`: The minimum lifetime of the referent region, as understood by\n///   the caller.\npub(crate) fn to_bitslice_mut<'a, O>(self) -> &'a mut BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tunsafe { &mut *self.to_bitslice_ptr_mut::<O>() }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::to_bitslice_ptr":["/// Type-casts the pointer structure into a raw region pointer.\n#[inline]\npub(crate) fn to_bitslice_ptr<O>(self) -> *const BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tptr::slice_from_raw_parts(\n\t\t\tself.ptr.as_ptr() as *const u8 as *const (),\n\t\t\tself.len,\n\t\t) as *const BitSlice<O, T>\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::to_bitslice_ptr_mut":["/// Typecasts the pointer structure into a raw mutable-region pointer.\n#[inline(always)]\npub(crate) fn to_bitslice_ptr_mut<O>(self) -> *mut BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tself.to_bitslice_ptr::<O>() as *mut BitSlice<O, T>\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::to_bitslice_ref":["/// Typecasts the pointer structure into a region reference.\n///\n/// # Safety\n///\n/// This must only be used when the pointer refers to a region that is\n/// correctly initialized in the caller’s context. There must be no `&mut\n/// BitSlice<O, T>` references to the referent region.\n///\n/// # Lifetimes\n///\n/// - `'a`: The minimum lifetime of the referent region, as understood by\n///   the caller.\npub(crate) fn to_bitslice_ref<'a, O>(self) -> &'a BitSlice<O, T>\n\twhere O: BitOrder{\n\t\tunsafe { &*self.to_bitslice_ptr::<O>() }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::to_nonnull":["/// Typecasts the pointer structure into a `NonNull<BitSlice>` pointer.\n///\n/// This function is used by the owning indirect handles, and does not yet\n/// have any purpose in non-`alloc` programs.\n#[cfg(feature = \"alloc\")]\npub(crate) fn to_nonnull<O>(self) -> NonNull<BitSlice<O, T>>\n\twhere\n\t\tO: BitOrder,\n\t\tT: BitStore,{\n\t\tunsafe { NonNull::new_unchecked(self.to_bitslice_ptr_mut()) }\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::uninhabited":["/// Constructs an empty `BitPtr` at a bare pointer.\n///\n/// # Parameters\n///\n/// - `addr`: Some allocated address of a `T` element or region.\n///\n/// # Returns\n///\n/// A zero-length `BitPtr` at `addr`.\n///\n/// # Panics\n///\n/// This function panics if `addr` is not well-aligned to `T`. All addresses\n/// received from the Rust allocation system are required to satisfy this\n/// constraint.\n#[cfg(feature = \"alloc\")]\npub(crate) fn uninhabited(addr: impl Into<Address<T>>) -> Self{\n\t\tlet addr = addr.into();\n\t\tassert!(\n\t\t\taddr.value().trailing_zeros() as usize >= Self::PTR_HEAD_BITS,\n\t\t\t\"Pointer {:p} does not satisfy minimum alignment requirements {}\",\n\t\t\taddr.to_const(),\n\t\t\tSelf::PTR_HEAD_BITS\n\t\t);\n\t\tSelf {\n\t\t\tptr: match NonNull::new(addr.to_mut() as *mut u8) {\n\t\t\t\tSome(nn) => nn,\n\t\t\t\tNone => return Self::EMPTY,\n\t\t\t},\n\t\t\tlen: 0,\n\t\t\t_ty: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"pointer::BitPtr::<T>::write":["/// Writes a bit some distance away from `self`.\n///\n/// # Type Parameters\n///\n/// - `O`: A bit ordering.\n///\n/// # Parameters\n///\n/// - `&self`: The `self` pointer must be describing a write-capable region.\n/// - `index`: The bit distance away from `self` at which to write,\n///   according to the `O` ordering.\n/// - `value`: The bit value to insert at `index`.\n///\n/// # Effects\n///\n/// `value` is written to the bit specified by `index`, relative to\n/// `self.head()` and `self.pointer()`.\n#[inline]\npub(crate) unsafe fn write<O>(&self, index: usize, value: bool)\n\twhere O: BitOrder{\n\t\tlet (elt, bit) = self.head().offset(index as isize);\n\t\tlet base = self.pointer().to_access();\n\t\t(&*base.offset(elt)).write_bit::<O>(bit, value);\n\t}","Real(LocalPath(\"src/pointer.rs\"))"],"slice::BitSlice":["/** A slice of individual bits, anywhere in memory.\n\nThis is the main working type of the crate. It is analagous to `[bool]`, and is\nwritten to be as close as possible to drop-in replacable for it. This type\ncontains most of the *methods* used to operate on memory, but it will rarely be\nnamed directly in your code. You should generally prefer to use [`BitArray`] for\nfixed-size arrays or [`BitVec`] for dynamic vectors, and use `&BitSlice`\nreferences only where you would directly use `&[bool]` or `&[u8]` references\nbefore using this crate.\n\nAs it is a slice wrapper, you are intended to work with this through references\n(`&BitSlice<O, T>` and `&mut BitSlice<O, T>`) or through the other data\nstructures provided by `bitvec` that are implemented atop it. Once created,\nreferences to `BitSlice` are guaranteed to work just like references to `[bool]`\nto the fullest extent possible in the Rust language.\n\nEvery bit-vector crate can give you an opaque type that hides shift/mask\noperations from you. `BitSlice` does far more than this: it offers you the full\nRust guarantees about reference behavior, including lifetime tracking,\nmutability and aliasing awareness, and explicit memory control, *as well as* the\nfull set of tools and APIs available to the standard `[bool]` slice type.\n`BitSlice` can arbitrarily split and subslice, just like `[bool]`. You can write\na linear consuming function and keep the patterns already know.\n\nFor example, to trim all the bits off either edge that match a condition, you\ncould write\n\n```rust\nuse bitvec::prelude::*;\n\nfn trim<O: BitOrder, T: BitStore>(\n  bits: &BitSlice<O, T>,\n  to_trim: bool,\n) -> &BitSlice<O, T> {\n  let stop = |b: &bool| *b != to_trim;\n  let front = bits.iter().position(stop).unwrap_or(0);\n  let back = bits.iter().rposition(stop).unwrap_or(0);\n  &bits[front ..= back]\n}\n# assert_eq!(trim(bits![0, 0, 1, 1, 0, 1, 0], false), bits![1, 1, 0, 1]);\n```\n\nto get behavior something like\n`trim(&BitSlice[0, 0, 1, 1, 0, 1, 0], false) == &BitSlice[1, 1, 0, 1]`.\n\n# Documentation\n\nAll APIs that mirror something in the standard library will have an `Original`\nsection linking to the corresponding item. All APIs that have a different\nsignature or behavior than the original will have an `API Differences` section\nexplaining what has changed, and how to adapt your existing code to the change.\n\nThese sections look like this:\n\n# Original\n\n[`slice`](https://doc.rust-lang.org/std/primitive.slice.html)\n\n# API Differences\n\nThe slice type `[bool]` has no type parameters. `BitSlice<O, T>` has two: one\nfor the memory type used as backing storage, and one for the order of bits\nwithin that memory type.\n\n`&BitSlice<O, T>` is capable of producing `&bool` references to read bits out\nof its memory, but is not capable of producing `&mut bool` references to write\nbits *into* its memory. Any `[bool]` API that would produce a `&mut bool` will\ninstead produce a [`BitMut<O, T>`] proxy reference.\n\n# Behavior\n\n`BitSlice` is a wrapper over `[T]`. It describes a region of memory, and must be\nhandled indirectly. This is most commonly through the reference types\n`&BitSlice` and `&mut BitSlice`, which borrow memory owned by some other value\nin the program. These buffers can be directly owned by the sibling types\n`BitBox`, which behavios like `Box<[T]>`, and `BitVec`, which behaves like\n`Vec<T>`. It cannot be used as the type parameter to a standard-library-provided\nhandle type.\n\nThe `BitSlice` region provides access to each individual bit in the region, as\nif each bit had a memory address that you could use to dereference it. It packs\neach logical bit into exactly one bit of storage memory, just like\n[`std::bitset`] and [`std::vector<bool>`] in C++.\n\n# Type Parameters\n\n`BitSlice` has two type parameters which propagate through nearly every public\nAPI in the crate. These are very important to its operation, and your choice\nof type arguments informs nearly every part of this library’s behavior.\n\n## `T: BitStore`\n\nThis is the simpler of the two parameters. It refers to the integer type used to\nhold bits. It must be one of the Rust unsigned integer fundamentals: `u8`,\n`u16`, `u32`, `usize`, and on 64-bit systems only, `u64`. In addition, it can\nalso be the `Cell<N>` wrapper over any of those, or their equivalent types in\n`core::sync::atomic`. Unless you know you need to have `Cell` or atomic\nproperties, though, you should use a plain integer.\n\nThe default type argument is `usize`.\n\nThe argument you choose is used as the basis of a `[T]` slice, over which the\n`BitSlice` view type is placed. `BitSlice<_, T>` is subject to all of the rules\nabout alignment that `[T]` is. If you are working with in-memory representation\nformats, chances are that you already have a `T` type with which you’ve been\nworking, and should use it here.\n\nIf you are only using this crate to discard the seven wasted bits per `bool`\nof a collection of `bool`s, and are not too concerned about the in-memory\nrepresentation, then you should use the default type argument of `usize`. This\nis because most processors work best when moving an entire `usize` between\nmemory and the processor itself, and using a smaller type may cause it to slow\ndown.\n\n## `O: BitOrder`\n\nThis is the more complex parameter. It has a default argument which, like\n`usize`, is the good-enough choice when you do not explicitly need to control\nthe representation of bits in memory.\n\nThis parameter determines how to index the bits within a single memory element\n`T`. Computers all agree that in a slice of elements `T`, the element with the\nlower index has a lower memory address than the element with the higher index.\nBut the individual bits within an element do not have addresses, and so there is\nno uniform standard of which bit is the zeroth, which is the first, which is the\npenultimate, and which is the last.\n\nTo make matters even more confusing, there are two predominant ideas of\nin-element ordering that often *correlate* with the in-element *byte* ordering\nof integer types, but are in fact wholly unrelated! `bitvec` provides these two\nmain orders as types for you, and if you need a different one, it also provides\nthe tools you need to make your own.\n\n### Least Significant Bit Comes First\n\nThis ordering, named the [`Lsb0`] type, indexes bits within an element by\nplacing the `0` index at the least significant bit (numeric value `1`) and the\nfinal index at the most significant bit (numeric value `T::min_value()`, for\nsigned integers on most machines).\n\nFor example, this is the ordering used by the [TCP wire format], and by most C\ncompilers to lay out bit-field struct members on little-endian **byte**-ordered\nmachines.\n\n### Most Significant Bit Comes First\n\nThis ordering, named the [`Msb0`] type, indexes bits within an element by\nplacing the `0` index at the most significant bit (numeric value `T::min_value()`\nfor most signed integers) and the final index at the least significant bit\n(numeric value `1`).\n\nThis is the ordering used by most C compilers to lay out bit-field struct\nmembers on big-endian **byte**-ordered machines.\n\n### Default Ordering\n\nBecause the ordering does not matter to performance, and users who need to\nexplicitly control memory representation will provide an order *anyway*, the\ndefault ordering type follows the C-compiler convention. The ordering that\nmatches your target’s C-compiler bitfield layout is reëxported as\n[`bitvec::prelude::Local`], and used as the default argument. If you don’t\nalready know that you need a specific ordering, you should use `Local` and not\nworry too much about it.\n\n# Safety\n\n`BitSlice` is designed to never introduce new memory unsafety that you did not\nprovide yourself, either before or during the use of this crate. Bugs do, and\nhave, occured, and you are encouraged to submit any discovered flaw as a defect\nreport.\n\nThe `&BitSlice` reference type uses a private encoding scheme to hold all the\ninformation needed in its stack value. This encoding is **not** part of the\npublic API of the library, and is not binary-compatible with `&[T]`.\nFurthermore, in order to satisfy Rust’s requirements about alias conditions,\n`BitSlice` performs type transformations on the `T` parameter to ensure that it\nnever creates the potential for undefined behavior.\n\nYou must never attempt to type-cast a reference to `BitSlice` in any way. You\nmust not use `mem::transmute` with `BitSlice` anywhere in its type arguments.\nYou must not use `as`-casting to convert between `*BitSlice` and any other type.\nYou must not attempt to modify the binary representation of a `&BitSlice`\nreference value. These actions will all lead to runtime memory unsafety, are\n(hopefully) likely to induce a program crash, and may possibly cause undefined\nbehavior at compile-time.\n\nEverything in the `BitSlice` public API, even the `unsafe` parts, are guaranteed\nto have no more unsafety than their equivalent parts in the standard library.\nAll `unsafe` APIs will have documentation explicitly detailing what the API\nrequires you to uphold in order for it to function safely and correctly. All\nsafe APIs will do so themselves.\n\n# Performance\n\nLike the standard library’s `[T]` slice, `BitSlice` is designed to be very easy\nto use safely, while supporting `unsafe` when necessary. Rust has a powerful\noptimizing engine, and `BitSlice` will frequently be compiled to have zero\nruntime cost. Where it is slower, it will not be significantly slower than a\nmanual replacement.\n\nAs the machine instructions operate on registers rather than bits, your choice\nof `T: BitOrder` type parameter can influence your slice’s performance. Using\nlarger register types means that slices can gallop over completely-filled\ninterior elements faster, while narrower register types permit more graceful\nhandling of subslicing and aliased splits.\n\n# Construction\n\n`BitSlice` views of memory can be constructed over borrowed data in a number of\nways. As this is a reference-only type, it can only ever be built by borrowing\nan existing memory buffer and taking temporary control of your program’s view of\nthe region.\n\n## Macro Constructor\n\n`BitSlice` buffers can be constructed at compile-time through the [`bits!`]\nmacro. This macro accepts a superset of the `vec!` arguments, and creates an\nappropriate buffer in your program’s static memory.\n\n```rust\nuse bitvec::prelude::*;\n\nlet static_borrow = bits![0, 1, 0, 0, 1, 0, 0, 1];\nlet mutable_static: &mut BitSlice<_, _> = bits![mut 0; 8];\n\nassert_ne!(static_borrow, mutable_static);\nmutable_static.clone_from_bitslice(static_borrow);\nassert_eq!(static_borrow, mutable_static);\n```\n\nNote that, despite constructing a `static mut` binding, the `bits![mut …]` call\nis not `unsafe`, as the constructed symbol is hidden and only accessible by the\nsole `&mut` reference returned by the macro call.\n\n## Borrowing Constructors\n\nThe functions [`from_element`], [`from_element_mut`], [`from_slice`], and\n[`from_slice_mut`] take references to existing memory, and construct `BitSlice`\nreferences over them. These are the most basic ways to borrow memory and view it\nas bits.\n\n```rust\nuse bitvec::prelude::*;\n\nlet data = [0u16; 3];\nlet local_borrow = BitSlice::<Lsb0, _>::from_slice(&data);\n\nlet mut data = [0u8; 5];\nlet local_mut = BitSlice::<Lsb0, _>::from_slice_mut(&mut data);\n```\n\n## Trait Method Constructors\n\nThe [`BitView`] trait implements `.view_bits::<O>()` and `.view_bits_mut::<O>()`\nmethods on elements, arrays not larger than 32 elements, and slices. This trait,\nimported in the crate prelude, is *probably* the easiest way for you to borrow\nmemory.\n\n```rust\nuse bitvec::prelude::*;\n\nlet data = [0u32; 5];\nlet trait_view = data.view_bits::<Msb0>();\n\nlet mut data = 0usize;\nlet trait_mut = data.view_bits_mut::<Msb0>();\n```\n\n## Owned Bit Slices\n\nIf you wish to take ownership of a memory region and enforce that it is always\nviewed as a `BitSlice` by default, you can use one of the [`BitArray`],\n[`BitBox`], or [`BitVec`] types, rather than pairing ordinary buffer types with\nthe borrowing constructors.\n\n```rust\nuse bitvec::prelude::*;\n\nlet slice = bits![0; 27];\nlet array = bitarr![Local, u8; 0; 10];\n# #[cfg(feature = \"alloc\")] fn allocs() {\nlet boxed = bitbox![0; 10];\nlet vec = bitvec![0; 20];\n# } #[cfg(feature = \"alloc\")] allocs();\n\n// arrays always round up\nassert_eq!(array.as_bitslice(), slice[.. 16]);\n# #[cfg(feature = \"alloc\")] fn allocs2() {\n# let slice = bits![0; 27];\n# let boxed = bitbox![0; 10];\n# let vec = bitvec![0; 20];\nassert_eq!(boxed.as_bitslice(), slice[.. 10]);\nassert_eq!(vec.as_bitslice(), slice[.. 20]);\n# } #[cfg(feature = \"alloc\")] allocs2();\n```\n\n[TCP wire format]: https://en.wikipedia.org/wiki/Transmission_Control_Protocol#TCP_segment_structure\n[`BitArray`]: ../array/struct.BitArray.html\n[`BitBox`]: ../boxed/struct.BitBox.html\n[`BitMut<O, T>`]: struct.BitMut.html\n[`BitVec`]: ../vec/struct.BitVec.html\n[`BitView`]: ../view/trait.BitView.html\n[`Lsb0`]: ../order/struct.Lsb0.html\n[`Msb0`]: ../order/struct.Msb0.html\n[`bits!`]: ../macro.bits.html\n[`bitvec::prelude::Local`]: ../order/struct.Local.html\n[`std::bitset`]: https://en.cppreference.com/w/cpp/utility/bitset\n[`std::vector<bool>`]: https://en.cppreference.com/w/cpp/container/vector_bool\n**/\n#[repr(transparent)]\npub struct BitSlice<O = Local, T = usize>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Mark the in-element ordering of bits\n\t_ord: PhantomData<O>,\n\t/// Mark the element type of memory\n\t_typ: PhantomData<[T]>,\n\t/// Indicate that this is a newtype wrapper over a wholly-untyped slice.\n\t///\n\t/// This is necessary in order for the Rust compiler to remove restrictions\n\t/// on the possible values of references to this slice `&BitSlice` and\n\t/// `&mut BitSlice`.\n\t///\n\t/// Rust has firm requirements that *any* reference that is directly usable\n\t/// to dereference a real value must conform to its rules about address\n\t/// liveness, type alignment, and for slices, trustworthy length. It is\n\t/// undefined behavior for a slice reference *to a dereferencable type* to\n\t/// violate any of these restrictions.\n\t///\n\t/// However, the value of a reference to a zero-sized type has *no* such\n\t/// restrictions, because that reference can never perform direct memory\n\t/// access. The compiler will accept any value in a slot typed as `&[()]`,\n\t/// because the values in it will never be used for a load or store\n\t/// instruction. If this were `[T]`, then Rust would make the pointer\n\t/// encoding used to manage values of `&BitSlice` become undefined behavior.\n\t///\n\t/// See the `pointer` module for information on the encoding used.\n\t_mem: [()],\n}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::alias":["/// Marks an immutable slice as referring to aliased memory region.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub(crate) fn alias(&self) -> &BitSlice<O, T::Alias>{\n\t\tunsafe { &*(self.as_ptr() as *const BitSlice<O, T::Alias>) }\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::alias_mut":["/// Marks a mutable slice as describing an aliased memory region.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub(crate) fn alias_mut(&mut self) -> &mut BitSlice<O, T::Alias>{\n\t\tunsafe { &mut *(self as *mut Self as *mut BitSlice<O, T::Alias>) }\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::all":["/// Tests if *all* bits in the slice domain are set (logical `∧`).\n///\n/// # Truth Table\n///\n/// ```text\n/// 0 0 => 0\n/// 0 1 => 0\n/// 1 0 => 0\n/// 1 1 => 1\n/// ```\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// Whether all bits in the slice domain are set. The empty slice returns\n/// `true`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = 0xFDu8.view_bits::<Msb0>();\n/// assert!(bits[.. 4].all());\n/// assert!(!bits[4 ..].all());\n/// ```\n#[inline]\npub fn all(&self) -> bool{\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t/* Due to a bug in `rustc`, calling `.value()` on the two\n\t\t\t\t`BitMask` types, to use `T::Mem | T::Mem == T::Mem`, causes type\n\t\t\t\tresolution failure and only discovers the\n\t\t\t\t`for<'a> BitOr<&'a Self>` implementation in the trait bounds\n\t\t\t\t`T::Mem: BitMemory: IsUnsigned: BitOr<Self> + for<'a> BitOr<&'a Self>`.\n\n\t\t\t\tUntil this is fixed, routing through the `BitMask`\n\t\t\t\timplementation suffices. The by-val and by-ref operator traits\n\t\t\t\tare at the same position in the bounds chain, making this quite\n\t\t\t\ta strange bug.\n\t\t\t\t*/\n\t\t\t\t!O::mask(head, tail) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t== BitMask::ALL\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(true, |(head, elem)| {\n\t\t\t\t\t!O::mask(head, None) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t== BitMask::ALL\n\t\t\t\t}) && body.iter().copied().all(|e| e == T::Mem::ALL)\n\t\t\t\t\t&& tail.map_or(true, |(elem, tail)| {\n\t\t\t\t\t\t!O::mask(None, tail) | dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t\t== BitMask::ALL\n\t\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::any":["/// Tests if *any* bit in the slice is set (logical `∨`).\n///\n/// # Truth Table\n///\n/// ```text\n/// 0 0 => 0\n/// 0 1 => 1\n/// 1 0 => 1\n/// 1 1 => 1\n/// ```\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// Whether any bit in the slice domain is set. The empty slice returns\n/// `false`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = 0x40u8.view_bits::<Msb0>();\n/// assert!(bits[.. 4].any());\n/// assert!(!bits[4 ..].any());\n/// ```\n#[inline]\npub fn any(&self) -> bool{\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\tO::mask(head, tail) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t!= BitMask::ZERO\n\t\t\t},\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(false, |(head, elem)| {\n\t\t\t\t\tO::mask(head, None) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t!= BitMask::ZERO\n\t\t\t\t}) || body.iter().copied().any(|e| e != T::Mem::ZERO)\n\t\t\t\t\t|| tail.map_or(false, |(elem, tail)| {\n\t\t\t\t\t\tO::mask(None, tail) & dvl::load_aliased_local::<T>(elem)\n\t\t\t\t\t\t\t!= BitMask::ZERO\n\t\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::as_aliased_slice":["/// Accesses the total backing storage of the `BitSlice`, as a slice of its\n/// aliased elements.\n///\n/// Because `BitSlice` is permitted to create aliasing views to memory at\n/// runtime, this method is required to mark the entire slice as aliased in\n/// order to include the maybe-aliased edge elements.\n///\n/// You should prefer using [`.domain`] to produce a fine-grained view that\n/// only aliases when necessary. This method is only appropriate when you\n/// require a single, contiguous, slice, for some API.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// An aliased view of the entire memory region this slice covers, including\n/// contended edge elements.\n///\n/// [`.domain`]: #method.domain\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_aliased_slice(&self) -> &[T::Alias]{\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_alias(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::as_mut_slice":["/// Views the wholly-filled elements of the `BitSlice`.\n///\n/// This will not include partially-owned edge elements, as they may be\n/// aliased by other handles. To gain access to all elements that the\n/// `BitSlice` region covers, use one of the following:\n///\n/// - [`.as_aliased_slice`] produces a shared slice over all elements,\n///   marked as aliased to allow for the possibliity of mutation.\n/// - [`.domain_mut`] produces a view describing each component of the\n///   region, marking only the contended edges as aliased and the\n///   uncontended interior as unaliased.\n///\n/// # Parameters\n///\n/// - `&mut self`\n///\n/// # Returns\n///\n/// A mutable slice of all the wholly-filled elements in the `BitSlice`\n/// backing storage.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = [1u8, 64];\n/// let bits = data.view_bits_mut::<Msb0>();\n/// for elt in bits.as_mut_slice() {\n///   *elt |= 2;\n/// }\n/// assert_eq!(&[3, 66], bits.as_slice());\n/// ```\n///\n/// [`.as_aliased_slice`]: #method.as_aliased_slice\n/// [`.domain_mut`]: #method.domain_mut\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_slice(&mut self) -> &mut [T::Mem]{\n\t\tself.domain_mut().region().map_or(&mut [], |(_, b, _)| b)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::as_slice":["/// Views the wholly-filled elements of the `BitSlice`.\n///\n/// This will not include partially-owned edge elements, as they may be\n/// aliased by other handles. To gain access to all elements that the\n/// `BitSlice` region covers, use one of the following:\n///\n/// - [`.as_aliased_slice`] produces a shared slice over all elements,\n///   marked as aliased to allow for the possibliity of external mutation.\n/// - [`.domain`] produces a view describing each component of the region,\n///   marking only the contended edges as aliased and the uncontended\n///   interior as unaliased.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A slice of all the wholly-utilised elements in the `BitSlice` backing\n/// storage.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = [1u8, 66];\n/// let bits = data.view_bits::<Msb0>();\n///\n/// let accum = bits\n///   .as_slice()\n///   .iter()\n///   .copied()\n///   .map(u8::count_ones)\n///   .sum::<u32>();\n/// assert_eq!(accum, 3);\n/// ```\n///\n/// [`.as_aliased_slice`]: #method.as_aliased_slice]\n/// [`.domain`]: #method.domain\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_slice(&self) -> &[T::Mem]{\n\t\tself.domain().region().map_or(&[], |(_, b, _)| b)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::bit_domain":["/// Splits the slice into the logical components of its memory domain.\n///\n/// This produces a set of read-only subslices, marking as much as possible\n/// as affirmatively lacking any write-capable view (`T::NoAlias`). The\n/// unaliased view is able to safely perform unsynchronized reads from\n/// memory without causing undefined behavior, as the type system is able to\n/// statically prove that no other write-capable views exist.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A `BitDomain` structure representing the logical components of the\n/// memory region.\n///\n/// # Safety Exception\n///\n/// The following snippet describes a means of constructing a `T::NoAlias`\n/// view into memory that is, in fact, aliased:\n///\n/// ```rust\n/// # #[cfg(feature = \"atomic\")] {\n/// use bitvec::prelude::*;\n/// use core::sync::atomic::AtomicU8;\n/// type Bs<T> = BitSlice<Local, T>;\n///\n/// let data = [AtomicU8::new(0), AtomicU8::new(0), AtomicU8::new(0)];\n/// let bits: &Bs<AtomicU8> = data.view_bits::<Local>();\n/// let subslice: &Bs<AtomicU8> = &bits[4 .. 20];\n///\n/// let (_, noalias, _): (_, &Bs<u8>, _) =\n///   subslice.bit_domain().region().unwrap();\n/// # }\n/// ```\n///\n/// The `noalias` reference, which has memory type `u8`, assumes that it can\n/// act as an `&u8` reference: unsynchronized loads are permitted, as no\n/// handle exists which is capable of modifying the middle bit of `data`.\n/// This means that LLVM is permitted to issue loads from memory *wherever*\n/// it wants in the block during which `noalias` is live, as all loads are\n/// equivalent.\n///\n/// Use of the `bits` or `subslice` handles, which are still live for the\n/// lifetime of `noalias`, to issue [`.set_aliased`] calls into the middle\n/// element introduce **undefined behavior**. `bitvec` permits safe code to\n/// introduce this undefined behavior solely because it requires deliberate\n/// opt-in – you must start from atomic data; this cannot occur when `data`\n/// is non-atomic – and use of the shared-mutation facility simultaneously\n/// with the unaliasing view.\n///\n/// The [`.set_aliased`] method is speculative, and will be marked as\n/// `unsafe` or removed at any suspicion that its presence in the library\n/// has any costs.\n///\n/// # Examples\n///\n/// This method can be used to accelerate reads from a slice that is marked\n/// as aliased.\n///\n/// ```rust\n/// use bitvec::prelude::*;\n/// type Bs<T> = BitSlice<Local, T>;\n///\n/// let mut data = [0u8; 3];\n/// let bits = data.view_bits_mut::<Local>();\n/// let (a, b): (\n///   &mut Bs<<u8 as BitStore>::Alias>,\n///   &mut Bs<<u8 as BitStore>::Alias>,\n/// ) = bits.split_at_mut(4);\n/// let (partial, full, _): (\n///   &Bs<<u8 as BitStore>::Alias>,\n///   &Bs<<u8 as BitStore>::Mem>,\n///   _,\n/// ) = b.bit_domain().region().unwrap();\n/// read_from(partial); // uses alias-aware reads\n/// read_from(full); // uses ordinary reads\n/// # fn read_from<T: BitStore>(_: &BitSlice<Local, T>) {}\n/// ```\n///\n/// [`.set_aliased`]: #method.set_aliased\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn bit_domain(&self) -> BitDomain<O, T>{\n\t\tBitDomain::new(self)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::bit_domain_mut":["/// Splits the slice into the logical components of its memory domain.\n///\n/// This produces a set of mutable subslices, marking as much as possible as\n/// affirmatively lacking any other view (`T::Mem`). The bare view is able\n/// to safely perform unsynchronized reads from and writes to memory without\n/// causing undefined behavior, as the type system is able to statically\n/// prove that no other views exist.\n///\n/// # Why This Is More Sound Than `.bit_domain`\n///\n/// The `&mut` exclusion rule makes it impossible to construct two\n/// references over the same memory where one of them is marked `&mut`. This\n/// makes it impossible to hold a live reference to memory *separately* from\n/// any references produced from this method. For the duration of all\n/// references produced by this method, all ancestor references used to\n/// reach this method call are either suspended or dead, and the compiler\n/// will not allow you to use them.\n///\n/// As such, this method cannot introduce undefined behavior where a\n/// reference incorrectly believes that the referent memory region is\n/// immutable.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn bit_domain_mut(&mut self) -> BitDomainMut<O, T>{\n\t\tBitDomainMut::new(self)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::bitptr":["/// Type-cast the slice reference to its pointer structure.\n#[inline]\npub(crate) fn bitptr(&self) -> BitPtr<T>{\n\t\tBitPtr::from_bitslice_ptr(self.as_ptr())\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::copy_unchecked":["/// Copies a bit from one index to another without checking boundary\n/// conditions.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `from`: The index whose bit is to be copied\n/// - `to`: The index into which the copied bit is written.\n///\n/// # Effects\n///\n/// The bit at `from` is written into `to`.\n///\n/// # Safety\n///\n/// Both `from` and `to` must be less than `self.len()`, in order for\n/// `self` to legally read from and write to them, respectively.\n///\n/// If `self` had been split from a larger slice, reading from `from` or\n/// writing to `to` may not *necessarily* cause a memory-safety violation in\n/// the Rust model, due to the aliasing system `bitvec` employs. However,\n/// writing outside the bounds of a slice reference is *always* a logical\n/// error, as it causes changes observable by another reference handle.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 1u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// unsafe { bits.copy_unchecked(0, 2) };\n///\n/// assert_eq!(data, 5);\n/// ```\n#[inline]\npub unsafe fn copy_unchecked(&mut self, from: usize, to: usize){\n\t\tlet tmp = *self.get_unchecked(from);\n\t\tself.set_unchecked(to, tmp);\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::copy_within_unchecked":["/// Copies bits from one part of the slice to another part of itself.\n///\n/// `src` is the range within `self` to copy from. `dest` is the starting\n/// index of the range within `self` to copy to, which will have the same\n/// length as `src`. The two ranges may overlap. The ends of the two ranges\n/// must be less than or equal to `self.len()`.\n///\n/// # Effects\n///\n/// `self[src]` is copied to `self[dest .. dest + src.end() - src.start()]`.\n///\n/// # Panics\n///\n/// This function will panic if either range exceeds the end of the slice,\n/// or if the end of `src` is before the start.\n///\n/// # Safety\n///\n/// Both the `src` range and the target range `dest .. dest + src.len()`\n/// must not exceed the `self.len()` slice range.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0x07u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// unsafe { bits.copy_within_unchecked(5 .., 0); }\n///\n/// assert_eq!(data, 0xE7);\n/// ```\n#[inline]\npub unsafe fn copy_within_unchecked<R>(&mut self, src: R, dest: usize)\n\twhere R: RangeBounds<usize>{\n\t\tlet len = self.len();\n\t\tlet rev = src.contains(&dest);\n\t\tlet source = dvl::normalize_range(src, len);\n\t\tlet iter = source.zip(dest .. len);\n\t\tif rev {\n\t\t\tfor (from, to) in iter.rev() {\n\t\t\t\tself.copy_unchecked(from, to);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor (from, to) in iter {\n\t\t\t\tself.copy_unchecked(from, to);\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::count_ones":["/// Returns the number of ones in the memory region backing `self`.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// The number of high bits in the slice domain.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xF0u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// assert_eq!(bits[.. 4].count_ones(), 4);\n/// assert_eq!(bits[4 ..].count_ones(), 0);\n/// ```\n#[inline]\npub fn count_ones(&self) -> usize{\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => (O::mask(head, tail)\n\t\t\t\t& dvl::load_aliased_local::<T>(elem))\n\t\t\t.value()\n\t\t\t.count_ones() as usize,\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(0, |(head, elem)| {\n\t\t\t\t\t(O::mask(head, None) & dvl::load_aliased_local::<T>(elem))\n\t\t\t\t\t\t.value()\n\t\t\t\t\t\t.count_ones() as usize\n\t\t\t\t}) + body\n\t\t\t\t\t.iter()\n\t\t\t\t\t.copied()\n\t\t\t\t\t.map(|e| e.count_ones() as usize)\n\t\t\t\t\t.sum::<usize>() + tail.map_or(0, |(elem, tail)| {\n\t\t\t\t\t(O::mask(None, tail) & dvl::load_aliased_local::<T>(elem))\n\t\t\t\t\t\t.value()\n\t\t\t\t\t\t.count_ones() as usize\n\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::count_zeros":["/// Returns the number of zeros in the memory region backing `self`.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// The number of low bits in the slice domain.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xF0u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// assert_eq!(bits[.. 4].count_zeros(), 0);\n/// assert_eq!(bits[4 ..].count_zeros(), 4);\n/// ```\n#[inline]\npub fn count_zeros(&self) -> usize{\n\t\tmatch self.domain() {\n\t\t\tDomain::Enclave { head, elem, tail } => (!O::mask(head, tail)\n\t\t\t\t| dvl::load_aliased_local::<T>(elem))\n\t\t\t.value()\n\t\t\t.count_zeros() as usize,\n\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\thead.map_or(0, |(head, elem)| {\n\t\t\t\t\t(!O::mask(head, None)\n\t\t\t\t\t\t| elem.pipe(dvl::load_aliased_local::<T>))\n\t\t\t\t\t.value()\n\t\t\t\t\t.count_zeros() as usize\n\t\t\t\t}) + body\n\t\t\t\t\t.iter()\n\t\t\t\t\t.copied()\n\t\t\t\t\t.map(|e| e.count_zeros() as usize)\n\t\t\t\t\t.sum::<usize>() + tail.map_or(0, |(elem, tail)| {\n\t\t\t\t\t(!O::mask(None, tail)\n\t\t\t\t\t\t| elem.pipe(dvl::load_aliased_local::<T>))\n\t\t\t\t\t.value()\n\t\t\t\t\t.count_zeros() as usize\n\t\t\t\t})\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::domain":["/// Splits the slice into immutable references to its underlying memory\n/// components.\n///\n/// Unlike [`.bit_domain`] and [`.bit_domain_mut`], this does not return\n/// smaller `BitSlice` handles but rather appropriately-marked references to\n/// the underlying memory elements.\n///\n/// The aliased references allow mutation of these elements. You are\n/// required to not use mutating methods on these references *at all*. This\n/// function is not marked `unsafe`, but this is a contract you must uphold.\n/// Use [`.domain_mut`] to modify the underlying elements.\n///\n/// > It is not currently possible to forbid mutation through these\n/// > references. This may change in the future.\n///\n/// # Safety Exception\n///\n/// As with [`.bit_domain`], this produces unsynchronized immutable\n/// references over the fully-populated interior elements. If this view is\n/// constructed from a `BitSlice` handle over atomic memory, then it will\n/// remove the atomic access behavior for the interior elements. This *by\n/// itself* is safe, as long as no contemporaneous atomic writes to that\n/// memory can occur. You must not retain and use an atomic reference to the\n/// memory region marked as `NoAlias` for the duration of this view’s\n/// existence.\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// A read-only descriptor of the memory elements backing `*self`.\n///\n/// [`.bit_domain`]: #method.bit_domain\n/// [`.bit_domain_mut`]: #method.bit_domain_mut\n/// [`.domain_mut`]: #method.domain_mut\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn domain(&self) -> Domain<T>{\n\t\tDomain::new(self)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::domain_mut":["/// Splits the slice into mutable references to its underlying memory\n/// elements.\n///\n/// Like [`.domain`], this returns appropriately-marked references to the\n/// underlying memory elements. These references are all writable.\n///\n/// The aliased edge references permit modifying memory beyond their bit\n/// marker. You are required to only mutate the region of these edge\n/// elements that you currently govern. This function is not marked\n/// `unsafe`, but this is a contract you must uphold.\n///\n/// > It is not currently possible to forbid out-of-bounds mutation through\n/// > these references. This may change in the future.\n///\n/// # Parameters\n///\n/// - `&mut self`\n///\n/// # Returns\n///\n/// A descriptor of the memory elements underneath `*self`, permitting\n/// mutation.\n///\n/// [`.domain`]: #method.domain\n#[inline]\npub fn domain_mut(&mut self) -> DomainMut<T>{\n\t\tDomainMut::new(self)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::empty":["/// Produces the empty slice. This is equivalent to `&[]` for ordinary\n/// slices.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits: &BitSlice = BitSlice::empty();\n/// assert!(bits.is_empty());\n/// ```\n#[inline]\npub fn empty<'a>() -> &'a Self{\n\t\tBitPtr::EMPTY.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::empty_mut":["/// Produces the empty mutable slice. This is equivalent to `&mut []` for\n/// ordinary slices.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits: &mut BitSlice = BitSlice::empty_mut();\n/// assert!(bits.is_empty());\n/// ```\n#[inline]\npub fn empty_mut<'a>() -> &'a mut Self{\n\t\tBitPtr::EMPTY.to_bitslice_mut()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::for_each":["/// Applies a function to each bit in the slice.\n///\n/// `BitSlice` cannot implement `IndexMut`, as it cannot manifest `&mut\n/// bool` references, and the [`BitMut`] proxy reference has an unavoidable\n/// overhead. This method bypasses both problems, by applying a function to\n/// each pair of index and value in the slice, without constructing a proxy\n/// reference.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `func`: A function which receives two arguments, `index: usize` and\n///   `value: bool`, and returns a `bool`.\n///\n/// # Effects\n///\n/// For each index in the slice, the result of invoking `func` with the\n/// index number and current bit value is written into the slice.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits.for_each(|idx, _bit| idx % 3 == 0);\n/// assert_eq!(data, 0b100_100_10);\n/// ```\n#[inline]\npub fn for_each<F>(&mut self, mut func: F)\n\twhere F: FnMut(usize, bool) -> bool{\n\t\tfor idx in 0 .. self.len() {\n\t\t\tunsafe {\n\t\t\t\tlet tmp = *self.get_unchecked(idx);\n\t\t\t\tlet new = func(idx, tmp);\n\t\t\t\tself.set_unchecked(idx, new);\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_aliased_slice_unchecked":["/// Constructs a `BitSlice` over aliased memory.\n///\n/// This is restricted so that it can only be used within the crate.\n/// Construction of a `BitSlice` over externally-aliased memory is unsound.\npub(crate) unsafe fn from_aliased_slice_unchecked(slice: &[T]) -> &Self{\n\t\tBitPtr::new_unchecked(\n\t\t\tslice.as_ptr(),\n\t\t\tBitIdx::ZERO,\n\t\t\tslice.len() * T::Mem::BITS as usize,\n\t\t)\n\t\t.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_element":["/// Constructs a shared `&BitSlice` reference over a shared element.\n///\n/// The [`BitView`] trait, implemented on all `T` elements, provides a\n/// method [`.view_bits::<O>()`] which delegates to this function and may be\n/// more convenient for you to write.\n///\n/// # Parameters\n///\n/// - `elem`: A shared reference to a memory element.\n///\n/// # Returns\n///\n/// A shared `&BitSlice` over the `elem` element.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let elem = 0u8;\n/// let bits = BitSlice::<Local, _>::from_element(&elem);\n/// assert_eq!(bits.len(), 8);\n/// ```\n///\n/// [`BitView`]: ../view/trait.BitView.html\n/// [`.view_bits::<O>()`]: ../view/trait.BitView.html#method.view_bits\n#[inline]\npub fn from_element(elem: &T) -> &Self{\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(elem, BitIdx::ZERO, T::Mem::BITS as usize)\n\t\t}\n\t\t.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_element_mut":["/// Constructs an exclusive `&mut BitSlice` reference over an element.\n///\n/// The [`BitView`] trait, implemented on all `T` elements, provides a\n/// method [`.view_bits_mut::<O>()`] which delegates to this function and\n/// may be more convenient for you to write.\n///\n/// # Parameters\n///\n/// - `elem`: An exclusive reference to a memory element.\n///\n/// # Returns\n///\n/// An exclusive `&mut BitSlice` over the `elem` element.\n///\n/// Note that the original `elem` reference will be inaccessible for the\n/// duration of the returned slice handle’s lifetime.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut elem = 0u16;\n/// let bits = BitSlice::<Msb0, _>::from_element_mut(&mut elem);\n/// bits.set(15, true);\n/// assert!(bits.get(15).unwrap());\n/// assert_eq!(elem, 1);\n/// ```\n///\n/// [`BitView`]: ../view/trait.BitView.html\n/// [`.view_bits_mut::<O>()`]:\n/// ../view/trait.BitView.html#method.view_bits_mut\n#[inline]\npub fn from_element_mut(elem: &mut T) -> &mut Self{\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(elem, BitIdx::ZERO, T::Mem::BITS as usize)\n\t\t}\n\t\t.to_bitslice_mut()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_slice":["/// Constructs a shared `&BitSlice` reference over a shared element slice.\n///\n/// The [`BitView`] trait, implemented on all `[T]` slices, provides a\n/// method [`.view_bits::<O>()`] that is equivalent to this function and may\n/// be more convenient for you to write.\n///\n/// # Parameters\n///\n/// - `slice`: A shared reference over a sequence of memory elements.\n///\n/// # Returns\n///\n/// If `slice` does not have fewer than [`MAX_ELTS`] elements, this returns\n/// `None`. Otherwise, it returns a shared `&BitSlice` over the `slice`\n/// elements.\n///\n/// # Conditions\n///\n/// The produced `&BitSlice` handle always begins at the zeroth bit.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let slice = &[0u8, 1];\n/// let bits = BitSlice::<Msb0, _>::from_slice(slice).unwrap();\n/// assert!(bits[15]);\n/// ```\n///\n/// An example showing this function failing would require a slice exceeding\n/// `!0usize >> 3` bytes in size, which is infeasible to produce.\n///\n/// [`BitView`]: ../view/trait.BitView.html\n/// [`MAX_ELTS`]: #associatedconstant.MAX_ELTS\n/// [`.view_bits::<O>()`]: ../view/trait.BitView.html#method.view_bits\n#[inline]\npub fn from_slice(slice: &[T]) -> Option<&Self>{\n\t\tlet elts = slice.len();\n\t\t//  Starting at the zeroth bit makes this counter an exclusive cap, not\n\t\t//  an inclusive cap.\n\t\tif elts >= Self::MAX_ELTS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(unsafe { Self::from_slice_unchecked(slice) })\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_slice_mut":["/// Constructs an exclusive `&mut BitSlice` reference over a slice.\n///\n/// The [`BitView`] trait, implemented on all `[T]` slices, provides a\n/// method [`.view_bits_mut::<O>()`] that is equivalent to this function and\n/// may be more convenient for you to write.\n///\n/// # Parameters\n///\n/// - `slice`: An exclusive reference over a sequence of memory elements.\n///\n/// # Returns\n///\n/// An exclusive `&mut BitSlice` over the `slice` elements.\n///\n/// Note that the original `slice` reference will be inaccessible for the\n/// duration of the returned slice handle’s lifetime.\n///\n/// # Panics\n///\n/// This panics if `slice` does not have fewer than [`MAX_ELTS`] elements.\n///\n/// [`MAX_ELTS`]: #associatedconstant.MAX_ELTS\n///\n/// # Conditions\n///\n/// The produced `&mut BitSlice` handle always begins at the zeroth bit of\n/// the zeroth element in `slice`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut slice = [0u8; 2];\n/// let bits = BitSlice::<Lsb0, _>::from_slice_mut(&mut slice).unwrap();\n///\n/// assert!(!bits[0]);\n/// bits.set(0, true);\n/// assert!(bits[0]);\n/// assert_eq!(slice[0], 1);\n/// ```\n///\n/// This example attempts to construct a `&mut BitSlice` handle from a slice\n/// that is too large to index. Either the `vec!` allocation will fail, or\n/// the bit-slice constructor will fail.\n///\n/// ```rust,should_panic\n/// # #[cfg(feature = \"alloc\")] {\n/// use bitvec::prelude::*;\n///\n/// let mut data = vec![0usize; BitSlice::<Local, usize>::MAX_ELTS];\n/// let bits = BitSlice::<Local, _>::from_slice_mut(&mut data[..]).unwrap();\n/// # }\n/// # #[cfg(not(feature = \"alloc\"))] panic!(\"No allocator present\");\n/// ```\n///\n/// [`BitView`]: ../view/trait.BitView.html\n/// [`.view_bits_mut::<O>()`]:\n/// ../view/trait.BitView.html#method.view_bits_mut\n#[inline]\npub fn from_slice_mut(slice: &mut [T]) -> Option<&mut Self>{\n\t\tlet elts = slice.len();\n\t\tif elts >= Self::MAX_ELTS {\n\t\t\treturn None;\n\t\t}\n\t\tSome(unsafe { Self::from_slice_unchecked_mut(slice) })\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_slice_unchecked":["/// Converts a slice reference into a `BitSlice` reference without checking\n/// that its size can be safely used.\n///\n/// # Safety\n///\n/// If the `slice` length is too long, then it will be capped at\n/// [`MAX_BITS`]. You are responsible for ensuring that the input slice is\n/// not unduly truncated.\n///\n/// Prefer [`from_slice`].\n///\n/// [`MAX_BITS`]: #associatedconstant.MAX_BITS\n/// [`from_slice`]: #method.from_slice\n#[inline]\npub unsafe fn from_slice_unchecked(slice: &[T]) -> &Self{\n\t\t//  This branch could be removed by lowering the element ceiling by one,\n\t\t//  but `from_slice` should not be in any tight loops, so it’s fine.\n\t\tlet bits = cmp::min(slice.len() * T::Mem::BITS as usize, Self::MAX_BITS);\n\t\tBitPtr::new_unchecked(slice.as_ptr(), BitIdx::ZERO, bits)\n\t\t\t.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::from_slice_unchecked_mut":["/// Converts a slice reference into a `BitSlice` reference without checking\n/// that its size can be safely used.\n///\n/// # Safety\n///\n/// If the `slice` length is too long, then it will be capped at\n/// [`MAX_BITS`]. You are responsible for ensuring that the input slice is\n/// not unduly truncated.\n///\n/// Prefer [`from_slice_mut`].\n///\n/// [`MAX_BITS`]: #associatedconstant.MAX_BITS\n/// [`from_slice_mut`]: #method.from_slice_mut\n#[inline]\npub unsafe fn from_slice_unchecked_mut(slice: &mut [T]) -> &mut Self{\n\t\tlet bits = cmp::min(slice.len() * T::Mem::BITS as usize, Self::MAX_BITS);\n\t\tBitPtr::new_unchecked(slice.as_ptr(), BitIdx::ZERO, bits)\n\t\t\t.to_bitslice_mut()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::not_all":["/// Tests if *any* bit in the slice is unset (logical `¬∧`).\n///\n/// # Truth Table\n///\n/// ```text\n/// 0 0 => 1\n/// 0 1 => 1\n/// 1 0 => 1\n/// 1 1 => 0\n/// ```\n///\n/// # Parameters\n///\n/// - `&self\n///\n/// # Returns\n///\n/// Whether any bit in the slice domain is unset.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = 0xFDu8.view_bits::<Msb0>();\n/// assert!(!bits[.. 4].not_all());\n/// assert!(bits[4 ..].not_all());\n/// ```\n#[inline]\npub fn not_all(&self) -> bool{\n\t\t!self.all()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::not_any":["/// Tests if *all* bits in the slice are unset (logical `¬∨`).\n///\n/// # Truth Table\n///\n/// ```text\n/// 0 0 => 1\n/// 0 1 => 0\n/// 1 0 => 0\n/// 1 1 => 0\n/// ```\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// Whether all bits in the slice domain are unset.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = 0x40u8.view_bits::<Msb0>();\n/// assert!(!bits[.. 4].not_any());\n/// assert!(bits[4 ..].not_any());\n/// ```\n#[inline]\npub fn not_any(&self) -> bool{\n\t\t!self.any()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::set":["/// Sets the bit value at the given position.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `index`: The bit index to set. It must be in the range `0 ..\n///   self.len()`.\n/// - `value`: The value to be set, `true` for `1` and `false` for `0`.\n///\n/// # Effects\n///\n/// If `index` is valid, then the bit to which it refers is set to `value`.\n///\n/// # Panics\n///\n/// This method panics if `index` is outside the slice domain.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// assert!(!bits.get(7).unwrap());\n/// bits.set(7, true);\n/// assert!(bits.get(7).unwrap());\n/// assert_eq!(data, 1);\n/// ```\n///\n/// This example panics when it attempts to set a bit that is out of bounds.\n///\n/// ```rust,should_panic\n/// use bitvec::prelude::*;\n///\n/// let bits = BitSlice::<Local, usize>::empty_mut();\n/// bits.set(0, false);\n/// ```\n#[inline]\npub fn set(&mut self, index: usize, value: bool){\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index out of range: {} >= {}\", index, len);\n\t\tunsafe {\n\t\t\tself.set_unchecked(index, value);\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::set_all":["/// Sets all bits in the slice to a value.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `value`: The bit value to which all bits in the slice will be set.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut src = 0u8;\n/// let bits = src.view_bits_mut::<Msb0>();\n/// bits[2 .. 6].set_all(true);\n/// assert_eq!(bits.as_slice(), &[0b0011_1100]);\n/// bits[3 .. 5].set_all(false);\n/// assert_eq!(bits.as_slice(), &[0b0010_0100]);\n/// bits[.. 1].set_all(true);\n/// assert_eq!(bits.as_slice(), &[0b1010_0100]);\n/// ```\n#[inline]\npub fn set_all(&mut self, value: bool){\n\t\t//  Grab the function pointers used to commit bit-masks into memory.\n\t\tlet setter = <<T::Alias as BitStore>::Access>::get_writers(value);\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => {\n\t\t\t\t//  Step three: write the bitmask through the accessor.\n\t\t\t\tsetter(\n\t\t\t\t\t//  Step one: attach an `::Access` marker to the reference\n\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t//  Step two: insert an `::Alias` marker *into the bitmask*\n\t\t\t\t\t//  because typechecking is “fun”\n\t\t\t\t\tO::mask(head, tail).pipe(dvl::alias_mask::<T>),\n\t\t\t\t);\n\t\t\t},\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\tsetter(\n\t\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t\tO::mask(head, None).pipe(dvl::alias_mask::<T>),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\t//  loop assignment is `memset`’s problem, not ours\n\t\t\t\tunsafe {\n\t\t\t\t\tptr::write_bytes(\n\t\t\t\t\t\tbody.as_mut_ptr(),\n\t\t\t\t\t\t[0, !0][value as usize],\n\t\t\t\t\t\tbody.len(),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\tsetter(\n\t\t\t\t\t\tdvl::accessor(elem),\n\t\t\t\t\t\tO::mask(None, tail).pipe(dvl::alias_mask::<T>),\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::set_unchecked":["/// Sets a bit at an index, without checking boundary conditions.\n///\n/// This is generally not recommended; use with caution! For a safe\n/// alternative, see [`set`].\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `index`: The bit index to set. It must be in the range `0 ..\n///   self.len()`. It will not be checked.\n///\n/// # Effects\n///\n/// The bit at `index` is set to `value`.\n///\n/// # Safety\n///\n/// This method is **not** safe. It performs raw pointer arithmetic to seek\n/// from the start of the slice to the requested index, and set the bit\n/// there. It does not inspect the length of `self`, and it is free to\n/// perform out-of-bounds memory *write* access.\n///\n/// Use this method **only** when you have already performed the bounds\n/// check, and can guarantee that the call occurs with a safely in-bounds\n/// index.\n///\n/// # Examples\n///\n/// This example uses a bit slice of length 2, and demonstrates\n/// out-of-bounds access to the last bit in the element.\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = &mut data.view_bits_mut::<Msb0>()[2 .. 4];\n///\n/// assert_eq!(bits.len(), 2);\n/// unsafe {\n///   bits.set_unchecked(5, true);\n/// }\n/// assert_eq!(data, 1);\n/// ```\n///\n/// [`set`]: #method.set\n#[inline]\npub unsafe fn set_unchecked(&mut self, index: usize, value: bool){\n\t\tself.bitptr().write::<O>(index, value);\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::some":["/// Tests whether the slice has some, but not all, bits set and some, but\n/// not all, bits unset.\n///\n/// This is `false` if either [`.all`] or [`.not_any`] are `true`.\n///\n/// # Truth Table\n///\n/// ```text\n/// 0 0 => 0\n/// 0 1 => 1\n/// 1 0 => 1\n/// 1 1 => 0\n/// ```\n///\n/// # Parameters\n///\n/// - `&self`\n///\n/// # Returns\n///\n/// Whether the slice domain has mixed content. The empty slice returns\n/// `false`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b111_000_10u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// assert!(!bits[.. 3].some());\n/// assert!(!bits[3 .. 6].some());\n/// assert!(bits.some());\n/// ```\n///\n/// [`.all`]: #method.all\n/// [`.not_any`]: #method.not_any\n#[inline]\npub fn some(&self) -> bool{\n\t\tself.any() && self.not_all()\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::split_at_aliased_mut":["/// Splits a mutable slice at some mid-point.\n///\n/// This method has the same behavior as [`split_at_mut`], except that it\n/// does not apply an aliasing marker to the partitioned subslices.\n///\n/// # Safety\n///\n/// Because this method is defined only on `BitSlice`s whose `T` type is\n/// alias-safe, the subslices do not need to be additionally marked.\n///\n/// [`split_at_mut`]: #method.split_at_mut\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn split_at_aliased_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut Self, &mut Self){\n\t\tlet (head, tail) = self.split_at_mut(mid);\n\t\tunsafe { (Self::unalias_mut(head), Self::unalias_mut(tail)) }\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::split_at_aliased_unchecked_mut":["/// Splits a mutable slice at some mid-point, without checking boundary\n/// conditions.\n///\n/// This method has the same behavior as [`split_at_unchecked_mut`], except\n/// that it does not apply an aliasing marker to the partitioned subslices.\n///\n/// # Safety\n///\n/// See [`split_at_unchecked_mut`] for safety requirements.\n///\n/// Because this method is defined only on `BitSlice`s whose `T` type is\n/// alias-safe, the subslices do not need to be additionally marked.\n///\n/// [`split_at_unchecked_mut`]: #method.split_at_unchecked_mut\n#[inline]\npub unsafe fn split_at_aliased_unchecked_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut Self, &mut Self){\n\t\t//  Split the slice at the requested midpoint, adding an alias layer\n\t\tlet (head, tail) = self.split_at_unchecked_mut(mid);\n\t\t//  Remove the new alias layer.\n\t\t(Self::unalias_mut(head), Self::unalias_mut(tail))\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::split_at_unchecked":["/// Splits a slice at some mid-point, without checking boundary conditions.\n///\n/// This is generally not recommended; use with caution! For a safe\n/// alternative, see [`split_at`].\n///\n/// # Parameters\n///\n/// - `&self`\n/// - `mid`: The index at which to split the slice. This must be in the\n///   range `0 .. self.len()`.\n///\n/// # Returns\n///\n/// - `.0`: `&self[.. mid]`\n/// - `.1`: `&self[mid ..]`\n///\n/// # Safety\n///\n/// This function is **not** safe. It performs raw pointer arithmetic to\n/// construct two new references. If `mid` is out of bounds, then the first\n/// slice will be too large, and the second will be *catastrophically*\n/// incorrect. As both are references to invalid memory, they are undefined\n/// to *construct*, and may not ever be used.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0x0180u16;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// let (one, two) = unsafe { bits.split_at_unchecked(8) };\n/// assert!(one[7]);\n/// assert!(two[0]);\n/// ```\n///\n/// [`split_at`]: #method.split_at\n#[inline]\npub unsafe fn split_at_unchecked(&self, mid: usize) -> (&Self, &Self){\n\t\tmatch mid {\n\t\t\t0 => (Self::empty(), self),\n\t\t\tn if n == self.len() => (self, Self::empty()),\n\t\t\t_ => (self.get_unchecked(.. mid), self.get_unchecked(mid ..)),\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::split_at_unchecked_mut":["/// Splits a mutable slice at some mid-point, without checking boundary\n/// conditions.\n///\n/// This is generally not recommended; use with caution! For a safe\n/// alternative, see [`split_at_mut`].\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `mid`: The index at which to split the slice. This must be in the\n///   range `0 .. self.len()`.\n///\n/// # Returns\n///\n/// - `.0`: `&mut self[.. mid]`\n/// - `.1`: `&mut self[mid ..]`\n///\n/// # Safety\n///\n/// This function is **not** safe. It performs raw pointer arithmetic to\n/// construct two new references. If `mid` is out of bounds, then the first\n/// slice will be too large, and the second will be *catastrophically*\n/// incorrect. As both are references to invalid memory, they are undefined\n/// to *construct*, and may not ever be used.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u16;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// let (one, two) = unsafe { bits.split_at_unchecked_mut(8) };\n/// one.set(7, true);\n/// two.set(0, true);\n/// assert_eq!(data, 0x0180u16);\n/// ```\n///\n/// [`split_at_mut`]: #method.split_at_mut\n#[inline]\n#[allow(clippy::type_complexity)]\npub unsafe fn split_at_unchecked_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut BitSlice<O, T::Alias>, &mut BitSlice<O, T::Alias>){\n\t\tlet bp = self.alias_mut().bitptr();\n\t\tmatch mid {\n\t\t\t0 => (BitSlice::empty_mut(), bp.to_bitslice_mut()),\n\t\t\tn if n == self.len() => {\n\t\t\t\t(bp.to_bitslice_mut(), BitSlice::empty_mut())\n\t\t\t},\n\t\t\t_ => (\n\t\t\t\tbp.to_bitslice_mut().get_unchecked_mut(.. mid),\n\t\t\t\tbp.to_bitslice_mut().get_unchecked_mut(mid ..),\n\t\t\t),\n\t\t}\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::swap_unchecked":["/// Swaps the bits at two indices without checking boundary conditions.\n///\n/// This is generally not recommended; use with caution! For a safe\n/// alternative, see [`swap`].\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `a`: One index to swap.\n/// - `b`: The other index to swap.\n///\n/// # Effects\n///\n/// The bit at index `a` is written into index `b`, and the bit at index `b`\n/// is written into `a`.\n///\n/// # Safety\n///\n/// Both `a` and `b` must be less than `self.len()`. Indices greater than\n/// the length will cause out-of-bounds memory access, which can lead to\n/// memory unsafety and a program crash.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 8u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// unsafe { bits.swap_unchecked(0, 4); }\n///\n/// assert_eq!(data, 128);\n/// ```\n///\n/// [`swap`]: #method.swap\n#[inline]\npub unsafe fn swap_unchecked(&mut self, a: usize, b: usize){\n\t\tlet bit_a = *self.get_unchecked(a);\n\t\tlet bit_b = *self.get_unchecked(b);\n\t\tself.set_unchecked(a, bit_b);\n\t\tself.set_unchecked(b, bit_a);\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::BitSlice::<O, T>::unalias_mut":["/// Removes the aliasing marker from a mutable slice handle.\n///\n/// # Safety\n///\n/// This must only be used when the slice is either known to be unaliased,\n/// or this call is combined with an operation that adds an aliasing marker\n/// and the total number of aliasing markers must remain unchanged.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub(crate) unsafe fn unalias_mut(\n\t\tthis: &mut BitSlice<O, T::Alias>,\n\t) -> &mut Self{\n\t\t&mut *(this as *mut BitSlice<O, T::Alias> as *mut Self)\n\t}","Real(LocalPath(\"src/slice.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::align_to":["/// Transmute the bitslice to a bitslice of another type, ensuring alignment\n/// of the types is maintained.\n///\n/// This method splits the bitslice into three distinct bitslices: prefix,\n/// correctly aligned middle bitslice of a new type, and the suffix\n/// bitslice. The method may make the middle bitslice the greatest\n/// length possible for a given type and input bitslice, but only your\n/// algorithm's performance should depend on that, not its correctness. It\n/// is permissible for all of the input data to be returned as the prefix or\n/// suffix bitslice.\n///\n/// # Original\n///\n/// [`slice::align_to`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to)\n///\n/// # API Differences\n///\n/// Type `U` is **required** to have the same type family as type `T`.\n/// Whatever `T` is of the fundamental integers, atomics, or `Cell`\n/// wrappers, `U` must be a different width in the same family. Changing the\n/// type family with this method is **unsound** and strictly forbidden.\n/// Unfortunately, it cannot be guaranteed by this function, so you are\n/// required to abide by this limitation.\n///\n/// # Safety\n///\n/// This method is essentially a `transmute` with respect to the elements in\n/// the returned middle bitslice, so all the usual caveats pertaining to\n/// `transmute::<T, U>` also apply here.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// unsafe {\n///   let bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n///   let bits = bytes.view_bits::<Local>();\n///   let (prefix, shorts, suffix) = bits.align_to::<u16>();\n///   match prefix.len() {\n///     0 => {\n///       assert_eq!(shorts, bits[.. 48]);\n///       assert_eq!(suffix, bits[48 ..]);\n///     },\n///     8 => {\n///       assert_eq!(prefix, bits[.. 8]);\n///       assert_eq!(shorts, bits[8 ..]);\n///     },\n///     _ => unreachable!(\"This case will not occur\")\n///   }\n/// }\n/// ```\n#[inline]\npub unsafe fn align_to<U>(&self) -> (&Self, &BitSlice<O, U>, &Self)\n\twhere U: BitStore{\n\t\tlet bitptr = self.bitptr();\n\t\tlet bp_len = bitptr.len();\n\t\tlet (l, c, r) = bitptr.as_aliased_slice().align_to::<U::Alias>();\n\t\tlet l_start = bitptr.head().value() as usize;\n\t\tlet mut l = BitSlice::<O, T::Alias>::from_aliased_slice_unchecked(l);\n\t\tif l.len() > l_start {\n\t\t\tl = l.get_unchecked(l_start ..);\n\t\t}\n\t\tlet mut c = BitSlice::<O, U::Alias>::from_aliased_slice_unchecked(c);\n\t\tlet c_len = cmp::min(c.len(), bp_len - l.len());\n\t\tc = c.get_unchecked(.. c_len);\n\t\tlet mut r = BitSlice::<O, T::Alias>::from_aliased_slice_unchecked(r);\n\t\tlet r_len = bp_len - l.len() - c.len();\n\t\tif r.len() > r_len {\n\t\t\tr = r.get_unchecked(.. r_len);\n\t\t}\n\t\t(\n\t\t\tl.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<T>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t\tc.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<U>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t\tr.bitptr()\n\t\t\t\t.pipe(dvl::remove_bitptr_alias::<T>)\n\t\t\t\t.to_bitslice_ref(),\n\t\t)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::align_to_mut":["/// Transmute the bitslice to a bitslice of another type, ensuring alignment\n/// of the types is maintained.\n///\n/// This method splits the bitslice into three distinct bitslices: prefix,\n/// correctly aligned middle bitslice of a new type, and the suffix\n/// bitslice. The method may make the middle bitslice the greatest\n/// length possible for a given type and input bitslice, but only your\n/// algorithm's performance should depend on that, not its correctness. It\n/// is permissible for all of the input data to be returned as the prefix or\n/// suffix bitslice.\n///\n/// # Original\n///\n/// [`slice::align_to`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to)\n///\n/// # API Differences\n///\n/// Type `U` is **required** to have the same type family as type `T`.\n/// Whatever `T` is of the fundamental integers, atomics, or `Cell`\n/// wrappers, `U` must be a different width in the same family. Changing the\n/// type family with this method is **unsound** and strictly forbidden.\n/// Unfortunately, it cannot be guaranteed by this function, so you are\n/// required to abide by this limitation.\n///\n/// # Safety\n///\n/// This method is essentially a `transmute` with respect to the elements in\n/// the returned middle bitslice, so all the usual caveats pertaining to\n/// `transmute::<T, U>` also apply here.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// unsafe {\n///   let mut bytes: [u8; 7] = [1, 2, 3, 4, 5, 6, 7];\n///   let bits = bytes.view_bits_mut::<Local>();\n///   let (prefix, shorts, suffix) = bits.align_to_mut::<u16>();\n///   //  same access and behavior as in `align_to`\n/// }\n/// ```\n#[inline]\npub unsafe fn align_to_mut<U>(\n\t\t&mut self,\n\t) -> (&mut Self, &mut BitSlice<O, U>, &mut Self)\n\twhere U: BitStore{\n\t\tlet (l, c, r) = self.align_to::<U>();\n\t\t(\n\t\t\tl.bitptr().to_bitslice_mut(),\n\t\t\tc.bitptr().to_bitslice_mut(),\n\t\t\tr.bitptr().to_bitslice_mut(),\n\t\t)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::as_mut_ptr":["/// Returns an unsafe mutable bit-slice pointer to the region.\n///\n/// The caller must ensure that the slice outlives the pointer this function\n/// returns, or else it will end up pointing to garbage.\n///\n/// Modifying the container (such as `BitVec`) referenced by this slice may\n/// cause its buffer to be reällocated, which would also make any pointers\n/// to it invalid.\n///\n/// # Original\n///\n/// [`slice::as_mut_ptr`](https://doc.rust-lang.org/std/primitive.slice.html#method.as_mut_ptr)\n///\n/// # API Differences\n///\n/// This returns `*mut BitSlice`, which is the equivalont of `*mut [T]`\n/// instead of `*mut T`. The pointer encoding used requires more than one\n/// CPU word of space to address a single bit, so there is no advantage to\n/// removing the length information from the encoded pointer value.\n///\n/// # Notes\n///\n/// You **cannot** use any of the methods in the `pointer` fundamental type\n/// or the `core::ptr` module on the `*_ BitSlice` type. This pointer\n/// retains the `bitvec`-specific value encoding, and is incomprehensible by\n/// the Rust standard library.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u16;\n/// let bits = data.view_bits_mut::<Lsb0>();\n/// let bits_ptr = bits.as_mut_ptr();\n///\n/// for i in 0 .. bits.len() {\n///   unsafe { &mut *bits_ptr }.set(i, i % 2 == 0);\n/// }\n/// assert_eq!(data, 0b0101_0101_0101_0101);\n/// ```\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_ptr(&mut self) -> *mut Self{\n\t\tself as *mut Self\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::as_ptr":["/// Returns a raw bit-slice pointer to the region.\n///\n/// The caller must ensure that the slice outlives the pointer this function\n/// returns, or else it will end up pointing to garbage.\n///\n/// The caller must also ensure that the memory the pointer\n/// (non-transitively) points to is only written to if `T` allows shared\n/// mutation, using this pointer or any pointer derived from it. If you need\n/// to mutate the contents of the slice, use [`as_mut_ptr`].\n///\n/// Modifying the container (such as `BitVec`) referenced by this slice may\n/// cause its buffer to be reällocated, which would also make any pointers\n/// to it invalid.\n///\n/// # Original\n///\n/// [`slice::as_ptr`](https://doc.rust-lang.org/std/primitive.slice.html#method.as_ptr)\n///\n/// # API Differences\n///\n/// This returns `*const BitSlice`, which is the equivalent of `*const [T]`\n/// instead of `*const T`. The pointer encoding used requires more than one\n/// CPU word of space to address a single bit, so there is no advantage to\n/// removing the length information from the encoded pointer value.\n///\n/// # Notes\n///\n/// You **cannot** use any of the methods in the `pointer` fundamental type\n/// or the `core::ptr` module on the `*_ BitSlice` type. This pointer\n/// retains the `bitvec`-specific value encoding, and is incomprehensible by\n/// the Rust standard library.\n///\n/// The only thing you can do with this pointer is dereference it.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 2u16;\n/// let bits = data.view_bits::<Lsb0>();\n/// let bits_ptr = bits.as_ptr();\n///\n/// for i in 0 .. bits.len() {\n///   assert_eq!(bits[i], unsafe {\n///     (&*bits_ptr)[i]\n///   });\n/// }\n/// ```\n///\n/// [`as_mut_ptr`]: #method.as_mut_ptr\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_ptr(&self) -> *const Self{\n\t\tself as *const Self\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::chunks":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the beginning of the slice.\n///\n/// The chunks are slices and do not overlap. If `chunk_size` does not\n/// divide the length of the slice, then the last chunk will not have length\n/// `chunk_size`.\n///\n/// See [`chunks_exact`] for a variant of this iterator that returns chunks\n/// of always exactly `chunk_size` bits, and [`rchunks`] for the same\n/// iterator but starting at the end of the slice.\n///\n/// # Original\n///\n/// [`slice::chunks`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// let mut iter = bits.chunks(3);\n/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n/// assert_eq!(iter.next().unwrap(), &bits[3 .. 6]);\n/// assert_eq!(iter.next().unwrap(), &bits[6 ..]);\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// [`chunks_exact`]: #method.chunks_exact\n/// [`rchunks`]: #method.rchunks\n#[inline]\npub fn chunks(&self, chunk_size: usize) -> Chunks<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunks::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the beginning of the slice.\n///\n/// The chunks are slices and do not overlap. If `chunk_size` does not\n/// divide the length of the slice, then the last up to `chunk_size-1` bits\n/// will be omitted and can be retrieved from the `remainder` function of\n/// the iterator.\n///\n/// Due to each chunk having exactly `chunk_size` bits, the compiler may\n/// optimize the resulting code better than in the case of [`chunks`].\n///\n/// See [`chunks`] for a variant of this iterator that also returns the\n/// remainder as a smaller chunk, and [`rchunks_exact`] for the same\n/// iterator but starting at the end of the slice.\n///\n/// # Original\n///\n/// [`slice::chunks_exact`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// let mut iter = bits.chunks_exact(3);\n/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n/// assert_eq!(iter.next().unwrap(), &bits[3 .. 6]);\n/// assert!(iter.next().is_none());\n/// assert_eq!(iter.remainder(), &bits[6 ..]);\n/// ```\n///\n/// [`chunks`]: #method.chunks\n/// [`rchunks_exact`]: #method.rchunks_exact\n#[inline]\npub fn chunks_exact(&self, chunk_size: usize) -> ChunksExact<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksExact::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact_mut":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the beginning of the slice.\n///\n/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n/// not divide the beginning length of the slice, then the last up to\n/// `chunk_size-1` bits will be omitted and can be retrieved from the\n/// `into_remainder` function of the iterator.\n///\n/// Due to each chunk having exactly `chunk_size` bits, the compiler may\n/// optimize the resulting code better than in the case of [`chunks_mut`].\n///\n/// See [`chunks_mut`] for a variant of this iterator that also returns the\n/// remainder as a smaller chunk, and [`rchunks_exact_mut`] for the same\n/// iterator but starting at the end of the slice.\n///\n/// # Original\n///\n/// [`slice::chunks_exact_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_exact_mut)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// for (idx, chunk) in bits.chunks_exact_mut(3).enumerate() {\n///   chunk.set(idx, true);\n/// }\n/// assert_eq!(data, 0b00_010_001);\n/// ```\n///\n/// [`chunks_mut`]: #method.chunks_mut\n/// [`rchunks_exact_mut`]: #method.rchunks_exact_mut\n#[inline]\npub fn chunks_exact_mut(\n\t\t&mut self,\n\t\tchunk_size: usize,\n\t) -> ChunksExactMut<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksExactMut::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::chunks_mut":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the beginning of the slice.\n///\n/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n/// not divide the length of the slice, then the last chunk will not have\n/// length `chunk_size`.\n///\n/// See [`chunks_exact_mut`] for a variant of this iterator that returns\n/// chunks of always exactly `chunk_size` bits, and [`rchunks_mut`] for the\n/// same iterator but starting at the end of the slice.\n///\n/// # Original\n///\n/// [`slice::chunks_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks_mut)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// for (idx, chunk) in bits.chunks_mut(3).enumerate() {\n///   chunk.set(2 - idx, true);\n/// }\n/// assert_eq!(data, 0b01_010_100);\n/// ```\n///\n/// [`chunks_exact_mut`]: #method.chunks_exact_mut\n/// [`rchunks_mut`]: #method.rchunks_mut\n#[inline]\npub fn chunks_mut(&mut self, chunk_size: usize) -> ChunksMut<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tChunksMut::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_bitslice":["/// Copies the bits from `src` into `self`.\n///\n/// The length of `src` must be the same as `self`.\n///\n/// # Original\n///\n/// [`slice::clone_from_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.clone_from_slice)\n///\n/// # API Differences\n///\n/// This method is renamed, as it takes a bit slice rather than an element\n/// slice.\n///\n/// # Panics\n///\n/// This function will panic if the two slices have different lengths.\n///\n/// # Examples\n///\n/// Cloning two bits from a slice into another:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// let src = 0x0Fu16.view_bits::<Lsb0>();\n/// bits[.. 2].clone_from_bitslice(&src[2 .. 4]);\n/// assert_eq!(data, 0xC0);\n/// ```\n///\n/// Rust enforces that there can only be one mutable reference with no\n/// immutable references to a particular piece of data in a particular\n/// scope. Because of this, attempting to use `clone_from_bitslice` on a\n/// single slice will result in a compile failure:\n///\n/// ```rust,compile_fail\n/// use bitvec::prelude::*;\n///\n/// let mut data = 3u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits[.. 2].clone_from_bitslice(&bits[6 ..]);\n/// ```\n///\n/// To work around this, we can use [`split_at_mut`] to create two distinct\n/// sub-slices from a slice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 3u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// let (head, tail) = bits.split_at_mut(4);\n/// head.clone_from_bitslice(tail);\n/// assert_eq!(data, 0x33);\n/// ```\n///\n/// [`split_at_mut`]: #method.split_at_mut\n#[inline]\npub fn clone_from_bitslice<O2, T2>(&mut self, src: &BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tlet len = self.len();\n\t\tassert_eq!(len, src.len(), \"Cloning from slice requires equal lengths\",);\n\t\tfor idx in 0 .. len {\n\t\t\tunsafe {\n\t\t\t\tself.set_unchecked(idx, *src.get_unchecked(idx));\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_slice":["#[inline]\n#[doc(hidden)]\n#[deprecated(note = \"Use `.clone_from_bitslice` to copy between bitslices\")]\n#[cfg(not(tarpaulin_include))]\npub fn clone_from_slice<O2, T2>(&mut self, src: &BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tself.clone_from_bitslice(src)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::contains":["/// Returns `true` if the slice contains a subslice that matches the given\n/// span.\n///\n/// # Original\n///\n/// [`slice::contains`](https://doc.rust-lang.org/std/primitive.slice.html#method.contains)\n///\n/// # API Differences\n///\n/// This searches for a matching subslice (allowing different type\n/// parameters) rather than for a specific bit. Searching for a contained\n/// element with a given value is not as useful on a collection of `bool`.\n///\n/// Furthermore, `BitSlice` defines [`any`] and [`not_all`], which are\n/// optimized searchers for any `true` or `false` bit, respectively, in a\n/// sequence.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b0101_1010u8;\n/// let bits_msb = data.view_bits::<Msb0>();\n/// let bits_lsb = data.view_bits::<Lsb0>();\n/// assert!(bits_msb.contains(&bits_lsb[1 .. 5]));\n/// ```\n///\n/// This example uses a palindrome pattern to demonstrate that the slice\n/// being searched for does not need to have the same type parameters as the\n/// slice being searched.\n///\n/// [`any`]: #method.any\n/// [`not_all`]: #method.not_all\n#[inline]\npub fn contains<O2, T2>(&self, x: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tlet len = x.len();\n\t\tif len > self.len() {\n\t\t\treturn false;\n\t\t};\n\t\tself.windows(len).any(|s| s == x)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_bitslice":["/// Copies all bits from `src` into `self`.\n///\n/// The length of `src` must be the same as `self`.\n///\n/// # Original\n///\n/// [`slice::copy_from_slice`](https://doc.rust-lang.org/std/primitive.std.html#method.copy_from_slice)\n///\n/// # API Differences\n///\n/// This method is renamed, as it takes a bit slice rather than an element\n/// slice.\n///\n/// This is unable to guarantee a strictly faster copy behavior than\n/// [`clone_from_bitslice`]. In the future, the implementation *may*\n/// specialize, as the language allows.\n///\n/// # Panics\n///\n/// This function will panic if the two slices have different lengths.\n///\n/// # Examples\n///\n/// Copying two bits from a slice into another:\n///\n/// [`clone_from_bitslice`]: #method.clone_from_bitslice\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn copy_from_bitslice(&mut self, src: &Self){\n\t\tself.clone_from_bitslice(src);\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_slice":["#[inline]\n#[doc(hidden)]\n#[deprecated(note = \"Use `.copy_from_bitslice` to copy between bitslices\")]\n#[cfg(not(tarpaulin_include))]\npub fn copy_from_slice(&mut self, src: &Self){\n\t\tself.copy_from_bitslice(src)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::copy_within":["/// Copies bits from one part of the slice to another part of itself.\n///\n/// `src` is the range within `self` to copy from. `dest` is the starting\n/// index of the range within `self` to copy to, which will have the same\n/// length as `src`. The two ranges may overlap. The ends of the two ranges\n/// must be less than or equal to `self.len()`.\n///\n/// # Original\n///\n/// [`slice::copy_within`](https://doc.rust-lang.org/std/primitive.slice.html#method.copy_within)\n///\n/// # Panics\n///\n/// This function will panic if either range exceeds the end of the slice,\n/// or if the end of `src` is before the start.\n///\n/// # Examples\n///\n/// Copying four bytes within a slice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0x07u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// bits.copy_within(5 .., 0);\n///\n/// assert_eq!(data, 0xE7);\n/// ```\n#[inline]\npub fn copy_within<R>(&mut self, src: R, dest: usize)\n\twhere R: RangeBounds<usize>{\n\t\tlet len = self.len();\n\t\tlet src = dvl::normalize_range(src, len);\n\t\t//  Check that the source range is within bounds,\n\t\tdvl::assert_range(src.clone(), len);\n\t\t//  And that the destination range is within bounds.\n\t\tdvl::assert_range(dest .. dest + (src.end - src.start), len);\n\t\tunsafe {\n\t\t\tself.copy_within_unchecked(src, dest);\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::ends_with":["/// Returns `true` if `needle` is a suffix of the slice.\n///\n/// # Original\n///\n/// [`slice::ends_with`](https://doc.rust-lang.org/std/primitive.slice.html#method.ends_with)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b0100_1011u8;\n/// let haystack = data.view_bits::<Lsb0>();\n/// let needle = &data.view_bits::<Msb0>()[3 .. 6];\n/// assert!(haystack.ends_with(&needle[1 ..]));\n/// assert!(haystack.ends_with(needle));\n/// assert!(!haystack.ends_with(&haystack[2 .. 4]));\n/// ```\n///\n/// Always returns `true` if `needle` is an empty slice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let empty = BitSlice::<Local, usize>::empty();\n/// assert!(0u8.view_bits::<Local>().ends_with(empty));\n/// assert!(empty.ends_with(empty));\n/// ```\n#[inline]\npub fn ends_with<O2, T2>(&self, needle: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tlet nlen = needle.len();\n\t\tlet len = self.len();\n\t\tlen >= nlen && needle == unsafe { self.get_unchecked(len - nlen ..) }\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::first":["/// Returns the first bit of the slice, or `None` if it is empty.\n///\n/// # Original\n///\n/// [`slice::first`](https://doc.rust-lang.org/std/primitive.slice.html#method.first)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 1u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// assert_eq!(Some(&true), bits.first());\n///\n/// let empty = BitSlice::<Local, usize>::empty();\n/// assert_eq!(None, empty.first());\n/// ```\n#[inline]\npub fn first(&self) -> Option<&bool>{\n\t\tself.get(0)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::first_mut":["/// Returns a mutable pointer to the first bit of the slice, or `None` if it\n/// is empty.\n///\n/// # Original\n///\n/// [`slice::first_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.first_mut)\n///\n/// # API Differences\n///\n/// This crate cannot manifest `&mut bool` references, and must use the\n/// `BitMut` proxy type where `&mut bool` exists in the standard library\n/// API. The proxy value must be bound as `mut` in order to write through\n/// it.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// if let Some(mut first) = bits.first_mut() {\n///   *first = true;\n/// }\n/// assert_eq!(data, 1);\n/// ```\n#[inline]\npub fn first_mut(&mut self) -> Option<BitMut<O, T>>{\n\t\tself.get_mut(0)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::get":["/// Returns a reference to an element or subslice depending on the type of\n/// index.\n///\n/// - If given a position, returns a reference to the element at that\n///   position or `None` if out of bounds.\n/// - If given a range, returns the subslice corresponding to that range, or\n///   `None` if out of bounds.\n///\n/// # Original\n///\n/// [`slice::get`](https://doc.rust-lang.org/std/primitive.slice.html#method.get)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 2u8;\n/// let bits = data.view_bits::<Lsb0>();\n///\n/// assert_eq!(Some(&true), bits.get(1));\n/// assert_eq!(Some(&bits[1 .. 3]), bits.get(1 .. 3));\n/// assert_eq!(None, bits.get(9));\n/// assert_eq!(None, bits.get(8 .. 10));\n/// ```\n#[inline]\npub fn get<'a, I>(&'a self, index: I) -> Option<I::Immut>\n\twhere I: BitSliceIndex<'a, O, T>{\n\t\tindex.get(self)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::get_mut":["/// Returns a mutable reference to an element or subslice depending on the\n/// type of index (see [`get`]) or `None` if the index is out of bounds.\n///\n/// # Original\n///\n/// [`slice::get_mut`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get_mut)\n///\n/// # API Differences\n///\n/// When `I` is `usize`, this returns `BitMut` instead of `&mut bool`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u16;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// assert!(!bits.get(1).unwrap());\n/// *bits.get_mut(1).unwrap() = true;\n/// assert!(bits.get(1).unwrap());\n/// ```\n///\n/// [`get`]: #method.get\n#[inline]\npub fn get_mut<'a, I>(&'a mut self, index: I) -> Option<I::Mut>\n\twhere I: BitSliceIndex<'a, O, T>{\n\t\tindex.get_mut(self)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked":["/// Returns a reference to an element or subslice, without doing bounds\n/// checking.\n///\n/// This is generally not recommended; use with caution!\n///\n/// Unlike the original slice function, calling this with an out-of-bounds\n/// index is not *technically* compile-time [undefined behavior], as the\n/// references produced do not actually describe local memory. However, the\n/// use of an out-of-bounds index will eventually cause an out-of-bounds\n/// memory read, which is a runtime safety violation. For a safe alternative\n/// see [`get`].\n///\n/// # Original\n///\n/// [`slice::get_unchecked`](https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 2u16;\n/// let bits = data.view_bits::<Lsb0>();\n///\n/// unsafe{\n///   assert_eq!(bits.get_unchecked(1), &true);\n/// }\n/// ```\n///\n/// [`get`]: #method.get\n/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\n#[allow(clippy::missing_safety_doc)]\npub unsafe fn get_unchecked<'a, I>(&'a self, index: I) -> I::Immut\n\twhere I: BitSliceIndex<'a, O, T>{\n\t\tindex.get_unchecked(self)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked_mut":["/// Returns a mutable reference to the output at this location, without\n/// doing bounds checking.\n///\n/// This is generally not recommended; use with caution!\n///\n/// Unlike the original slice function, calling this with an out-of-bounds\n/// index is not *technically* compile-time [undefined behavior], as the\n/// references produced do not actually describe local memory. However, the\n/// use of an out-of-bounds index will eventually cause an out-of-bounds\n/// memory write, which is a runtime safety violation. For a safe\n/// alternative see [`get_mut`].\n///\n/// # Original\n///\n/// [`slice::get_unchecked_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked_mut)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u16;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// unsafe {\n///   let mut bit = bits.get_unchecked_mut(1);\n///   *bit = true;\n/// }\n/// assert_eq!(data, 2);\n/// ```\n///\n/// [`get_mut`]: #method.get_mut\n/// [undefined behavior]: ../../reference/behavior-considered-undefined.html\n#[inline]\n#[allow(clippy::missing_safety_doc)]\npub unsafe fn get_unchecked_mut<'a, I>(&'a mut self, index: I) -> I::Mut\n\twhere I: BitSliceIndex<'a, O, T>{\n\t\tindex.get_unchecked_mut(self)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::is_empty":["/// Returns `true` if the slice has a length of 0.\n///\n/// # Original\n///\n/// [`slice::is_empty`](https://doc.rust-lang.org/std/primitive.slice.html#method.is_empty)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// assert!(BitSlice::<Local, u8>::empty().is_empty());\n/// assert!(!(0u32.view_bits::<Local>()).is_empty());\n/// ```\n#[inline]\npub fn is_empty(&self) -> bool{\n\t\t/* TODO(myrrlyn): Investigate coercing all empty slices to `empty()`\n\n\t\tThe empty slice pointer represents its entire `.len` field as zero,\n\t\twhich removes a shift operation in the pointer decoding. `BitSlice` only\n\t\tmonotonically decreases, so when it becomes empty, writing `0` to `.len`\n\t\tmay be more advantageous than preserving the `head` component.\n\t\t*/\n\t\tself.bitptr().len() == 0\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::iter":["/// Returns an iterator over the slice.\n///\n/// # Original\n///\n/// [`slice::iter`](https://doc.rust-lang.org/std/primitive.slice.html#method.iter)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 130u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// let mut iterator = bits.iter();\n///\n/// assert_eq!(iterator.next(), Some(&false));\n/// assert_eq!(iterator.next(), Some(&true));\n/// assert_eq!(iterator.nth(5), Some(&true));\n/// assert_eq!(iterator.next(), None);\n/// ```\n#[inline]\npub fn iter(&self) -> Iter<O, T>{\n\t\tself.into_iter()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::iter_mut":["/// Returns an iterator that allows modifying each bit.\n///\n/// # Original\n///\n/// [`slice::iter_mut`](https://doc.rust-lang.org/std/primitive.slice.html#Method.iter_mut)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// for (idx, mut elem) in bits.iter_mut().enumerate() {\n///   *elem = idx % 3 == 0;\n/// }\n/// assert_eq!(data, 0b100_100_10);\n/// ```\n#[inline]\npub fn iter_mut(&mut self) -> IterMut<O, T>{\n\t\tself.into_iter()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::last":["/// Returns the last bit of the slice, or `None` if it is empty.\n///\n/// # Original\n///\n/// [`slice::last`](https://doc.rust-lang.org/std/primitive.slice.html#method.last)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 1u8;\n/// let bits = data.view_bits::<Msb0>();\n/// assert_eq!(Some(&true), bits.last());\n///\n/// let empty = BitSlice::<Local, usize>::empty();\n/// assert_eq!(None, empty.last());\n/// ```\n#[inline]\npub fn last(&self) -> Option<&bool>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => Some(unsafe { self.get_unchecked(len - 1) }),\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::last_mut":["/// Returns a mutable pointer to the last bit of the slice, or `None` if it\n/// is empty.\n///\n/// # Original\n///\n/// [`slice::last_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.last_mut)\n///\n/// # API Differences\n///\n/// This crate cannot manifest `&mut bool` references, and must use the\n/// `BitMut` proxy type where `&mut bool` exists in the standard library\n/// API. The proxy value must be bound as `mut` in order to write through\n/// it.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// if let Some(mut last) = bits.last_mut() {\n///   *last = true;\n/// }\n/// assert_eq!(data, 1);\n/// ```\n#[inline]\npub fn last_mut(&mut self) -> Option<BitMut<O, T>>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => Some(unsafe { self.get_unchecked_mut(len - 1) }),\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::len":["/// Returns the number of bits in the slice.\n///\n/// # Original\n///\n/// [`slice::len`](https://doc.rust-lang.org/std/primitive.slice.html#method.len)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0u32;\n/// let bits = data.view_bits::<Local>();\n/// assert_eq!(bits.len(), 32);\n/// ```\n#[inline]\npub fn len(&self) -> usize{\n\t\tself.bitptr().len()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the end of the slice.\n///\n/// The chunks are slices and do not overlap. If `chunk_size` does not\n/// divide the length of the slice, then the last chunk will not have length\n/// `chunk_size`.\n///\n/// See [`rchunks_exact`] for a variant of this iterator that returns chunks\n/// of always exactly `chunk_size` bits, and [`chunks`] for the same\n/// iterator but starting at the beginning of the slice.\n///\n/// # Original\n///\n/// [`slice::rchunks`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// let mut iter = bits.rchunks(3);\n/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n/// assert_eq!(iter.next().unwrap(), &bits[2 .. 5]);\n/// assert_eq!(iter.next().unwrap(), &bits[.. 2]);\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// [`chunks`]: #method.chunks\n/// [`rchunks_exact`]: #method.rchunks_exact\n#[inline]\npub fn rchunks(&self, chunk_size: usize) -> RChunks<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunks::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the end of the slice.\n///\n/// The chunks are slices and do not overlap. If `chunk_size` does not\n/// divide the length of the slice, then the last up to `chunk_size-1` bits\n/// will be omitted and can be retrieved from the `remainder` function of\n/// the iterator.\n///\n/// Due to each chunk having exactly `chunk_size` bits, the compiler can\n/// often optimize the resulting code better than in the case of [`chunks`].\n///\n/// See [`rchunks`] for a variant of this iterator that also returns the\n/// remainder as a smaller chunk, and [`chunks_exact`] for the same iterator\n/// but starting at the beginning of the slice.\n///\n/// # Original\n///\n/// [`slice::rchunks_exact`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks_exact)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// let mut iter = bits.rchunks_exact(3);\n/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n/// assert_eq!(iter.next().unwrap(), &bits[2 .. 5]);\n/// assert!(iter.next().is_none());\n/// assert_eq!(iter.remainder(), &bits[.. 2]);\n/// ```\n///\n/// [`chunks`]: #method.chunks\n/// [`rchunks`]: #method.rchunks\n/// [`chunks_exact`]: #method.chunks_exact\n#[inline]\npub fn rchunks_exact(&self, chunk_size: usize) -> RChunksExact<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksExact::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact_mut":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the end of the slice.\n///\n/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n/// not divide the length of the slice, then the last up to `chunk_size-1`\n/// bits will be omitted and can be retrieved from the `into_remainder`\n/// function of the iterator.\n///\n/// Due to each chunk having exactly `chunk_size` bits, the compiler can\n/// often optimize the resulting code better than in the case of\n/// [`chunks_mut`].\n///\n/// See [`rchunks_mut`] for a variant of this iterator that also returns the\n/// remainder as a smaller chunk, and [`chunks_exact_mut`] for the same\n/// iterator but starting at the beginning of the slice.\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// for (idx, chunk) in bits.rchunks_exact_mut(3).enumerate() {\n///   chunk.set(idx, true);\n/// }\n/// assert_eq!(data, 0b001_010_00);\n/// ```\n///\n/// [`chunks_mut`]: #method.chunks_mut\n/// [`rchunks_mut`]: #method.rchunks_mut\n/// [`chunks_exact_mut`]: #method.chunks_exact_mut\n#[inline]\npub fn rchunks_exact_mut(\n\t\t&mut self,\n\t\tchunk_size: usize,\n\t) -> RChunksExactMut<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksExactMut::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_mut":["/// Returns an iterator over `chunk_size` bits of the slice at a time,\n/// starting at the end of the slice.\n///\n/// The chunks are mutable slices, and do not overlap. If `chunk_size` does\n/// not divide the length of the slice, then the last chunk will not have\n/// length `chunk_size`.\n///\n/// See [`rchunks_exact_mut`] for a variant of this iterator that returns\n/// chunks of always exactly `chunk_size` bits, and [`chunks_mut`] for the\n/// same iterator but starting at the beginning of the slice.\n///\n/// # Original\n///\n/// [`slice::rchunks_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rchunks_mut)\n///\n/// # Panics\n///\n/// Panics if `chunk_size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// for (idx, chunk) in bits.rchunks_mut(3).enumerate() {\n///   chunk.set(2 - idx, true);\n/// }\n/// assert_eq!(data, 0b100_010_01);\n/// ```\n///\n/// [`chunks_mut`]: #method.chunks_mut\n/// [`rchunks_exact_mut`]: #method.rchunks_exact_mut\n#[inline]\npub fn rchunks_mut(&mut self, chunk_size: usize) -> RChunksMut<O, T>{\n\t\tassert_ne!(chunk_size, 0, \"Chunk width cannot be 0\");\n\t\tRChunksMut::new(self, chunk_size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::repeat":["/// Creates a vector by repeating a slice `n` times.\n///\n/// # Original\n///\n/// [`slice::repeat`](https://doc.rust-lang.org/std/primitive.slice.html#method.repeat)\n///\n/// # Panics\n///\n/// This function will panic if the capacity would overflow.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// assert_eq!(bits![0, 1].repeat(3), bits![0, 1, 0, 1, 0, 1]);\n/// ```\n///\n/// A panic upon overflow:\n///\n/// ```rust,should_panic\n/// use bitvec::prelude::*;\n///\n/// // this will panic at runtime\n/// bits![0, 1].repeat(BitSlice::<Local, usize>::MAX_BITS);\n/// ```\n#[inline]\npub fn repeat(&self, n: usize) -> BitVec<O, T>\n\twhere\n\t\tO: BitOrder,\n\t\tT: BitStore,{\n\t\tlet len = self.len();\n\t\tlet total = len.checked_mul(n).expect(\"capacity overflow\");\n\t\tlet mut out = BitVec::with_capacity(total);\n\t\tfor span in (0 .. n).map(|rep| rep * len .. (rep + 1) * len) {\n\t\t\tunsafe { out.get_unchecked_mut(span) }.clone_from_bitslice(self);\n\t\t}\n\t\tunsafe {\n\t\t\tout.set_len(total);\n\t\t}\n\t\tout\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::reverse":["/// Reverses the order of bits in the slice, in place.\n///\n/// # Original\n///\n/// [`slice::reverse`](https://doc.rust-lang.org/std/primitive.slice.html#method.reverse)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0b1_1001100u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits[1 ..].reverse();\n/// assert_eq!(data, 0b1_0011001);\n/// ```\n#[inline]\npub fn reverse(&mut self){\n\t\t/* This would be better written as a recursive algorithm that swaps the\n\t\tedge bits and recurses on `[1 .. len - 1]`, but Rust does not guarantee\n\t\ttail-call optimization, and manual iteration allows for slight\n\t\tperformance optimization on the range reduction.\n\n\t\tBegin with raw pointer manipulation. That’s how you know this is a good\n\t\tfunction.\n\t\t*/\n\t\tlet mut bitptr = self.bitptr();\n\t\tloop {\n\t\t\t//  Reversing 1 or 0 bits has no effect.\n\t\t\tlet len = bitptr.len();\n\t\t\tif len < 2 {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tunsafe {\n\t\t\t\t//  Swap the 0 and `len - 1` indices,\n\t\t\t\tlet back = len - 1;\n\t\t\t\tbitptr.to_bitslice_mut::<O>().swap_unchecked(0, back);\n\n\t\t\t\t//  Move the pointer upwards by one bit.\n\t\t\t\tbitptr.incr_head();\n\t\t\t\t//  The length is unchanged, and must now be brought down by 2\n\t\t\t\t//  in order to remove both the front and back bits.\n\t\t\t\tbitptr.set_len(len - 2);\n\n\t\t\t\t//  TODO(myrrlyn): See if range subslicing can be made faster.\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rotate_left":["/// Rotates the slice in-place such that the first `by` bits of the slice\n/// move to the end while the last `self.len() - by` bits move to the front.\n/// After calling `rotate_left`, the bit previously at index `by` will\n/// become the first bit in the slice.\n///\n/// # Original\n///\n/// [`slice::rotate_left`](https://doc.rust-lang.org/std/primitive.slice.html#rotate_left)\n///\n/// # Panics\n///\n/// This function will panic if `by` is greater than the length of the\n/// slice. Note that `by == self.len()` does *not* panic and is a no-op\n/// rotation.\n///\n/// # Complexity\n///\n/// Takes linear (in `self.len()`) time.\n///\n/// # Performance\n///\n/// While this is faster than the equivalent rotation on `[bool]`, it is\n/// slower than a handcrafted partial-element rotation on `[T]`. Because of\n/// the support for custom orderings, and the lack of specialization, this\n/// method can only accelerate by reducing the number of loop iterations\n/// performed on the slice body, and cannot accelerate by using shift-mask\n/// instructions to move multiple bits in one operation.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n/// let mut data = 0xF0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits.rotate_left(2);\n/// assert_eq!(data, 0xC3);\n/// ```\n///\n/// Rotating a subslice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0xF0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits[1 .. 5].rotate_left(1);\n/// assert_eq!(data, 0b1_1101_000);\n/// ```\n#[inline]\npub fn rotate_left(&mut self, mut by: usize){\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tby <= len,\n\t\t\t\"Slices cannot be rotated by more than their length\"\n\t\t);\n\t\tif by == 0 || by == len {\n\t\t\treturn;\n\t\t}\n\t\t/* The standard one-element-at-a-time algorithm is necessary for `[T]`\n\t\trotation, because it must not allocate, but bit slices have an advantage\n\t\tin that placing a single element `T` on the stack as a temporary has\n\t\tsignificant logical acceleration.\n\n\t\tInstead, we can move `min(T::Mem::BITS, by)` bits from the front of the\n\t\tslice into the stack, then shunt the rest of the slice downwards, then\n\t\tinsert the stack bits into the now-open back, repeating until complete.\n\t\t*/\n\t\tlet mut tmp = 0usize;\n\t\tlet tmp_bits = BitSlice::<O, _>::from_element_mut(&mut tmp);\n\t\twhile by > 0 {\n\t\t\t//  Note: in theory, the \"head to tmp\" operation could be optimized\n\t\t\t//  to a single element copy of `head .. BITS`, at the cost of more\n\t\t\t//  loops.\n\t\t\tlet shamt = cmp::min(usize::BITS as usize, by);\n\t\t\tunsafe {\n\t\t\t\tlet tmp_bits = tmp_bits.get_unchecked_mut(.. shamt);\n\t\t\t\ttmp_bits.clone_from_bitslice(self.get_unchecked(.. shamt));\n\t\t\t\tself.copy_within_unchecked(shamt .., 0);\n\t\t\t\tself.get_unchecked_mut(len - shamt ..)\n\t\t\t\t\t.clone_from_bitslice(tmp_bits);\n\t\t\t}\n\t\t\tby -= shamt;\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rotate_right":["/// Rotates the slice in-place such that the first `self.len() - by` bits of\n/// the slice move to the end while the last `by` bits move to the front.\n/// After calling `rotate_right`, the bit previously at index `self.len() -\n/// by` will become the first bit in the slice.\n///\n/// # Original\n///\n/// [`slice::rotate_right`](https://doc.rust-lang.org/std/primitive.slice.html#rotate_right)\n///\n/// # Panics\n///\n/// This function will panic if `by` is greater than the length of the\n/// slice. Note that `by == self.len()` does *not* panic and is a no-op\n/// rotation.\n///\n/// # Complexity\n///\n/// Takes linear (in `self.len()`) time.\n///\n/// # Performance\n///\n/// While this is faster than the equivalent rotation on `[bool]`, it is\n/// slower than a handcrafted partial-element rotation on `[T]`. Because of\n/// the support for custom orderings, and the lack of specialization, this\n/// method can only accelerate by reducing the number of loop iterations\n/// performed on the slice body, and cannot accelerate by using shift-mask\n/// instructions to move multiple bits in one operation.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0xF0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits.rotate_right(2);\n/// assert_eq!(data, 0x3C);\n/// ```\n///\n/// Rotate a subslice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0xF0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// bits[1 .. 5].rotate_right(1);\n/// assert_eq!(data, 0b1_0111_000);\n/// ```\n#[inline]\npub fn rotate_right(&mut self, mut by: usize){\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tby <= len,\n\t\t\t\"Slices cannot be rotated by more than their length\"\n\t\t);\n\t\tif by == 0 || by == len {\n\t\t\treturn;\n\t\t}\n\t\tlet mut tmp = 0usize;\n\t\tlet tmp_bits = BitSlice::<O, _>::from_element_mut(&mut tmp);\n\t\twhile by > 0 {\n\t\t\tlet shamt = cmp::min(usize::BITS as usize, by);\n\t\t\tlet mid = len - shamt;\n\t\t\tunsafe {\n\t\t\t\tlet tmp_bits = tmp_bits.get_unchecked_mut(.. shamt);\n\t\t\t\ttmp_bits.clone_from_bitslice(self.get_unchecked(mid ..));\n\t\t\t\tself.copy_within_unchecked(.. mid, shamt);\n\t\t\t\tself.get_unchecked_mut(.. shamt)\n\t\t\t\t\t.clone_from_bitslice(tmp_bits);\n\t\t\t}\n\t\t\tby -= shamt;\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rsplit":["/// Returns an iterator over subslices separated by bits that match `pred`,\n/// starting at the end of the slice and working backwards. The matched bit\n/// is not contained in the subslices.\n///\n/// # Original\n///\n/// [`slice::rsplit`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplit)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b0001_0000u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.rsplit(|_pos, bit| *bit);\n///\n/// assert_eq!(iter.next().unwrap(), &bits[4 ..]);\n/// assert_eq!(iter.next().unwrap(), &bits[.. 3]);\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// As with `split()`, if the first or last bit is matched, an empty slice\n/// will be the first (or last) item returned by the iterator.\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b1001_0001u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.rsplit(|_pos, bit| *bit);\n/// assert!(iter.next().unwrap().is_empty());\n/// assert_eq!(iter.next().unwrap(), &bits[4 .. 7]);\n/// assert_eq!(iter.next().unwrap(), &bits[1 .. 3]);\n/// assert!(iter.next().unwrap().is_empty());\n/// assert!(iter.next().is_none());\n/// ```\n#[inline]\npub fn rsplit<F>(&self, pred: F) -> RSplit<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tRSplit::new(self, pred)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rsplit_mut":["/// Returns an iterator over mutable subslices separated by bits that match\n/// `pred`, starting at the end of the slice and working backwards. The\n/// matched bit is not contained in the subslices.\n///\n/// # Original\n///\n/// [`slice::rsplit_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplit_mut)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0b001_000_10u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// for group in bits.rsplit_mut(|_pos, bit| *bit) {\n///   *group.get_mut(0).unwrap() = true;\n/// }\n/// assert_eq!(data, 0b101_100_11);\n/// ```\n#[inline]\npub fn rsplit_mut<F>(&mut self, pred: F) -> RSplitMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tRSplitMut::new(self.alias_mut(), pred)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn":["/// Returns an iterator over subslices separated by bits that match `pred`\n/// limited to returining at most `n` items. This starts at the end of the\n/// slice and works backwards. The matched bit is not contained in the\n/// subslices.\n///\n/// The last item returned, if any, will contain the remainder of the slice.\n///\n/// # Original\n///\n/// [`slice::rsplitn`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplitn)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// for group in bits.rsplitn(2, |pos, _bit| pos % 3 == 2) {\n/// # #[cfg(feature = \"std\")] {\n///   println!(\"{}\", group.len());\n/// # }\n/// }\n/// //  2\n/// //  5\n/// # //  [10]\n/// # //  [00101]\n/// ```\n#[inline]\npub fn rsplitn<F>(&self, n: usize, pred: F) -> RSplitN<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tRSplitN::new(self, pred, n)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn_mut":["/// Returns an iterator over subslices separated by bits that match `pred`\n/// limited to returning at most `n` items. This starts at the end of the\n/// slice and works backwards. The matched bit is not contained in the\n/// subslices.\n///\n/// The last item returned, if any, will contain the remainder of the slice.\n///\n/// # Original\n///\n/// [`slice::rsplitn_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.rsplitn_mut)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0b001_000_10u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// for group in bits.rsplitn_mut(2, |_pos, bit| *bit) {\n///   *group.get_mut(0).unwrap() = true;\n/// }\n/// assert_eq!(data, 0b101_000_11);\n/// ```\n#[inline]\npub fn rsplitn_mut<F>(&mut self, n: usize, pred: F) -> RSplitNMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tRSplitNMut::new(self.alias_mut(), pred, n)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split":["/// Returns an iterator over subslices separated by bits that match `pred`.\n/// The matched bit is not contained in the subslices.\n///\n/// # Original\n///\n/// [`slice::split`](https://doc.rust-lang.org/std/primitive.slice.html#method.split)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b01_001_000u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.split(|_pos, bit| *bit);\n///\n/// assert_eq!(iter.next().unwrap(), &bits[.. 1]);\n/// assert_eq!(iter.next().unwrap(), &bits[2 .. 4]);\n/// assert_eq!(iter.next().unwrap(), &bits[5 ..]);\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// If the first bit is matched, an empty slice will be the first item\n/// returned by the iterator. Similarly, if the last element in the slice is\n/// matched, an empty slice will be the last item returned by the iterator:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 1u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.split(|_pos, bit| *bit);\n///\n/// assert_eq!(iter.next().unwrap(), &bits[.. 7]);\n/// assert!(iter.next().unwrap().is_empty());\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// If two matched bits are directly adjacent, an empty slice will be\n/// present between them:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b001_100_00u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.split(|pos, bit| *bit);\n///\n/// assert_eq!(iter.next().unwrap(), &bits[0 .. 2]);\n/// assert!(iter.next().unwrap().is_empty());\n/// assert_eq!(iter.next().unwrap(), &bits[4 .. 8]);\n/// assert!(iter.next().is_none());\n/// ```\n#[inline]\npub fn split<F>(&self, pred: F) -> Split<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tSplit::new(self, pred)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_at":["/// Divides one slice into two at an index.\n///\n/// The first will contain all indices from `[0, mid)` (excluding the index\n/// `mid` itself) and the second will contain all indices from `[mid, len)`\n/// (excluding the index `len` itself).\n///\n/// # Original\n///\n/// [`slice::split_at`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at)\n///\n/// # Panics\n///\n/// Panics if `mid > len`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xC3u8;\n/// let bits = data.view_bits::<Local>();\n///\n/// let (left, right) = bits.split_at(0);\n/// assert!(left.is_empty());\n/// assert_eq!(right, bits);\n///\n/// let (left, right) = bits.split_at(2);\n/// assert_eq!(left, &bits[.. 2]);\n/// assert_eq!(right, &bits[2 ..]);\n///\n/// let (left, right) = bits.split_at(8);\n/// assert_eq!(left, bits);\n/// assert!(right.is_empty());\n/// ```\n#[inline]\npub fn split_at(&self, mid: usize) -> (&Self, &Self){\n\t\tlet len = self.len();\n\t\tassert!(mid <= len, \"Index {} out of bounds: {}\", mid, len);\n\t\tunsafe { self.split_at_unchecked(mid) }\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_at_mut":["/// Divides one mutable slice into two at an index.\n///\n/// The first will contain all indices from `[0, mid)` (excluding the index\n/// `mid` itself) and the second will contain all indices from `[mid, len)`\n/// (excluding the index `len` itself).\n///\n/// # Original\n///\n/// [`slice::split_at_mut`](https://doc.rust-lang.org/std/primitive.html#method.split_at_mut)\n///\n/// # API Differences\n///\n/// Because the partition point `mid` is permitted to occur in the interior\n/// of a memory element `T`, this method is required to mark the returned\n/// slices as being to aliased memory. This marking ensures that writes to\n/// the covered memory use the appropriate synchronization behavior of your\n/// build to avoid data races – by default, this makes all writes atomic; on\n/// builds with the `atomic` feature disabled, this uses `Cell`s and\n/// forbids the produced subslices from leaving the current thread.\n///\n/// See the [`BitStore`] documentation for more information.\n///\n/// # Panics\n///\n/// Panics if `mid > len`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n/// // scoped to restrict the lifetime of the borrows\n/// {\n///   let (left, right) = bits.split_at_mut(3);\n///   *left.get_mut(1).unwrap() = true;\n///   *right.get_mut(2).unwrap() = true;\n/// }\n/// assert_eq!(data, 0b010_00100);\n/// ```\n///\n/// [`BitStore`]: ../store/trait.BitStore.html\n#[inline]\n#[allow(clippy::type_complexity)]\npub fn split_at_mut(\n\t\t&mut self,\n\t\tmid: usize,\n\t) -> (&mut BitSlice<O, T::Alias>, &mut BitSlice<O, T::Alias>){\n\t\tlet len = self.len();\n\t\tassert!(mid <= len, \"Index {} out of bounds: {}\", mid, len);\n\t\tunsafe { self.split_at_unchecked_mut(mid) }\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_first":["/// Returns the first and all the rest of the bits of the slice, or `None`\n/// if it is empty.\n///\n/// # Original\n///\n/// [`slice::split_first`](https://doc.rust-lang.org/std/primitive.slice.html#split_first)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 1u8;\n/// let bits = data.view_bits::<Lsb0>();\n/// if let Some((first, rest)) = bits.split_first() {\n///   assert!(*first);\n/// }\n/// ```\n#[inline]\npub fn split_first(&self) -> Option<(&bool, &Self)>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\t_ => unsafe {\n\t\t\t\tlet (head, rest) = self.split_at_unchecked(1);\n\t\t\t\tSome((head.get_unchecked(0), rest))\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_first_mut":["/// Returns the first and all the rest of the bits of the slice, or `None`\n/// if it is empty.\n///\n/// # Original\n///\n/// [`slice::split_first_mut`](https://doc.rust-lang.org/std/primitive.slice.html#split_first_mut)\n///\n/// # API Differences\n///\n/// This crate cannot manifest `&mut bool` references, and must use the\n/// `BitMut` proxy type where `&mut bool` exists in the standard library\n/// API. The proxy value must be bound as `mut` in order to write through\n/// it.\n///\n/// Because the references are permitted to use the same memory address,\n/// they are marked as aliasing in order to satisfy Rust’s requirements\n/// about freedom from data races.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0usize;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// if let Some((mut first, rest)) = bits.split_first_mut() {\n///   *first = true;\n///   *rest.get_mut(1).unwrap() = true;\n/// }\n/// assert_eq!(data, 5);\n///\n/// assert!(BitSlice::<Local, usize>::empty_mut().split_first_mut().is_none());\n/// ```\n#[inline]\n#[allow(clippy::type_complexity)]\npub fn split_first_mut(\n\t\t&mut self,\n\t) -> Option<(BitMut<O, T::Alias>, &mut BitSlice<O, T::Alias>)>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\t_ => unsafe {\n\t\t\t\tlet (head, rest) = self.split_at_unchecked_mut(1);\n\t\t\t\tSome((head.get_unchecked_mut(0), rest))\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_last":["/// Returns the last and all the rest of the bits of the slice, or `None` if\n/// it is empty.\n///\n/// # Original\n///\n/// [`slice::split_last`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_last)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 1u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// if let Some((last, rest)) = bits.split_last() {\n///   assert!(*last);\n/// }\n/// ```\n#[inline]\npub fn split_last(&self) -> Option<(&bool, &Self)>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => unsafe {\n\t\t\t\tlet (rest, tail) = self.split_at_unchecked(len.wrapping_sub(1));\n\t\t\t\tSome((tail.get_unchecked(0), rest))\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_last_mut":["/// Returns the last and all the rest of the bits of the slice, or `None` if\n/// it is empty.\n///\n/// # Original\n///\n/// [`slice::split_last_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_last_mut)\n///\n/// # API Differences\n///\n/// This crate cannot manifest `&mut bool` references, and must use the\n/// `BitMut` proxy type where `&mut bool` exists in the standard library\n/// API. The proxy value must be bound as `mut` in order to write through\n/// it.\n///\n/// Because the references are permitted to use the same memory address,\n/// they are marked as aliasing in order to satisfy Rust’s requirements\n/// about freedom from data races.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// if let Some((mut last, rest)) = bits.split_last_mut() {\n///   *last = true;\n///   *rest.get_mut(5).unwrap() = true;\n/// }\n/// assert_eq!(data, 5);\n///\n/// assert!(BitSlice::<Local, usize>::empty_mut().split_last_mut().is_none());\n/// ```\n#[inline]\n#[allow(clippy::type_complexity)]\npub fn split_last_mut(\n\t\t&mut self,\n\t) -> Option<(BitMut<O, T::Alias>, &mut BitSlice<O, T::Alias>)>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tlen => unsafe {\n\t\t\t\tlet (rest, tail) = self.split_at_unchecked_mut(len - 1);\n\t\t\t\tSome((tail.get_unchecked_mut(0), rest))\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::split_mut":["/// Returns an iterator over mutable subslices separated by bits that match\n/// `pred`. The matched bit is not contained in the subslices.\n///\n/// # Original\n///\n/// [`slice::split_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_mut)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0b001_000_10u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// for group in bits.split_mut(|_pos, bit| *bit) {\n///   *group.get_mut(0).unwrap() = true;\n/// }\n/// assert_eq!(data, 0b101_100_11);\n/// ```\n#[inline]\npub fn split_mut<F>(&mut self, pred: F) -> SplitMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tSplitMut::new(self.alias_mut(), pred)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::splitn":["/// Returns an iterator over subslices separated by bits that match `pred`,\n/// limited to returning at most `n` items. The matched bit is not contained\n/// in the subslices.\n///\n/// The last item returned, if any, will contain the remainder of the slice.\n///\n/// # Original\n///\n/// [`slice::splitn`](https://doc.rust-lang.org/std/primitive.slice.html#method.splitn)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// for group in bits.splitn(2, |pos, _bit| pos % 3 == 2) {\n/// # #[cfg(feature = \"std\")] {\n///   println!(\"{}\", group.len());\n/// # }\n/// }\n/// //  2\n/// //  5\n/// # //  [10]\n/// # //  [00101]\n/// ```\n#[inline]\npub fn splitn<F>(&self, n: usize, pred: F) -> SplitN<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tSplitN::new(self, pred, n)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::splitn_mut":["/// Returns an iterator over subslices separated by bits that match `pred`,\n/// limited to returning at most `n` items. The matched element is not\n/// contained in the subslices.\n///\n/// The last item returned, if any, will contain the remainder of the slice.\n///\n/// # Original\n///\n/// [`slice::splitn_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.splitn_mut)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 0b001_000_10u8;\n/// let bits = data.view_bits_mut::<Msb0>();\n///\n/// for group in bits.splitn_mut(2, |_pos, bit| *bit) {\n///   *group.get_mut(0).unwrap() = true;\n/// }\n/// assert_eq!(data, 0b101_100_10);\n/// ```\n#[inline]\npub fn splitn_mut<F>(&mut self, n: usize, pred: F) -> SplitNMut<O, T, F>\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tSplitNMut::new(self.alias_mut(), pred, n)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::starts_with":["/// Returns `true` if `needle` is a prefix of the slice.\n///\n/// # Original\n///\n/// [`slice::starts_with`](https://doc.rust-lang.org/std/primitive.slice.html#method.starts_with)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0b0100_1011u8;\n/// let haystack = data.view_bits::<Msb0>();\n/// let needle = &data.view_bits::<Lsb0>()[2 .. 5];\n/// assert!(haystack.starts_with(&needle[.. 2]));\n/// assert!(haystack.starts_with(needle));\n/// assert!(!haystack.starts_with(&haystack[2 .. 4]));\n/// ```\n///\n/// Always returns `true` if `needle` is an empty slice:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let empty = BitSlice::<Local, usize>::empty();\n/// assert!(0u8.view_bits::<Local>().starts_with(empty));\n/// assert!(empty.starts_with(empty));\n/// ```\n#[inline]\npub fn starts_with<O2, T2>(&self, needle: &BitSlice<O2, T2>) -> bool\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tlet len = needle.len();\n\t\tself.len() >= len && needle == unsafe { self.get_unchecked(.. len) }\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::swap":["/// Swaps two bits in the slice.\n///\n/// # Original\n///\n/// [`slice::swap`](https://doc.rust-lang.org/std/primitive.slice.html#method.swap)\n///\n/// # Arguments\n///\n/// - `a`: The index of the first bit\n/// - `b`: The index of the second bit\n///\n/// # Panics\n///\n/// Panics if `a` or `b` are out of bounds.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut data = 2u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n/// bits.swap(1, 3);\n/// assert_eq!(data, 8);\n/// ```\n#[inline]\npub fn swap(&mut self, a: usize, b: usize){\n\t\tlet len = self.len();\n\t\tassert!(a < len, \"Index {} out of bounds: {}\", a, len);\n\t\tassert!(b < len, \"Index {} out of bounds: {}\", b, len);\n\t\tunsafe {\n\t\t\tself.swap_unchecked(a, b);\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_bitslice":["/// Swaps all bits in `self` with those in `other`.\n///\n/// The length of `other` must be the same as `self`.\n///\n/// # Original\n///\n/// [`slice::swap_with_slice`](https://doc.rust-lang.org/std/primitive.slice.html#method.swap_with_slice)\n///\n/// # API Differences\n///\n/// This method is renamed, as it takes a bit slice rather than an element\n/// slice.\n///\n/// # Panics\n///\n/// This function will panic if the two slices have different lengths.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut one = [0xA5u8, 0x69];\n/// let mut two = 0x1234u16;\n/// let one_bits = one.view_bits_mut::<Msb0>();\n/// let two_bits = two.view_bits_mut::<Lsb0>();\n///\n/// one_bits.swap_with_bitslice(two_bits);\n///\n/// assert_eq!(one, [0x2C, 0x48]);\n/// # #[cfg(target_endian = \"little\")] {\n/// assert_eq!(two, 0x96A5);\n/// # }\n/// ```\n#[inline]\npub fn swap_with_bitslice<O2, T2>(&mut self, other: &mut BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tlet len = self.len();\n\t\tassert_eq!(len, other.len());\n\t\tfor n in 0 .. len {\n\t\t\tunsafe {\n\t\t\t\tlet (this, that) =\n\t\t\t\t\t(*self.get_unchecked(n), *other.get_unchecked(n));\n\t\t\t\tself.set_unchecked(n, that);\n\t\t\t\tother.set_unchecked(n, this);\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_slice":["#[inline]\n#[doc(hidden)]\n#[deprecated(note = \"Use `.swap_with_bitslice` to swap between bitslices\")]\n#[cfg(not(tarpaulin_include))]\npub fn swap_with_slice<O2, T2>(&mut self, other: &mut BitSlice<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tself.swap_with_bitslice(other);\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::to_bitvec":["/// Copies `self` into a new `BitVec`.\n///\n/// # Original\n///\n/// [`slice::to_vec`](https://doc.rust-lang.org/std.primitive.html#method.to_vec)\n///\n/// # Examples\n///\n/// ```rust\n/// # #[cfg(feature = \"stde\")] {\n/// use bitvec::prelude::*;\n///\n/// let bits = bits![0, 1, 0, 1];\n/// let bv = bits.to_bitvec();\n/// assert_eq!(bits, bv);\n/// # }\n/// ```\n#[inline]\npub fn to_bitvec(&self) -> BitVec<O, T>{\n\t\tself.pipe(BitVec::from_bitslice)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::to_vec":["#[doc(hidden)]\n#[deprecated(note = \"Use `.to_bitvec` to convert a bit slice into a vector\")]\npub fn to_vec(&self) -> BitVec<O, T>{\n\t\tself.to_bitvec()\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::<impl slice::BitSlice<O, T>>::windows":["/// Returns an iterator over all contiguous windows of length `size`. The\n/// windows overlap. If the slice is shorter than `size`, the iterator\n/// returns no values.\n///\n/// # Original\n///\n/// [`slice::windows`](https://doc.rust-lang.org/std/primitive.slice.html#method.windows)\n///\n/// # Panics\n///\n/// Panics if `size` is 0.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0xA5u8;\n/// let bits = data.view_bits::<Msb0>();\n/// let mut iter = bits.windows(6);\n/// assert_eq!(iter.next().unwrap(), &bits[.. 6]);\n/// assert_eq!(iter.next().unwrap(), &bits[1 .. 7]);\n/// assert_eq!(iter.next().unwrap(), &bits[2 ..]);\n/// assert!(iter.next().is_none());\n/// ```\n///\n/// If the slice is shorter than `size`:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = BitSlice::<Local, usize>::empty();\n/// let mut iter = bits.windows(1);\n/// assert!(iter.next().is_none());\n/// ```\n#[inline]\npub fn windows(&self, size: usize) -> Windows<O, T>{\n\t\tassert_ne!(size, 0, \"Window width cannot be 0\");\n\t\tWindows::new(self, size)\n\t}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::BitSliceIndex":["/** A helper trait used for indexing operations.\n\nThis trait has its definition stabilized, but has not stabilized its associated\nfunctions. This means it cannot be implemented outside of the distribution\nlibraries. *Furthermore*, since `bitvec` cannot create `&mut bool` references,\nit is insufficient for `bitvec`’s uses.\n\nThere is no tracking issue for `feature(slice_index_methods)`.\n\n# Original\n\n[`slice::SliceIndex`](https://doc.rust-lang.org/stable/core/slice/trait.SliceIndex.html)\n\n# API Differences\n\n`SliceIndex::Output` is not usable here, because the `usize` implementation\ncannot produce `&mut bool`. Instead, two output types `Immut` and `Mut` are\ndefined. The range implementations define these to be the appropriately mutable\n`BitSlice` reference; the `usize` implementation defines them to be `&bool` and\nthe proxy type.\n**/\npub trait BitSliceIndex<'a, O, T>\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The output type for immutable functions.\n\ttype Immut;\n\n\t/// The output type for mutable functions.\n\ttype Mut;\n\n\t/// Returns a shared reference to the output at this location, if in bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::get`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get)\n\tfn get(self, slice: &'a BitSlice<O, T>) -> Option<Self::Immut>;\n\n\t/// Returns a mutable reference to the output at this location, if in\n\t/// bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::get_mut`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get_mut)\n\tfn get_mut(self, slice: &'a mut BitSlice<O, T>) -> Option<Self::Mut>;\n\n\t/// Returns a shared reference to the output at this location, without\n\t/// performing any bounds checking. Calling this method with an\n\t/// out-of-bounds index is [undefined behavior] even if the resulting\n\t/// reference is not used.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::get_unchecked`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get_unchecked)\n\t///\n\t/// # Safety\n\t///\n\t/// As this function does not perform boundary checking, the caller must\n\t/// ensure that `self` is an index within the boundaries of `slice` before\n\t/// calling in order to prevent boundary escapes and the ensuing safety\n\t/// violations.\n\t///\n\t/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n\tunsafe fn get_unchecked(self, slice: &'a BitSlice<O, T>) -> Self::Immut;\n\n\t/// Returns a mutable reference to the output at this location, without\n\t/// performing any bounds checking. Calling this method with an\n\t/// out-of-bounds index is [undefined behavior] even if the resulting\n\t/// reference is not used.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::get_unchecked_mut`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.get_unchecked_mut)\n\t///\n\t/// # Safety\n\t///\n\t/// As this function does not perform boundary checking, the caller must\n\t/// ensure that `self` is an index within the boundaries of `slice` before\n\t/// calling in order to prevent boundary escapes and the ensuing safety\n\t/// violations.\n\t///\n\t/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n\tunsafe fn get_unchecked_mut(\n\t\tself,\n\t\tslice: &'a mut BitSlice<O, T>,\n\t) -> Self::Mut;\n\n\t/// Returns a shared reference to the output at this location, panicking if\n\t/// out of bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::index`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.index)\n\tfn index(self, slice: &'a BitSlice<O, T>) -> Self::Immut;\n\n\t/// Returns a mutable reference to the output at this location, panicking if\n\t/// out of bounds.\n\t///\n\t/// # Original\n\t///\n\t/// [`SliceIndex::index_mut`](https://doc.rust-lang.org/core/slice/trait.SliceIndex.html#method.index_mut)\n\tfn index_mut(self, slice: &'a mut BitSlice<O, T>) -> Self::Mut;\n}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::from_mut":["/** Converts a reference to `T` into a bitslice over one element.\n\n# Original\n\n[`slice::from_mut`](https://doc.rust-lang.org/core/slice/fn.from_mut.html)\n**/\n#[inline(always)]\npub fn from_mut<O, T>(elem: &mut T) -> &mut BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore + BitMemory,{\n\tBitSlice::from_element_mut(elem)\n}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::from_raw_parts":["/// Forms a bitslice from a pointer and a length.\n///\n/// The `len` argument is the number of **elements**, not the number of bits.\n///\n/// # Original\n///\n/// [`slice::from_raw_parts`](https://doc.rust-lang.org/core/slice/fn.from_raw_parts.html)\n///\n/// # Safety\n///\n/// Behavior is undefined if any of the following conditions are violated:\n///\n/// - `data` must be [valid] for `len * mem::size_of::<T>()` many bytes, and it\n///   must be properly aligned. This means in particular:\n///   - The entire memory range of this slice must be contained within a single\n///     allocated object! Slices can never span across multiple allocated\n///     objects.\n///   - `data` must be non-null and aligned even for zero-length slices. The\n///     `&BitSlice` pointer encoding requires this porperty to hold. You can\n///     obtain a pointer that is usable as `data` for zero-length slices using\n///     [`NonNull::dangling()`].\n/// - The memory referenced by the returned bitslice must not be mutated for the\n///   duration of the lifetime `'a`, except inside an `UnsafeCell`.\n/// - The total size `len * T::Mem::BITS` of the slice must be no larger than\n///   [`BitSlice::<_, T>::MAX_BITS`]\n///\n/// # Caveat\n///\n/// The lifetime for the returned slice is inferred from its usage. To prevent\n/// accidental misuse, it's suggested to tie the lifetime to whichever source\n/// lifetime is safe in the context, such as by providing a helper function\n/// taking the lifetime of a host value for the slice, or by explicit\n/// annotation.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n/// use bitvec::slice as bv_slice;\n///\n/// let x = 42u8;\n/// let ptr = &x as *const _;\n/// let bits = unsafe {\n///   bv_slice::from_raw_parts::<Local, u8>(ptr, 1)\n/// };\n/// assert_eq!(bits.count_ones(), 3);\n/// ```\n///\n/// [valid]: https://doc.rust-lang.org/core/ptr/index.html#safety\n/// [`BitSlice::<_, T>::MAX_BITS`]:\n/// struct.BitSlice.html#associatedconstant.MAX_BITS [`NonNull::dangling()`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.dangling\n#[inline]\npub unsafe fn from_raw_parts<'a, O, T>(\n\tdata: *const T,\n\tlen: usize,\n) -> &'a BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore + BitMemory,{\n\tsuper::bits_from_raw_parts(data, 0, len * T::Mem::BITS as usize)\n\t\t.unwrap_or_else(|| {\n\t\t\tpanic!(\n\t\t\t\t\"Failed to construct `&{}BitSlice` from invalid pointer {:p} \\\n\t\t\t\t or element count {}\",\n\t\t\t\t\"\", data, len\n\t\t\t)\n\t\t})\n}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::from_raw_parts_mut":["/// Performs the same functionality as [`from_raw_parts`], except that a mutable\n/// bitslice is returned.\n///\n/// # Original\n///\n/// [`slice::from_raw_parts_mut`](https://doc.rust-lang.org/core/slice/fn.from_raw_parts_mut.html)\n///\n/// # Safety\n///\n/// Behavior is undefined if any of the following conditions are violated:\n///\n/// - `data` must be [valid] for `len * mem::size_of::<T>()` many bytes, and it\n///   must be properly aligned. This means in particular:\n///   - The entire memory range of this slice must be contained within a single\n///     allocated object! Slices can never span across multiple allocated\n///     objects.\n///   - `data` must be non-null and aligned even for zero-length slices. The\n///     `&BitSlice` pointer encoding requires this porperty to hold. You can\n///     obtain a pointer that is usable as `data` for zero-length slices using\n///     [`NonNull::dangling()`].\n/// - The memory referenced by the returned bitslice must not be accessed\n///   through other pointer (not derived from the return value) for the duration\n///   of the lifetime `'a`. Both read and write accesses are forbidden.\n/// - The total size `len * T::Mem::BITS` of the slice must be no larger than\n///   [`BitSlice::<_, T>::MAX_BITS`]\n///\n/// [valid]: https://doc.rust-lang.org/core/ptr/index.html#safety\n/// [`BitSlice::<_, T>::MAX_BITS`]:\n/// struct.BitSlice.html#associatedconstant.MAX_BITS\n/// [`NonNull::dangling()`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.dangling\n#[inline]\npub unsafe fn from_raw_parts_mut<'a, O, T>(\n\tdata: *mut T,\n\tlen: usize,\n) -> &'a mut BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore + BitMemory,{\n\tsuper::bits_from_raw_parts_mut(data, 0, len * T::Mem::BITS as usize)\n\t\t.unwrap_or_else(|| {\n\t\t\tpanic!(\n\t\t\t\t\"Failed to construct `&{}BitSlice` from invalid pointer {:p} \\\n\t\t\t\t or element count {}\",\n\t\t\t\t\"mut \", data, len\n\t\t\t)\n\t\t})\n}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::api::from_ref":["/** Converts a reference to `T` into a bitslice over one element.\n\n# Original\n\n[`slice::from_ref`](https://doc.rust-lang.org/core/slice/fn.from_ref.html)\n**/\n#[inline(always)]\npub fn from_ref<O, T>(elem: &T) -> &BitSlice<O, T>\nwhere\n\tO: BitOrder,\n\tT: BitStore + BitMemory,{\n\tBitSlice::from_element(elem)\n}","Real(LocalPath(\"src/slice/api.rs\"))"],"slice::bits_from_raw_parts":["/** Constructs a `&BitSlice` reference from its component data.\n\nThis is logically equivalent to [`slice::from_raw_parts`] for `[T]`.\n\n# Lifetimes\n\n- `'a`: The lifetime of the returned bitslice handle. This must be no longer\n  than the duration of the referent region, as it is illegal for references to\n  dangle.\n\n# Type Parameters\n\n- `O`: The ordering of bits within elements `T`.\n- `T`: The type of each memory element in the backing storage region.\n\n# Parameters\n\n- `addr`: The base address of the memory region that the `BitSlice` covers.\n- `head`: The index of the first live bit in `*addr`, at which the `BitSlice`\n  begins. This is required to be in the range `0 .. T::Mem::BITS`.\n- `bits`: The number of live bits, beginning at `head` in `*addr`, that the\n  `BitSlice` contains. This must be no greater than `BitSlice::MAX_BITS`.\n\n# Returns\n\nIf the input parameters are valid, this returns `Some` shared reference to a\n`BitSlice`. The failure conditions causing this to return `None` are:\n\n- `head` is not less than [`T::Mem::BITS`]\n- `bits` is greater than [`BitSlice::<O, T>::MAX_BITS`]\n- `addr` is not adequately aligned to `T`\n- `addr` is so high in the memory space that the region wraps to the base of the\n  memory space\n\n# Safety\n\nThe memory region described by the returned `BitSlice` must be validly allocated\nwithin the caller’s memory management system. It must also not be modified for\nthe duration of the lifetime `'a`, unless the `T` type parameter permits safe\nshared mutation.\n\n[`BitSlice::<O, T>::MAX_BITS`]: struct.BitSlice.html#associatedconstant.MAX_BITS\n[`T::Mem::BITS`]: ../mem/trait.BitMemory.html#associatedconstant.BITS\n[`slice::from_raw_parts`]: https://doc.rust-lang.org/core/slice/fn.from_raw_parts.html\n**/\n#[inline]\npub unsafe fn bits_from_raw_parts<'a, O, T>(\n\taddr: *const T,\n\thead: u8,\n\tbits: usize,\n) -> Option<&'a BitSlice<O, T>>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore + BitMemory,{\n\tlet head = crate::index::BitIdx::new(head)?;\n\tBitPtr::new(addr, head, bits).map(BitPtr::to_bitslice_ref)\n}","Real(LocalPath(\"src/slice.rs\"))"],"slice::bits_from_raw_parts_mut":["/** Constructs a `&mut BitSlice` reference from its component data.\n\nThis is logically equivalent to [`slice::from_raw_parts_mut`] for `[T]`.\n\n# Lifetimes\n\n- `'a`: The lifetime of the returned bitslice handle. This must be no longer\n  than the duration of the referent region, as it is illegal for references to\n  dangle.\n\n# Type Parameters\n\n- `O`: The ordering of bits within elements `T`.\n- `T`: The type of each memory element in the backing storage region.\n\n# Parameters\n\n- `addr`: The base address of the memory region that the `BitSlice` covers.\n- `head`: The index of the first live bit in `*addr`, at which the `BitSlice`\n  begins. This is required to be in the range `0 .. T::Mem::BITS`.\n- `bits`: The number of live bits, beginning at `head` in `*addr`, that the\n  `BitSlice` contains. This must be no greater than `BitSlice::MAX_BITS`.\n\n# Returns\n\nIf the input parameters are valid, this returns `Some` shared reference to a\n`BitSlice`. The failure conditions causing this to return `None` are:\n\n- `head` is not less than [`T::Mem::BITS`]\n- `bits` is greater than [`BitSlice::<O, T>::MAX_BITS`]\n- `addr` is not adequately aligned to `T`\n- `addr` is so high in the memory space that the region wraps to the base of the\n  memory space\n\n# Safety\n\nThe memory region described by the returned `BitSlice` must be validly allocated\nwithin the caller’s memory management system. It must also not be reachable for\nthe lifetime `'a` by any path other than references derived from the return\nvalue.\n\n[`BitSlice::<O, T>::MAX_BITS`]: struct.BitSlice.html#associatedconstant.MAX_BITS\n[`T::Mem::BITS`]: ../mem/trait.BitMemory.html#associatedconstant.BITS\n[`slice::from_raw_parts_mut`]: https://doc.rust-lang.org/core/slice/fn.from_raw_parts_mut.html\n**/\n#[inline]\npub unsafe fn bits_from_raw_parts_mut<'a, O, T>(\n\taddr: *mut T,\n\thead: u8,\n\tbits: usize,\n) -> Option<&'a mut BitSlice<O, T>>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore + BitMemory,{\n\tlet head = crate::index::BitIdx::new(head)?;\n\tBitPtr::new(addr, head, bits).map(BitPtr::to_bitslice_mut)\n}","Real(LocalPath(\"src/slice.rs\"))"],"slice::iter::<impl std::iter::IntoIterator for &'a mut slice::BitSlice<O, T>>::into_iter":["fn into_iter(self) -> Self::IntoIter{\n\t\tlet (addr, head, bits) = self.alias().bitptr().raw_parts();\n\n\t\tlet addr = addr.to_access()\n\t\t\tas *mut <<T as BitStore>::Alias as BitStore>::Access;\n\t\tlet base = unsafe { NonNull::new_unchecked(addr) };\n\n\t\tlet (elts, tail) = head.offset(bits as isize);\n\t\tlet last = unsafe { NonNull::new_unchecked(addr.offset(elts)) };\n\n\t\tSelf::IntoIter {\n\t\t\tbase,\n\t\t\tlast,\n\t\t\thead,\n\t\t\ttail,\n\t\t\t_ref: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::<impl std::iter::IntoIterator for &'a slice::BitSlice<O, T>>::into_iter":["fn into_iter(self) -> Self::IntoIter{\n\t\tlet (addr, head, bits) = self.bitptr().raw_parts();\n\n\t\tlet addr = addr.to_access() as *mut T::Access;\n\t\tlet base = unsafe { NonNull::new_unchecked(addr) };\n\n\t\tlet (elts, tail) = head.offset(bits as isize);\n\t\tlet last = unsafe { NonNull::new_unchecked(addr.offset(elts)) };\n\n\t\tSelf::IntoIter {\n\t\t\tbase,\n\t\t\tlast,\n\t\t\thead,\n\t\t\ttail,\n\t\t\t_ref: PhantomData,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Chunks":["/** An iterator over a bit slice in (non-overlapping) chunks (`chunk_size` bits\nat a time), starting at the beginning of the slice.\n\nWhen the slice length is not evenly divided by the chunk size, the last slice of\nthe iteration will be the remainder.\n\nThis struct is created by the [`chunks`] method on [bit slices].\n\n# Original\n\n[`slice::Chunks`](https://doc.rust-lang.org/core/slice/struct.Chunks.html)\n\n[bit slices]: struct.BitSlice.html\n[`chunks`]: struct.BitSlice.html#method.chunks\n**/\npub struct Chunks<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a BitSlice<O, T>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Chunks::<'a, O, T>::new":["inline(always)\npub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self{\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExact":["/** An iterator over a bit slice in (non-overlapping) chunks (`chunk_size` bits\nat a time), starting at the beginning of the slice.\n\nWhen the slice len is not evenly divided by the chunk size, the last up to\n`chunk_size - 1` bits will be ommitted but can be retrieved from the\n[`remainder`] function from the iterator.\n\nThis struct is created by the [`chunks_exact`] method on [bit slices].\n\n# Original\n\n[`slice::ChunksExact`](https://doc.rust-lang.org/core/slice/struct.ChunksExact.html)\n\n[bit slices]: struct.BitSlice.html\n[`chunks_exact`]: struct.BitSlice.html#method.chunks_exact\n[`remainder`]: #method.remainder\n**/\npub struct ChunksExact<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a BitSlice<O, T>,\n\t/// Any remnant of the chunked `BitSlice` not divisible by `width`.\n\textra: &'a BitSlice<O, T>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExact::<'a, O, T>::new":["inline(always)\npub(super) fn new(slice: &'a BitSlice<O, T>, width: usize) -> Self{\n\t\tlet len = slice.len();\n\t\tlet rem = len % width;\n\t\tlet (slice, extra) = unsafe { slice.split_at_unchecked(len - rem) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExact::<'a, O, T>::remainder":["/// Returns the remainder of the original bit slice that is not going to be\n/// returned by the iterator. The returned slice has at most `chunk_size-1`\n/// bits.\n///\n/// # Original\n///\n/// [`slice::ChunksExact::remainder`](https://doc.rust-lang.org/core/slice/struct.ChunksExact.html#method.remainder)\npub fn remainder(&self) -> &'a BitSlice<O, T>{\n\t\tself.extra\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExactMut":["/** An iterator over a bit slice in (non-overlapping) mutable chunks\n(`chunk_size` bits at a time), starting at the beginning of the slice.\n\nWhen the slice len is not evenly divided by the chunk size, the last up to\n`chunk_size-1` bits will be omitted but can be retrieved from the\n[`into_remainder`] function from the iterator.\n\nThis struct is created by the [`chunks_exact_mut`] method on [bit slices].\n\n# Original\n\n[`slice::ChunksExactMut`](https://doc.rust-lang.org/core/slice/struct.ChunksExactMut.html)\n\n# API Differences\n\nAll slices yielded from this iterator are marked as aliased.\n\n[bit slices]: struct.BitSlice.html\n[`chunks_exact_mut`]: struct.BitSlice.html#method.chunks_exact_mut\n[`into_remainder`]: #method.into_remainder\n**/\npub struct ChunksExactMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\t/// Any remnant of the chunked `BitSlice` not divisible by `width`.\n\textra: &'a mut BitSlice<O, T::Alias>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExactMut::<'a, O, T>::into_remainder":["/// Returns the remainder of the original slice that is not going to be\n/// returned by the iterator. The returned slice has at most `chunk_size-1`\n/// bits.\n///\n/// # Original\n///\n/// [`slice::ChunksExactMut::into_remainder`](https://doc.rust-lang.org/core/slice/struct.ChunksExactMut.html#method.into_remainder)\n///\n/// # API Differences\n///\n/// The remainder slice, as with all slices yielded from this iterator, is\n/// marked as aliased.\n#[inline]\npub fn into_remainder(self) -> &'a mut BitSlice<O, T::Alias>{\n\t\tself.extra\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksExactMut::<'a, O, T>::new":["inline(always)\npub(super) fn new(slice: &'a mut BitSlice<O, T>, width: usize) -> Self{\n\t\tlet len = slice.len();\n\t\tlet rem = len % width;\n\t\tlet (slice, extra) = unsafe { slice.split_at_unchecked_mut(len - rem) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksMut":["/** An iterator over a bit slice in (non-overlapping) mutable chunks\n(`chunk_size` bits at a time), starting at the beginning of the slice.\n\nWhen the slice len is not evenly divided by the chunk size, the last slice of\nthe iteration will be the remainder.\n\nThis struct is created by the [`chunks_mut`] method on [bit slices].\n\n# Original\n\n[`slice::ChunksMut`](https://doc.rust-lang.org/core/slice/struct.ChunksMut.html)\n\n# API Differences\n\nAll slices yielded from this iterator are marked as aliased.\n\n[bit slices]: struct.BitSlice.html\n[`chunks_mut`]: struct.BitSlice.html#chunks_mut\n**/\npub struct ChunksMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::ChunksMut::<'a, O, T>::new":["inline(always)\npub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self{\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter":["/** Immutable slice iterator\n\nThis struct is created by the [`iter`] method on [`BitSlice`]s.\n\n# Original\n\n[`slice::Iter`](https://doc.rust-lang.org/core/slice/struct.Iter.html)\n\n# Examples\n\nBasic usage:\n\n```rust\n# #[cfg(feature = \"std\")] {\nuse bitvec::prelude::*;\n\n// First, we declare a type which has `iter` method to get the `Iter` struct (&BitSlice here):\nlet data = 129u8;\nlet bits = BitSlice::<Local, _>::from_element(&data);\n\n// Then, we iterato over it:\nfor bit in bits.iter() {\n  println!(\"{}\", bit);\n}\n# }\n```\n\n[`BitSlice`]: struct.BitSlice.html\n[`iter`]: struct.BitSlice.html#method.iter\n**/\npub struct Iter<'a, O, T>\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Address of the element with the first live bit.\n\tbase: NonNull<T::Access>,\n\t/// Address of the element containing the first dead bit.\n\t///\n\t/// This address may or may not be dereferencable, but thanks to a rule in\n\t/// the C++ (and thus LLVM) memory model emplaced specifically to allow\n\t/// double-pointer iteration, creation of an address one element after the\n\t/// end of a live region is required to be legal. It is not required to be\n\t/// equal to a numerically-identical base address of a separate adjoining\n\t/// region, but that is not important here.\n\tlast: NonNull<T::Access>,\n\t/// Semantic index of the first live bit.\n\thead: BitIdx<T::Mem>,\n\t/// Semantic index of the first dead bit after the last live bit. This may\n\t/// be in an element beyond the dereferencable region.\n\t///\n\t/// This is not a `BitTail` because reverse iteration requires a valid\n\t/// index, and the use of a pointer that may point outside the element\n\t/// region has a smoother codepath than the use of an index that may be\n\t/// outside the element.\n\ttail: BitIdx<T::Mem>,\n\t/// `Iter` is semantically equivalent to a `&BitSlice`.\n\t_ref: PhantomData<&'a BitSlice<O, T>>,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter::<'a, O, T>::as_bitslice":["/// Views the underlying data as a subslice of the original data.\n///\n/// This has the same lifetime as the original bit slice, and so the\n/// iterator can continue to be used while this exists.\n///\n/// # Original\n///\n/// [`Iter::as_slice`](https://doc.rust-lang.org/core/slice/struct.Iter.html#method.as_slice)\n///\n/// # API Differences\n///\n/// This is renamed, as its return type is not an element slice `&[T]` or\n/// `&[bool]` but a bit slice.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n///\n/// // First, we declare a type which has the `iter` method to get the `Iter`\n/// // struct (&BitSlice here):\n/// let data = 129u8;\n/// let bits = BitSlice::<Msb0, _>::from_element(&data);\n///\n/// // Then, we get the iterator:\n/// let mut iter = bits.iter();\n/// // So if we print what `as_bitslice` returns here, we have \"[1, 0, 0, 0, 0, 0, 0, 1]\":\n/// println!(\"{:?}\", iter.as_bitslice());\n///\n/// // Next, we move to the second element of the slice:\n/// iter.next();\n/// // Now `as_bitslice` returns \"[0, 0, 0, 0, 0, 0, 1]\":\n/// println!(\"{:?}\", iter.as_bitslice());\n/// # }\n/// ```\n#[inline]\npub fn as_bitslice(&self) -> &'a BitSlice<O, T>{\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(\n\t\t\t\tself.base.as_ptr() as *const T::Access as *const T,\n\t\t\t\tself.head,\n\t\t\t\tself.len(),\n\t\t\t)\n\t\t}\n\t\t.to_bitslice_ref()\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter::<'a, O, T>::as_slice":["#[inline]\n#[doc(hidden)]\n#[deprecated(\n\t\tnote = \"Use `.as_bitslice` on iterators to view the remaining data\"\n\t)]\n#[cfg(not(tarpaulin_include))]\npub fn as_slice(&self) -> &'a BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter::<'a, O, T>::inherent_is_empty":["/// Tests whether the iterator is *any* empty iterator.\npub(crate) fn inherent_is_empty(&self) -> bool{\n\t\t\t\tself.base == self.last && self.head == self.tail\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter::<'a, O, T>::pop_back":["/// Removes the bit at the back of the iterator.\nfn pop_back(&mut self) -> <Self as Iterator>::Item{\n\t\tlet (tail, offset) = self.tail.decr();\n\t\tself.last = unsafe {\n\t\t\tNonNull::new_unchecked(self.last.as_ptr().offset(-(offset as isize)))\n\t\t};\n\t\tself.tail = tail;\n\t\tif unsafe { &*self.last.as_ptr() }.get_bit::<O>(self.tail) {\n\t\t\t&true\n\t\t}\n\t\telse {\n\t\t\t&false\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Iter::<'a, O, T>::pop_front":["/// Removes the bit at the front of the iterator.\nfn pop_front(&mut self) -> <Self as Iterator>::Item{\n\t\tlet out = unsafe { &*self.base.as_ptr() }.get_bit::<O>(self.head);\n\t\tlet (head, incr) = self.head.incr();\n\t\tself.base = unsafe {\n\t\t\tNonNull::new_unchecked(self.base.as_ptr().add(incr as usize))\n\t\t};\n\t\tself.head = head;\n\n\t\tif out { &true } else { &false }\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut":["/** Mutable bit slice iterator.\n\nThis struct is created by the [`iter_mut`] method on [`BitSlice`]s.\n\n# Original\n\n[`slice::IterMut`](https://doc.rust-lang.org/core/slice/struct.IterMut.html)\n\n# API Differences\n\nIn addition to returning `BitMut` instead of `&mut bool`, all references\nproduced from this iterator are marked as aliasing. This is necessary because\nthe references receive the lifetime of the original slice, not of the iterator\nobject, and the iterator is able to produce multiple live references in the same\nscope.\n\n# Examples\n\nBasic usage:\n\n```rust\nuse bitvec::prelude::*;\n// First, we declare a type which has `iter_mut` method to get the `IterMut`\n// struct (&BitSlice here):\nlet mut data = 0u8;\nlet bits = data.view_bits_mut::<Msb0>();\n\n// Then, we iterate over it and modify bits:\nfor (idx, mut bit) in bits.iter_mut().enumerate() {\n  *bit = idx % 3 == 0;\n}\nassert_eq!(data, 0b100_100_10);\n```\n\n[`BitSlice`]: struct.BitSlice.html\n[`iter_mut`]: struct.BitSlice.html#method.iter_mut\n**/\npub struct IterMut<'a, O, T>\nwhere\n\tO: 'a + BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Address of the element with the first live bit.\n\tbase: NonNull<<T::Alias as BitStore>::Access>,\n\t/// Address of the element with the first dead bit. See `Iter.last`.\n\tlast: NonNull<<T::Alias as BitStore>::Access>,\n\t/// Index of the first live bit in `*base`.\n\thead: BitIdx<<T::Alias as BitStore>::Mem>,\n\t/// Index of the first dead bit in `*last`. See `Iter.tail`.\n\ttail: BitIdx<<T::Alias as BitStore>::Mem>,\n\t/// `IterMut` is semantically an aliasing `&mut BitSlice`.\n\t_ref: PhantomData<&'a mut BitSlice<O, T::Alias>>,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut::<'a, O, T>::inherent_is_empty":["/// Tests whether the iterator is *any* empty iterator.\npub(crate) fn inherent_is_empty(&self) -> bool{\n\t\t\t\tself.base == self.last && self.head == self.tail\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut::<'a, O, T>::into_bitslice":["/// Views the underlying data as a subslice of the original data.\n///\n/// To avoid creating `&mut` references that alias the same *bits*, this is\n/// forced to consume the iterator.\n///\n/// # Original\n///\n/// [`IterMut::into_bitslice`](https://doc.rust-lang.org/core/slice/struct.IterMut.html#method.into_bitslice)\n///\n/// # API Differences\n///\n/// This is renamed, as its return type is not an element slice `&mut [T]`\n/// or `&mut [bool]` but a bit slice.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n///\n/// // First, we declare a type which has `iter_mut` method to get the `IterMut`\n/// // struct (&BitSlice here):\n/// let mut data = 0u8;\n/// let bits = data.view_bits_mut::<Lsb0>();\n///\n/// {\n///   // Then, we get the iterator:\n///   let mut iter = bits.iter_mut();\n///   // We move to the next element:\n///   iter.next();\n///   // So if we print what `into_bitslice` method returns here, we have\n///   // \"[0, 0, 0, 0, 0, 0, 0]\":\n///   println!(\"{:?}\", iter.into_bitslice());\n/// }\n///\n/// // Now let's modify a value of the slice:\n/// {\n///   // First we get back the iterator:\n///   let mut iter = bits.iter_mut();\n///   // We change the value of the first bit of the slice returned by the `next` method:\n///   *iter.next().unwrap() = true;\n/// }\n/// // Now data is \"1\":\n/// assert_eq!(data, 1);\n/// # }\npub fn into_bitslice(self) -> &'a mut BitSlice<O, T::Alias>{\n\t\tunsafe {\n\t\t\tBitPtr::new_unchecked(\n\t\t\t\tself.base.as_ptr()\n\t\t\t\t\tas *const <<T as BitStore>::Alias as BitStore>::Access\n\t\t\t\t\tas *const <T as BitStore>::Alias,\n\t\t\t\tself.head,\n\t\t\t\tself.len(),\n\t\t\t)\n\t\t}\n\t\t.to_bitslice_mut()\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut::<'a, O, T>::into_slice":["#[inline]\n#[doc(hidden)]\n#[deprecated(note = \"Use `.into_bitslice` on mutable iterators to view \\\n\t                     the remaining data\")]\n#[cfg(not(tarpaulin_include))]\npub fn into_slice(self) -> &'a mut BitSlice<O, T::Alias>{\n\t\tself.into_bitslice()\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut::<'a, O, T>::pop_back":["/// Removes the bit at the back of the iterator.\nfn pop_back(&mut self) -> <Self as Iterator>::Item{\n\t\tlet (tail, decr) = self.tail.decr();\n\t\tself.last = unsafe {\n\t\t\tNonNull::new_unchecked(self.last.as_ptr().sub(decr as usize))\n\t\t};\n\t\tself.tail = tail;\n\n\t\tunsafe { BitMut::new_unchecked(self.last.as_ptr(), self.tail) }\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::IterMut::<'a, O, T>::pop_front":["/// Removes the bit at the front of the iterator.\nfn pop_front(&mut self) -> <Self as Iterator>::Item{\n\t\tlet out =\n\t\t\tunsafe { BitMut::new_unchecked(self.base.as_ptr(), self.head) };\n\n\t\tlet (head, incr) = self.head.incr();\n\t\tself.base = unsafe {\n\t\t\tNonNull::new_unchecked(self.base.as_ptr().add(incr as usize))\n\t\t};\n\t\tself.head = head;\n\n\t\tout\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunks":["/** An iterator over a bit slice in (non-overlapping) chunks (`chunk_size` bits\nat a time), starting at the end of the slice.\n\nWhen the slice length is not evenly divided by the chunk size, the last slice of\nthe iteration will be the remainder.\n\nThis struct is created by the [`rchunks`] method on [`BitSlice`]s.\n\n# Original\n\n[`slice::RChunks`](https://doc.rust-lang.org/core/slice/struct.RChunks.html)\n\n[`BitSlice`]: struct.BitSlice.html\n[`rchunks`]: struct.BitSlice.html#method.rchunks\n**/\npub struct RChunks<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a BitSlice<O, T>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunks::<'a, O, T>::new":["inline(always)\npub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self{\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExact":["/** An iterator over a bit slice in (non-overlapping) chunks (`chunk_size` bits\nat a time), starting at the end of the slice.\n\nWhen the slice len is not evenly divided by the chunk size, the last up to\n`chunk_size-1` bits will be omitted but can be retrieved from the [`remainder`]\nfunction from the iterator.\n\nThis struct is created by the [`rchunks_exact`] method on [bit slices].\n\n# Original\n\n[`slice::RChunksExact`](https://doc.rust-lang.org/core/slice/struct.RChunksExact.html)\n\n[bit slices]: struct.BitSlice.html\n[`rchunks_exact`]: struct.BitSlice.html#method.rchunks_exact\n[`remainder`]: #method.remainder\n**/\npub struct RChunksExact<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a BitSlice<O, T>,\n\t/// Any remnant of the chunked `BitSlice` not divisible by `width`.\n\textra: &'a BitSlice<O, T>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExact::<'a, O, T>::new":["inline(always)\npub(super) fn new(slice: &'a BitSlice<O, T>, width: usize) -> Self{\n\t\tlet (extra, slice) =\n\t\t\tunsafe { slice.split_at_unchecked(slice.len() % width) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExact::<'a, O, T>::remainder":["/// Returns the remainder of the original slice that is not going to be\n/// returned by the iterator. The returned slice has at most `chunk_size-1`\n/// bits.\n///\n/// # Original\n///\n/// [`slice::RChunksExact::remainder`](https://doc.rust-lang.org/core/slice/struct.RChunksExact.html#method.remainder)\n#[inline]\npub fn remainder(&self) -> &'a BitSlice<O, T>{\n\t\tself.extra\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExactMut":["/** An iterator over a bit slice in (non-overlapping) mutable chunks\n(`chunk_size` bits at a time), starting at the end of the slice.\n\nWhen the slice len is not evenly divided by the chunk size, the last up to\n`chunk_size-1` bits will be omitted but can be retrieved from the\n[`into_remainder`] function from the iterator.\n\nThis struct is created by the [`rchunks_exact_mut`] method on [bit slices].\n\n# Original\n\n[`slice::RChunksExactMut`](https://doc.rust-lang.org/core/slice/struct.RChunksExactMut.html)\n\n# API Differences\n\nAll slices yielded from this iterator are marked as aliased.\n\n[bit slices]: struct.BitSlice.html\n[`into_remainder`]: #method.into_remainder\n[`rchunks_exact_mut`]: struct.BitSlice.html#method.rchunks_exact_mut\n**/\npub struct RChunksExactMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\t/// Any remnant of the chunked `BitSlice` not divisible by `width`.\n\textra: &'a mut BitSlice<O, T::Alias>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExactMut::<'a, O, T>::into_remainder":["/// Returns the remainder of the original slice that is not going to be\n/// returned by the iterator. The returned slice has at most `chunk_size-1`\n/// bits.\n///\n/// # Original\n///\n/// [`slice::RChunksExactMut::into_remainder`](https://doc.rust-lang.org/core/slice/struct.RChunksExactMut.html#method.into_remainder)\n///\n/// # API Differences\n///\n/// The remainder slice, as with all slices yielded from this iterator, is\n/// marked as aliased.\n#[inline]\npub fn into_remainder(self) -> &'a mut BitSlice<O, T::Alias>{\n\t\tself.extra\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksExactMut::<'a, O, T>::new":["inline(always)\npub(super) fn new(slice: &'a mut BitSlice<O, T>, width: usize) -> Self{\n\t\tlet (extra, slice) =\n\t\t\tunsafe { slice.split_at_unchecked_mut(slice.len() % width) };\n\t\tSelf {\n\t\t\tslice,\n\t\t\textra,\n\t\t\twidth,\n\t\t}\n\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksMut":["/** An iterator over a slice in (non-overlapping) mutable chunks (`chunk_size`\nbits at a time), starting at the end of the slice.\n\nWhen the slice length is not evenly divided by the chunk size, the last slice of\nthe iteration will be the remainder.\n\nThis struct is created by the [`rchunks_mut`] method on [bit slices].\n\n# API Differences\n\nAll slices yielded from this iterator are marked as aliased.\n\n[bit slices]: struct.BitSlice.html\n[`rchunks_mut`]: struct.BitSlice.html#method.rchunks_mut\n**/\npub struct RChunksMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being chunked.\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\t/// The width of the produced chunks.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RChunksMut::<'a, O, T>::new":["inline(always)\npub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self{\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplit":["/** An iterator over subslices separated by bits that match a predicate\nfunction, starting from the end of the slice.\n\nThis struct is created by the [`rsplit`] method on [bit slices].\n\n# Original\n\n[`slice::RSplit`](https://doc.rust-lang.org/core/slice/struct.RSplit.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`rsplit`]: struct.BitSlice.html#method.rsplit\n**/\npub struct RSplit<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tslice: &'a BitSlice<O, T>,\n\t/// The function used to test whether a split should occur.\n\tpred: P,\n\t/// Whether the split is finished.\n\tdone: bool,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplit::<'a, O, T, P>::new":["#[inline]\npub(super) fn new(slice: $item, pred: P) -> Self{\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitMut":["/** An iterator over subslices separated by bits that match a predicate\nfunction, starting from the end of the slice.\n\nThis struct is created by the [`rsplit_mut`] method on [bit slices].\n\n# Original\n\n[`slice::RSplit`](https://doc.rust-lang.org/core/slice/struct.RSplit.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`rsplit_mut`]: struct.BitSlice.html#method.rsplit_mut\n**/\npub struct RSplitMut<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\tpred: P,\n\tdone: bool,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitMut::<'a, O, T, P>::new":["#[inline]\npub(super) fn new(slice: $item, pred: P) -> Self{\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitN":["/** An iterator over subslices separated by bits that match a predicate\nfunction, limited to a given number of splits, starting from the end of the\nslice.\n\nThis struct is created by the [`rsplitn`] method on [bit slices].\n\n# Original\n\n[`slice::RSplitN`](https://doc.rust-lang.org/core/slice/struct.RSplitN.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`rsplitn`]: struct.BitSlice.html#method.rsplitn\n**/\npub struct RSplitN<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tinner: RSplit<'a, O, T, P>,\n\t/// The number of splits remaining.\n\tcount: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitN::<'a, O, T, P>::new":["pub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitNMut":["/** An iterator over subslices separated by bits that match a predicate\nfunction, limited to a given number of splits, starting from the end of the\nslice.\n\nThis struct is created by the [`rsplitn_mut`] method on [bit slices].\n\n# Original\n\n[`slice::RSplitNMut`](https://doc.rust-lang.org/core/slice/struct.RSplitNMut.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`rsplitn_mut`]: struct.BitSlice.html#method.rsplitn_mut\n**/\npub struct RSplitNMut<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tinner: RSplitMut<'a, O, T, P>,\n\t/// The number of splits remaining.\n\tcount: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::RSplitNMut::<'a, O, T, P>::new":["pub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Split":["/** An iterator over subslices separated by bits that match a predicate\nfunction.\n\nThis struct is created by the [`split`] method on [bit slices].\n\n# Original\n\n[`slice::Split`](https://doc.rust-lang.org/core/slice/struct.Split.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`split`]: struct.BitSlice.html#method.split\n**/\npub struct Split<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tslice: &'a BitSlice<O, T>,\n\t/// The function used to test whether a split should occur.\n\tpred: P,\n\t/// Whether the split is finished.\n\tdone: bool,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Split::<'a, O, T, P>::new":["#[inline]\npub(super) fn new(slice: $item, pred: P) -> Self{\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitIter":["/// An internal abstraction over the splitting iterators, so that `splitn`,\n/// `splitn_mut`, etc, can be implemented once.\n#[doc(hidden)]\ntrait SplitIter: DoubleEndedIterator {\n\t/// Marks the underlying iterator as complete, extracting the remaining\n\t/// portion of the slice.\n\tfn finish(&mut self) -> Option<Self::Item>;\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitMut":["/** An iterator over the mutable subslices of the slice which are separated by\nbits that match `pred`.\n\nThis struct is created by the [`split_mut`] method on [bit slices].\n\n# Original\n\n[`slice::SplitMut`](https://doc.rust-lang.org/core/slice/struct.SplitMut.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`split_mut`]: struct.BitSlice.html#method.split_mut\n**/\npub struct SplitMut<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\tslice: &'a mut BitSlice<O, T::Alias>,\n\tpred: P,\n\tdone: bool,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitMut::<'a, O, T, P>::new":["#[inline]\npub(super) fn new(slice: $item, pred: P) -> Self{\n\t\t\t\tSelf {\n\t\t\t\t\tslice,\n\t\t\t\t\tpred,\n\t\t\t\t\tdone: false,\n\t\t\t\t}\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitN":["/** An iterator over subslices separated by bits that match a predicate\nfunction, limited to a given number of splits.\n\nThis struct is created by the [`splitn`] method on [bit slices].\n\n# Original\n\n[`slice::SplitN`](https://doc.rust-lang.org/core/slice/struct.SplitN.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`splitn`]: struct.BitSlice.html#method.splitn\n**/\npub struct SplitN<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tinner: Split<'a, O, T, P>,\n\t/// The number of splits remaining.\n\tcount: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitN::<'a, O, T, P>::new":["pub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitNMut":["/** An iterator over subslices separated by bits that match a predicate\nfunction, limited to a given number of splits.\n\nThis struct is created by the [`splitn_mut`] method on [bit slices].\n\n# Original\n\n[`slice::SplitNMut`](https://doc.rust-lang.org/core/slice/struct.SplitNMut.html)\n\n# API Differences\n\nIn order to allow more than one bit of information for the split decision, the\npredicate receives the index of each bit, as well as its value.\n\n[bit slices]: struct.BitSlice.html\n[`splitn_mut`]: struct.BitSlice.html#method.splitn_mut\n**/\npub struct SplitNMut<'a, O, T, P>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tP: FnMut(usize, &bool) -> bool,\n{\n\t/// The `BitSlice` being split.\n\tinner: SplitMut<'a, O, T, P>,\n\t/// The number of splits remaining.\n\tcount: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::SplitNMut::<'a, O, T, P>::new":["pub(super) fn new(\n\t\t\t\tslice: $item,\n\t\t\t\tpred: P,\n\t\t\t\tcount: usize,\n\t\t\t) -> Self{Self{\n\t\t\t\tinner: <$inner<'a, O, T, P>>::new(slice, pred),\n\t\t\t\tcount,\n\t\t\t}}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Windows":["/** An iterator over overlapping subslices of length `size`.\n\nThis struct is created by the [`windows`] method on [bit slices].\n\n# Original\n\n[`slice::Windows`](https://doc.rust-lang.org/core/slice/struct.Windows.html)\n\n[bit slices]: struct.BitSlice.html\n[`windows`]: struct.BitSlice.html#method.windows\n**/\npub struct Windows<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// The `BitSlice` being windowed.\n\tslice: &'a BitSlice<O, T>,\n\t/// The width of the produced windows.\n\twidth: usize,\n}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::iter::Windows::<'a, O, T>::new":["inline(always)\npub(super) fn new(\n\t\t\t\tslice: &'a $($m)? BitSlice<O, T>,\n\t\t\t\twidth: usize,\n\t\t\t) -> Self{\n\t\t\t\tSelf { slice: slice $( . $a () )?, width }\n\t\t\t}","Real(LocalPath(\"src/slice/iter.rs\"))"],"slice::ops::<impl std::ops::BitAndAssign<Rhs> for slice::BitSlice<O, T>>::bitand_assign":["fn bitand_assign(&mut self, rhs: Rhs){\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit & iter.next().unwrap_or(false));\n\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::BitOrAssign<Rhs> for slice::BitSlice<O, T>>::bitor_assign":["fn bitor_assign(&mut self, rhs: Rhs){\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit | iter.next().unwrap_or(false));\n\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::BitXorAssign<Rhs> for slice::BitSlice<O, T>>::bitxor_assign":["fn bitxor_assign(&mut self, rhs: Rhs){\n\t\tlet mut iter = rhs.into_iter();\n\t\tself.for_each(|_, bit| bit ^ iter.next().unwrap_or(false));\n\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::RangeFull> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index":["fn index(&self, index: $t) -> &Self::Output{\n\t\t\t\tindex.index(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Index<usize> for slice::BitSlice<O, T>>::index":["/// Looks up a single bit by semantic index.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = bits![Msb0, u8; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0];\n/// assert!(!bits[7]); // --------------------------^  |  |\n/// assert!( bits[8]); // -----------------------------^  |\n/// assert!(!bits[9]); // --------------------------------^\n/// ```\n///\n/// If the index is greater than or equal to the length, indexing will\n/// panic.\n///\n/// The below test will panic when accessing index 1, as only index 0 is\n/// valid.\n///\n/// ```rust,should_panic\n/// use bitvec::prelude::*;\n///\n/// let bits = bits![0,  ];\n/// bits[1]; // --------^\n/// ```\nfn index(&self, index: usize) -> &Self::Output{\n\t\tindex.index(self)\n\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFull> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["fn index_mut(&mut self, index: $t) -> &mut Self::Output{\n\t\t\t\tindex.index_mut(self)\n\t\t\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::ops::<impl std::ops::Not for &'a mut slice::BitSlice<O, T>>::not":["fn not(self) -> Self::Output{\n\t\tmatch self.domain_mut() {\n\t\t\tDomainMut::Enclave { head, elem, tail } => elem\n\t\t\t\t.pipe(dvl::accessor)\n\t\t\t\t.invert_bits(dvl::alias_mask::<T>(O::mask(head, tail))),\n\t\t\tDomainMut::Region { head, body, tail } => {\n\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\telem.pipe(dvl::accessor)\n\t\t\t\t\t\t.invert_bits(dvl::alias_mask::<T>(O::mask(head, None)));\n\t\t\t\t}\n\t\t\t\tfor elem in body {\n\t\t\t\t\t*elem = !*elem;\n\t\t\t\t}\n\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\telem.pipe(dvl::accessor)\n\t\t\t\t\t\t.invert_bits(dvl::alias_mask::<T>(O::mask(None, tail)));\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t\tself\n\t}","Real(LocalPath(\"src/slice/ops.rs\"))"],"slice::proxy::BitMut":["/** Proxy reference type, equivalent to `&mut bool`.\n\nThis is a two-word structure capable of correctly referring to a single bit in\na memory element. Because Rust does not permit reference-like objects in the\nsame manner that C++ does – `&T` and `&mut T` values are required to be\nimmediately-valid pointers, not objects – `bitvec` cannot manifest encoded\n`&mut Bit` values in the same way that it can manifest `&mut BitSlice`.\n\nInstead, this type implements `Deref` and `DerefMut` to an internal `bool` slot,\nand in `Drop` commits the value of that `bool` to the proxied bit in the source\n`BitSlice` from which the `BitMut` value was created. The combination of Rust’s\nown exclusion rules and the aliasing type system in this library ensure that a\n`BitMut` value has unique access to the bit it proxies, and the memory element\nit uses will not have destructive data races from other views.\n\n# Lifetimes\n\n- `'a`: The lifetime of the source `&'a mut BitSlice` that created the `BitMut`.\n\n# Type Parameters\n\n- `O`: The `BitOrder` type parameter from the source `&mut BitSlice`.\n- `T`: The `BitStore` type parameter from the source `&mut BitSlice`.\n\n# Examples\n\n```rust\nuse bitvec::prelude::*;\n\nlet bits = bits![mut 0; 2];\n\nlet (left, right) = bits.split_at_mut(1);\nlet mut first = left.get_mut(0).unwrap();\nlet second = right.get_mut(0).unwrap();\n\n// Referential behavior\n*first = true;\n// Direct write\nsecond.set(true);\n\ndrop(first); // it’s not a reference!\nassert_eq!(bits, bits![1; 2]);\n```\n**/\npub struct BitMut<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Accessing pointer to the containing element.\n\taddr: NonNull<T::Access>,\n\t/// Index of the proxied bit within the containing element.\n\thead: BitIdx<T::Mem>,\n\t/// A local cache for `Deref` usage.\n\tdata: bool,\n\t/// This type is semantically equivalent to a mutable slice of length 1.\n\t_ref: PhantomData<&'a mut BitSlice<O, T>>,\n}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"slice::proxy::BitMut::<'_, O, T>::new_unchecked":["/// Constructs a new proxy from provided element and bit addresses.\n///\n/// # Parameters\n///\n/// - `addr`: The address of a memory element, correctly typed for access.\n/// - `head`: The index of a bit within `*addr`.\n///\n/// # Safety\n///\n/// The caller must produce `addr`’s value from a valid reference, and its\n/// type from the correct access requirements at time of construction.\n#[inline]\npub(crate) unsafe fn new_unchecked(\n\t\taddr: *const T::Access,\n\t\thead: BitIdx<T::Mem>,\n\t) -> Self{\n\t\tSelf {\n\t\t\t_ref: PhantomData,\n\t\t\taddr: NonNull::new_unchecked(addr as *mut T::Access),\n\t\t\thead,\n\t\t\tdata: (&*addr).get_bit::<O>(head),\n\t\t}\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"slice::proxy::BitMut::<'_, O, T>::set":["/// Writes a bit into the proxied location without an intermediate copy.\n///\n/// This function writes `value` directly into the proxied location, and\n/// does not store `value` in the proxy’s internal cache. This should be\n/// equivalent to the behavior seen when using ordinary `DerefMut` proxying,\n/// but the latter depends on compiler optimization.\n///\n/// # Parameters\n///\n/// - `self`: This destroys the proxy, as it becomes invalid when writing\n///   directly to the location without updating the cache.\n/// - `value`: The new bit to write into the proxied slot.\n#[inline]\npub fn set(mut self, value: bool){\n\t\tself.write(value);\n\t\tmem::forget(self);\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"slice::proxy::BitMut::<'_, O, T>::write":["/// Commits a bit into memory.\n///\n/// This is the internal function used to drive `.set()` and `.drop()`.\n#[inline]\nfn write(&mut self, value: bool){\n\t\tunsafe { (&*self.addr.as_ptr()).write_bit::<O>(self.head, value) }\n\t}","Real(LocalPath(\"src/slice/proxy.rs\"))"],"slice::traits::<impl std::borrow::ToOwned for slice::BitSlice<O, T>>::to_owned":["#[inline]\nfn to_owned(&self) -> Self::Owned{\n\t\tBitVec::from_bitslice(self)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::Ord for slice::BitSlice<O, T>>::cmp":["#[inline]\nfn cmp(&self, rhs: &Self) -> cmp::Ordering{\n\t\tself.partial_cmp(rhs)\n\t\t\t.expect(\"BitSlice has a total ordering\")\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialEq<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, rhs: &&mut BitSlice<O2, T2>) -> bool{\n\t\t*self == **rhs\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialEq<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, rhs: &&BitSlice<O2, T2>) -> bool{\n\t\t*self == **rhs\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, rhs: &BitSlice<O2, T2>) -> bool{\n\t\t**self == rhs\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, rhs: &BitSlice<O2, T2>) -> bool{\n\t\t**self == rhs\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["fn eq(&self, rhs: &BitSlice<O2, T2>) -> bool{\n\t\tself.len() == rhs.len()\n\t\t\t&& self.iter().zip(rhs.iter()).all(|(l, r)| l == r)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &&mut BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(**self).partial_cmp(&**rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &&mut BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(*self).partial_cmp(&**rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &&BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(**self).partial_cmp(&**rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &&BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(*self).partial_cmp(&**rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(**self).partial_cmp(rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, rhs: &BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\t(*self).partial_cmp(rhs)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["fn partial_cmp(&self, rhs: &BitSlice<O2, T2>) -> Option<cmp::Ordering>{\n\t\tfor (l, r) in self.iter().zip(rhs.iter()) {\n\t\t\tmatch (l, r) {\n\t\t\t\t(true, false) => return Some(cmp::Ordering::Greater),\n\t\t\t\t(false, true) => return Some(cmp::Ordering::Less),\n\t\t\t\t_ => continue,\n\t\t\t}\n\t\t}\n\t\tself.len().partial_cmp(&rhs.len())\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::convert::TryFrom<&'a [T]> for &'a slice::BitSlice<O, T>>::try_from":["#[inline]\nfn try_from(slice: &'a [T]) -> Result<Self, Self::Error>{\n\t\tBitSlice::from_slice(slice).ok_or(slice)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::default::Default for &mut slice::BitSlice<O, T>>::default":["#[inline]\nfn default() -> Self{\n\t\tBitSlice::empty_mut()\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::default::Default for &slice::BitSlice<O, T>>::default":["#[inline]\nfn default() -> Self{\n\t\tBitSlice::empty()\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t/// Renders an accumulated text buffer as UTF-8.\n\t\t\t\tstruct Seq<'a>(&'a [u8]);\n\t\t\t\timpl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//  If the alternate flag is set, include the radix prefix.\n\t\t\t\tlet start = if fmt.alternate() { 0 } else { 2 };\n\t\t\t\t//  Create a list format accumulator.\n\t\t\t\tlet mut dbg = fmt.debug_list();\n\t\t\t\t/* Create a static buffer of the maximum number of UTF-8 bytes\n\t\t\t\tneeded to render a `usize` in the selected radix. Rust does not\n\t\t\t\tyet grant access to trait constants for use in constant\n\t\t\t\texpressions within generics.\n\t\t\t\t*/\n\t\t\t\tlet mut w: [u8; (usize::BITS as usize / $blksz) + 2] =\n\t\t\t\t\t[b'0'; (usize::BITS as usize / $blksz) + 2];\n\t\t\t\t//  Write the prefix symbol into the buffer.\n\t\t\t\tw[1] = $pfx;\n\t\t\t\t//  This closure does the main work of rendering a bit slice as\n\t\t\t\t//  text. It will be called on each memory element of the slice\n\t\t\t\t//  undergoing formatting.\n\t\t\t\tlet mut writer = |bits: &BitSlice<O, T::Mem>| {\n\t\t\t\t\t//  Set the end index of the format buffer.\n\t\t\t\t\tlet mut end = 2;\n\t\t\t\t\t/* Taking `rchunks` clusters the bits to the right edge, so\n\t\t\t\t\tthat any remainder is in the left-most (first-rendered)\n\t\t\t\t\tdigit, in the same manner as how English clusters digits in\n\t\t\t\t\tordinary writing.\n\n\t\t\t\t\tSince `rchunks` takes from the back, it must be reversed in\n\t\t\t\t\torder to traverse from front to back. The enumeration\n\t\t\t\t\tprovides the offset from the buffer start for writing the\n\t\t\t\t\tcomputed digit into the format buffer.\n\t\t\t\t\t*/\n\t\t\t\t\tfor (index, chunk) in bits.rchunks($blksz).rev().enumerate()\n\t\t\t\t\t{\n\t\t\t\t\t\t//  Accumulate an Lsb0 representation of the slice\n\t\t\t\t\t\t//  contents.\n\t\t\t\t\t\tlet mut val = 0u8;\n\t\t\t\t\t\tfor bit in chunk {\n\t\t\t\t\t\t\tval <<= 1;\n\t\t\t\t\t\t\tval |= *bit as u8;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//  Translate the accumulator into ASCII hexadecimal\n\t\t\t\t\t\t//  glyphs, and write the glyph into the format buffer.\n\t\t\t\t\t\tw[2 + index] = match val {\n\t\t\t\t\t\t\tv @ 0 ..= 9 => b'0' + v,\n\t\t\t\t\t\t\tv @ 10 ..= 16 => $base + (v - 10),\n\t\t\t\t\t\t\t_ => unsafe { core::hint::unreachable_unchecked() },\n\t\t\t\t\t\t};\n\t\t\t\t\t\tend += 1;\n\t\t\t\t\t}\n\t\t\t\t\t//  View the format buffer as UTF-8 and write it into the\n\t\t\t\t\t//  main formatter.\n\t\t\t\t\tdbg.entry(&Seq(&w[start .. end]));\n\t\t\t\t};\n\t\t\t\t//  Break the source `BitSlice` into its element-wise components.\n\t\t\t\tmatch self.domain() {\n\t\t\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t\t\t//  Load a copy of `*elem` into the stack,\n\t\t\t\t\t\tlet tmp: T::Mem =\n\t\t\t\t\t\t\telem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t//  View it as a `BitSlice` over the whole element,\n\t\t\t\t\t\t// narrow it to the live range, and render it.\n\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\tbits.get_unchecked(\n\t\t\t\t\t\t\t\thead.value() as usize .. tail.value() as usize,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t.pipe(writer);\n\t\t\t\t\t},\n\t\t\t\t\t//  Same process as above, but with different truncations.\n\t\t\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(head.value() as usize ..)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor elem in body.iter() {\n\t\t\t\t\t\t\telem.pipe(BitSlice::<O, T::Mem>::from_element)\n\t\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(.. tail.value() as usize)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tdbg.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq":["/// Renders an accumulated text buffer as UTF-8.\nstruct Seq<'a>(&'a [u8]);","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Debug for slice::BitSlice<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tif fmt.alternate() {\n\t\t\tPointer::fmt(self, fmt)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tBinary::fmt(self, fmt)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Display for slice::BitSlice<O, T>>::fmt":["#[inline(always)]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tBinary::fmt(self, fmt)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t/// Renders an accumulated text buffer as UTF-8.\n\t\t\t\tstruct Seq<'a>(&'a [u8]);\n\t\t\t\timpl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//  If the alternate flag is set, include the radix prefix.\n\t\t\t\tlet start = if fmt.alternate() { 0 } else { 2 };\n\t\t\t\t//  Create a list format accumulator.\n\t\t\t\tlet mut dbg = fmt.debug_list();\n\t\t\t\t/* Create a static buffer of the maximum number of UTF-8 bytes\n\t\t\t\tneeded to render a `usize` in the selected radix. Rust does not\n\t\t\t\tyet grant access to trait constants for use in constant\n\t\t\t\texpressions within generics.\n\t\t\t\t*/\n\t\t\t\tlet mut w: [u8; (usize::BITS as usize / $blksz) + 2] =\n\t\t\t\t\t[b'0'; (usize::BITS as usize / $blksz) + 2];\n\t\t\t\t//  Write the prefix symbol into the buffer.\n\t\t\t\tw[1] = $pfx;\n\t\t\t\t//  This closure does the main work of rendering a bit slice as\n\t\t\t\t//  text. It will be called on each memory element of the slice\n\t\t\t\t//  undergoing formatting.\n\t\t\t\tlet mut writer = |bits: &BitSlice<O, T::Mem>| {\n\t\t\t\t\t//  Set the end index of the format buffer.\n\t\t\t\t\tlet mut end = 2;\n\t\t\t\t\t/* Taking `rchunks` clusters the bits to the right edge, so\n\t\t\t\t\tthat any remainder is in the left-most (first-rendered)\n\t\t\t\t\tdigit, in the same manner as how English clusters digits in\n\t\t\t\t\tordinary writing.\n\n\t\t\t\t\tSince `rchunks` takes from the back, it must be reversed in\n\t\t\t\t\torder to traverse from front to back. The enumeration\n\t\t\t\t\tprovides the offset from the buffer start for writing the\n\t\t\t\t\tcomputed digit into the format buffer.\n\t\t\t\t\t*/\n\t\t\t\t\tfor (index, chunk) in bits.rchunks($blksz).rev().enumerate()\n\t\t\t\t\t{\n\t\t\t\t\t\t//  Accumulate an Lsb0 representation of the slice\n\t\t\t\t\t\t//  contents.\n\t\t\t\t\t\tlet mut val = 0u8;\n\t\t\t\t\t\tfor bit in chunk {\n\t\t\t\t\t\t\tval <<= 1;\n\t\t\t\t\t\t\tval |= *bit as u8;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//  Translate the accumulator into ASCII hexadecimal\n\t\t\t\t\t\t//  glyphs, and write the glyph into the format buffer.\n\t\t\t\t\t\tw[2 + index] = match val {\n\t\t\t\t\t\t\tv @ 0 ..= 9 => b'0' + v,\n\t\t\t\t\t\t\tv @ 10 ..= 16 => $base + (v - 10),\n\t\t\t\t\t\t\t_ => unsafe { core::hint::unreachable_unchecked() },\n\t\t\t\t\t\t};\n\t\t\t\t\t\tend += 1;\n\t\t\t\t\t}\n\t\t\t\t\t//  View the format buffer as UTF-8 and write it into the\n\t\t\t\t\t//  main formatter.\n\t\t\t\t\tdbg.entry(&Seq(&w[start .. end]));\n\t\t\t\t};\n\t\t\t\t//  Break the source `BitSlice` into its element-wise components.\n\t\t\t\tmatch self.domain() {\n\t\t\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t\t\t//  Load a copy of `*elem` into the stack,\n\t\t\t\t\t\tlet tmp: T::Mem =\n\t\t\t\t\t\t\telem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t//  View it as a `BitSlice` over the whole element,\n\t\t\t\t\t\t// narrow it to the live range, and render it.\n\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\tbits.get_unchecked(\n\t\t\t\t\t\t\t\thead.value() as usize .. tail.value() as usize,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t.pipe(writer);\n\t\t\t\t\t},\n\t\t\t\t\t//  Same process as above, but with different truncations.\n\t\t\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(head.value() as usize ..)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor elem in body.iter() {\n\t\t\t\t\t\t\telem.pipe(BitSlice::<O, T::Mem>::from_element)\n\t\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(.. tail.value() as usize)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tdbg.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq":["/// Renders an accumulated text buffer as UTF-8.\nstruct Seq<'a>(&'a [u8]);","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t/// Renders an accumulated text buffer as UTF-8.\n\t\t\t\tstruct Seq<'a>(&'a [u8]);\n\t\t\t\timpl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//  If the alternate flag is set, include the radix prefix.\n\t\t\t\tlet start = if fmt.alternate() { 0 } else { 2 };\n\t\t\t\t//  Create a list format accumulator.\n\t\t\t\tlet mut dbg = fmt.debug_list();\n\t\t\t\t/* Create a static buffer of the maximum number of UTF-8 bytes\n\t\t\t\tneeded to render a `usize` in the selected radix. Rust does not\n\t\t\t\tyet grant access to trait constants for use in constant\n\t\t\t\texpressions within generics.\n\t\t\t\t*/\n\t\t\t\tlet mut w: [u8; (usize::BITS as usize / $blksz) + 2] =\n\t\t\t\t\t[b'0'; (usize::BITS as usize / $blksz) + 2];\n\t\t\t\t//  Write the prefix symbol into the buffer.\n\t\t\t\tw[1] = $pfx;\n\t\t\t\t//  This closure does the main work of rendering a bit slice as\n\t\t\t\t//  text. It will be called on each memory element of the slice\n\t\t\t\t//  undergoing formatting.\n\t\t\t\tlet mut writer = |bits: &BitSlice<O, T::Mem>| {\n\t\t\t\t\t//  Set the end index of the format buffer.\n\t\t\t\t\tlet mut end = 2;\n\t\t\t\t\t/* Taking `rchunks` clusters the bits to the right edge, so\n\t\t\t\t\tthat any remainder is in the left-most (first-rendered)\n\t\t\t\t\tdigit, in the same manner as how English clusters digits in\n\t\t\t\t\tordinary writing.\n\n\t\t\t\t\tSince `rchunks` takes from the back, it must be reversed in\n\t\t\t\t\torder to traverse from front to back. The enumeration\n\t\t\t\t\tprovides the offset from the buffer start for writing the\n\t\t\t\t\tcomputed digit into the format buffer.\n\t\t\t\t\t*/\n\t\t\t\t\tfor (index, chunk) in bits.rchunks($blksz).rev().enumerate()\n\t\t\t\t\t{\n\t\t\t\t\t\t//  Accumulate an Lsb0 representation of the slice\n\t\t\t\t\t\t//  contents.\n\t\t\t\t\t\tlet mut val = 0u8;\n\t\t\t\t\t\tfor bit in chunk {\n\t\t\t\t\t\t\tval <<= 1;\n\t\t\t\t\t\t\tval |= *bit as u8;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//  Translate the accumulator into ASCII hexadecimal\n\t\t\t\t\t\t//  glyphs, and write the glyph into the format buffer.\n\t\t\t\t\t\tw[2 + index] = match val {\n\t\t\t\t\t\t\tv @ 0 ..= 9 => b'0' + v,\n\t\t\t\t\t\t\tv @ 10 ..= 16 => $base + (v - 10),\n\t\t\t\t\t\t\t_ => unsafe { core::hint::unreachable_unchecked() },\n\t\t\t\t\t\t};\n\t\t\t\t\t\tend += 1;\n\t\t\t\t\t}\n\t\t\t\t\t//  View the format buffer as UTF-8 and write it into the\n\t\t\t\t\t//  main formatter.\n\t\t\t\t\tdbg.entry(&Seq(&w[start .. end]));\n\t\t\t\t};\n\t\t\t\t//  Break the source `BitSlice` into its element-wise components.\n\t\t\t\tmatch self.domain() {\n\t\t\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t\t\t//  Load a copy of `*elem` into the stack,\n\t\t\t\t\t\tlet tmp: T::Mem =\n\t\t\t\t\t\t\telem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t//  View it as a `BitSlice` over the whole element,\n\t\t\t\t\t\t// narrow it to the live range, and render it.\n\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\tbits.get_unchecked(\n\t\t\t\t\t\t\t\thead.value() as usize .. tail.value() as usize,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t.pipe(writer);\n\t\t\t\t\t},\n\t\t\t\t\t//  Same process as above, but with different truncations.\n\t\t\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(head.value() as usize ..)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor elem in body.iter() {\n\t\t\t\t\t\t\telem.pipe(BitSlice::<O, T::Mem>::from_element)\n\t\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(.. tail.value() as usize)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tdbg.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq":["/// Renders an accumulated text buffer as UTF-8.\nstruct Seq<'a>(&'a [u8]);","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::Pointer for slice::BitSlice<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Slice\", Some(any::type_name::<O>()), None)\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt":["fn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\t\t\t/// Renders an accumulated text buffer as UTF-8.\n\t\t\t\tstruct Seq<'a>(&'a [u8]);\n\t\t\t\timpl Debug for Seq<'_> {\n\t\t\t\t\tfn fmt(&self, fmt: &mut Formatter) -> fmt::Result {\n\t\t\t\t\t\tfmt.write_str(unsafe {\n\t\t\t\t\t\t\tstr::from_utf8_unchecked(self.0)\n\t\t\t\t\t\t})\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//  If the alternate flag is set, include the radix prefix.\n\t\t\t\tlet start = if fmt.alternate() { 0 } else { 2 };\n\t\t\t\t//  Create a list format accumulator.\n\t\t\t\tlet mut dbg = fmt.debug_list();\n\t\t\t\t/* Create a static buffer of the maximum number of UTF-8 bytes\n\t\t\t\tneeded to render a `usize` in the selected radix. Rust does not\n\t\t\t\tyet grant access to trait constants for use in constant\n\t\t\t\texpressions within generics.\n\t\t\t\t*/\n\t\t\t\tlet mut w: [u8; (usize::BITS as usize / $blksz) + 2] =\n\t\t\t\t\t[b'0'; (usize::BITS as usize / $blksz) + 2];\n\t\t\t\t//  Write the prefix symbol into the buffer.\n\t\t\t\tw[1] = $pfx;\n\t\t\t\t//  This closure does the main work of rendering a bit slice as\n\t\t\t\t//  text. It will be called on each memory element of the slice\n\t\t\t\t//  undergoing formatting.\n\t\t\t\tlet mut writer = |bits: &BitSlice<O, T::Mem>| {\n\t\t\t\t\t//  Set the end index of the format buffer.\n\t\t\t\t\tlet mut end = 2;\n\t\t\t\t\t/* Taking `rchunks` clusters the bits to the right edge, so\n\t\t\t\t\tthat any remainder is in the left-most (first-rendered)\n\t\t\t\t\tdigit, in the same manner as how English clusters digits in\n\t\t\t\t\tordinary writing.\n\n\t\t\t\t\tSince `rchunks` takes from the back, it must be reversed in\n\t\t\t\t\torder to traverse from front to back. The enumeration\n\t\t\t\t\tprovides the offset from the buffer start for writing the\n\t\t\t\t\tcomputed digit into the format buffer.\n\t\t\t\t\t*/\n\t\t\t\t\tfor (index, chunk) in bits.rchunks($blksz).rev().enumerate()\n\t\t\t\t\t{\n\t\t\t\t\t\t//  Accumulate an Lsb0 representation of the slice\n\t\t\t\t\t\t//  contents.\n\t\t\t\t\t\tlet mut val = 0u8;\n\t\t\t\t\t\tfor bit in chunk {\n\t\t\t\t\t\t\tval <<= 1;\n\t\t\t\t\t\t\tval |= *bit as u8;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//  Translate the accumulator into ASCII hexadecimal\n\t\t\t\t\t\t//  glyphs, and write the glyph into the format buffer.\n\t\t\t\t\t\tw[2 + index] = match val {\n\t\t\t\t\t\t\tv @ 0 ..= 9 => b'0' + v,\n\t\t\t\t\t\t\tv @ 10 ..= 16 => $base + (v - 10),\n\t\t\t\t\t\t\t_ => unsafe { core::hint::unreachable_unchecked() },\n\t\t\t\t\t\t};\n\t\t\t\t\t\tend += 1;\n\t\t\t\t\t}\n\t\t\t\t\t//  View the format buffer as UTF-8 and write it into the\n\t\t\t\t\t//  main formatter.\n\t\t\t\t\tdbg.entry(&Seq(&w[start .. end]));\n\t\t\t\t};\n\t\t\t\t//  Break the source `BitSlice` into its element-wise components.\n\t\t\t\tmatch self.domain() {\n\t\t\t\t\tDomain::Enclave { head, elem, tail } => {\n\t\t\t\t\t\t//  Load a copy of `*elem` into the stack,\n\t\t\t\t\t\tlet tmp: T::Mem =\n\t\t\t\t\t\t\telem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t//  View it as a `BitSlice` over the whole element,\n\t\t\t\t\t\t// narrow it to the live range, and render it.\n\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\tbits.get_unchecked(\n\t\t\t\t\t\t\t\thead.value() as usize .. tail.value() as usize,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t\t.pipe(writer);\n\t\t\t\t\t},\n\t\t\t\t\t//  Same process as above, but with different truncations.\n\t\t\t\t\tDomain::Region { head, body, tail } => {\n\t\t\t\t\t\tif let Some((head, elem)) = head {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(head.value() as usize ..)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor elem in body.iter() {\n\t\t\t\t\t\t\telem.pipe(BitSlice::<O, T::Mem>::from_element)\n\t\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif let Some((elem, tail)) = tail {\n\t\t\t\t\t\t\tlet tmp = elem.pipe(dvl::load_aliased_local::<T>);\n\t\t\t\t\t\t\tlet bits = tmp.view_bits::<O>();\n\t\t\t\t\t\t\tunsafe {\n\t\t\t\t\t\t\t\tbits.get_unchecked(.. tail.value() as usize)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t.pipe(&mut writer);\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\t\t\t\t}\n\t\t\t\tdbg.finish()\n\t\t\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq":["/// Renders an accumulated text buffer as UTF-8.\nstruct Seq<'a>(&'a [u8]);","Real(LocalPath(\"src/slice/traits.rs\"))"],"slice::traits::<impl std::hash::Hash for slice::BitSlice<O, T>>::hash":["#[inline]\nfn hash<H>(&self, hasher: &mut H)\n\twhere H: Hasher{\n\t\tfor bit in self {\n\t\t\thasher.write_u8(*bit as u8);\n\t\t}\n\t}","Real(LocalPath(\"src/slice/traits.rs\"))"],"store::BitStore":["/** Common interface for memory regions.\n\nThis trait is implemented on the fundamental integers, their `Cell` wrappers,\nand (if present) their `Atomic` variants. Users provide this type as a parameter\nto their data structures in order to inform the structure of how it may access\nthe memory it describes.\n\nSpecifically, this has the davantage that a `BitSlice<_, Cell<_>>` knows that it\nhas a view of memory that will not undergo concurrent modification. As such, it\ncan forego atomic accesses, and just use ordinary load/store instructions\nwithout fear of causing observable race conditions.\n\nThe associated types `Mem` and `Alias` allow implementors to know the register\nwidth of the memory they describe (`Mem`) and to know the aliasing status of the\nregion.\n\n# Generic Programming\n\nGeneric programming with associated types is *hard*, especially when using them,\nas in this trait, to implement a closed graph of relationships between types.\n\nFor example, this trait is implemented such that for any given type `T`,\n`T::Alias::Mem` == `T::Mem` == `T::NoAlias::Mem`, `T::Alias::Alias == T::Alias`,\nand `T::NoAlias::NoAlias == T::NoAlias`. Unfortunately, the Rust type system\ndoes not allow these relationships to be described, so generic programming that\nperforms type transitions will *rapidly* become uncomfortable to use.\n\nInternally, `bitvec` makes use of type-manipulation functions that are known to\nbe correct with respect to the implementations of `BitStore` in order to ease\nimplementation of library methods.\n\nYou are not expected to do significant programming that is generic over the\n`BitStore` memory parameter. When using a concrete type, the compiler will\ngladly reduce the abstract type associations into their instantiated selections,\nallowing monomorphized code to be *much* more convenient than generic.\n\nIf you have a use case that involves generic programming over this trait, and\nyou are encountering difficulties dealing with the type associations, please\nfile an issue asking for support in this area.\n\n# Supertraits\n\nThis trait has trait requirements that better express its behavior:\n\n- `Sealed` prevents it from being implemented by downstream libraries (`Sealed`\n  is a public trait in a private module, that only this crate can name).\n- `Sized` instructs the compiler that values of this type can be used as\n  immediates.\n- `Debug` informs the compiler that other structures using this trait bound can\n  correctly derive `Debug`.\n  **/\npub trait BitStore: seal::Sealed + Sized + Debug {\n\t/// The register type that the implementor describes.\n\ttype Mem: BitMemory + Into<Self> + BitStore;\n\n\t/// The modifier type over `Self::Mem` used to perform memory access.\n\ttype Access: BitAccess<Self::Mem>;\n\n\t/// A sibling `BitStore` implementor that performs alias-aware memory\n\t/// access.\n\t///\n\t/// While the associated type always has the same `Mem` concrete type as\n\t/// `Self`, attempting to encode this requirement as `<Mem = Self::Mem>\n\t/// causes Rust to enter an infinite recursion in the trait solver.\n\t///\n\t/// Instead, the two `Radium` bounds inform the compiler that the `Alias` is\n\t/// irradiant over both the current memory and the destination memory types,\n\t/// allowing generic type algebra to resolve correctly even though the fact\n\t/// that `Radium` is only implemented once is not guaranteed.\n\ttype Alias: BitStore\n\t\t+ Radium<Self::Mem>\n\t\t+ Radium<<Self::Alias as BitStore>::Mem>;\n\n\t/// Marker for the thread safety of the implementor.\n\t///\n\t/// This is necessary because `Cell<T: Send>` is `Send`, but `Cell` does not\n\t/// use synchronization instructions and thus cannot be used for aliased\n\t/// parallelized memory manipulation.\n\t#[doc(hidden)]\n\ttype Threadsafe;\n\n\t/// Require that all implementors are aligned to their width.\n\t#[doc(hidden)]\n\tconst __ALIGNED_TO_SIZE: [(); 0];\n\n\t/// Require that the `::Alias` associated type has the same width and\n\t/// alignment as `Self`.\n\t#[doc(hidden)]\n\tconst __ALIAS_WIDTH: [(); 0];\n}","Real(LocalPath(\"src/store.rs\"))"],"store::seal::Sealed":["/// Marker trait to seal `BitStore` against downstream implementation.\n///\n/// This trait is public in the module, so that other modules in the crate\n/// can use it, but so long as it is not exported by the crate root and this\n/// module is private, this trait effectively forbids downstream\n/// implementation of the `BitStore` trait.\n#[doc(hidden)]\npub trait Sealed {}","Real(LocalPath(\"src/store.rs\"))"],"vec::BitVec":["/** A vector of individual bits, allocated on the heap.\n\nThis is a managed, heap-allocated, buffer that contains a `BitSlice` region. It\nis analagous to `Vec<bool>`, and is written to be as close as possible to\ndrop-in replacabale for it. This type contains little interesting behavior in\nits own right, dereferencing instead to [`BitSlice`] for manipulation of the\nbuffer contents, and serves primarily as an interface to the allocator. If you\nrequire statically-allocated, fixed-size, owned buffers, you should use the\n[`BitArray`] type.\n\nBecause `BitVec` directly owns its memory, and can guarantee that no other\nobject in a program has access to its buffers, `BitVec` is able to override some\nbehavior from `BitSlice` in more efficient manners.\n\n# Documentation\n\nAll APIs that mirror something in the standard library will have an `Original`\nsection linking to the corresponding item. All APIs that have a different\nsignature or behavior than the original will have an `API Differences` section\nexplaining what has changed, and how to adapt your existing code to the change.\n\nThese sections look like this:\n\n# Original\n\n[`Vec<T>`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html)\n\n# API Differences\n\nThe buffer type `Vec<bool>` has no type parameters. `BitVec<O, T>` has the same\ntwo type parameters as `BitSlice<O, T>`. Otherwise, `BitVec` is able to\nimplement the full API surface of `Vec<bool>`.\n\n# Behavior\n\nBecause `BitVec` is a fully-owned buffer, it is able to operate on its memory\nwithout concern for any other views that may alias. This enables it to\nspecialize some `BitSlice` behavior to be faster or more efficient.\n\n# Type Parameters\n\nThis takes the same two type parameters, `O: BitOrder` and `T: BitStore`, as\n`BitSlice`.\n\n# Safety\n\nLike `BitSlice`, `BitVec` is exactly equal in size to `Vec`, and is also\nabsolutely representation-incompatible with it. You must never attempt to\ntype-cast between `Vec<T>` and `BitVec` in any way, nor attempt to modify the\nmemory value of a `BitVec` handle. Doing so will cause allocator and memory\nerrors in your program, likely inducing a panic.\n\nEverything in the `BitVec` public API, even the `unsafe` parts, are guaranteed\nto have no more unsafety than their equivalent items in the standard library.\nAll `unsafe` APIs will have documentation explicitly detailing what the API\nrequires you to uphold in order for it to function safely and correctly. All\nsafe APIs will do so themselves.\n\n# Performance\n\nThe choice of `T: BitStore` type parameter can impact your vector’s performance,\nas the allocator operates in units of `T` rather than in bits. This means that\nlarger register types will increase the amount of memory reserved in each call\nto the allocator, meaning fewer calls to `.push()` will actually cause a\nreällocation. In addition, iteration over the vector is governed by the\n`BitSlice` characteristics on the type parameter. You are generally better off\nusing larger types when your vector is a data collection rather than a specific\nI/O protocol buffer.\n\n# Macro Construction\n\nHeap allocation can only occur at runtime, but the [`bitvec!`] macro will\nconstruct an appropriate `BitSlice` buffer at compile-time, and at run-time,\nonly copy the buffer into a heap allocation.\n\n[`BitArray`]: ../array/struct.BitArray.html\n[`BitSlice`]: ../slice/struct.BitSlice.html\n[`bitvec!`]: ../macro.bitvec.html\n**/\n#[repr(C)]\npub struct BitVec<O = Local, T = usize>\nwhere\n\tO: BitOrder,\n\tT: BitStore,\n{\n\t/// Region pointer describing the live portion of the owned buffer.\n\tpointer: NonNull<BitSlice<O, T>>,\n\t/// Allocated capacity, in elements `T`, of the owned buffer.\n\tcapacity: usize,\n}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::as_bitptr":["/// Returns a raw pointer to the vector’s region.\n///\n/// The caller must ensure that the vector outlives the pointer this\n/// function returns, or else it will end up pointing to garbage. Modifying\n/// the vector may cause its buffer to be reallocated, which would also make\n/// any pointers to it invalid.\n///\n/// The caller must also ensure that the memory the pointer\n/// (non-transitively) points to is never written to (except inside an\n/// `UnsafeCell`) using this pointer or any pointer derived from it. If you\n/// need to mutate the contents of the region, use [`as_mut_bitptr`].\n///\n/// This pointer is an opaque crate-internal type. Its in-memory\n/// representation is unsafe to modify in any way. The only safe action to\n/// take with this pointer is to pass it, unchanged, back into a `bitvec`\n/// API.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0; 20];\n/// let ptr = bv.as_bitptr();\n///\n/// let bits = unsafe { &*ptr };\n/// assert_eq!(bv, bits);\n/// ```\n///\n/// [`as_mut_bitptr`]: #method.as_mut_bitptr\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitptr(&self) -> *const BitSlice<O, T>{\n\t\tself.pointer.as_ptr() as *const BitSlice<O, T>\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::as_bitslice":["/// Views the buffer’s contents as a `BitSlice`.\n///\n/// This is equivalent to `&bv[..]`.\n///\n/// # Original\n///\n/// [`Vec::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_slice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0, 1, 1, 0];\n/// let bits = bv.as_bitslice();\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitslice(&self) -> &BitSlice<O, T>{\n\t\tunsafe { &*self.pointer.as_ptr() }\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::as_mut_bitptr":["/// Returns an unsafe mutable pointer to the vector’s region.\n///\n/// The caller must ensure that the vector outlives the pointer this\n/// function returns, or else it will end up pointing to garbage. Modifying\n/// the vector may cause its buffer to be reallocated, which would also make\n/// any pointers to it invalid.\n///\n/// This pointer is an opaque crate-internal type. Its in-memory\n/// representation is unsafe to modify in any way. The only safe action to\n/// take with this pointer is to pass it, unchanged, back into a `bitvec`\n/// API.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0; 20];\n/// let ptr = bv.as_mut_bitptr();\n///\n/// let bits = unsafe { &mut *ptr };\n/// assert_eq!(bv, bits);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_bitptr(&mut self) -> *mut BitSlice<O, T>{\n\t\tself.pointer.as_ptr()\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::as_mut_bitslice":["/// Extracts a mutable bit-slice of the entire vector.\n///\n/// Equivalent to `&mut bv[..]`.\n///\n/// # Original\n///\n/// [`Vec::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_slice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 0, 1];\n/// let bits = bv.as_mut_bitslice();\n/// bits.set(0, true);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T>{\n\t\tunsafe { &mut *self.pointer.as_ptr() }\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::bitptr":["#[inline]\npub(crate) fn bitptr(&self) -> BitPtr<T>{\n\t\tself.pointer.as_ptr().pipe(BitPtr::from_bitslice_ptr_mut)\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::elements":["/// Gets the number of elements `T` that contain live bits of the vector.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![Local, u16; 1; 50];\n/// assert_eq!(bv.elements(), 4);\n/// ```\n#[inline]\npub fn elements(&self) -> usize{\n\t\tself.bitptr().elements()\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::extend_from_bitslice":["/// Copies all bits in a `BitSlice` into the `BitVec`.\n///\n/// This is provided for API completeness; it has no performance benefits\n/// compared to use of the [`Extend`] implementation.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `other`: A `BitSlice` reference of the same type parameters as `self`.\n///\n/// # Behavior\n///\n/// `self` is extended by the length of `other`, and then the contents of\n/// `other` are copied into the newly-allocated end of `self`.\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1];\n/// bv.extend_from_bitslice(bits![1, 1, 0, 1]);\n///\n/// assert_eq!(bv, bits![0, 1, 1, 1, 0, 1]);\n/// ```\n///\n/// [`Extend`]: #impl-Extend<%26'a bool>\n/// [`.as_bitslice()`]: #method.as_bitslice()\n#[inline]\npub fn extend_from_bitslice(&mut self, other: &BitSlice<O, T>){\n\t\tlet len = self.len();\n\t\tlet olen = other.len();\n\t\tself.resize(len + olen, false);\n\t\tunsafe { self.get_unchecked_mut(len ..) }.clone_from_bitslice(other);\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::force_align":["/// Ensures that the live region of the vector’s contents begins at the\n/// leading edge of the buffer.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let data = 0x3Cu8;\n/// let bits = data.view_bits::<Msb0>();\n///\n/// let mut bv = bits[2 .. 6].to_bitvec();\n/// assert_eq!(bv, bits[2 .. 6]);\n/// assert_eq!(bv.as_slice()[0], data);\n///\n/// bv.force_align();\n/// assert_eq!(bv, bits[2 .. 6]);\n/// //  It is not specified what happens to bits that are no longer used.\n/// assert_eq!(bv.as_slice()[0] & 0xF0, 0xF0);\n/// ```\n#[inline]\npub fn force_align(&mut self){\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head().value() as usize;\n\t\tif head == 0 {\n\t\t\treturn;\n\t\t}\n\t\tlet last = bitptr.len() + head;\n\t\tunsafe {\n\t\t\tself.pointer =\n\t\t\t\tbitptr.tap_mut(|bp| bp.set_head(BitIdx::ZERO)).to_nonnull();\n\t\t\tself.copy_within_unchecked(head .. last, 0);\n\t\t}\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::from_bitslice":["/// Clones a `&BitSlice` into a `BitVec`.\n///\n/// # Original\n///\n/// [`<Vec<T: Clone> as Clone>::clone`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#impl-Clone)\n///\n/// # Effects\n///\n/// This performs a direct element-wise copy from the source slice to the\n/// newly-allocated buffer, then sets the vector to have the same starting\n/// bit as the slice did. This allows for faster behavior. If you require\n/// that the vector start at the leading edge of the first element, use\n/// [`force_align`] to guarantee this.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bits = bits![0, 1, 0, 1, 1, 0, 1, 1];\n/// let bv = BitVec::from_bitslice(&bits[2 ..]);\n/// assert_eq!(bv, bits[2 ..]);\n/// ```\n///\n/// [`force_align`]: #method.force_align\n#[inline]\npub fn from_bitslice(slice: &BitSlice<O, T>) -> Self{\n\t\tlet mut bitptr = slice.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_access(), bitptr.elements());\n\t\tlet source = unsafe { slice::from_raw_parts(base, elts) };\n\n\t\tlet mut vec = elts.pipe(Vec::with_capacity).pipe(ManuallyDrop::new);\n\n\t\tvec.extend(source.iter().map(BitAccess::load_value));\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(vec.as_ptr() as *const T);\n\t\t}\n\n\t\tlet capacity = vec.capacity();\n\t\tSelf {\n\t\t\tpointer: bitptr.to_nonnull(),\n\t\t\tcapacity,\n\t\t}\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::from_vec":["/// Converts a `Vec<T>` into a `BitVec<O, T>` without copying its buffer.\n///\n/// # Parameters\n///\n/// - `vec`: A vector to view as bits.\n///\n/// # Returns\n///\n/// A `BitVec` over the `vec` buffer.\n///\n/// # Panics\n///\n/// This panics if `vec` is too long to convert into a `BitVec`. See\n/// [`BitSlice::MAX_ELTS`].\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let vec = vec![0u8; 4];\n/// let bv = BitVec::<Local, _>::from_vec(vec);\n/// assert_eq!(bv, bits![0; 32]);\n/// ```\n///\n/// [`BitSlice::MAX_ELTS`]:\n/// ../slice/struct.BitSlice.html#associatedconstant.MAX_ELTS\n#[inline]\npub fn from_vec(vec: Vec<T>) -> Self{\n\t\tSelf::try_from_vec(vec)\n\t\t\t.expect(\"Vector was too long to be converted into a `BitVec`\")\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::into_boxed_bitslice":["/// Converts the vector into [`BitBox<O, T>`].\n///\n/// Note that this will drop any excess capacity.\n///\n/// # Original\n///\n/// [`Vec::into_boxed_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.into_boxed_slice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1; 50];\n/// let bb: BitBox = bv.into_boxed_bitslice();\n/// assert_eq!(bb, bits![1; 50]);\n/// ```\n///\n/// [`BitBox<O, T>`]: ../boxed/struct.BitBox.html\n#[inline]\npub fn into_boxed_bitslice(self) -> BitBox<O, T>{\n\t\tlet mut bitptr = self.bitptr();\n\t\tlet boxed = self.into_boxed_slice().pipe(ManuallyDrop::new);\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(boxed.as_ptr());\n\t\t}\n\t\tunsafe { BitBox::from_raw(bitptr.to_bitslice_ptr_mut::<O>()) }\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::into_vec":["/// Converts the vector back into an ordinary vector of memory elements.\n///\n/// This does not affect the vector’s buffer, only the handle used to\n/// control it.\n///\n/// # Parameters\n///\n/// - `self`\n///\n/// # Returns\n///\n/// An ordinary vector containing all of the bit-vector’s memory buffer.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0; 5];\n/// let vec = bv.into_vec();\n/// assert_eq!(vec, [0]);\n/// ```\n#[inline]\npub fn into_vec(self) -> Vec<T>{\n\t\tlet mut this = ManuallyDrop::new(self);\n\t\tlet buf = this.as_mut_slice();\n\t\tunsafe {\n\t\t\tVec::from_raw_parts(\n\t\t\t\tbuf.as_mut_ptr() as *mut T,\n\t\t\t\tbuf.len(),\n\t\t\t\tthis.capacity,\n\t\t\t)\n\t\t}\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::repeat":["/// Constructs a `BitVec` from a value repeated many times.\n///\n/// This function is equivalent to the `bitvec![O, T; bit; len]` macro call,\n/// and is in fact the implementation of that macro syntax.\n///\n/// # Parameters\n///\n/// - `bit`: The bit value to which all `len` allocated bits will be set.\n/// - `len`: The number of live bits in the constructed `BitVec`.\n///\n/// # Returns\n///\n/// A `BitVec` with `len` live bits, all set to `bit`.\n#[inline]\npub fn repeat(bit: bool, len: usize) -> Self{\n\t\tlet mut out = Self::with_capacity(len);\n\t\tunsafe {\n\t\t\tout.set_len(len);\n\t\t}\n\t\tout.set_elements(if bit { T::Mem::ALL } else { T::Mem::ZERO });\n\t\tout\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::set_elements":["/// Writes a value into every element that the vector considers live.\n///\n/// This unconditionally writes `element` into each live location in the\n/// backing buffer, without altering the `BitVec`’s length or capacity.\n///\n/// It is unspecified what effects this has on the allocated but dead\n/// elements in the buffer.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `element`: The value which will be written to each live location in\n///   the vector’s buffer.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![Local, u8; 0; 10];\n/// assert_eq!(bv.as_slice(), [0, 0]);\n/// bv.set_elements(0xA5);\n/// assert_eq!(bv.as_slice(), [0xA5, 0xA5]);\n/// ```\n#[inline]\npub fn set_elements(&mut self, element: T::Mem){\n\t\tself.as_mut_slice()\n\t\t\t.iter_mut()\n\t\t\t.for_each(|elt| *elt = element.into());\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::try_from_vec":["/// Converts a `Vec<T>` into a `BitVec<O, T>` without copying its buffer.\n///\n/// This method takes ownership of a memory buffer and enables it to be used\n/// as a bit-vector. Because `Vec` can be longer than `BitVec`s, this is a\n/// fallible method, and the original vector will be returned if it cannot\n/// be converted.\n///\n/// # Parameters\n///\n/// - `vec`: Some vector of memory, to be viewed as bits.\n///\n/// # Returns\n///\n/// If `vec` is short enough to be viewed as a `BitVec`, then this returns\n/// a `BitVec` over the `vec` buffer. If `vec` is too long, then this\n/// returns `vec` unmodified.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let vec = vec![0u8; 4];\n/// let bv = BitVec::<Local, _>::try_from_vec(vec).unwrap();\n/// assert_eq!(bv, bits![0; 32]);\n/// ```\n///\n/// An example showing this function failing would require an allocation\n/// exceeding `!0usize >> 3` bytes in size, which is infeasible to produce.\n#[inline]\npub fn try_from_vec(vec: Vec<T>) -> Result<Self, Vec<T>>{\n\t\tlet len = vec.len();\n\t\tif len > BitSlice::<O, T>::MAX_ELTS {\n\t\t\treturn Err(vec);\n\t\t}\n\n\t\tlet vec = ManuallyDrop::new(vec);\n\t\tlet (base, capacity) = (vec.as_ptr(), vec.capacity());\n\t\tOk(Self {\n\t\t\tpointer: unsafe {\n\t\t\t\tBitPtr::new_unchecked(\n\t\t\t\t\tbase,\n\t\t\t\t\tBitIdx::ZERO,\n\t\t\t\t\tlen * T::Mem::BITS as usize,\n\t\t\t\t)\n\t\t\t}\n\t\t\t.to_nonnull(),\n\t\t\tcapacity,\n\t\t})\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::BitVec::<O, T>::with_vec":["/// Permits a function to modify the `Vec<T>` backing storage of a\n/// `BitVec<_, T>`.\n///\n/// This produces a temporary `Vec<T::Mem>` structure governing the\n/// `BitVec`’s buffer and allows a function to view it mutably. After the\n/// callback returns, the `Vec` is written back into `self` and forgotten.\n///\n/// # Type Parameters\n///\n/// - `F`: A function which operates on a mutable borrow of a `Vec<T::Mem>`\n///   buffer controller.\n/// - `R`: The return type of the `F` function.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `func`: A function which receives a mutable borrow of a `Vec<T::Mem>`\n///   controlling `self`’s buffer.\n///\n/// # Returns\n///\n/// The return value of `func`. `func` is forbidden from borrowing any part\n/// of the `Vec<T::Mem>` temporary view.\nfn with_vec<F, R>(&mut self, func: F) -> R\n\twhere F: FnOnce(&mut ManuallyDrop<Vec<T::Mem>>) -> R{\n\t\tlet cap = self.capacity;\n\t\tlet mut bitptr = self.bitptr();\n\t\tlet (base, elts) =\n\t\t\t(bitptr.pointer().to_mut() as *mut T::Mem, bitptr.elements());\n\n\t\tlet mut vec = unsafe { Vec::from_raw_parts(base, elts, cap) }\n\t\t\t.pipe(ManuallyDrop::new);\n\t\tlet out = func(&mut vec);\n\n\t\tunsafe {\n\t\t\tbitptr.set_pointer(vec.as_ptr() as *mut T);\n\t\t}\n\t\tself.pointer = bitptr.to_nonnull();\n\t\tself.capacity = vec.capacity();\n\t\tout\n\t}","Real(LocalPath(\"src/vec.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::append":["/// Moves all the bits of `other` into `self`, leaving `other` empty.\n///\n/// # Original\n///\n/// [`Vec::append`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.append)\n///\n/// # Panics\n///\n/// Panics if the number of bits overflows the maximum vector capacity.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv1 = bitvec![0; 10];\n/// let mut bv2 = bitvec![1; 10];\n///\n/// bv1.append(&mut bv2);\n///\n/// assert_eq!(bv1.count_ones(), 10);\n/// assert!(bv2.is_empty());\n/// ```\n#[inline]\npub fn append<O2, T2>(&mut self, other: &mut BitVec<O2, T2>)\n\twhere\n\t\tO2: BitOrder,\n\t\tT2: BitStore,{\n\t\tself.extend(other.iter().copied());\n\t\tother.clear();\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::as_mut_ptr":["/// Returns an unsafe mutable pointer to the vector’s buffer.\n///\n/// The caller must ensure that the vector outlives the pointer this\n/// function returns, or else it will end up pointing to garbage. Modifying\n/// the vector may cause its buffer to be reällocated, which would also make\n/// any pointers to it invalid.\n///\n/// # Original\n///\n/// [`Vec::as_mut_ptr`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_ptr)\n///\n/// # Analogue\n///\n/// See [`as_mut_bitptr`] for a `&mut BitVec -> *mut BitSlice` transform.\n///\n/// # Eaxmples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let size = 4;\n/// let mut bv: BitVec<Msb0, usize> = BitVec::with_capacity(size);\n/// let bv_ptr = bv.as_mut_ptr();\n///\n/// unsafe {\n///   *bv_ptr = !0;\n///   bv.set_len(size);\n/// }\n/// assert_eq!(bv.len(), 4);\n/// assert!(bv.all());\n/// ```\n///\n/// [`as_mut_bitptr`]: #method.as_mut_bitptr\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_ptr(&mut self) -> *mut T{\n\t\tself.bitptr().pointer().to_mut()\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::as_mut_slice":["/// Extracts a mutable slice of the entire vector.\n///\n/// # Original\n///\n/// [`Vec::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_mut_slice)\n///\n/// # Analogue\n///\n/// See [`as_mut_bitslice`] for a `&mut BitVec -> &mut BitSlice` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n/// use std::io::{self, Read};\n/// let mut buffer = bitvec![Msb0, u8; 0; 24];\n/// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();\n/// # }\n/// ```\n///\n/// [`as_mut_bitslice`]: #method.as_mut_bitslice\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_slice(&mut self) -> &mut [T]{\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_mut(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts_mut(base, elts) }\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::as_ptr":["/// Returns a raw pointer to the vector’s buffer.\n///\n/// The caller must ensure that the vector outlives the pointer this\n/// function returns, or else it will end up pointing to garbage. Modifying\n/// the vector may cause its buffer to be reällocated, which would also make\n/// any pointers to it invalid.\n///\n/// The caller must also ensure that the memory the pointer\n/// (non-transitively) points to is never written to (except inside an\n/// `UnsafeCell`) using this pointer or any pointer derived from it. If you\n/// need to mutate the contents of the slice, use [`as_mut_ptr`].\n///\n/// # Original\n///\n/// [`Vec::as_ptr`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_ptr)\n///\n/// # Analogue\n///\n/// See [`as_bitptr`] for a `&BitVec -> *const BitSlice` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![Lsb0; 0, 1, 0, 1];\n/// let bv_ptr = bv.as_ptr();\n///\n/// unsafe {\n///   assert_eq!(*bv_ptr, 0b1010);\n/// }\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_ptr(&self) -> *const T{\n\t\tself.bitptr().pointer().to_const()\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::as_slice":["/// Extracts an element slice containing the entire vector.\n///\n/// # Original\n///\n/// [`Vec::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.as_slice)\n///\n/// # Analogue\n///\n/// See [`as_bitslice`] for a `&BitVec -> &BitSlice` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// # #[cfg(feature = \"std\")] {\n/// use bitvec::prelude::*;\n/// use std::io::{self, Write};\n/// let buffer = bitvec![Msb0, u8; 0, 1, 0, 1, 1, 0, 0, 0];\n/// io::sink().write(buffer.as_slice()).unwrap();\n/// # }\n/// ```\n///\n/// [`as_bitslice`]: #method.as_bitslice\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_slice(&self) -> &[T]{\n\t\tlet bitptr = self.bitptr();\n\t\tlet (base, elts) = (bitptr.pointer().to_const(), bitptr.elements());\n\t\tunsafe { slice::from_raw_parts(base, elts) }\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::capacity":["/// Returns the number of bits the vector can hold without reällocating.\n///\n/// # Original\n///\n/// [`Vec::capacity`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.capacity)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv: BitVec<Local, usize> = BitVec::with_capacity(100);\n/// assert!(bv.capacity() >= 100);\n/// ```\n#[inline]\npub fn capacity(&self) -> usize{\n\t\tself.capacity\n\t\t\t.checked_mul(T::Mem::BITS as usize)\n\t\t\t.expect(\"Vector capacity exceeded\")\n\t\t\t//  Don’t forget to subtract any dead bits in the front of the base!\n\t\t\t//  This has to be saturating, becase a non-zero head on a zero\n\t\t\t//  capacity underflows.\n\t\t\t.saturating_sub(self.bitptr().head().value() as usize)\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::clear":["/// Clears the vector, removing all values.\n///\n/// Note that this method has no effect on the allocated capacity of the\n/// vector.\n///\n/// # Original\n///\n/// [`Vec::clear`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.clear)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 0, 1];\n///\n/// bv.clear();\n///\n/// assert!(bv.is_empty());\n/// ```\ninline(always)\npub fn clear(&mut self){\n\t\tunsafe {\n\t\t\tself.set_len(0);\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::drain":["/// Creates a draining iterator that removes the specified range in the\n/// vector and yields the removed items.\n///\n/// Note 1: The bit range is removed even if the iterator is only partially\n/// consumed or not consumed at all.\n///\n/// Note 2: It is unspecified how many bits are removed from the vector if\n/// the `Drain` value is leaked.\n///\n/// # Original\n///\n/// [`Vec::drain`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.drain)\n///\n/// # Panics\n///\n/// Panics if the starting point is greater than the end point or if the end\n/// point is greater than the length of the vector.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 1];\n/// let bv2: BitVec = bv.drain(1 ..).collect();\n/// assert_eq!(bv, bits![0]);\n/// assert_eq!(bv2, bits![1, 1]);\n///\n/// // A full range clears the vector\n/// bv.drain(..);\n/// assert_eq!(bv, bits![]);\n/// ```\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn drain<R>(&mut self, range: R) -> Drain<O, T>\n\twhere R: RangeBounds<usize>{\n\t\tDrain::new(self, range)\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::extend_from_slice":["/// Clones and appends all `bool`s in a slice to the `BitVec`.\n///\n/// Iterates over the slice `other`, clones each `bool`, and then appends it\n/// to the `BitVec`. The `other` slice is traversed in-order.\n///\n/// Prefer the [`Extend`] implementation; this method is retained only for\n/// API compatibility, and offers no performance benefit.\n///\n/// # Original\n///\n/// [`Vec::extend_from_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.extend_from_slice)\n///\n/// # Analogue\n///\n/// See [`extend_from_bitslice`] for the method to append a bit-slice of the\n/// same type parameters to a bit-vector.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0];\n/// bv.extend_from_slice(&[true]);\n/// assert_eq!(bv, bits![0, 1]);\n/// ```\n///\n/// [`extend`]: #impl-Extend<%26'a bool>\n/// [`extend_from_bitslice`]: #method.extend_from_bitslice\ninline(always)\npub fn extend_from_slice(&mut self, other: &[bool]){\n\t\tself.extend(other)\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::from_raw_parts":["/// Creates a `BitVec<O, T>` directly from the raw components of another\n/// bit-vector.\n///\n/// # Original\n///\n/// [`Vec::from_raw_parts`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.from_raw_parts)\n///\n/// # API Differences\n///\n/// Ordinary vectors decompose into their buffer pointer and element length\n/// separately; bit vectors must keep these two components bundled into the\n/// `*BitSlice` region pointer. As such, this only accepts two components;\n/// the slice pointer and the buffer capacity.\n///\n/// `Vec` could define its raw parts as `*[T]` and `usize` also, but Rust\n/// does not make working with raw slice pointers easy.\n///\n/// # Panics\n///\n/// This function panics if `pointer` is the null pointer.\n///\n/// # Safety\n///\n/// This is highly unsafe, due to the number of invariants that aren’t\n/// checked:\n///\n/// - `pointer` needs to have been previously allocated via `BitVec<O, T>`\n///   (at least, it’s highly likely to be incorrect if it wasn’t).\n/// - `T` needs to have the same size and alignment as what `pointer` was\n///   allocated with. (`T` having a less strict alignment is not sufficient;\n///   the alignment really needs to be equal to satisfy the [`dealloc`]\n///   requirement that memory must be allocated and deällocated with the\n///   same layout.)\n/// - `capacity` needs to be the capacity that the pointer was allocated\n///   with.\n///\n/// In addition to the invariants inherited from `Vec::from_raw_parts`, the\n/// fact that this function takes a bit-slice pointer adds another one:\n///\n/// - **`pointer` MUST NOT have had its value modified in any way in the**\n/// **time when it was outside of a `bitvec` container type.**\n///\n/// Violating these *will* cause problems like corrupting the allocator’s\n/// internal data structures. For example it is **not** safe to build a\n/// `BitVec<_, u8>` from a pointer to a C `char` array with length `size_t`.\n/// It’s also not safe to build one from a `BitVec<_, u16>` and its length,\n/// becauset the allocator cares about the alignment, and these two types\n/// have different alignments. The buffer was allocated with alignment 2\n/// (for `u16`), but after turning it into a `BitVec<_, u8>`, it’ll be\n/// deällocated with alignment 1.\n///\n/// The ownership of `pointer` is effectively transferred to the `BitVec<O,\n/// T>` which may then deällocate, reällocate, or change the contents of\n/// memory pointed to by the pointer at will. Ensure that nothing else uses\n/// the pointer after calling this function.\n///\n/// # Examples\n///\n/// ```rust\n/// # extern crate core;\n/// use bitvec::prelude::*;\n/// use bitvec as bv;\n/// use core::mem;\n///\n/// let bv = bitvec![0, 1, 0, 1];\n///\n/// // Prevent running `bv`’s destructor so we are in complete control\n/// // of the allocation.\n/// let mut bv = mem::ManuallyDrop::new(bv);\n///\n/// // Pull out the various important pieces of information about `bv`\n/// let p = bv.as_mut_ptr();\n/// let e = bv.elements();\n/// let cap = bv.capacity();\n///\n/// unsafe {\n///   let bits = bv::slice::from_raw_parts_mut::<Local, _>(p, e);\n///   let len = bits.len();\n///\n///   // Overwrite memory with a new pattern\n///   bits.iter_mut().for_each(|mut b| *b = true);\n///\n///   // Put everything back together into a BitVec\n///   let rebuilt = BitVec::from_raw_parts(bits as *mut _, cap);\n///   assert_eq!(rebuilt.len(), len);\n/// }\n/// ```\n#[inline]\npub unsafe fn from_raw_parts(\n\t\tpointer: *mut BitSlice<O, T>,\n\t\tcapacity: usize,\n\t) -> Self{\n\t\tif (pointer as *mut [()]).is_null() {\n\t\t\tpanic!(\"Attempted to reconstruct a `BitVec` from a null pointer\");\n\t\t}\n\t\tpointer\n\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.to_nonnull()\n\t\t\t.pipe(|pointer| Self { pointer, capacity })\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::insert":["/// Inserts a bit at position `index` within the vector, shifting all bits\n/// after it to the right.\n///\n/// # Original\n///\n/// [`Vec::insert`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.insert)\n///\n/// # Panics\n///\n/// Panics if `index > len`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0; 5];\n/// bv.insert(4, true);\n/// assert_eq!(bv, bits![0, 0, 0, 0, 1, 0]);\n/// bv.insert(2, true);\n/// assert_eq!(bv, bits![0, 0, 1, 0, 0, 1, 0]);\n/// ```\n#[inline]\npub fn insert(&mut self, index: usize, value: bool){\n\t\tlet len = self.len();\n\t\tassert!(index <= len, \"Index {} out of bounds: {}\", index, len);\n\t\tself.push(value);\n\t\tunsafe { self.get_unchecked_mut(index ..) }.rotate_right(1);\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::into_boxed_slice":["/// Converts the vector into [`Box<[T]>`].\n///\n/// Note that this will drop any excess capacity.\n///\n/// # Original\n///\n/// [`Vec::into_boxed_slice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.into_boxed_slice)\n///\n/// # Analogue\n///\n/// See [`into_boxed_bitslice`] for a `BitVec -> BitBox` transform.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0, 1, 0];\n///\n/// let slice = bv.into_boxed_slice();\n/// assert_eq!(slice.len(), 1);\n/// ```\n///\n/// Any excess capacity is removed:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv: BitVec = BitVec::with_capacity(100);\n/// bv.extend([false, true, false].iter().copied());\n///\n/// assert!(bv.capacity() >= 100);\n/// let slice = bv.into_boxed_slice();\n/// assert_eq!(slice.into_vec().capacity(), 1);\n/// ```\n///\n/// [`Box<[T]>`]: https://doc.rust-lang.org/alloc/boxed/struct.Box.html\n/// [`into_boxed_bitslice`]: #method.into_boxed_bitslice\n#[inline]\npub fn into_boxed_slice(self) -> Box<[T]>{\n\t\tself.into_vec().into_boxed_slice()\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::new":["/// Constructs a new, empty `BitVec<O, T>`.\n///\n/// The vector will not allocate until bits are pushed into it.\n///\n/// # Original\n///\n/// [`Vec::new`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.new)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = BitVec::<Local, usize>::new();\n/// ```\n#[inline]\npub fn new() -> Self{\n\t\tSelf {\n\t\t\tpointer: BitPtr::<T>::EMPTY.to_nonnull(),\n\t\t\tcapacity: 0,\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::pop":["/// Removes the last bit from a vector and returns it, or [`None`] if it is\n/// empty.\n///\n/// # Original\n///\n/// [`Vec::pop`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.pop)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 0, 1];\n/// assert_eq!(bv.pop(), Some(true));\n/// assert!(bv.not_any());\n/// ```\n///\n/// [`None`]: https://doc.rust-lang.org/core/option/enum.Option.html#variant.None\n#[inline]\npub fn pop(&mut self) -> Option<bool>{\n\t\tmatch self.len() {\n\t\t\t0 => None,\n\t\t\tn => unsafe {\n\t\t\t\tlet m = n - 1;\n\t\t\t\t(*self.get_unchecked(m)).tap(|_| self.set_len(m)).pipe(Some)\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::push":["/// Appends a bit to the back of a collection.\n///\n/// # Original\n///\n/// [`Vec::push`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.push)\n///\n/// # Panics\n///\n/// Panics if the number of bits in the vector exceeds the maximum vector\n/// capacity.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 0];\n/// bv.push(true);\n/// assert_eq!(bv.count_ones(), 1);\n/// ```\n#[inline]\npub fn push(&mut self, value: bool){\n\t\tlet len = self.len();\n\t\tassert!(\n\t\t\tlen <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Exceeded capacity: {} >= {}\",\n\t\t\tlen,\n\t\t\tBitSlice::<O, T>::MAX_BITS,\n\t\t);\n\t\tif self.is_empty() || self.bitptr().tail().value() == T::Mem::BITS {\n\t\t\tself.with_vec(|v| v.push(T::Mem::ZERO));\n\t\t}\n\t\tunsafe {\n\t\t\tself.pointer = self\n\t\t\t\t.pointer\n\t\t\t\t.as_ptr()\n\t\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t\t.tap_mut(|bp| bp.set_len(len + 1))\n\t\t\t\t.to_nonnull();\n\t\t\tself.set_unchecked(len, value);\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::remove":["/// Removes and returns the bit at position `index` within the vector,\n/// shifting all bits after it to the left.\n///\n/// # Original\n///\n/// [`Vec::remove`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.remove)\n///\n/// # Panics\n///\n/// Panics if `index` is out of bounds.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 0];\n/// assert!(bv.remove(1));\n/// assert_eq!(bv, bits![0, 0]);\n/// ```\n#[inline]\npub fn remove(&mut self, index: usize) -> bool{\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index {} out of bounds: {}\", index, len);\n\t\tlet last = len - 1;\n\t\tunsafe {\n\t\t\tself.get_unchecked_mut(index ..).rotate_left(1);\n\t\t\tself.set_len(last);\n\t\t\t*self.get_unchecked(last)\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::reserve":["/// Reserves capacity for at least `additional` more bits to be inserted in\n/// the given `BitVec<O, T>`. The collection may reserve more space to avoid\n/// frequent reällocations. After calling `reserve`, capacity will be\n/// greater than or equal to `self.len() + additional`. Does nothing if\n/// capacity is already sufficient.\n///\n/// # Original\n///\n/// [`Vec::reserve`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.reserve)\n///\n/// # Panics\n///\n/// Panics if the new capacity exceeds the vector’s limits.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1];\n/// bv.reserve(100);\n/// assert!(bv.capacity() >= 101);\n/// ```\n#[inline]\npub fn reserve(&mut self, additional: usize){\n\t\tlet new_len = self\n\t\t\t.len()\n\t\t\t.checked_add(additional)\n\t\t\t.expect(\"Vector capacity exceeded\");\n\t\tassert!(\n\t\t\tnew_len <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tnew_len,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head();\n\t\tlet elts = bitptr.elements();\n\t\t//  Only reserve if the request needs new elements.\n\t\tif let Some(extra) = head.span(new_len).0.checked_sub(elts) {\n\t\t\tself.with_vec(|v| v.reserve(extra));\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::reserve_exact":["/// Reserves the minimum capacity for exactly `additional` more bits to be\n/// inserted in the given `BitVec<O, T>`. After calling `reserve_exact`,\n/// capacity will be greater than or equal to `self.len() + additional`.\n/// Does nothing if the capacity is already sufficient.\n///\n/// Note that the allocator may give the collection more space than it\n/// requests. Therefore, capacity can not be relied upon to be precisely\n/// minimal. Prefer `reserve` if future insertions are expected.\n///\n/// # Original\n///\n/// [`Vec::reserve_exact`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.reserve_exact)\n///\n/// # Panics\n///\n/// Panics if the new capacity exceeds the vector’s limits.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1];\n/// bv.reserve_exact(100);\n/// assert!(bv.capacity() >= 101);\n/// ```\n#[inline]\npub fn reserve_exact(&mut self, additional: usize){\n\t\tlet new_len = self\n\t\t\t.len()\n\t\t\t.checked_add(additional)\n\t\t\t.expect(\"Vector capacity exceeded\");\n\t\tassert!(\n\t\t\tnew_len <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tnew_len,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet bitptr = self.bitptr();\n\t\tlet head = bitptr.head();\n\t\tlet elts = bitptr.elements();\n\t\t//  Only reserve if the request needs new elements.\n\t\tif let Some(extra) = head.span(new_len).0.checked_sub(elts) {\n\t\t\tself.with_vec(|v| v.reserve_exact(extra));\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::resize":["/// Resizes the `BitVec` in-place so that `len` is equal to `new_len`.\n///\n/// If `new_len` is greater than `len`, the `BitVec` is extended by the\n/// difference, with each additional slot filled with `value`. If `new_len`\n/// is less than `len`, the `BitVec` is simply truncated.\n///\n/// This method requires a single `bool` value. If you need more\n/// flexibility, use [`resize_with`].\n///\n/// # Original\n///\n/// [`Vec::resize`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.resize)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1];\n/// bv.resize(3, false);\n/// assert_eq!(bv, bits![1, 0, 0]);\n///\n/// let mut bv = bitvec![1; 4];\n/// bv.resize(2, false);\n/// assert_eq!(bv, bits![1; 2]);\n/// ```\n///\n/// [`resize_with`]: #method.resize_with\n#[inline]\npub fn resize(&mut self, new_len: usize, value: bool){\n\t\tlet len = self.len();\n\t\tif new_len > len {\n\t\t\tlet ext = new_len - len;\n\t\t\tself.reserve(ext);\n\t\t\t/* Initialize all of the newly-allocated memory, not just the bits\n\t\t\tthat will become live. This is a requirement for correctness.\n\n\t\t\t*Strictly speaking*, only `len .. ⌈new_len / bit_width⌉` needs to be\n\t\t\tinitialized, but computing the correct boundary is probably not\n\t\t\tsufficiently less effort than just initializing the complete\n\t\t\tallocation to be worth the instructions. If users complain about\n\t\t\tperformance on this method, revisit this decision, but if they don’t\n\t\t\tthen the naïve solution is fine.\n\t\t\t*/\n\t\t\tlet capa = self.capacity();\n\t\t\tunsafe {\n\t\t\t\tself.get_unchecked_mut(len .. capa).set_all(value);\n\t\t\t}\n\t\t}\n\t\tunsafe {\n\t\t\tself.set_len(new_len);\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::resize_with":["/// Resizes the `BitVec` in-place so that `len` is equal to `new_len`.\n///\n/// If `new_len` is greater than `len`, the `BitVec` is extended by the\n/// difference, with each additional slot filled with the result of calling\n/// the closure `func`. The return values from `func` will end up in the\n/// `BitVec` in the order they have been generated.\n///\n/// If `new_len` is less than `len`, the `Vec` is simply truncated.\n///\n/// This method uses a closure to create new values on every push. If you’d\n/// rather [`Clone`] a given bit, use [`resize`]. If you want to use the\n/// [`Default`] trait to generate values, you can pass [`Default::default`]\n/// as the second argument.\n///\n/// # Original\n///\n/// [`Vec::resize_with`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.resize_with)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1; 3];\n/// bv.resize_with(5, Default::default);\n/// assert_eq!(bv, bits![1, 1, 1, 0, 0]);\n///\n/// let mut bv = bitvec![];\n/// let mut p = 0;\n/// bv.resize_with(4, || { p += 1; p % 2 == 0 });\n/// assert_eq!(bv, bits![0, 1, 0, 1]);\n/// ```\n///\n/// [`Clone`]: https://doc.rust-lang.org/std/clone/trait.Clone.html\n/// [`Default`]: https://doc.rust-lang.org/std/default/trait.Default.html\n/// [`Default::default`]: https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default\n/// [`resize`]: #method.resize\n#[inline]\npub fn resize_with<F>(&mut self, new_len: usize, mut func: F)\n\twhere F: FnMut() -> bool{\n\t\tlet len = self.len();\n\t\tif new_len > len {\n\t\t\tlet ext = new_len - len;\n\t\t\tself.reserve(ext);\n\t\t\tunsafe {\n\t\t\t\tself.get_unchecked_mut(len .. new_len)\n\t\t\t\t\t.for_each(|_, _| func());\n\t\t\t}\n\t\t}\n\t\tunsafe {\n\t\t\tself.set_len(new_len);\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::retain":["/// Retains only the bits specified by the predicate.\n///\n/// In other words, remove all bits `b` such that `func(idx(b), &b)` returns\n/// `false`. This method operates in place, visiting each bit exactly once\n/// in the original order, and preserves the order of the retained bits.\n///\n/// # Original\n///\n/// [`Vec::retain`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.retain)\n///\n/// # API Differences\n///\n/// In order to allow more than one bit of information for the split\n/// decision, the predicate receives the index of each bit, as well as its\n/// value.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 1, 0, 0, 1];\n/// bv.retain(|i, b| (i % 2 == 0) ^ b);\n/// assert_eq!(bv, bits![0, 1, 0, 1]);\n/// ```\n#[inline]\npub fn retain<F>(&mut self, mut func: F)\n\twhere F: FnMut(usize, &bool) -> bool{\n\t\tfor n in (0 .. self.len()).rev() {\n\t\t\tif !func(n, unsafe { self.get_unchecked(n) }) {\n\t\t\t\tself.remove(n);\n\t\t\t}\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::set_len":["/// Forces the length of the vector to `new_len`.\n///\n/// This is a low-level operation that maintains none of the normal\n/// invariants of the type. Normally changing the length of a vector is done\n/// using one of the safe operations instead, such as [`truncate`],\n/// [`resize`], [`extend`], or [`clear`].\n///\n/// # Original\n///\n/// [`Vec::set_len`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.set_len)\n///\n/// # Safety\n///\n/// - `new_len` must be less than or equal to [`capacity()`].\n///\n/// # Examples\n///\n/// This method can be useful for situations in which the vector is serving\n/// as a buffer for other code, particularly over FFI:\n///\n/// ```rust\n/// # #![allow(dead_code)]\n/// # #![allow(improper_ctypes)]\n/// # const ERL_OK: i32 = 0;\n/// # extern \"C\" {\n/// #   fn erl_read_bits(\n/// #     bv: *mut BitVec<Msb0, u8>,\n/// #     bits_reqd: usize,\n/// #     bits_read: *mut usize,\n/// #   ) -> i32;\n/// # }\n/// use bitvec::prelude::*;\n///\n/// // `bitvec` could pair with `rustler` for a better bitstream\n/// type ErlBitstring = BitVec<Msb0, u8>;\n/// # pub fn _test() {\n/// let mut bits_read = 0;\n/// // An imaginary Erlang function wants a large bit buffer.\n/// let mut buf = ErlBitstring::with_capacity(32_768);\n/// // SAFETY: When `erl_read_bits` returns `ERL_OK`, it holds that:\n/// // 1. `bits_read` bits were initialized.\n/// // 2. `bits_read` <= the capacity (32_768)\n/// // which makes `set_len` safe to call.\n/// unsafe {\n///   // Make the FFI call...\n///   let status = erl_read_bits(&mut buf, 10, &mut bits_read);\n///   if status == ERL_OK {\n///     // ...and update the length to what was read in.\n///     buf.set_len(bits_read);\n///   }\n/// }\n/// # }\n/// ```\n///\n/// [`capacity()`]: #method.capacity\n/// [`clear`]: #method.clear\n/// [`extend`]: #method.extend\n/// [`resize`]: #method.resize\n/// [`truncate`]: #method.truncate\n#[inline]\npub unsafe fn set_len(&mut self, new_len: usize){\n\t\tassert!(\n\t\t\tnew_len <= BitPtr::<T>::REGION_MAX_BITS,\n\t\t\t\"Capacity exceeded: {} exceeds maximum length {}\",\n\t\t\tnew_len,\n\t\t\tBitPtr::<T>::REGION_MAX_BITS,\n\t\t);\n\t\tlet cap = self.capacity();\n\t\tassert!(\n\t\t\tnew_len <= cap,\n\t\t\t\"Capacity exceeded: {} exceeds allocation size {}\",\n\t\t\tnew_len,\n\t\t\tcap,\n\t\t);\n\t\tself.pointer = self\n\t\t\t.pointer\n\t\t\t.as_ptr()\n\t\t\t.pipe(BitPtr::from_bitslice_ptr_mut)\n\t\t\t.tap_mut(|bp| bp.set_len(new_len))\n\t\t\t.to_nonnull()\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::shrink_to_fit":["/// Shrinks the capacity of the vector as much as possible.\n///\n/// It will drop down as close as possible to the length but the allocator\n/// may still inform the vector that there is space for a few more bits.\n///\n/// # Original\n///\n/// [`Vec::shrink_to_fit`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.shrink_to_fit)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = BitVec::<Local, usize>::with_capacity(100);\n/// bv.extend([false, true, false].iter().copied());\n/// assert!(bv.capacity() >= 100);\n/// bv.shrink_to_fit();\n/// assert!(bv.capacity() >= 3);\n/// ```\n#[inline]\npub fn shrink_to_fit(&mut self){\n\t\tself.with_vec(|v| v.shrink_to_fit());\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::splice":["/// Creates a splicing iterator that replaces the specified range in the\n/// vector with the given `replace_with` iterator and yields the removed\n/// items. `replace_with` does not need to be the same length as `range`.\n///\n/// The element range is removed even if the iterator is not consumed until\n/// the end.\n///\n/// It is unspecified how many bits are removed from the vector if the\n/// `Splice` value is leaked.\n///\n/// The input iterator `replace_with` is only consumed when the `Splice`\n/// value is dropped.\n///\n/// This is optimal if:\n///\n/// - the tail (bits in the vector after `range`) is empty\n/// - or `replace_with` yields fewer bits than `range`’s length\n/// - or the lower bound of its `size_hint()` is exact\n///\n/// Otherwise, a temporary vector is allocated and the tail is moved twice.\n///\n/// # Original\n///\n/// [`Vec::splice`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.splice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 1, 0];\n/// let new = bits![1, 0];\n/// let old: BitVec = bv.splice(.. 2, new.iter().copied()).collect();\n/// assert_eq!(bv, bits![1, 0, 0]);\n/// assert_eq!(old, bits![0, 1]);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn splice<R, I>(\n\t\t&mut self,\n\t\trange: R,\n\t\treplace_with: I,\n\t) -> Splice<O, T, I::IntoIter>\n\twhere\n\t\tR: RangeBounds<usize>,\n\t\tI: IntoIterator<Item = bool>,{\n\t\tSplice::new(self.drain(range), replace_with)\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::split_off":["/// Splits the collection into two at the given index.\n///\n/// Returns a newly allocated vector containing the elements in range `[at,\n/// len)`. After the call, the original vector will be left containing the\n/// bits `[0, at)` with its previous capacity unchanged.\n///\n/// # Original\n///\n/// [`Vec::split_off`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.split_off)\n///\n/// # Panics\n///\n/// Panics if `at > len`.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 0, 1];\n/// let bv2 = bv.split_off(1);\n/// assert_eq!(bv, bits![0]);\n/// assert_eq!(bv2, bits![0, 1]);\n/// ```\n#[inline]\npub fn split_off(&mut self, at: usize) -> Self{\n\t\tlet len = self.len();\n\t\tassert!(at <= len, \"Index {} out of bounds: {}\", at, len);\n\t\tmatch at {\n\t\t\t0 => mem::replace(self, Self::with_capacity(self.capacity())),\n\t\t\tn if n == len => Self::new(),\n\t\t\t_ => unsafe {\n\t\t\t\tself.set_len(at);\n\t\t\t\tself.get_unchecked(at .. len).to_owned()\n\t\t\t},\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::swap_remove":["/// Removes a bit from the vector and returns it.\n///\n/// The removed bit is replaced by the last bit of the vector.\n///\n/// This does not preserve ordering, but is O(1).\n///\n/// # Original\n///\n/// [`Vec::swap_remove`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.swap_remove)\n///\n/// # Panics\n///\n/// Panics if `index` is out of bounds.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0, 0, 1, 0, 1];\n/// assert!(!bv.swap_remove(1));\n/// assert_eq!(bv, bits![0, 1, 1, 0]);\n///\n/// assert!(!bv.swap_remove(0));\n/// assert_eq!(bv, bits![0, 1, 1]);\n/// ```\n#[inline]\npub fn swap_remove(&mut self, index: usize) -> bool{\n\t\tlet len = self.len();\n\t\tassert!(index < len, \"Index {} out of bounds: {}\", index, len);\n\t\tlet last = len - 1;\n\t\t//  TODO(myrrlyn): Implement `BitSlice::xchg`?\n\t\tunsafe {\n\t\t\tself.swap_unchecked(index, last);\n\t\t\tself.set_len(last);\n\t\t\t*self.get_unchecked(last)\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::truncate":["/// Shortens the vector, keeping the first `len` bits and dropping the rest.\n///\n/// If `len` is greater than the vector’s current length, this has no\n/// effect.\n///\n/// The [`drain`] method can emulate `truncate`, but causes the excess bits\n/// to be returned instead of dropped.\n///\n/// Note that this method has no effect on the allocated capacity of the\n/// vector.\n///\n/// # Original\n///\n/// [`Vec::truncate`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.truncate)\n///\n/// # Examples\n///\n/// Truncating a five bit vector to two bits:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1; 5];\n/// bv.truncate(2);\n/// assert_eq!(bv.len(), 2);\n/// ```\n///\n/// No truncation occurs when `len` is greater than the vector’s current\n/// length:\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![1; 3];\n/// bv.truncate(8);\n/// assert_eq!(bv.len(), 3);\n/// ```\n///\n/// Truncating when `len == 0` is equivalent to calling the [`clean`]\n/// method.\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = bitvec![0; 3];\n/// bv.truncate(0);\n/// assert!(bv.is_empty());\n/// ```\n///\n/// [`clear`]: #method.clear\n/// [`drain`]: #method.drain\n#[inline]\npub fn truncate(&mut self, len: usize){\n\t\tif len < self.len() {\n\t\t\tunsafe { self.set_len(len) }\n\t\t}\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::api::<impl vec::BitVec<O, T>>::with_capacity":["/// Constructs a new, empty `BitVec<O, T>` with the specified capacity.\n///\n/// The vector will be able to hold at least `capacity` bits without\n/// reällocating. If `capacity` is 0, the vector will not allocate.\n///\n/// It is important to note that although the returned vector has the\n/// *capacity* specified, the vector will have a zero *length*. For an\n/// explanation of the difference between length and capacity, see\n/// *[Capacity and reällocation]*.\n///\n/// # Original\n///\n/// [`Vec::with_capacity`](https://doc.rust-lang.org/alloc/vec/struct.Vec.html#method.with_capacity)\n///\n/// # Panics\n///\n/// Panics if the requested capacity exceeds the vector’s limits.\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let mut bv = BitVec::<Local, usize>::with_capacity(10);\n///\n/// // The vector contains no items, even though it has capacity for more\n/// assert_eq!(bv.len(), 0);\n///\n/// // These are all done without reallocating...\n/// for i in 0..10 {\n///   bv.push(true);\n/// }\n///\n/// // ...but this may make the vector reallocate\n/// bv.push(false);\n/// ```\n///\n/// [Capacity and reällocation]: #capacity-and-reallocation\n#[inline]\npub fn with_capacity(capacity: usize) -> Self{\n\t\tassert!(\n\t\t\tcapacity <= BitSlice::<O, T>::MAX_BITS,\n\t\t\t\"Vector capacity exceeded: {} > {}\",\n\t\t\tcapacity,\n\t\t\tBitSlice::<O, T>::MAX_BITS\n\t\t);\n\t\tlet vec = capacity\n\t\t\t.pipe(crate::mem::elts::<T>)\n\t\t\t.pipe(Vec::<T>::with_capacity);\n\t\tlet (ptr, capacity) = (vec.as_ptr(), vec.capacity());\n\t\tmem::forget(vec);\n\t\tptr.pipe(BitPtr::uninhabited)\n\t\t\t.pipe(BitPtr::to_nonnull)\n\t\t\t.pipe(|pointer| Self { pointer, capacity })\n\t}","Real(LocalPath(\"src/vec/api.rs\"))"],"vec::iter::<impl std::iter::Extend<&'a bool> for vec::BitVec<O, T>>::extend":["#[inline]\nfn extend<I>(&mut self, iter: I)\n\twhere I: IntoIterator<Item = &'a bool>{\n\t\tself.extend(iter.into_iter().copied());\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::Extend<bool> for vec::BitVec<O, T>>::extend":["#[inline]\nfn extend<I>(&mut self, iter: I)\n\twhere I: IntoIterator<Item = bool>{\n\t\tlet mut iter = iter.into_iter();\n\t\tmatch iter.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => {\n\t\t\t\t// This body exists to try to accelerate the push-per-bit loop.\n\t\t\t\tself.reserve(n);\n\t\t\t\tlet len = self.len();\n\t\t\t\tlet new_len = len + n;\n\t\t\t\tlet new = unsafe { self.get_unchecked_mut(len .. new_len) };\n\t\t\t\tlet mut pulled = 0;\n\t\t\t\tfor (slot, bit) in new.iter_mut().zip(iter.by_ref()) {\n\t\t\t\t\tslot.set(bit);\n\t\t\t\t\tpulled += 1;\n\t\t\t\t}\n\t\t\t\tunsafe {\n\t\t\t\t\tself.set_len(len + pulled);\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\t\titer.for_each(|bit| self.push(bit));\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::FromIterator<&'a bool> for vec::BitVec<O, T>>::from_iter":["#[inline]\nfn from_iter<I>(iter: I) -> Self\n\twhere I: IntoIterator<Item = &'a bool>{\n\t\titer.into_iter().copied().pipe(Self::from_iter)\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::FromIterator<bool> for vec::BitVec<O, T>>::from_iter":["#[inline]\nfn from_iter<I>(iter: I) -> Self\n\twhere I: IntoIterator<Item = bool>{\n\t\tlet iter = iter.into_iter();\n\t\tlet mut out = match iter.size_hint() {\n\t\t\t(n, None) | (_, Some(n)) => Self::with_capacity(n),\n\t\t};\n\t\tout.extend(iter);\n\t\tout\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::IntoIterator for &'a mut vec::BitVec<O, T>>::into_iter":["#[inline]\nfn into_iter(self) -> Self::IntoIter{\n\t\tself.as_mut_bitslice().into_iter()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::IntoIterator for &'a vec::BitVec<O, T>>::into_iter":["#[inline]\nfn into_iter(self) -> Self::IntoIter{\n\t\tself.as_bitslice().into_iter()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::<impl std::iter::IntoIterator for vec::BitVec<O, T>>::into_iter":["#[inline]\nfn into_iter(self) -> Self::IntoIter{\n\t\tIntoIter {\n\t\t\titer: self.as_bitslice().bitptr().to_bitslice_ref().iter(),\n\t\t\t_bv: self,\n\t\t}\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Drain":["/** A draining iterator for `BitVec<O, T>`.\n\nThis `struct` is created by the [`drain`] method on [`BitVec`].\n\n# Original\n\n[`vec::Drain`](https://doc.rust-lang.org/alloc/vec/struct.Drain.html)\n\n[`BitVec`]: struct.BitVec.html\n[`drain`]: struct.BitVec.html#method.drain\n**/\npub struct Drain<'a, O, T>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n{\n\t/// Exclusive reference to the vector this drains.\n\tsource: NonNull<BitVec<O, T>>,\n\t/// The range of the source vector’s buffer being drained.\n\tdrain: Iter<'a, O, T>,\n\t/// The range of the source vector’s preserved tail. This runs from the back\n\t/// edge of the drained region to the vector’s original length.\n\ttail: Range<usize>,\n}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Drain::<'a, O, T>::as_bitslice":["/// Returns the remaining bits of this iterator as a bit-slice.\n///\n/// # Original\n///\n/// [`Drain::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.Drain.html#method.as_slice)\n///\n/// # API Differences\n///\n/// This method is renamed, as it operates on a bit-slice rather than an\n/// element slice.\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitslice(&self) -> &'a BitSlice<O, T>{\n\t\tself.drain.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Drain::<'a, O, T>::fill":["/// Attempts to overwrite the drained region with another iterator.\n///\n/// # Type Parameters\n///\n/// - `I`: Some source of `bool`s.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `iter`: A source of `bool`s with which to overwrite the drained span.\n///\n/// # Returns\n///\n/// Whether the drained span was completely filled, or if the replacement\n/// source `iter`ator was exhausted first.\n///\n/// # Effects\n///\n/// The source vector is extended to include all bits filled in from the\n/// replacement `iter`ator, but is *not* extended to include the tail, even\n/// if drained region is completely filled. This work is done in the\n/// destructor.\n#[inline]\nfn fill<I>(&mut self, iter: &mut I) -> FillStatus\n\twhere I: Iterator<Item = bool>{\n\t\tlet bitvec = unsafe { self.source.as_mut() };\n\t\t//  Get the length of the source vector. This will be grown as `iter`\n\t\t//  writes into the drain span.\n\t\tlet mut len = bitvec.len();\n\t\t//  Get the drain span as a bit-slice.\n\t\tlet span = unsafe { bitvec.get_unchecked_mut(len .. self.tail.start) };\n\n\t\t//  Set the exit flag to assume completion.\n\t\tlet mut out = FillStatus::FullSpan;\n\t\t//  Write the `iter` bits into the drain `span`.\n\t\tfor slot in span {\n\t\t\t//  While the `iter` is not exhausted, write it into the span and\n\t\t\t//  increase the vector length counter.\n\t\t\tif let Some(bit) = iter.next() {\n\t\t\t\tslot.set(bit);\n\t\t\t\tlen += 1;\n\t\t\t}\n\t\t\t//  If the `iter` exhausts before the drain `span` is filled, set\n\t\t\t//  the exit flag accordingly.\n\t\t\telse {\n\t\t\t\tout = FillStatus::EmptyInput;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t//  Update the vector length counter to include the bits written by\n\t\t//  `iter`.\n\t\tunsafe {\n\t\t\tbitvec.set_len(len);\n\t\t}\n\t\tout\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Drain::<'a, O, T>::move_tail":["/// Inserts `additional` capacity between the vector and the tail.\n///\n/// # Parameters\n///\n/// - `&mut self`\n/// - `additional`: The amount of new bits to reserve between the head and\n///   tail sections of the vector.\n///\n/// # Effects\n///\n/// This is permitted to reällocate the buffer in order to grow capacity.\n/// After completion, the tail segment will be relocated to begin\n/// `additional` bits after the head segment ends. The drain iteration\n/// cursor will not be modified.\n#[inline]\nunsafe fn move_tail(&mut self, additional: usize){\n\t\tlet bitvec = self.source.as_mut();\n\t\tlet tail_len = self.tail.end - self.tail.start;\n\n\t\t//  Reserve allocation capacity for `additional` and the tail.\n\t\t//  `.reserve()` begins from the `bitvec.len()`, so the tail length must\n\t\t//  still be included.\n\t\tlet full_len = additional + tail_len;\n\t\tbitvec.reserve(full_len);\n\t\tlet new_tail_start = additional + self.tail.start;\n\t\tlet orig_tail = mem::replace(\n\t\t\t&mut self.tail,\n\t\t\tnew_tail_start .. new_tail_start + tail_len,\n\t\t);\n\t\t//  Temporarily resize the vector to include the full buffer. This is\n\t\t//  necessary until `copy_within_unchecked` stops using `.len()`\n\t\t//  internally.\n\t\tlet len = bitvec.len();\n\t\tbitvec.set_len(full_len);\n\t\tbitvec.copy_within_unchecked(orig_tail, new_tail_start);\n\t\tbitvec.set_len(len);\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Drain::<'a, O, T>::new":["#[inline]\npub(super) fn new<R>(source: &'a mut BitVec<O, T>, range: R) -> Self\n\twhere R: RangeBounds<usize>{\n\t\t//  Hold the current vector size for bounds comparison.\n\t\tlet len = source.len();\n\t\t//  Normalize the input range and assert that it is within bounds.\n\t\tlet drain = dvl::normalize_range(range, len);\n\t\tdvl::assert_range(drain.clone(), len);\n\n\t\t//  The tail region is everything after the drain, before the real end.\n\t\tlet tail = drain.end .. len;\n\t\t//  The drain span is an iterator over the provided range.\n\t\tlet drain = unsafe {\n\t\t\t//  Set the source vector to end before the drain.\n\t\t\tsource.set_len(drain.start);\n\t\t\t//  Grab the drain range and produce an iterator over it.\n\t\t\tsource\n\t\t\t\t.as_bitslice()\n\t\t\t\t.get_unchecked(drain)\n\t\t\t\t//  Detach the region from the `source` borrow.\n\t\t\t\t.bitptr()\n\t\t\t\t.to_bitslice_ref()\n\t\t\t\t.iter()\n\t\t};\n\t\tlet source = source.into();\n\t\tSelf {\n\t\t\tsource,\n\t\t\tdrain,\n\t\t\ttail,\n\t\t}\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::FillStatus":["/// `std` uses a `bool` flag for done/not done, which is less clear about what\n/// it signals.\n#[repr(u8)]\nenum FillStatus {\n\t/// The drain span is completely filled.\n\tFullSpan   = 0,\n\t/// The replacement source is completely emptied.\n\tEmptyInput = 1,\n}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::IntoIter":["/** An iterator that moves out of a vector.\n\nThis `struct` is created by the `into_iter` method on [`BitVec`] (provided by\nthe [`IntoIterator`] trait).\n\n# Original\n\n[`vec::IntoIter`](https://doc.rust-lang.org/alloc/vec/struct.IntoIter.html)\n\n# API Differences\n\nThis explicitly requires that `O` and `T` type parameters are `'static`, which\nis not a bound present in the original. However, it is always *true*, so it will\nnot cause a compilation error.\n\n[`BitVec`]: struct.BitVec.html\n[`IntoIterator`]: https://doc.rust-lang.org/core/iter/trait.IntoIterator.html\n**/\npub struct IntoIter<O, T>\nwhere\n\tO: 'static + BitOrder,\n\tT: 'static + BitStore,\n{\n\t/// Take ownership of the vector for destruction.\n\t_bv: BitVec<O, T>,\n\t/// Use `BitSlice` iteration processes. This requires a `'static` lifetime,\n\t/// since it cannot borrow from itself.\n\titer: Iter<'static, O, T>,\n}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::IntoIter::<O, T>::as_bitslice":["/// Returns the remaining bits of this iterator as a bitslice.\n///\n/// # Original\n///\n/// [`vec::IntoIter::as_slice`](https://doc.rust-lang.org/alloc/vec/struct.IntoIter.html#method.as_slice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0, 1, 0, 1];\n/// let mut into_iter = bv.into_iter();\n/// assert_eq!(into_iter.as_bitslice(), bits![0, 1, 0, 1]);\n/// let _ = into_iter.next().unwrap();\n/// assert_eq!(into_iter.as_bitslice(), bits![1, 0, 1]);\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_bitslice(&self) -> &BitSlice<O, T>{\n\t\tself.iter.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::IntoIter::<O, T>::as_mut_bitslice":["/// Returns the remaining bits of this iterator as a mutable slice.\n///\n/// # Original\n///\n/// [`vec::IntoIter::as_mut_slice`](https://doc.rust-lang.org/alloc/vec/struct.IntoIter.html#method.as_mut_slice)\n///\n/// # Examples\n///\n/// ```rust\n/// use bitvec::prelude::*;\n///\n/// let bv = bitvec![0, 1, 0, 1];\n/// let mut into_iter = bv.into_iter();\n/// assert_eq!(into_iter.as_bitslice(), bits![0, 1, 0, 1]);\n/// into_iter.as_mut_bitslice().set(2, true);\n/// assert!(!into_iter.next().unwrap());\n/// assert!(into_iter.next().unwrap());\n/// assert!(into_iter.next().unwrap());\n/// ```\n#[inline]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_bitslice(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.iter.as_bitslice().bitptr().to_bitslice_mut()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::IntoIter::<O, T>::as_mut_slice":["inline(always)\n#[doc(hidden)]\n#[deprecated(note = \"Use `.as_mut_bitslice()` on iterators to view the \\\n\t                     remaining data.\")]\n#[cfg(not(tarpaulin_include))]\npub fn as_mut_slice(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::IntoIter::<O, T>::as_slice":["#[doc(hidden)]\n#[inline(always)]\n#[cfg(not(tarpaulin_include))]\n#[deprecated(\n\t\tnote = \"Use `.as_bitslice()` on iterators to view the remaining data.\"\n\t)]\npub fn as_slice(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Splice":["/** A splicing iterator for `BitVec`.\n\nThis struct is created by the [`splice()`] method on [`BitVec`]. See its\ndocumentation for more.\n\n# Original\n\n[`vec::Splice`](https://doc.rust-lang.org/alloc/vec/struct.Splice.html)\n\n[`BitVec`]: struct.BitVec.html\n[`splice()`]: struct.BitVec.html#method.splice\n**/\npub struct Splice<'a, O, T, I>\nwhere\n\tO: BitOrder,\n\tT: 'a + BitStore,\n\tI: Iterator<Item = bool>,\n{\n\t/// The region of the vector being spliced.\n\tdrain: Drain<'a, O, T>,\n\t/// The bitstream to be written into the drain.\n\tsplice: I,\n}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::iter::Splice::<'a, O, T, I>::new":["/// Constructs a splice out of a drain and a replacement.\npub(super) fn new<II>(drain: Drain<'a, O, T>, splice: II) -> Self\n\twhere II: IntoIterator<IntoIter = I, Item = bool>{\n\t\tlet splice = splice.into_iter();\n\t\tSelf { drain, splice }\n\t}","Real(LocalPath(\"src/vec/iter.rs\"))"],"vec::ops::<impl std::ops::BitAnd<Rhs> for vec::BitVec<O, T>>::bitand":["#[inline]\nfn bitand(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() &= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::BitAndAssign<Rhs> for vec::BitVec<O, T>>::bitand_assign":["#[inline]\nfn bitand_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() &= rhs;\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::BitOr<Rhs> for vec::BitVec<O, T>>::bitor":["#[inline]\nfn bitor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() |= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::BitOrAssign<Rhs> for vec::BitVec<O, T>>::bitor_assign":["#[inline]\nfn bitor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() |= rhs;\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::BitXor<Rhs> for vec::BitVec<O, T>>::bitxor":["#[inline]\nfn bitxor(mut self, rhs: Rhs) -> Self::Output{\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t\tself\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::BitXorAssign<Rhs> for vec::BitVec<O, T>>::bitxor_assign":["#[inline]\nfn bitxor_assign(&mut self, rhs: Rhs){\n\t\t*self.as_mut_bitslice() ^= rhs;\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::Deref for vec::BitVec<O, T>>::deref":["#[inline(always)]\nfn deref(&self) -> &Self::Target{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::DerefMut for vec::BitVec<O, T>>::deref_mut":["#[inline(always)]\nfn deref_mut(&mut self) -> &mut Self::Target{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::Drop for vec::BitVec<O, T>>::drop":["#[inline]\nfn drop(&mut self){\n\t\t//  The buffer elements do not have destructors.\n\t\tself.clear();\n\t\t//  Run the `Vec` destructor to deällocate the buffer.\n\t\tself.with_vec(|vec| unsafe { ManuallyDrop::drop(vec) });\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::Index<Idx> for vec::BitVec<O, T>>::index":["#[inline]\nfn index(&self, index: Idx) -> &Self::Output{\n\t\tself.as_bitslice().index(index)\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::IndexMut<Idx> for vec::BitVec<O, T>>::index_mut":["#[inline]\nfn index_mut(&mut self, index: Idx) -> &mut Self::Output{\n\t\tself.as_mut_bitslice().index_mut(index)\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::ops::<impl std::ops::Not for vec::BitVec<O, T>>::not":["#[inline]\nfn not(mut self) -> Self::Output{\n\t\tfor elem in self.as_mut_slice().iter_mut().map(dvl::mem_mut) {\n\t\t\t*elem = !*elem;\n\t\t}\n\t\tself\n\t}","Real(LocalPath(\"src/vec/ops.rs\"))"],"vec::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow":["#[inline(always)]\nfn borrow(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow_mut":["#[inline(always)]\nfn borrow_mut(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone":["#[inline]\nfn clone(&self) -> Self{\n\t\tself.as_bitslice().pipe(Self::from_bitslice)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone_from":["#[inline]\nfn clone_from(&mut self, other: &Self){\n\t\tself.clear();\n\t\tself.reserve(other.len());\n\t\tself.with_vec(|v| {\n\t\t\tv.extend(\n\t\t\t\tother\n\t\t\t\t\t.as_slice()\n\t\t\t\t\t.iter()\n\t\t\t\t\t.map(dvl::accessor)\n\t\t\t\t\t.map(BitAccess::load_value),\n\t\t\t)\n\t\t});\n\t\tunsafe {\n\t\t\tself.set_len(other.len());\n\t\t}\n\t\tself.pointer = self\n\t\t\t.bitptr()\n\t\t\t.tap_mut(|bp| unsafe { bp.set_head(other.bitptr().head()) })\n\t\t\t.to_nonnull();\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::Ord for vec::BitVec<O, T>>::cmp":["#[inline]\nfn cmp(&self, other: &Self) -> cmp::Ordering{\n\t\tself.as_bitslice().cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialEq<Rhs> for vec::BitVec<O, T>>::eq":["#[inline]\nfn eq(&self, other: &Rhs) -> bool{\n\t\tother == self.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitVec<O2, T2>) -> bool{\n\t\t**self == other.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitVec<O2, T2>) -> bool{\n\t\t*self == other.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["#[inline]\nfn eq(&self, other: &BitVec<O2, T2>) -> bool{\n\t\tself == other.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialOrd<Rhs> for vec::BitVec<O, T>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &Rhs) -> Option<cmp::Ordering>{\n\t\tother.partial_cmp(self.as_bitslice())\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::cmp::PartialOrd<vec::BitVec<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["#[inline]\nfn partial_cmp(&self, other: &BitVec<O, T>) -> Option<cmp::Ordering>{\n\t\tself.partial_cmp(other.as_bitslice())\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_mut":["#[inline(always)]\nfn as_mut(&mut self) -> &mut BitSlice<O, T>{\n\t\tself.as_mut_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_ref":["#[inline(always)]\nfn as_ref(&self) -> &BitSlice<O, T>{\n\t\tself.as_bitslice()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::From<&'a mut slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["#[inline(always)]\nfn from(slice: &'a mut BitSlice<O, T>) -> Self{\n\t\tslice.to_bitvec()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["#[inline(always)]\nfn from(slice: &'a BitSlice<O, T>) -> Self{\n\t\tslice.to_bitvec()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::From<boxed::BitBox<O, T>> for vec::BitVec<O, T>>::from":["#[inline(always)]\nfn from(boxed: BitBox<O, T>) -> Self{\n\t\tboxed.into_bitvec()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::Into<std::vec::Vec<T>> for vec::BitVec<O, T>>::into":["#[inline(always)]\nfn into(self) -> Vec<T>{\n\t\tself.into_vec()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::convert::TryFrom<std::vec::Vec<T>> for vec::BitVec<O, T>>::try_from":["#[inline(always)]\nfn try_from(vec: Vec<T>) -> Result<Self, Self::Error>{\n\t\tSelf::try_from_vec(vec)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::default::Default for vec::BitVec<O, T>>::default":["#[inline(always)]\nfn default() -> Self{\n\t\tSelf::new()\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::Binary for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tBinary::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::Debug for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tif fmt.alternate() {\n\t\t\tPointer::fmt(self, fmt)?;\n\t\t\tfmt.write_str(\" \")?;\n\t\t}\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::Display for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tDisplay::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::LowerHex for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tLowerHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::Octal for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tOctal::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::Pointer for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tself.bitptr()\n\t\t\t.render(fmt, \"Vec\", Some(any::type_name::<O>()), &[(\n\t\t\t\t\"capacity\",\n\t\t\t\t&self.capacity() as &dyn Debug,\n\t\t\t)])\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::fmt::UpperHex for vec::BitVec<O, T>>::fmt":["#[inline]\nfn fmt(&self, fmt: &mut Formatter) -> fmt::Result{\n\t\tUpperHex::fmt(self.as_bitslice(), fmt)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"vec::traits::<impl std::hash::Hash for vec::BitVec<O, T>>::hash":["#[inline]\nfn hash<H>(&self, state: &mut H)\n\twhere H: Hasher{\n\t\tself.as_bitslice().hash(state)\n\t}","Real(LocalPath(\"src/vec/traits.rs\"))"],"view::AsBits":["/** Views a region as an immutable bit-slice only.\n\nThis trait is an analogue to the [`AsRef`] trait, in that it enables any type to\nprovide an immutable-only view of a bit slice.\n\nIt does not require an `AsRef<[T: BitStore]>` implementation, and a blanket\nimplementation for all such types is provided. This allows you to choose whether\nto implement only one of `AsBits<T>` or `AsRef<[T]>`, and gain a bit-slice view\nwith either choice.\n\n# Type Parameters\n\n- `T`: The underlying storage region.\n\n# Notes\n\nYou are not *forbidden* from creating multiple views with different element\ntypes to the same region, but doing so is likely to cause inconsistent and\nunsurprising behavior.\n\nRefrain from implementing this trait with more than one storage argument unless\nyou are sure that you can uphold the memory region requirements of all of them,\nand are aware of the behavior conflicts that may arise.\n\n[`AsRef`]: https://doc.rust-lang.org/core/convert/trait.AsRef.html\n**/\npub trait AsBits<T>\nwhere T: BitStore\n{\n\t/// Views memory as a slice of immutable bits.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: The bit ordering used for the region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: The value that is providing a bit-slice view.\n\t///\n\t/// # Returns\n\t///\n\t/// An immutable view into some bits.\n\tfn as_bits<O>(&self) -> &BitSlice<O, T>\n\twhere O: BitOrder;\n}","Real(LocalPath(\"src/view.rs\"))"],"view::AsBitsMut":["/** Views a region as a mutable bit-slice.\n\nThis trait is an analogue to the [`AsMut`] trait, in that it enables any type to\nprovide a mutable view of a bit slice.\n\nIt does not require an `AsMut<[T: BitStore]>` implementation, and a blanket\nimplementation for all such types is provided. This allows you to choose whether\nto implement only one of `AsBitsMut<T>` or `AsMut<[T]>`, and gain a bit-slice\nview with either choice.\n\n# Type Parameters\n\n- `T`: The underlying storage region.\n\n# Notes\n\nYou are not *forbidden* from creating multiple views with different element\ntypes to the same region, but doing so is likely to cause inconsistent and\nunsurprising behavior.\n\nRefrain from implementing this trait with more than one storage argument unless\nyou are sure that you can uphold the memory region requirements of all of them,\nand are aware of the behavior conflicts that may arise.\n\n[`AsMut`]: https://doc.rust-lang.org/core/convert/trait.AsMut.html\n**/\npub trait AsBitsMut<T>\nwhere T: BitStore\n{\n\t/// Views memory as a slice of mutable bits.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: The bit ordering used for the region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&mut self`: The value that is providing a bit-slice view.\n\t///\n\t/// # Returns\n\t///\n\t/// A mutable view into some bits.\n\tfn as_bits_mut<O>(&mut self) -> &mut BitSlice<O, T>\n\twhere O: BitOrder;\n}","Real(LocalPath(\"src/view.rs\"))"],"view::BitView":["/** Views a type that can store bits as a bit-slice.\n\nThis trait is implemented on all `T: BitStore` types, and the arrays and slices\nof them that are supported by the standard library.\n\nThis means that until type-level integers are stabilized, only arrays in\n`[T: BitStore; 0 ..= 32]` will implement the trait; wider arrays will need to\nreborrow as slices `[T]` in order to use the slice implementation.\n\nIf you have a type that contains a bit-storage type that can be viewed with this\ntrait, then you can implement this trait by forwarding to the interior view.\n**/\npub trait BitView {\n\t/// The access-control type of the storage region.\n\ttype Store: BitStore;\n\n\t/// The underlying register type of the storage region.\n\ttype Mem: BitMemory;\n\n\t/// Views a memory region as a `BitSlice`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: The bit ordering used for the region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: The region to view as individual bits.\n\t///\n\t/// # Returns\n\t///\n\t/// A `&BitSlice` view over the region at `*self`.\n\tfn view_bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder;\n\n\t#[doc(hidden)]\n\t#[inline(always)]\n\t#[deprecated(\n\t\tsince = \"0.18.0\",\n\t\tnote = \"The method is renamed to `.view_bits`\"\n\t)]\n\tfn bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder {\n\t\tself.view_bits::<O>()\n\t}\n\n\t/// Views a memory region as a mutable `BitSlice`.\n\t///\n\t/// # Type Parameters\n\t///\n\t/// - `O`: The bit ordering used for the region.\n\t///\n\t/// # Parameters\n\t///\n\t/// - `&self`: The region to view as individual mutable bits.\n\t///\n\t/// # Returns\n\t///\n\t/// A `&mut BitSlice` view over the region at `*self`.\n\tfn view_bits_mut<O>(&mut self) -> &mut BitSlice<O, Self::Store>\n\twhere O: BitOrder;\n\n\t#[doc(hidden)]\n\t#[inline(always)]\n\t#[deprecated(\n\t\tsince = \"0.18.0\",\n\t\tnote = \"The method is renamed to `.view_bits_mut`\"\n\t)]\n\tfn bits_mut<O>(&mut self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder {\n\t\tself.view_bits_mut::<O>()\n\t}\n\n\t/// Produces the number of bits that the implementing type can hold.\n\t#[doc(hidden)]\n\tfn const_bits() -> usize\n\twhere Self: Sized {\n\t\tSelf::const_elts() << <<Self::Store as BitStore>::Mem as BitMemory>::INDX\n\t}\n\n\t/// Produces the number of memory elements that the implementing type holds.\n\t#[doc(hidden)]\n\tfn const_elts() -> usize\n\twhere Self: Sized;\n}","Real(LocalPath(\"src/view.rs\"))"],"view::BitView::bits":["#[doc(hidden)]\n#[inline(always)]\n#[deprecated(\n\t\tsince = \"0.18.0\",\n\t\tnote = \"The method is renamed to `.view_bits`\"\n\t)]\nfn bits<O>(&self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tself.view_bits::<O>()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"view::BitView::bits_mut":["#[doc(hidden)]\n#[inline(always)]\n#[deprecated(\n\t\tsince = \"0.18.0\",\n\t\tnote = \"The method is renamed to `.view_bits_mut`\"\n\t)]\nfn bits_mut<O>(&mut self) -> &BitSlice<O, Self::Store>\n\twhere O: BitOrder{\n\t\tself.view_bits_mut::<O>()\n\t}","Real(LocalPath(\"src/view.rs\"))"],"view::BitView::const_bits":["/// Produces the number of bits that the implementing type can hold.\n#[doc(hidden)]\nfn const_bits() -> usize\n\twhere Self: Sized{\n\t\tSelf::const_elts() << <<Self::Store as BitStore>::Mem as BitMemory>::INDX\n\t}","Real(LocalPath(\"src/view.rs\"))"]},"struct_constructor":{"&'a [<T as store::BitStore>::Alias]":["as_aliased_slice"],"&<T as store::BitStore>::Access":["accessor"],"&<array::BitArray<O, V> as std::ops::Deref>::Target":["deref"],"&<array::BitArray<O, V> as std::ops::Index<Idx>>::Output":["index"],"&<boxed::BitBox<O, T> as std::ops::Deref>::Target":["deref"],"&<boxed::BitBox<O, T> as std::ops::Index<Idx>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::Range<usize>>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeFrom<usize>>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeFull>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeInclusive<usize>>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeTo<usize>>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeToInclusive<usize>>>::Output":["index"],"&<slice::BitSlice<O, T> as std::ops::Index<usize>>::Output":["index"],"&<slice::proxy::BitMut<'_, O, T> as std::ops::Deref>::Target":["deref"],"&<vec::BitVec<O, T> as std::ops::Deref>::Target":["deref"],"&<vec::BitVec<O, T> as std::ops::Index<Idx>>::Output":["index"],"&[<T as store::BitStore>::Alias]":["as_aliased_slice"],"&[<T as store::BitStore>::Mem]":["as_slice"],"&[<V as view::BitView>::Mem]":["as_raw_slice"],"&[<V as view::BitView>::Store]":["as_slice"],"&[T]":["as_slice"],"&bool":["first","last"],"&mut <T as store::BitStore>::Mem":["mem_mut"],"&mut <array::BitArray<O, V> as std::ops::Deref>::Target":["deref_mut"],"&mut <array::BitArray<O, V> as std::ops::Index<Idx>>::Output":["index_mut"],"&mut <boxed::BitBox<O, T> as std::ops::Deref>::Target":["deref_mut"],"&mut <boxed::BitBox<O, T> as std::ops::Index<Idx>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::Range<usize>>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeFrom<usize>>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeFull>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeInclusive<usize>>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeTo<usize>>>::Output":["index_mut"],"&mut <slice::BitSlice<O, T> as std::ops::Index<std::ops::RangeToInclusive<usize>>>::Output":["index_mut"],"&mut <slice::proxy::BitMut<'_, O, T> as std::ops::Deref>::Target":["deref_mut"],"&mut <vec::BitVec<O, T> as std::ops::Deref>::Target":["deref_mut"],"&mut <vec::BitVec<O, T> as std::ops::Index<Idx>>::Output":["index_mut"],"&mut [<T as store::BitStore>::Mem]":["as_mut_slice"],"&mut [<V as view::BitView>::Mem]":["as_raw_mut_slice"],"&mut [<V as view::BitView>::Store]":["as_mut_slice"],"&mut [T]":["as_mut_slice"],"(&'a mut slice::BitSlice<O, T>, &'a mut slice::BitSlice<O, <T as store::BitStore>::Mem>, &'a mut slice::BitSlice<O, T>)":["region"],"(&'a slice::BitSlice<O, T>, &'a slice::BitSlice<O, <T as store::BitStore>::Mem>, &'a slice::BitSlice<O, T>)":["region"],"(&bool, &slice::BitSlice<O, T>)":["split_first","split_last"],"(&mut slice::BitSlice<O, <T as store::BitStore>::Alias>, &mut slice::BitSlice<O, <T as store::BitStore>::Alias>)":["split_at_mut","split_at_unchecked_mut"],"(&mut slice::BitSlice<O, T>, &mut slice::BitSlice<O, T>)":["split_at_aliased_mut","split_at_aliased_unchecked_mut"],"(&mut slice::BitSlice<O, T>, &mut slice::BitSlice<O, U>, &mut slice::BitSlice<O, T>)":["align_to_mut"],"(&slice::BitSlice<O, T>, &slice::BitSlice<O, T>)":["split_at","split_at_unchecked"],"(&slice::BitSlice<O, T>, &slice::BitSlice<O, U>, &slice::BitSlice<O, T>)":["align_to"],"(index::BitIdx<<T as store::BitStore>::Mem>, &'a <T as store::BitStore>::Alias, index::BitTail<<T as store::BitStore>::Mem>)":["enclave"],"(index::BitIdx<<T as store::BitStore>::Mem>, &'a mut slice::BitSlice<O, T>, index::BitTail<<T as store::BitStore>::Mem>)":["enclave"],"(index::BitIdx<<T as store::BitStore>::Mem>, &'a slice::BitSlice<O, T>, index::BitTail<<T as store::BitStore>::Mem>)":["enclave"],"(index::BitIdx<M>, bool)":["decr","incr"],"(isize, index::BitIdx<M>)":["offset"],"(pointer::Address<T>, index::BitIdx<<T as store::BitStore>::Mem>, usize)":["raw_parts"],"(slice::proxy::BitMut<'_, O, <T as store::BitStore>::Alias>, &mut slice::BitSlice<O, <T as store::BitStore>::Alias>)":["split_first_mut","split_last_mut"],"(std::option::Option<(index::BitIdx<<T as store::BitStore>::Mem>, &'a <T as store::BitStore>::Alias)>, &'a [<T as store::BitStore>::Mem], std::option::Option<(&'a <T as store::BitStore>::Alias, index::BitTail<<T as store::BitStore>::Mem>)>)":["region"],"(std::option::Option<(index::BitIdx<<T as store::BitStore>::Mem>, &'a <T as store::BitStore>::Alias)>, &'a mut [<T as store::BitStore>::Mem], std::option::Option<(&'a <T as store::BitStore>::Alias, index::BitTail<<T as store::BitStore>::Mem>)>)":["region"],"(usize, index::BitTail<M>)":["span"],"(usize, std::option::Option<usize>)":["size_hint"],"*const <T as store::BitStore>::Access":["to_access"],"*const <T as store::BitStore>::Alias":["to_alias"],"<&'a array::BitArray<O, V> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<&'a mut array::BitArray<O, V> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<&'a mut slice::BitSlice<O, T> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<&'a mut slice::BitSlice<O, T> as std::ops::Not>::Output":["not"],"<&'a mut vec::BitVec<O, T> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<&'a slice::BitSlice<O, T> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<&'a vec::BitVec<O, T> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<<T as store::BitStore>::Alias as store::BitStore>::Mem":["alias_mem"],"<I as slice::api::BitSliceIndex<'a, O, T>>::Immut":["get","get_unchecked"],"<I as slice::api::BitSliceIndex<'a, O, T>>::Mut":["get_mut","get_unchecked_mut"],"<Self as slice::api::BitSliceIndex<'a, O, T>>::Immut":["get","get_unchecked","index"],"<Self as slice::api::BitSliceIndex<'a, O, T>>::Mut":["get_mut","get_unchecked_mut","index_mut"],"<Self as std::iter::Iterator>::Item":["finish"],"<T as store::BitStore>::Mem":["load_aliased_local","remove_alias"],"<array::BitArray<O, V> as std::ops::BitAnd<Rhs>>::Output":["bitand"],"<array::BitArray<O, V> as std::ops::BitOr<Rhs>>::Output":["bitor"],"<array::BitArray<O, V> as std::ops::BitXor<Rhs>>::Output":["bitxor"],"<array::BitArray<O, V> as std::ops::Not>::Output":["not"],"<boxed::BitBox<O, T> as std::ops::BitAnd<Rhs>>::Output":["bitand"],"<boxed::BitBox<O, T> as std::ops::BitOr<Rhs>>::Output":["bitor"],"<boxed::BitBox<O, T> as std::ops::BitXor<Rhs>>::Output":["bitxor"],"<boxed::BitBox<O, T> as std::ops::Not>::Output":["not"],"<domain::Domain<'a, T> as std::iter::Iterator>::Item":["next","next_back"],"<index::BitMask<M> as std::ops::Not>::Output":["not"],"<slice::BitSlice<O, T> as std::borrow::ToOwned>::Owned":["to_owned"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back","pop_back","pop_front"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back","pop_back","pop_front"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::Item":["finish","next","next_back"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::Item":["finish","next","next_back"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::Item":["next"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::Item":["next"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::Item":["finish","next","next_back"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::Item":["finish","next","next_back"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::Item":["next"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::Item":["next"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::Immut":["get","get_unchecked","index"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::Mut":["get_mut","get_unchecked_mut","index_mut"],"<vec::BitVec<O, T> as std::iter::IntoIterator>::IntoIter":["into_iter"],"<vec::BitVec<O, T> as std::ops::BitAnd<Rhs>>::Output":["bitand"],"<vec::BitVec<O, T> as std::ops::BitOr<Rhs>>::Output":["bitor"],"<vec::BitVec<O, T> as std::ops::BitXor<Rhs>>::Output":["bitxor"],"<vec::BitVec<O, T> as std::ops::Not>::Output":["not"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::Item":["last","next","next_back","nth","nth_back"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::Item":["next","next_back","nth_back"],"array::BitArray":["clone","default","from","new","try_from","zeroed"],"array::traits::TryFromBitSliceError":["clone"],"bool":["all","any","contains","ends_with","eq","get_bit","inherent_is_empty","is_empty","not_all","not_any","pop","read","remove","some","starts_with","swap_remove","test"],"boxed::BitBox":["clone","default","from","from_bitslice","from_boxed_slice","from_raw","into_boxed_bitslice","new","try_from","try_from_boxed_slice"],"domain::BitDomain":["bit_domain","clone","empty","major","minor","new","partial_head","partial_tail","spanning"],"domain::BitDomainMut":["bit_domain_mut","empty","major","minor","new","partial_head","partial_tail","spanning"],"domain::Domain":["clone","domain","empty","major","minor","new","partial_head","partial_tail","spanning"],"domain::DomainMut":["domain_mut","empty","major","minor","new","partial_head","partial_tail","spanning"],"for<'a> fn(&'a Self, index::BitIdx<M>)":["get_writer"],"for<'a> fn(&'a Self, index::BitMask<M>)":["get_writers"],"impl std::iter::Iterator<Item = index::BitIdx<M>> + std::iter::DoubleEndedIterator + std::iter::ExactSizeIterator + std::iter::FusedIterator":["range","range_all"],"impl std::iter::Iterator<Item = index::BitSel<M>> + std::iter::DoubleEndedIterator + std::iter::ExactSizeIterator + std::iter::FusedIterator":["range_all"],"impl std::iter::Iterator<Item = index::BitTail<M>> + std::iter::DoubleEndedIterator + std::iter::ExactSizeIterator + std::iter::FusedIterator":["range_from"],"index::BitIdx":["clone","default","head","new","new_unchecked"],"index::BitMask":["clone","default","mask","new","sum"],"index::BitPos":["at","clone","default","new","new_unchecked","position"],"index::BitSel":["clone","default","new","new_unchecked","select"],"index::BitTail":["clone","default","new_unchecked","tail"],"order::Lsb0":["clone","default"],"order::Msb0":["clone","default"],"pointer::Address":["clone","from","new","pointer"],"pointer::BitPtr":["bitptr","clone","default","from_bitslice_ptr","from_bitslice_ptr_mut","new","new_unchecked","uninhabited"],"slice::iter::Chunks":["chunks","clone","new"],"slice::iter::ChunksExact":["chunks_exact","clone","new"],"slice::iter::ChunksExactMut":["chunks_exact_mut","new"],"slice::iter::ChunksMut":["chunks_mut","new"],"slice::iter::Iter":["clone","iter"],"slice::iter::IterMut":["iter_mut"],"slice::iter::RChunks":["clone","new","rchunks"],"slice::iter::RChunksExact":["clone","new","rchunks_exact"],"slice::iter::RChunksExactMut":["new","rchunks_exact_mut"],"slice::iter::RChunksMut":["new","rchunks_mut"],"slice::iter::RSplit":["clone","new","rsplit"],"slice::iter::RSplitMut":["new","rsplit_mut"],"slice::iter::RSplitN":["new","rsplitn"],"slice::iter::RSplitNMut":["new","rsplitn_mut"],"slice::iter::Split":["clone","new","split"],"slice::iter::SplitMut":["new","split_mut"],"slice::iter::SplitN":["new","splitn"],"slice::iter::SplitNMut":["new","splitn_mut"],"slice::iter::Windows":["clone","new","windows"],"slice::proxy::BitMut":["first_mut","last_mut","new_unchecked"],"std::boxed::Box":["into","into_boxed_slice"],"std::cmp::Ordering":["cmp","partial_cmp"],"std::ops::Range":["normalize_range"],"std::pin::Pin":["pin"],"std::ptr::NonNull":["to_nonnull"],"std::vec::Vec":["into","into_vec"],"u8":["u8_from_be_bits","u8_from_le_bits","value"],"usize":["aligned_to_size","capacity","cmp_layout","const_bits","const_elts","count","count_ones","count_zeros","elements","len","read","value","write"],"vec::BitVec":["clone","default","from","from_bitslice","from_iter","from_raw_parts","from_vec","into_bitvec","new","repeat","split_off","to_bitvec","to_vec","try_from","try_from_vec","with_capacity"],"vec::iter::Drain":["drain","new"],"vec::iter::FillStatus":["clone","fill"],"vec::iter::IntoIter":["clone"],"vec::iter::Splice":["new","splice"]},"struct_to_trait":{"<A as view::AsBits<T>>::A":["view::AsBits"],"<A as view::AsBitsMut<T>>::A":["view::AsBitsMut"],"<R as access::BitAccess<M>>::R":["access::BitAccess"],"<T as view::BitView>::T":["view::BitView"],"array::BitArray":["field::BitField","std::borrow::Borrow","std::borrow::BorrowMut","std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::convert::AsMut","std::convert::AsRef","std::convert::From","std::convert::TryFrom","std::default::Default","std::fmt::Binary","std::fmt::Debug","std::fmt::Display","std::fmt::LowerHex","std::fmt::Octal","std::fmt::UpperHex","std::hash::Hash","std::marker::Copy","std::marker::Unpin","std::ops::BitAnd","std::ops::BitAndAssign","std::ops::BitOr","std::ops::BitOrAssign","std::ops::BitXor","std::ops::BitXorAssign","std::ops::Deref","std::ops::DerefMut","std::ops::Index","std::ops::IndexMut","std::ops::Not"],"array::traits::TryFromBitSliceError":["std::clone::Clone","std::error::Error","std::fmt::Debug","std::fmt::Display","std::marker::Copy"],"boxed::BitBox":["field::BitField","std::borrow::Borrow","std::borrow::BorrowMut","std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::convert::AsMut","std::convert::AsRef","std::convert::From","std::convert::Into","std::convert::TryFrom","std::default::Default","std::fmt::Binary","std::fmt::Debug","std::fmt::Display","std::fmt::LowerHex","std::fmt::Octal","std::fmt::Pointer","std::fmt::UpperHex","std::hash::Hash","std::marker::Send","std::marker::Sync","std::marker::Unpin","std::ops::BitAnd","std::ops::BitAndAssign","std::ops::BitOr","std::ops::BitOrAssign","std::ops::BitXor","std::ops::BitXorAssign","std::ops::Deref","std::ops::DerefMut","std::ops::Drop","std::ops::Index","std::ops::IndexMut","std::ops::Not"],"domain::BitDomain":["std::clone::Clone","std::fmt::Debug","std::marker::Copy"],"domain::BitDomainMut":["std::fmt::Debug"],"domain::Domain":["std::clone::Clone","std::fmt::Binary","std::fmt::Debug","std::fmt::LowerHex","std::fmt::Octal","std::fmt::UpperHex","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator","std::marker::Copy"],"domain::DomainMut":["std::fmt::Debug"],"index::BitIdx":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Binary","std::fmt::Debug","std::fmt::Display","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"index::BitMask":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::fmt::Display","std::hash::Hash","std::iter::Sum","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq","std::ops::BitAnd","std::ops::BitOr","std::ops::Not"],"index::BitPos":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"index::BitSel":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::fmt::Display","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"index::BitTail":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::fmt::Display","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"order::Lsb0":["order::BitOrder","std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"order::Msb0":["order::BitOrder","std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::default::Default","std::fmt::Debug","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"pointer::Address":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::convert::From","std::fmt::Debug","std::fmt::Pointer","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"pointer::BitPtr":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::default::Default","std::fmt::Debug","std::fmt::Pointer","std::hash::Hash","std::marker::Copy","std::marker::StructuralEq"],"slice::BitSlice":["field::BitField","std::borrow::ToOwned","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::fmt::Binary","std::fmt::Debug","std::fmt::Display","std::fmt::LowerHex","std::fmt::Octal","std::fmt::Pointer","std::fmt::UpperHex","std::hash::Hash","std::marker::Send","std::marker::Sync","std::ops::BitAndAssign","std::ops::BitOrAssign","std::ops::BitXorAssign","std::ops::Index","std::ops::IndexMut"],"slice::iter::Chunks":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::ChunksExact":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::ChunksExactMut":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::ChunksMut":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::Iter":["std::clone::Clone","std::convert::AsRef","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator","std::marker::Copy","std::marker::Send","std::marker::Sync"],"slice::iter::IterMut":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator","std::marker::Send","std::marker::Sync"],"slice::iter::RChunks":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RChunksExact":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RChunksExactMut":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RChunksMut":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RSplit":["slice::iter::SplitIter","std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RSplitMut":["slice::iter::SplitIter","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RSplitN":["std::fmt::Debug","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::RSplitNMut":["std::fmt::Debug","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::Split":["slice::iter::SplitIter","std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::SplitMut":["slice::iter::SplitIter","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::SplitN":["std::fmt::Debug","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::SplitNMut":["std::fmt::Debug","std::iter::FusedIterator","std::iter::Iterator"],"slice::iter::Windows":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"slice::proxy::BitMut":["std::fmt::Debug","std::ops::Deref","std::ops::DerefMut","std::ops::Drop"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq":["std::fmt::Debug"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq":["std::fmt::Debug"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq":["std::fmt::Debug"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq":["std::fmt::Debug"],"std::cell::Cell":["store::BitStore","store::seal::Sealed"],"std::ops::Range":["slice::api::BitSliceIndex"],"std::ops::RangeFrom":["slice::api::BitSliceIndex"],"std::ops::RangeFull":["slice::api::BitSliceIndex"],"std::ops::RangeInclusive":["slice::api::BitSliceIndex"],"std::ops::RangeTo":["slice::api::BitSliceIndex"],"std::ops::RangeToInclusive":["slice::api::BitSliceIndex"],"std::sync::atomic::AtomicU16":["store::BitStore","store::seal::Sealed"],"std::sync::atomic::AtomicU32":["store::BitStore","store::seal::Sealed"],"std::sync::atomic::AtomicU64":["store::BitStore","store::seal::Sealed"],"std::sync::atomic::AtomicU8":["store::BitStore","store::seal::Sealed"],"std::sync::atomic::AtomicUsize":["store::BitStore","store::seal::Sealed"],"vec::BitVec":["field::BitField","std::borrow::Borrow","std::borrow::BorrowMut","std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::convert::AsMut","std::convert::AsRef","std::convert::From","std::convert::Into","std::convert::TryFrom","std::default::Default","std::fmt::Binary","std::fmt::Debug","std::fmt::Display","std::fmt::LowerHex","std::fmt::Octal","std::fmt::Pointer","std::fmt::UpperHex","std::hash::Hash","std::io::Write","std::iter::Extend","std::iter::FromIterator","std::iter::IntoIterator","std::marker::Send","std::marker::Sync","std::marker::Unpin","std::ops::BitAnd","std::ops::BitAndAssign","std::ops::BitOr","std::ops::BitOrAssign","std::ops::BitXor","std::ops::BitXorAssign","std::ops::Deref","std::ops::DerefMut","std::ops::Drop","std::ops::Index","std::ops::IndexMut","std::ops::Not"],"vec::iter::Drain":["std::convert::AsRef","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator","std::marker::Send","std::marker::Sync","std::ops::Drop"],"vec::iter::FillStatus":["std::clone::Clone","std::cmp::Eq","std::cmp::Ord","std::cmp::PartialEq","std::cmp::PartialOrd","std::fmt::Debug","std::marker::Copy","std::marker::StructuralEq","std::marker::StructuralPartialEq"],"vec::iter::IntoIter":["std::clone::Clone","std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator"],"vec::iter::Splice":["std::fmt::Debug","std::iter::DoubleEndedIterator","std::iter::ExactSizeIterator","std::iter::FusedIterator","std::iter::Iterator","std::ops::Drop"]},"targets":{"<A as view::AsBits<T>>::as_bits":["as_bits","Real(LocalPath(\"src/view.rs\"))","view::AsBits"],"<A as view::AsBitsMut<T>>::as_bits_mut":["as_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::AsBitsMut"],"<T as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<T as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<T as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 0] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 0] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 0] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 10] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 10] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 10] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 11] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 11] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 11] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 12] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 12] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 12] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 13] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 13] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 13] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 14] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 14] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 14] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 15] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 15] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 15] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 16] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 16] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 16] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 17] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 17] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 17] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 18] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 18] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 18] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 19] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 19] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 19] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 1] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 1] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 1] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 20] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 20] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 20] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 21] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 21] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 21] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 22] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 22] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 22] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 23] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 23] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 23] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 24] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 24] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 24] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 25] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 25] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 25] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 26] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 26] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 26] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 27] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 27] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 27] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 28] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 28] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 28] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 29] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 29] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 29] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 2] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 2] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 2] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 30] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 30] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 30] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 31] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 31] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 31] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 32] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 32] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 32] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 33] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 33] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 33] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 34] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 34] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 34] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 35] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 35] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 35] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 36] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 36] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 36] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 37] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 37] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 37] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 38] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 38] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 38] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 39] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 39] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 39] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 3] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 3] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 3] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 40] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 40] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 40] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 41] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 41] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 41] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 42] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 42] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 42] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 43] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 43] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 43] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 44] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 44] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 44] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 45] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 45] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 45] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 46] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 46] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 46] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 47] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 47] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 47] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 48] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 48] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 48] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 49] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 49] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 49] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 4] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 4] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 4] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 50] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 50] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 50] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 51] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 51] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 51] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 52] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 52] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 52] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 53] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 53] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 53] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 54] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 54] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 54] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 55] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 55] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 55] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 56] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 56] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 56] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 57] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 57] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 57] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 58] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 58] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 58] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 59] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 59] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 59] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 5] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 5] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 5] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 60] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 60] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 60] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 61] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 61] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 61] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 62] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 62] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 62] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 63] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 63] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 63] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 64] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 64] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 64] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 6] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 6] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 6] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 7] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 7] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 7] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 8] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 8] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 8] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 9] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 9] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T; 9] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T] as view::BitView>::const_elts":["const_elts","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T] as view::BitView>::view_bits":["view_bits","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<[T] as view::BitView>::view_bits_mut":["view_bits_mut","Real(LocalPath(\"src/view.rs\"))","view::BitView"],"<array::BitArray<O, V> as field::BitField>::load_be":["load_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<array::BitArray<O, V> as field::BitField>::load_le":["load_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<array::BitArray<O, V> as field::BitField>::store_be":["store_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<array::BitArray<O, V> as field::BitField>::store_le":["store_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<array::traits::TryFromBitSliceError as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::Display"],"<boxed::BitBox<O, T> as field::BitField>::load_be":["load_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<boxed::BitBox<O, T> as field::BitField>::load_le":["load_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<boxed::BitBox<O, T> as field::BitField>::store_be":["store_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<boxed::BitBox<O, T> as field::BitField>::store_le":["store_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<domain::BitDomain<'_, O, T> as std::clone::Clone>::clone":["clone","Real(LocalPath(\"src/domain.rs\"))","std::clone::Clone"],"<domain::Domain<'_, T> as std::clone::Clone>::clone":["clone","Real(LocalPath(\"src/domain.rs\"))","std::clone::Clone"],"<domain::Domain<'_, T> as std::fmt::Binary>::fmt":["fmt","Real(LocalPath(\"src/domain.rs\"))","std::fmt::Binary"],"<domain::Domain<'_, T> as std::fmt::LowerHex>::fmt":["fmt","Real(LocalPath(\"src/domain.rs\"))","std::fmt::LowerHex"],"<domain::Domain<'_, T> as std::fmt::Octal>::fmt":["fmt","Real(LocalPath(\"src/domain.rs\"))","std::fmt::Octal"],"<domain::Domain<'_, T> as std::fmt::UpperHex>::fmt":["fmt","Real(LocalPath(\"src/domain.rs\"))","std::fmt::UpperHex"],"<domain::Domain<'_, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/domain.rs\"))","std::iter::ExactSizeIterator"],"<domain::Domain<'a, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/domain.rs\"))","std::iter::DoubleEndedIterator"],"<domain::Domain<'a, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/domain.rs\"))","std::iter::Iterator"],"<index::BitIdx<M> as std::fmt::Binary>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Binary"],"<index::BitIdx<M> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Debug"],"<index::BitIdx<M> as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Display"],"<index::BitMask<M> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Debug"],"<index::BitMask<M> as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Display"],"<index::BitMask<M> as std::iter::Sum<index::BitSel<M>>>::sum":["sum","Real(LocalPath(\"src/index.rs\"))","std::iter::Sum"],"<index::BitMask<M> as std::ops::BitAnd<M>>::bitand":["bitand","Real(LocalPath(\"src/index.rs\"))","std::ops::BitAnd"],"<index::BitMask<M> as std::ops::BitOr<M>>::bitor":["bitor","Real(LocalPath(\"src/index.rs\"))","std::ops::BitOr"],"<index::BitMask<M> as std::ops::Not>::not":["not","Real(LocalPath(\"src/index.rs\"))","std::ops::Not"],"<index::BitPos<M> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Debug"],"<index::BitSel<M> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Debug"],"<index::BitSel<M> as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Display"],"<index::BitTail<M> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Debug"],"<index::BitTail<M> as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/index.rs\"))","std::fmt::Display"],"<order::Lsb0 as order::BitOrder>::at":["at","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<order::Lsb0 as order::BitOrder>::mask":["mask","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<order::Lsb0 as order::BitOrder>::select":["select","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<order::Msb0 as order::BitOrder>::at":["at","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<order::Msb0 as order::BitOrder>::mask":["mask","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<order::Msb0 as order::BitOrder>::select":["select","Real(LocalPath(\"src/order.rs\"))","order::BitOrder"],"<pointer::Address<T> as std::clone::Clone>::clone":["clone","Real(LocalPath(\"src/pointer.rs\"))","std::clone::Clone"],"<pointer::Address<T> as std::convert::From<&T>>::from":["from","Real(LocalPath(\"src/pointer.rs\"))","std::convert::From"],"<pointer::Address<T> as std::convert::From<&mut T>>::from":["from","Real(LocalPath(\"src/pointer.rs\"))","std::convert::From"],"<pointer::Address<T> as std::convert::From<*const T>>::from":["from","Real(LocalPath(\"src/pointer.rs\"))","std::convert::From"],"<pointer::Address<T> as std::convert::From<*mut T>>::from":["from","Real(LocalPath(\"src/pointer.rs\"))","std::convert::From"],"<pointer::Address<T> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/pointer.rs\"))","std::fmt::Debug"],"<pointer::Address<T> as std::fmt::Pointer>::fmt":["fmt","Real(LocalPath(\"src/pointer.rs\"))","std::fmt::Pointer"],"<pointer::BitPtr<T> as std::clone::Clone>::clone":["clone","Real(LocalPath(\"src/pointer.rs\"))","std::clone::Clone"],"<pointer::BitPtr<T> as std::cmp::PartialEq<pointer::BitPtr<U>>>::eq":["eq","Real(LocalPath(\"src/pointer.rs\"))","std::cmp::PartialEq"],"<pointer::BitPtr<T> as std::default::Default>::default":["default","Real(LocalPath(\"src/pointer.rs\"))","std::default::Default"],"<pointer::BitPtr<T> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/pointer.rs\"))","std::fmt::Debug"],"<pointer::BitPtr<T> as std::fmt::Pointer>::fmt":["fmt","Real(LocalPath(\"src/pointer.rs\"))","std::fmt::Pointer"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_be":["load_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::load_le":["load_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_be":["store_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Lsb0, T> as field::BitField>::store_le":["store_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_be":["load_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::load_le":["load_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_be":["store_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::BitSlice<order::Msb0, T> as field::BitField>::store_le":["store_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<slice::iter::Chunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Chunks<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::ChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Iter<'_, O, T> as std::clone::Clone>::clone":["clone","Real(LocalPath(\"src/slice/iter.rs\"))","std::clone::Clone"],"<slice::iter::Iter<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["as_ref","Real(LocalPath(\"src/slice/iter.rs\"))","std::convert::AsRef"],"<slice::iter::Iter<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Iter<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Iter<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::IterMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::IterMut<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunks<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunks<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExact<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExact<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExactMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksExactMut<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksMut<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RChunksMut<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplit<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::RSplit<'a, O, T, P> as slice::iter::SplitIter>::finish":["finish","Real(LocalPath(\"src/slice/iter.rs\"))","slice::iter::SplitIter"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplit<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::RSplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["finish","Real(LocalPath(\"src/slice/iter.rs\"))","slice::iter::SplitIter"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::RSplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Split<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::Split<'a, O, T, P> as slice::iter::SplitIter>::finish":["finish","Real(LocalPath(\"src/slice/iter.rs\"))","slice::iter::SplitIter"],"<slice::iter::Split<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Split<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::SplitMut<'a, O, T, P> as slice::iter::SplitIter>::finish":["finish","Real(LocalPath(\"src/slice/iter.rs\"))","slice::iter::SplitIter"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitN<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitN<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitNMut<'_, O, T, P> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/iter.rs\"))","std::fmt::Debug"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::SplitNMut<'a, O, T, P> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Windows<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::ExactSizeIterator"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Windows<'a, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::DoubleEndedIterator"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::iter::Windows<'a, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::Iterator"],"<slice::proxy::BitMut<'_, O, T> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/proxy.rs\"))","std::fmt::Debug"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Deref>::deref":["deref","Real(LocalPath(\"src/slice/proxy.rs\"))","std::ops::Deref"],"<slice::proxy::BitMut<'_, O, T> as std::ops::DerefMut>::deref_mut":["deref_mut","Real(LocalPath(\"src/slice/proxy.rs\"))","std::ops::DerefMut"],"<slice::proxy::BitMut<'_, O, T> as std::ops::Drop>::drop":["drop","Real(LocalPath(\"src/slice/proxy.rs\"))","std::ops::Drop"],"<slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Debug"],"<slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Debug"],"<slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Debug"],"<slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq<'_> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Debug"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::Range<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFrom<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeFull as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeTo<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<std::ops::RangeToInclusive<usize> as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index":["index","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<usize as slice::api::BitSliceIndex<'a, O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/api.rs\"))","slice::api::BitSliceIndex"],"<vec::BitVec<O, T> as field::BitField>::load_be":["load_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<vec::BitVec<O, T> as field::BitField>::load_le":["load_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<vec::BitVec<O, T> as field::BitField>::store_be":["store_be","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<vec::BitVec<O, T> as field::BitField>::store_le":["store_le","Real(LocalPath(\"src/field.rs\"))","field::BitField"],"<vec::iter::Drain<'_, O, T> as std::convert::AsRef<slice::BitSlice<O, T>>>::as_ref":["as_ref","Real(LocalPath(\"src/vec/iter.rs\"))","std::convert::AsRef"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::Drain<'_, O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::Drain<'_, O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::ExactSizeIterator"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Drain<'_, O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Drain<'_, O, T> as std::ops::Drop>::drop":["drop","Real(LocalPath(\"src/vec/iter.rs\"))","std::ops::Drop"],"<vec::iter::Drain<'a, O, T> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/vec/iter.rs\"))","std::fmt::Debug"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::IntoIter<O, T> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::IntoIter<O, T> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::ExactSizeIterator"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::last":["last","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::nth":["nth","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::IntoIter<O, T> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::next_back":["next_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::DoubleEndedIterator>::nth_back":["nth_back","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::DoubleEndedIterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::ExactSizeIterator>::len":["len","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::ExactSizeIterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::count":["count","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::next":["next","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Splice<'_, O, T, I> as std::iter::Iterator>::size_hint":["size_hint","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Iterator"],"<vec::iter::Splice<'_, O, T, I> as std::ops::Drop>::drop":["drop","Real(LocalPath(\"src/vec/iter.rs\"))","std::ops::Drop"],"access::BitAccess::clear_bit":["clear_bit","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::clear_bits":["clear_bits","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::get_bit":["get_bit","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::get_bits":["get_bits","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::get_writer":["get_writer","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::get_writers":["get_writers","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::invert_bit":["invert_bit","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::invert_bits":["invert_bits","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::load_value":["load_value","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::set_bit":["set_bit","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::set_bits":["set_bits","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::store_value":["store_value","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::write_bit":["write_bit","Real(LocalPath(\"src/access.rs\"))",""],"access::BitAccess::write_bits":["write_bits","Real(LocalPath(\"src/access.rs\"))",""],"array::BitArray::<O, V>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::as_mut_bitslice":["as_mut_bitslice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::as_mut_slice":["as_mut_slice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::as_raw_mut_slice":["as_raw_mut_slice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::as_raw_slice":["as_raw_slice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::as_slice":["as_slice","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::new":["new","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::unwrap":["unwrap","Real(LocalPath(\"src/array.rs\"))",""],"array::BitArray::<O, V>::zeroed":["zeroed","Real(LocalPath(\"src/array.rs\"))",""],"array::ops::<impl std::ops::BitAnd<Rhs> for array::BitArray<O, V>>::bitand":["bitand","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitAnd"],"array::ops::<impl std::ops::BitAndAssign<Rhs> for array::BitArray<O, V>>::bitand_assign":["bitand_assign","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitAndAssign"],"array::ops::<impl std::ops::BitOr<Rhs> for array::BitArray<O, V>>::bitor":["bitor","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitOr"],"array::ops::<impl std::ops::BitOrAssign<Rhs> for array::BitArray<O, V>>::bitor_assign":["bitor_assign","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitOrAssign"],"array::ops::<impl std::ops::BitXor<Rhs> for array::BitArray<O, V>>::bitxor":["bitxor","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitXor"],"array::ops::<impl std::ops::BitXorAssign<Rhs> for array::BitArray<O, V>>::bitxor_assign":["bitxor_assign","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::BitXorAssign"],"array::ops::<impl std::ops::Deref for array::BitArray<O, V>>::deref":["deref","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::Deref"],"array::ops::<impl std::ops::DerefMut for array::BitArray<O, V>>::deref_mut":["deref_mut","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::DerefMut"],"array::ops::<impl std::ops::Index<Idx> for array::BitArray<O, V>>::index":["index","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::Index"],"array::ops::<impl std::ops::IndexMut<Idx> for array::BitArray<O, V>>::index_mut":["index_mut","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::IndexMut"],"array::ops::<impl std::ops::Not for array::BitArray<O, V>>::not":["not","Real(LocalPath(\"src/array/ops.rs\"))","std::ops::Not"],"array::traits::<impl std::borrow::Borrow<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow":["borrow","Real(LocalPath(\"src/array/traits.rs\"))","std::borrow::Borrow"],"array::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::borrow_mut":["borrow_mut","Real(LocalPath(\"src/array/traits.rs\"))","std::borrow::BorrowMut"],"array::traits::<impl std::cmp::Ord for array::BitArray<O, V>>::cmp":["cmp","Real(LocalPath(\"src/array/traits.rs\"))","std::cmp::Ord"],"array::traits::<impl std::cmp::PartialEq<Rhs> for array::BitArray<O, V>>::eq":["eq","Real(LocalPath(\"src/array/traits.rs\"))","std::cmp::PartialEq"],"array::traits::<impl std::cmp::PartialEq<array::BitArray<O, V>> for slice::BitSlice<O, T>>::eq":["eq","Real(LocalPath(\"src/array/traits.rs\"))","std::cmp::PartialEq"],"array::traits::<impl std::cmp::PartialOrd<Rhs> for array::BitArray<O, V>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/array/traits.rs\"))","std::cmp::PartialOrd"],"array::traits::<impl std::cmp::PartialOrd<array::BitArray<O, V>> for slice::BitSlice<O, T>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/array/traits.rs\"))","std::cmp::PartialOrd"],"array::traits::<impl std::convert::AsMut<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_mut":["as_mut","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::AsMut"],"array::traits::<impl std::convert::AsRef<slice::BitSlice<O, <V as view::BitView>::Store>> for array::BitArray<O, V>>::as_ref":["as_ref","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::AsRef"],"array::traits::<impl std::convert::From<V> for array::BitArray<O, V>>::from":["from","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::From"],"array::traits::<impl std::convert::TryFrom<&'a mut slice::BitSlice<O, <V as view::BitView>::Store>> for &'a mut array::BitArray<O, V>>::try_from":["try_from","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::TryFrom"],"array::traits::<impl std::convert::TryFrom<&'a slice::BitSlice<O, <V as view::BitView>::Store>> for &'a array::BitArray<O, V>>::try_from":["try_from","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::TryFrom"],"array::traits::<impl std::convert::TryFrom<&slice::BitSlice<O2, T>> for array::BitArray<O, V>>::try_from":["try_from","Real(LocalPath(\"src/array/traits.rs\"))","std::convert::TryFrom"],"array::traits::<impl std::default::Default for array::BitArray<O, V>>::default":["default","Real(LocalPath(\"src/array/traits.rs\"))","std::default::Default"],"array::traits::<impl std::fmt::Binary for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::Binary"],"array::traits::<impl std::fmt::Debug for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::Debug"],"array::traits::<impl std::fmt::Display for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::Display"],"array::traits::<impl std::fmt::LowerHex for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::LowerHex"],"array::traits::<impl std::fmt::Octal for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::Octal"],"array::traits::<impl std::fmt::UpperHex for array::BitArray<O, V>>::fmt":["fmt","Real(LocalPath(\"src/array/traits.rs\"))","std::fmt::UpperHex"],"array::traits::<impl std::hash::Hash for array::BitArray<O, V>>::hash":["hash","Real(LocalPath(\"src/array/traits.rs\"))","std::hash::Hash"],"array::traits::<impl std::iter::IntoIterator for &'a array::BitArray<O, V>>::into_iter":["into_iter","Real(LocalPath(\"src/array/traits.rs\"))","std::iter::IntoIterator"],"array::traits::<impl std::iter::IntoIterator for &'a mut array::BitArray<O, V>>::into_iter":["into_iter","Real(LocalPath(\"src/array/traits.rs\"))","std::iter::IntoIterator"],"array::traits::TryFromBitSliceError::err":["err","Real(LocalPath(\"src/array/traits.rs\"))",""],"boxed::BitBox::<O, T>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::as_mut_bitslice":["as_mut_bitslice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::as_mut_slice":["as_mut_slice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::as_slice":["as_slice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::bitptr":["bitptr","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::from_bitslice":["from_bitslice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::from_boxed_slice":["from_boxed_slice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::into_boxed_slice":["into_boxed_slice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::try_from_boxed_slice":["try_from_boxed_slice","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::BitBox::<O, T>::with_box":["with_box","Real(LocalPath(\"src/boxed.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::from_raw":["from_raw","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::into_bitvec":["into_bitvec","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::into_raw":["into_raw","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::leak":["leak","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::new":["new","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::api::<impl boxed::BitBox<O, T>>::pin":["pin","Real(LocalPath(\"src/boxed/api.rs\"))",""],"boxed::ops::<impl std::ops::BitAnd<Rhs> for boxed::BitBox<O, T>>::bitand":["bitand","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitAnd"],"boxed::ops::<impl std::ops::BitAndAssign<Rhs> for boxed::BitBox<O, T>>::bitand_assign":["bitand_assign","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitAndAssign"],"boxed::ops::<impl std::ops::BitOr<Rhs> for boxed::BitBox<O, T>>::bitor":["bitor","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitOr"],"boxed::ops::<impl std::ops::BitOrAssign<Rhs> for boxed::BitBox<O, T>>::bitor_assign":["bitor_assign","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitOrAssign"],"boxed::ops::<impl std::ops::BitXor<Rhs> for boxed::BitBox<O, T>>::bitxor":["bitxor","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitXor"],"boxed::ops::<impl std::ops::BitXorAssign<Rhs> for boxed::BitBox<O, T>>::bitxor_assign":["bitxor_assign","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::BitXorAssign"],"boxed::ops::<impl std::ops::Deref for boxed::BitBox<O, T>>::deref":["deref","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::Deref"],"boxed::ops::<impl std::ops::DerefMut for boxed::BitBox<O, T>>::deref_mut":["deref_mut","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::DerefMut"],"boxed::ops::<impl std::ops::Drop for boxed::BitBox<O, T>>::drop":["drop","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::Drop"],"boxed::ops::<impl std::ops::Index<Idx> for boxed::BitBox<O, T>>::index":["index","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::Index"],"boxed::ops::<impl std::ops::IndexMut<Idx> for boxed::BitBox<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::IndexMut"],"boxed::ops::<impl std::ops::Not for boxed::BitBox<O, T>>::not":["not","Real(LocalPath(\"src/boxed/ops.rs\"))","std::ops::Not"],"boxed::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow":["borrow","Real(LocalPath(\"src/boxed/traits.rs\"))","std::borrow::Borrow"],"boxed::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::borrow_mut":["borrow_mut","Real(LocalPath(\"src/boxed/traits.rs\"))","std::borrow::BorrowMut"],"boxed::traits::<impl std::clone::Clone for boxed::BitBox<O, T>>::clone":["clone","Real(LocalPath(\"src/boxed/traits.rs\"))","std::clone::Clone"],"boxed::traits::<impl std::cmp::Ord for boxed::BitBox<O, T>>::cmp":["cmp","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::Ord"],"boxed::traits::<impl std::cmp::PartialEq<Rhs> for boxed::BitBox<O, T>>::eq":["eq","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialEq"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialEq"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialEq"],"boxed::traits::<impl std::cmp::PartialEq<boxed::BitBox<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialEq"],"boxed::traits::<impl std::cmp::PartialOrd<Rhs> for boxed::BitBox<O, T>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialOrd"],"boxed::traits::<impl std::cmp::PartialOrd<boxed::BitBox<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/boxed/traits.rs\"))","std::cmp::PartialOrd"],"boxed::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_mut":["as_mut","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::AsMut"],"boxed::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::as_ref":["as_ref","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::AsRef"],"boxed::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for boxed::BitBox<O, T>>::from":["from","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::From"],"boxed::traits::<impl std::convert::From<vec::BitVec<O, T>> for boxed::BitBox<O, T>>::from":["from","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::From"],"boxed::traits::<impl std::convert::Into<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::into":["into","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::Into"],"boxed::traits::<impl std::convert::TryFrom<std::boxed::Box<[T]>> for boxed::BitBox<O, T>>::try_from":["try_from","Real(LocalPath(\"src/boxed/traits.rs\"))","std::convert::TryFrom"],"boxed::traits::<impl std::default::Default for boxed::BitBox<O, T>>::default":["default","Real(LocalPath(\"src/boxed/traits.rs\"))","std::default::Default"],"boxed::traits::<impl std::fmt::Binary for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::Binary"],"boxed::traits::<impl std::fmt::Debug for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::Debug"],"boxed::traits::<impl std::fmt::Display for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::Display"],"boxed::traits::<impl std::fmt::LowerHex for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::LowerHex"],"boxed::traits::<impl std::fmt::Octal for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::Octal"],"boxed::traits::<impl std::fmt::Pointer for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::Pointer"],"boxed::traits::<impl std::fmt::UpperHex for boxed::BitBox<O, T>>::fmt":["fmt","Real(LocalPath(\"src/boxed/traits.rs\"))","std::fmt::UpperHex"],"boxed::traits::<impl std::hash::Hash for boxed::BitBox<O, T>>::hash":["hash","Real(LocalPath(\"src/boxed/traits.rs\"))","std::hash::Hash"],"devel::accessor":["accessor","Real(LocalPath(\"src/devel.rs\"))",""],"devel::alias_mask":["alias_mask","Real(LocalPath(\"src/devel.rs\"))",""],"devel::alias_mem":["alias_mem","Real(LocalPath(\"src/devel.rs\"))",""],"devel::assert_range":["assert_range","Real(LocalPath(\"src/devel.rs\"))",""],"devel::load_aliased_local":["load_aliased_local","Real(LocalPath(\"src/devel.rs\"))",""],"devel::mem_mut":["mem_mut","Real(LocalPath(\"src/devel.rs\"))",""],"devel::nonnull_slice_to_base":["nonnull_slice_to_base","Real(LocalPath(\"src/devel.rs\"))",""],"devel::normalize_range":["normalize_range","Real(LocalPath(\"src/devel.rs\"))",""],"devel::remove_alias":["remove_alias","Real(LocalPath(\"src/devel.rs\"))",""],"devel::remove_bitptr_alias":["remove_bitptr_alias","Real(LocalPath(\"src/devel.rs\"))",""],"devel::remove_mem":["remove_mem","Real(LocalPath(\"src/devel.rs\"))",""],"domain::BitDomain::<'a, O, T>::empty":["empty","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::enclave":["enclave","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::major":["major","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::minor":["minor","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::new":["new","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::partial_head":["partial_head","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::partial_tail":["partial_tail","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::region":["region","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomain::<'a, O, T>::spanning":["spanning","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::empty":["empty","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::enclave":["enclave","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::major":["major","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::minor":["minor","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::new":["new","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::partial_head":["partial_head","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::partial_tail":["partial_tail","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::region":["region","Real(LocalPath(\"src/domain.rs\"))",""],"domain::BitDomainMut::<'a, O, T>::spanning":["spanning","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::empty":["empty","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::enclave":["enclave","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::major":["major","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::minor":["minor","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::new":["new","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::partial_head":["partial_head","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::partial_tail":["partial_tail","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::region":["region","Real(LocalPath(\"src/domain.rs\"))",""],"domain::Domain::<'a, T>::spanning":["spanning","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::empty":["empty","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::enclave":["enclave","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::major":["major","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::minor":["minor","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::new":["new","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::partial_head":["partial_head","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::partial_tail":["partial_tail","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::region":["region","Real(LocalPath(\"src/domain.rs\"))",""],"domain::DomainMut::<'a, T>::spanning":["spanning","Real(LocalPath(\"src/domain.rs\"))",""],"field::BitField::load":["load","Real(LocalPath(\"src/field.rs\"))",""],"field::BitField::store":["store","Real(LocalPath(\"src/field.rs\"))",""],"field::check":["check","Real(LocalPath(\"src/field.rs\"))",""],"field::get":["get","Real(LocalPath(\"src/field.rs\"))",""],"field::io::<impl std::io::Read for &'a slice::BitSlice<O, T>>::read":["read","Real(LocalPath(\"src/field/io.rs\"))","std::io::Read"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::flush":["flush","Real(LocalPath(\"src/field/io.rs\"))","std::io::Write"],"field::io::<impl std::io::Write for &'a mut slice::BitSlice<O, T>>::write":["write","Real(LocalPath(\"src/field/io.rs\"))","std::io::Write"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::flush":["flush","Real(LocalPath(\"src/field/io.rs\"))","std::io::Write"],"field::io::<impl std::io::Write for vec::BitVec<O, T>>::write":["write","Real(LocalPath(\"src/field/io.rs\"))","std::io::Write"],"field::resize":["resize","Real(LocalPath(\"src/field.rs\"))",""],"field::resize_inner":["resize_inner","Real(LocalPath(\"src/field.rs\"))",""],"field::set":["set","Real(LocalPath(\"src/field.rs\"))",""],"index::BitIdx::<M>::decr":["decr","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::incr":["incr","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::mask":["mask","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::new":["new","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::offset":["offset","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::position":["position","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::range":["range","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::range_all":["range_all","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::select":["select","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::span":["span","Real(LocalPath(\"src/index.rs\"))",""],"index::BitIdx::<M>::value":["value","Real(LocalPath(\"src/index.rs\"))",""],"index::BitMask::<M>::combine":["combine","Real(LocalPath(\"src/index.rs\"))",""],"index::BitMask::<M>::insert":["insert","Real(LocalPath(\"src/index.rs\"))",""],"index::BitMask::<M>::new":["new","Real(LocalPath(\"src/index.rs\"))",""],"index::BitMask::<M>::test":["test","Real(LocalPath(\"src/index.rs\"))",""],"index::BitMask::<M>::value":["value","Real(LocalPath(\"src/index.rs\"))",""],"index::BitPos::<M>::mask":["mask","Real(LocalPath(\"src/index.rs\"))",""],"index::BitPos::<M>::new":["new","Real(LocalPath(\"src/index.rs\"))",""],"index::BitPos::<M>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/index.rs\"))",""],"index::BitPos::<M>::select":["select","Real(LocalPath(\"src/index.rs\"))",""],"index::BitPos::<M>::value":["value","Real(LocalPath(\"src/index.rs\"))",""],"index::BitSel::<M>::mask":["mask","Real(LocalPath(\"src/index.rs\"))",""],"index::BitSel::<M>::new":["new","Real(LocalPath(\"src/index.rs\"))",""],"index::BitSel::<M>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/index.rs\"))",""],"index::BitSel::<M>::range_all":["range_all","Real(LocalPath(\"src/index.rs\"))",""],"index::BitSel::<M>::value":["value","Real(LocalPath(\"src/index.rs\"))",""],"index::BitTail::<M>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/index.rs\"))",""],"index::BitTail::<M>::range_from":["range_from","Real(LocalPath(\"src/index.rs\"))",""],"index::BitTail::<M>::span":["span","Real(LocalPath(\"src/index.rs\"))",""],"index::BitTail::<M>::value":["value","Real(LocalPath(\"src/index.rs\"))",""],"macros::internal::u8_from_be_bits":["u8_from_be_bits","Real(LocalPath(\"src/macros/internal.rs\"))",""],"macros::internal::u8_from_le_bits":["u8_from_le_bits","Real(LocalPath(\"src/macros/internal.rs\"))",""],"mem::aligned_to_size":["aligned_to_size","Real(LocalPath(\"src/mem.rs\"))",""],"mem::cmp_layout":["cmp_layout","Real(LocalPath(\"src/mem.rs\"))",""],"mem::elts":["elts","Real(LocalPath(\"src/mem.rs\"))",""],"order::BitOrder::mask":["mask","Real(LocalPath(\"src/order.rs\"))",""],"order::BitOrder::select":["select","Real(LocalPath(\"src/order.rs\"))",""],"order::verify":["verify","Real(LocalPath(\"src/order.rs\"))",""],"order::verify_for_type":["verify_for_type","Real(LocalPath(\"src/order.rs\"))",""],"pointer::Address::<T>::new":["new","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::Address::<T>::to_access":["to_access","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::Address::<T>::to_alias":["to_alias","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::Address::<T>::to_const":["to_const","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::Address::<T>::to_mut":["to_mut","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::Address::<T>::value":["value","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::as_aliased_slice":["as_aliased_slice","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::elements":["elements","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::from_bitslice_ptr":["from_bitslice_ptr","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::from_bitslice_ptr_mut":["from_bitslice_ptr_mut","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::head":["head","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::incr_head":["incr_head","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::len":["len","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::new":["new","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::pointer":["pointer","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::raw_parts":["raw_parts","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::read":["read","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::render":["render","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::set_head":["set_head","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::set_len":["set_len","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::set_pointer":["set_pointer","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::tail":["tail","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::to_bitslice_mut":["to_bitslice_mut","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::to_bitslice_ptr":["to_bitslice_ptr","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::to_bitslice_ptr_mut":["to_bitslice_ptr_mut","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::to_bitslice_ref":["to_bitslice_ref","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::to_nonnull":["to_nonnull","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::uninhabited":["uninhabited","Real(LocalPath(\"src/pointer.rs\"))",""],"pointer::BitPtr::<T>::write":["write","Real(LocalPath(\"src/pointer.rs\"))",""],"slice::BitSlice::<O, T>::alias":["alias","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::alias_mut":["alias_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::all":["all","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::any":["any","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::as_aliased_slice":["as_aliased_slice","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::as_mut_slice":["as_mut_slice","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::as_slice":["as_slice","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::bit_domain":["bit_domain","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::bit_domain_mut":["bit_domain_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::bitptr":["bitptr","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::copy_unchecked":["copy_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::copy_within_unchecked":["copy_within_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::count_ones":["count_ones","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::count_zeros":["count_zeros","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::domain":["domain","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::domain_mut":["domain_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::empty":["empty","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::empty_mut":["empty_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::for_each":["for_each","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_aliased_slice_unchecked":["from_aliased_slice_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_element":["from_element","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_element_mut":["from_element_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_slice":["from_slice","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_slice_mut":["from_slice_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_slice_unchecked":["from_slice_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::from_slice_unchecked_mut":["from_slice_unchecked_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::not_all":["not_all","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::not_any":["not_any","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::set":["set","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::set_all":["set_all","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::set_unchecked":["set_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::some":["some","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::split_at_aliased_mut":["split_at_aliased_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::split_at_aliased_unchecked_mut":["split_at_aliased_unchecked_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::split_at_unchecked":["split_at_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::split_at_unchecked_mut":["split_at_unchecked_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::swap_unchecked":["swap_unchecked","Real(LocalPath(\"src/slice.rs\"))",""],"slice::BitSlice::<O, T>::unalias_mut":["unalias_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::align_to":["align_to","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::align_to_mut":["align_to_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::as_mut_ptr":["as_mut_ptr","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::as_ptr":["as_ptr","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::chunks":["chunks","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact":["chunks_exact","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::chunks_exact_mut":["chunks_exact_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::chunks_mut":["chunks_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_bitslice":["clone_from_bitslice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::clone_from_slice":["clone_from_slice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::contains":["contains","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_bitslice":["copy_from_bitslice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::copy_from_slice":["copy_from_slice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::copy_within":["copy_within","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::ends_with":["ends_with","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::first":["first","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::first_mut":["first_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::get":["get","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::get_mut":["get_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked":["get_unchecked","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::get_unchecked_mut":["get_unchecked_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::is_empty":["is_empty","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::iter":["iter","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::iter_mut":["iter_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::last":["last","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::last_mut":["last_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::len":["len","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rchunks":["rchunks","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact":["rchunks_exact","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_exact_mut":["rchunks_exact_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rchunks_mut":["rchunks_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::repeat":["repeat","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::reverse":["reverse","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rotate_left":["rotate_left","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rotate_right":["rotate_right","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rsplit":["rsplit","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rsplit_mut":["rsplit_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn":["rsplitn","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::rsplitn_mut":["rsplitn_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split":["split","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_at":["split_at","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_at_mut":["split_at_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_first":["split_first","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_first_mut":["split_first_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_last":["split_last","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_last_mut":["split_last_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::split_mut":["split_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::splitn":["splitn","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::splitn_mut":["splitn_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::starts_with":["starts_with","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::swap":["swap","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_bitslice":["swap_with_bitslice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::swap_with_slice":["swap_with_slice","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::to_bitvec":["to_bitvec","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::to_vec":["to_vec","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::<impl slice::BitSlice<O, T>>::windows":["windows","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::from_mut":["from_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::from_raw_parts":["from_raw_parts","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::from_raw_parts_mut":["from_raw_parts_mut","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::api::from_ref":["from_ref","Real(LocalPath(\"src/slice/api.rs\"))",""],"slice::bits_from_raw_parts":["bits_from_raw_parts","Real(LocalPath(\"src/slice.rs\"))",""],"slice::bits_from_raw_parts_mut":["bits_from_raw_parts_mut","Real(LocalPath(\"src/slice.rs\"))",""],"slice::iter::<impl std::iter::IntoIterator for &'a mut slice::BitSlice<O, T>>::into_iter":["into_iter","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::IntoIterator"],"slice::iter::<impl std::iter::IntoIterator for &'a slice::BitSlice<O, T>>::into_iter":["into_iter","Real(LocalPath(\"src/slice/iter.rs\"))","std::iter::IntoIterator"],"slice::iter::Chunks::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::ChunksExact::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::ChunksExact::<'a, O, T>::remainder":["remainder","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::ChunksExactMut::<'a, O, T>::into_remainder":["into_remainder","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::ChunksExactMut::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::ChunksMut::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Iter::<'a, O, T>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Iter::<'a, O, T>::as_slice":["as_slice","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Iter::<'a, O, T>::inherent_is_empty":["inherent_is_empty","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Iter::<'a, O, T>::pop_back":["pop_back","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Iter::<'a, O, T>::pop_front":["pop_front","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::IterMut::<'a, O, T>::inherent_is_empty":["inherent_is_empty","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::IterMut::<'a, O, T>::into_bitslice":["into_bitslice","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::IterMut::<'a, O, T>::into_slice":["into_slice","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::IterMut::<'a, O, T>::pop_back":["pop_back","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::IterMut::<'a, O, T>::pop_front":["pop_front","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunks::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunksExact::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunksExact::<'a, O, T>::remainder":["remainder","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunksExactMut::<'a, O, T>::into_remainder":["into_remainder","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunksExactMut::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RChunksMut::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RSplit::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RSplitMut::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RSplitN::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::RSplitNMut::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Split::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::SplitMut::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::SplitN::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::SplitNMut::<'a, O, T, P>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::iter::Windows::<'a, O, T>::new":["new","Real(LocalPath(\"src/slice/iter.rs\"))",""],"slice::ops::<impl std::ops::BitAndAssign<Rhs> for slice::BitSlice<O, T>>::bitand_assign":["bitand_assign","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::BitAndAssign"],"slice::ops::<impl std::ops::BitOrAssign<Rhs> for slice::BitSlice<O, T>>::bitor_assign":["bitor_assign","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::BitOrAssign"],"slice::ops::<impl std::ops::BitXorAssign<Rhs> for slice::BitSlice<O, T>>::bitxor_assign":["bitxor_assign","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::BitXorAssign"],"slice::ops::<impl std::ops::Index<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<std::ops::RangeFull> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::Index<usize> for slice::BitSlice<O, T>>::index":["index","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Index"],"slice::ops::<impl std::ops::IndexMut<std::ops::Range<usize>> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFrom<usize>> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeFull> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeTo<usize>> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::IndexMut<std::ops::RangeToInclusive<usize>> for slice::BitSlice<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::IndexMut"],"slice::ops::<impl std::ops::Not for &'a mut slice::BitSlice<O, T>>::not":["not","Real(LocalPath(\"src/slice/ops.rs\"))","std::ops::Not"],"slice::proxy::BitMut::<'_, O, T>::new_unchecked":["new_unchecked","Real(LocalPath(\"src/slice/proxy.rs\"))",""],"slice::proxy::BitMut::<'_, O, T>::set":["set","Real(LocalPath(\"src/slice/proxy.rs\"))",""],"slice::proxy::BitMut::<'_, O, T>::write":["write","Real(LocalPath(\"src/slice/proxy.rs\"))",""],"slice::traits::<impl std::borrow::ToOwned for slice::BitSlice<O, T>>::to_owned":["to_owned","Real(LocalPath(\"src/slice/traits.rs\"))","std::borrow::ToOwned"],"slice::traits::<impl std::cmp::Ord for slice::BitSlice<O, T>>::cmp":["cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::Ord"],"slice::traits::<impl std::cmp::PartialEq<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialEq"],"slice::traits::<impl std::cmp::PartialEq<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialEq"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialEq"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialEq"],"slice::traits::<impl std::cmp::PartialEq<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialEq"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<&mut slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<&slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &mut slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for &slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::cmp::PartialOrd<slice::BitSlice<O2, T2>> for slice::BitSlice<O1, T1>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/slice/traits.rs\"))","std::cmp::PartialOrd"],"slice::traits::<impl std::convert::TryFrom<&'a [T]> for &'a slice::BitSlice<O, T>>::try_from":["try_from","Real(LocalPath(\"src/slice/traits.rs\"))","std::convert::TryFrom"],"slice::traits::<impl std::default::Default for &mut slice::BitSlice<O, T>>::default":["default","Real(LocalPath(\"src/slice/traits.rs\"))","std::default::Default"],"slice::traits::<impl std::default::Default for &slice::BitSlice<O, T>>::default":["default","Real(LocalPath(\"src/slice/traits.rs\"))","std::default::Default"],"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Binary"],"slice::traits::<impl std::fmt::Debug for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Debug"],"slice::traits::<impl std::fmt::Display for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Display"],"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::LowerHex"],"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Octal"],"slice::traits::<impl std::fmt::Pointer for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::Pointer"],"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt":["fmt","Real(LocalPath(\"src/slice/traits.rs\"))","std::fmt::UpperHex"],"slice::traits::<impl std::hash::Hash for slice::BitSlice<O, T>>::hash":["hash","Real(LocalPath(\"src/slice/traits.rs\"))","std::hash::Hash"],"vec::BitVec::<O, T>::as_bitptr":["as_bitptr","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::as_mut_bitptr":["as_mut_bitptr","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::as_mut_bitslice":["as_mut_bitslice","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::bitptr":["bitptr","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::elements":["elements","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::extend_from_bitslice":["extend_from_bitslice","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::force_align":["force_align","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::from_bitslice":["from_bitslice","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::from_vec":["from_vec","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::into_boxed_bitslice":["into_boxed_bitslice","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::into_vec":["into_vec","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::repeat":["repeat","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::set_elements":["set_elements","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::try_from_vec":["try_from_vec","Real(LocalPath(\"src/vec.rs\"))",""],"vec::BitVec::<O, T>::with_vec":["with_vec","Real(LocalPath(\"src/vec.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::append":["append","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::as_mut_ptr":["as_mut_ptr","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::as_mut_slice":["as_mut_slice","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::as_ptr":["as_ptr","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::as_slice":["as_slice","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::capacity":["capacity","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::clear":["clear","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::drain":["drain","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::extend_from_slice":["extend_from_slice","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::from_raw_parts":["from_raw_parts","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::insert":["insert","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::into_boxed_slice":["into_boxed_slice","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::new":["new","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::pop":["pop","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::push":["push","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::remove":["remove","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::reserve":["reserve","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::reserve_exact":["reserve_exact","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::resize":["resize","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::resize_with":["resize_with","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::retain":["retain","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::set_len":["set_len","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::shrink_to_fit":["shrink_to_fit","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::splice":["splice","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::split_off":["split_off","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::swap_remove":["swap_remove","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::truncate":["truncate","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::api::<impl vec::BitVec<O, T>>::with_capacity":["with_capacity","Real(LocalPath(\"src/vec/api.rs\"))",""],"vec::iter::<impl std::iter::Extend<&'a bool> for vec::BitVec<O, T>>::extend":["extend","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Extend"],"vec::iter::<impl std::iter::Extend<bool> for vec::BitVec<O, T>>::extend":["extend","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::Extend"],"vec::iter::<impl std::iter::FromIterator<&'a bool> for vec::BitVec<O, T>>::from_iter":["from_iter","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::FromIterator"],"vec::iter::<impl std::iter::FromIterator<bool> for vec::BitVec<O, T>>::from_iter":["from_iter","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::FromIterator"],"vec::iter::<impl std::iter::IntoIterator for &'a mut vec::BitVec<O, T>>::into_iter":["into_iter","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::IntoIterator"],"vec::iter::<impl std::iter::IntoIterator for &'a vec::BitVec<O, T>>::into_iter":["into_iter","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::IntoIterator"],"vec::iter::<impl std::iter::IntoIterator for vec::BitVec<O, T>>::into_iter":["into_iter","Real(LocalPath(\"src/vec/iter.rs\"))","std::iter::IntoIterator"],"vec::iter::Drain::<'a, O, T>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::Drain::<'a, O, T>::fill":["fill","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::Drain::<'a, O, T>::move_tail":["move_tail","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::Drain::<'a, O, T>::new":["new","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::IntoIter::<O, T>::as_bitslice":["as_bitslice","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::IntoIter::<O, T>::as_mut_bitslice":["as_mut_bitslice","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::IntoIter::<O, T>::as_mut_slice":["as_mut_slice","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::IntoIter::<O, T>::as_slice":["as_slice","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::iter::Splice::<'a, O, T, I>::new":["new","Real(LocalPath(\"src/vec/iter.rs\"))",""],"vec::ops::<impl std::ops::BitAnd<Rhs> for vec::BitVec<O, T>>::bitand":["bitand","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitAnd"],"vec::ops::<impl std::ops::BitAndAssign<Rhs> for vec::BitVec<O, T>>::bitand_assign":["bitand_assign","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitAndAssign"],"vec::ops::<impl std::ops::BitOr<Rhs> for vec::BitVec<O, T>>::bitor":["bitor","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitOr"],"vec::ops::<impl std::ops::BitOrAssign<Rhs> for vec::BitVec<O, T>>::bitor_assign":["bitor_assign","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitOrAssign"],"vec::ops::<impl std::ops::BitXor<Rhs> for vec::BitVec<O, T>>::bitxor":["bitxor","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitXor"],"vec::ops::<impl std::ops::BitXorAssign<Rhs> for vec::BitVec<O, T>>::bitxor_assign":["bitxor_assign","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::BitXorAssign"],"vec::ops::<impl std::ops::Deref for vec::BitVec<O, T>>::deref":["deref","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::Deref"],"vec::ops::<impl std::ops::DerefMut for vec::BitVec<O, T>>::deref_mut":["deref_mut","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::DerefMut"],"vec::ops::<impl std::ops::Drop for vec::BitVec<O, T>>::drop":["drop","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::Drop"],"vec::ops::<impl std::ops::Index<Idx> for vec::BitVec<O, T>>::index":["index","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::Index"],"vec::ops::<impl std::ops::IndexMut<Idx> for vec::BitVec<O, T>>::index_mut":["index_mut","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::IndexMut"],"vec::ops::<impl std::ops::Not for vec::BitVec<O, T>>::not":["not","Real(LocalPath(\"src/vec/ops.rs\"))","std::ops::Not"],"vec::traits::<impl std::borrow::Borrow<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow":["borrow","Real(LocalPath(\"src/vec/traits.rs\"))","std::borrow::Borrow"],"vec::traits::<impl std::borrow::BorrowMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::borrow_mut":["borrow_mut","Real(LocalPath(\"src/vec/traits.rs\"))","std::borrow::BorrowMut"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone":["clone","Real(LocalPath(\"src/vec/traits.rs\"))","std::clone::Clone"],"vec::traits::<impl std::clone::Clone for vec::BitVec<O, T>>::clone_from":["clone_from","Real(LocalPath(\"src/vec/traits.rs\"))","std::clone::Clone"],"vec::traits::<impl std::cmp::Ord for vec::BitVec<O, T>>::cmp":["cmp","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::Ord"],"vec::traits::<impl std::cmp::PartialEq<Rhs> for vec::BitVec<O, T>>::eq":["eq","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialEq"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &mut slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialEq"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for &slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialEq"],"vec::traits::<impl std::cmp::PartialEq<vec::BitVec<O2, T2>> for slice::BitSlice<O1, T1>>::eq":["eq","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialEq"],"vec::traits::<impl std::cmp::PartialOrd<Rhs> for vec::BitVec<O, T>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialOrd"],"vec::traits::<impl std::cmp::PartialOrd<vec::BitVec<O, T>> for slice::BitSlice<O, T>>::partial_cmp":["partial_cmp","Real(LocalPath(\"src/vec/traits.rs\"))","std::cmp::PartialOrd"],"vec::traits::<impl std::convert::AsMut<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_mut":["as_mut","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::AsMut"],"vec::traits::<impl std::convert::AsRef<slice::BitSlice<O, T>> for vec::BitVec<O, T>>::as_ref":["as_ref","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::AsRef"],"vec::traits::<impl std::convert::From<&'a mut slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["from","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::From"],"vec::traits::<impl std::convert::From<&'a slice::BitSlice<O, T>> for vec::BitVec<O, T>>::from":["from","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::From"],"vec::traits::<impl std::convert::From<boxed::BitBox<O, T>> for vec::BitVec<O, T>>::from":["from","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::From"],"vec::traits::<impl std::convert::Into<std::vec::Vec<T>> for vec::BitVec<O, T>>::into":["into","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::Into"],"vec::traits::<impl std::convert::TryFrom<std::vec::Vec<T>> for vec::BitVec<O, T>>::try_from":["try_from","Real(LocalPath(\"src/vec/traits.rs\"))","std::convert::TryFrom"],"vec::traits::<impl std::default::Default for vec::BitVec<O, T>>::default":["default","Real(LocalPath(\"src/vec/traits.rs\"))","std::default::Default"],"vec::traits::<impl std::fmt::Binary for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::Binary"],"vec::traits::<impl std::fmt::Debug for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::Debug"],"vec::traits::<impl std::fmt::Display for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::Display"],"vec::traits::<impl std::fmt::LowerHex for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::LowerHex"],"vec::traits::<impl std::fmt::Octal for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::Octal"],"vec::traits::<impl std::fmt::Pointer for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::Pointer"],"vec::traits::<impl std::fmt::UpperHex for vec::BitVec<O, T>>::fmt":["fmt","Real(LocalPath(\"src/vec/traits.rs\"))","std::fmt::UpperHex"],"vec::traits::<impl std::hash::Hash for vec::BitVec<O, T>>::hash":["hash","Real(LocalPath(\"src/vec/traits.rs\"))","std::hash::Hash"],"view::BitView::bits":["bits","Real(LocalPath(\"src/view.rs\"))",""],"view::BitView::bits_mut":["bits_mut","Real(LocalPath(\"src/view.rs\"))",""],"view::BitView::const_bits":["const_bits","Real(LocalPath(\"src/view.rs\"))",""]},"trait_to_struct":{"access::BitAccess":["<R as access::BitAccess<M>>::R"],"field::BitField":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"order::BitOrder":["order::Lsb0","order::Msb0"],"slice::api::BitSliceIndex":["std::ops::Range","std::ops::RangeFrom","std::ops::RangeFull","std::ops::RangeInclusive","std::ops::RangeTo","std::ops::RangeToInclusive"],"slice::iter::SplitIter":["slice::iter::RSplit","slice::iter::RSplitMut","slice::iter::Split","slice::iter::SplitMut"],"std::borrow::Borrow":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::borrow::BorrowMut":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::borrow::ToOwned":["slice::BitSlice"],"std::clone::Clone":["array::BitArray","array::traits::TryFromBitSliceError","boxed::BitBox","domain::BitDomain","domain::Domain","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::Iter","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RSplit","slice::iter::Split","slice::iter::Windows","vec::BitVec","vec::iter::FillStatus","vec::iter::IntoIter"],"std::cmp::Eq":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::BitSlice","vec::BitVec","vec::iter::FillStatus"],"std::cmp::Ord":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","slice::BitSlice","vec::BitVec","vec::iter::FillStatus"],"std::cmp::PartialEq":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::BitSlice","vec::BitVec","vec::iter::FillStatus"],"std::cmp::PartialOrd":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","slice::BitSlice","vec::BitVec","vec::iter::FillStatus"],"std::convert::AsMut":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::convert::AsRef":["array::BitArray","boxed::BitBox","slice::iter::Iter","vec::BitVec","vec::iter::Drain"],"std::convert::From":["array::BitArray","boxed::BitBox","pointer::Address","vec::BitVec"],"std::convert::Into":["boxed::BitBox","vec::BitVec"],"std::convert::TryFrom":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::default::Default":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::BitPtr","vec::BitVec"],"std::error::Error":["array::traits::TryFromBitSliceError"],"std::fmt::Binary":["array::BitArray","boxed::BitBox","domain::Domain","index::BitIdx","slice::BitSlice","vec::BitVec"],"std::fmt::Debug":["array::BitArray","array::traits::TryFromBitSliceError","boxed::BitBox","domain::BitDomain","domain::BitDomainMut","domain::Domain","domain::DomainMut","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::BitSlice","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::ChunksExactMut","slice::iter::ChunksMut","slice::iter::Iter","slice::iter::IterMut","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RChunksExactMut","slice::iter::RChunksMut","slice::iter::RSplit","slice::iter::RSplitMut","slice::iter::RSplitN","slice::iter::RSplitNMut","slice::iter::Split","slice::iter::SplitMut","slice::iter::SplitN","slice::iter::SplitNMut","slice::iter::Windows","slice::proxy::BitMut","slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq","vec::BitVec","vec::iter::Drain","vec::iter::FillStatus","vec::iter::IntoIter","vec::iter::Splice"],"std::fmt::Display":["array::BitArray","array::traits::TryFromBitSliceError","boxed::BitBox","index::BitIdx","index::BitMask","index::BitSel","index::BitTail","slice::BitSlice","vec::BitVec"],"std::fmt::LowerHex":["array::BitArray","boxed::BitBox","domain::Domain","slice::BitSlice","vec::BitVec"],"std::fmt::Octal":["array::BitArray","boxed::BitBox","domain::Domain","slice::BitSlice","vec::BitVec"],"std::fmt::Pointer":["boxed::BitBox","pointer::Address","pointer::BitPtr","slice::BitSlice","vec::BitVec"],"std::fmt::UpperHex":["array::BitArray","boxed::BitBox","domain::Domain","slice::BitSlice","vec::BitVec"],"std::hash::Hash":["array::BitArray","boxed::BitBox","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::BitSlice","vec::BitVec"],"std::io::Write":["vec::BitVec"],"std::iter::DoubleEndedIterator":["domain::Domain","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::ChunksExactMut","slice::iter::ChunksMut","slice::iter::Iter","slice::iter::IterMut","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RChunksExactMut","slice::iter::RChunksMut","slice::iter::RSplit","slice::iter::RSplitMut","slice::iter::Split","slice::iter::SplitMut","slice::iter::Windows","vec::iter::Drain","vec::iter::IntoIter","vec::iter::Splice"],"std::iter::ExactSizeIterator":["domain::Domain","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::ChunksExactMut","slice::iter::ChunksMut","slice::iter::Iter","slice::iter::IterMut","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RChunksExactMut","slice::iter::RChunksMut","slice::iter::Windows","vec::iter::Drain","vec::iter::IntoIter","vec::iter::Splice"],"std::iter::Extend":["vec::BitVec"],"std::iter::FromIterator":["vec::BitVec"],"std::iter::FusedIterator":["domain::Domain","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::ChunksExactMut","slice::iter::ChunksMut","slice::iter::Iter","slice::iter::IterMut","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RChunksExactMut","slice::iter::RChunksMut","slice::iter::RSplit","slice::iter::RSplitMut","slice::iter::RSplitN","slice::iter::RSplitNMut","slice::iter::Split","slice::iter::SplitMut","slice::iter::SplitN","slice::iter::SplitNMut","slice::iter::Windows","vec::iter::Drain","vec::iter::IntoIter","vec::iter::Splice"],"std::iter::IntoIterator":["vec::BitVec"],"std::iter::Iterator":["domain::Domain","slice::iter::Chunks","slice::iter::ChunksExact","slice::iter::ChunksExactMut","slice::iter::ChunksMut","slice::iter::Iter","slice::iter::IterMut","slice::iter::RChunks","slice::iter::RChunksExact","slice::iter::RChunksExactMut","slice::iter::RChunksMut","slice::iter::RSplit","slice::iter::RSplitMut","slice::iter::RSplitN","slice::iter::RSplitNMut","slice::iter::Split","slice::iter::SplitMut","slice::iter::SplitN","slice::iter::SplitNMut","slice::iter::Windows","vec::iter::Drain","vec::iter::IntoIter","vec::iter::Splice"],"std::iter::Sum":["index::BitMask"],"std::marker::Copy":["array::BitArray","array::traits::TryFromBitSliceError","domain::BitDomain","domain::Domain","index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","slice::iter::Iter","vec::iter::FillStatus"],"std::marker::Send":["boxed::BitBox","slice::BitSlice","slice::iter::Iter","slice::iter::IterMut","vec::BitVec","vec::iter::Drain"],"std::marker::StructuralEq":["index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","pointer::BitPtr","vec::iter::FillStatus"],"std::marker::StructuralPartialEq":["index::BitIdx","index::BitMask","index::BitPos","index::BitSel","index::BitTail","order::Lsb0","order::Msb0","pointer::Address","vec::iter::FillStatus"],"std::marker::Sync":["boxed::BitBox","slice::BitSlice","slice::iter::Iter","slice::iter::IterMut","vec::BitVec","vec::iter::Drain"],"std::marker::Unpin":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::ops::BitAnd":["array::BitArray","boxed::BitBox","index::BitMask","vec::BitVec"],"std::ops::BitAndAssign":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"std::ops::BitOr":["array::BitArray","boxed::BitBox","index::BitMask","vec::BitVec"],"std::ops::BitOrAssign":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"std::ops::BitXor":["array::BitArray","boxed::BitBox","vec::BitVec"],"std::ops::BitXorAssign":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"std::ops::Deref":["array::BitArray","boxed::BitBox","slice::proxy::BitMut","vec::BitVec"],"std::ops::DerefMut":["array::BitArray","boxed::BitBox","slice::proxy::BitMut","vec::BitVec"],"std::ops::Drop":["boxed::BitBox","slice::proxy::BitMut","vec::BitVec","vec::iter::Drain","vec::iter::Splice"],"std::ops::Index":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"std::ops::IndexMut":["array::BitArray","boxed::BitBox","slice::BitSlice","vec::BitVec"],"std::ops::Not":["array::BitArray","boxed::BitBox","index::BitMask","vec::BitVec"],"store::BitStore":["std::cell::Cell","std::sync::atomic::AtomicU16","std::sync::atomic::AtomicU32","std::sync::atomic::AtomicU64","std::sync::atomic::AtomicU8","std::sync::atomic::AtomicUsize"],"store::seal::Sealed":["std::cell::Cell","std::sync::atomic::AtomicU16","std::sync::atomic::AtomicU32","std::sync::atomic::AtomicU64","std::sync::atomic::AtomicU8","std::sync::atomic::AtomicUsize"],"view::AsBits":["<A as view::AsBits<T>>::A"],"view::AsBitsMut":["<A as view::AsBitsMut<T>>::A"],"view::BitView":["<T as view::BitView>::T"]},"type_to_def_path":{"array::BitArray<O, V>":"array::BitArray","array::traits::TryFromBitSliceError":"array::traits::TryFromBitSliceError","boxed::BitBox<O, T>":"boxed::BitBox","domain::BitDomain<'a, O, T>":"domain::BitDomain","domain::BitDomainMut<'a, O, T>":"domain::BitDomainMut","domain::Domain<'a, T>":"domain::Domain","domain::DomainMut<'a, T>":"domain::DomainMut","index::BitIdx<M>":"index::BitIdx","index::BitMask<M>":"index::BitMask","index::BitPos<M>":"index::BitPos","index::BitSel<M>":"index::BitSel","index::BitTail<M>":"index::BitTail","order::Lsb0":"order::Lsb0","order::Msb0":"order::Msb0","pointer::Address<T>":"pointer::Address","pointer::BitPtr<T>":"pointer::BitPtr","slice::BitSlice<O, T>":"slice::BitSlice","slice::iter::Chunks<'a, O, T>":"slice::iter::Chunks","slice::iter::ChunksExact<'a, O, T>":"slice::iter::ChunksExact","slice::iter::ChunksExactMut<'a, O, T>":"slice::iter::ChunksExactMut","slice::iter::ChunksMut<'a, O, T>":"slice::iter::ChunksMut","slice::iter::Iter<'a, O, T>":"slice::iter::Iter","slice::iter::IterMut<'a, O, T>":"slice::iter::IterMut","slice::iter::RChunks<'a, O, T>":"slice::iter::RChunks","slice::iter::RChunksExact<'a, O, T>":"slice::iter::RChunksExact","slice::iter::RChunksExactMut<'a, O, T>":"slice::iter::RChunksExactMut","slice::iter::RChunksMut<'a, O, T>":"slice::iter::RChunksMut","slice::iter::RSplit<'a, O, T, P>":"slice::iter::RSplit","slice::iter::RSplitMut<'a, O, T, P>":"slice::iter::RSplitMut","slice::iter::RSplitN<'a, O, T, P>":"slice::iter::RSplitN","slice::iter::RSplitNMut<'a, O, T, P>":"slice::iter::RSplitNMut","slice::iter::Split<'a, O, T, P>":"slice::iter::Split","slice::iter::SplitMut<'a, O, T, P>":"slice::iter::SplitMut","slice::iter::SplitN<'a, O, T, P>":"slice::iter::SplitN","slice::iter::SplitNMut<'a, O, T, P>":"slice::iter::SplitNMut","slice::iter::Windows<'a, O, T>":"slice::iter::Windows","slice::proxy::BitMut<'a, O, T>":"slice::proxy::BitMut","slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq<'a>":"slice::traits::<impl std::fmt::Binary for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq<'a>":"slice::traits::<impl std::fmt::LowerHex for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq<'a>":"slice::traits::<impl std::fmt::Octal for slice::BitSlice<O, T>>::fmt::Seq","slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq<'a>":"slice::traits::<impl std::fmt::UpperHex for slice::BitSlice<O, T>>::fmt::Seq","vec::BitVec<O, T>":"vec::BitVec","vec::iter::Drain<'a, O, T>":"vec::iter::Drain","vec::iter::FillStatus":"vec::iter::FillStatus","vec::iter::IntoIter<O, T>":"vec::iter::IntoIter","vec::iter::Splice<'a, O, T, I>":"vec::iter::Splice"}}